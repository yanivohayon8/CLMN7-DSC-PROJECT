{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import ast\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "import gensim\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.features.segment_transcript import CreateBlocksteBlocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundbase_dir = '../data/raw/groundbase'\n",
    "transcripts_dir = os.path.join(groundbase_dir,'transcripts')\n",
    "topic_dataset_path = os.path.join(groundbase_dir,'dataset.csv')\n",
    "transcript_filespath = glob.glob(groundbase_dir + '/transcripts/*.json')\n",
    "\n",
    "'''Read the transcript'''\n",
    "transcripts_jsons = {}\n",
    "for fl in transcript_filespath:\n",
    "    with open(fl,encoding=\"utf8\") as f:\n",
    "        transcript =ast.literal_eval(f.read()) #json.load(f)\n",
    "        vid = fl.split('\\\\')[-1].split('.')[0]\n",
    "        #print(vid)\n",
    "        transcripts_jsons[vid] = transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shift index</th>\n",
       "      <th>topic shifts(ends)</th>\n",
       "      <th>label</th>\n",
       "      <th>video</th>\n",
       "      <th>subject</th>\n",
       "      <th>youtube link</th>\n",
       "      <th>length</th>\n",
       "      <th>video id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>00:11:17</td>\n",
       "      <td>Syllabus , Textbook and references</td>\n",
       "      <td>Mod-01 Lec-01 Foundation of Scientific Computi...</td>\n",
       "      <td>Foundation of Scientific Computing</td>\n",
       "      <td>https://www.youtube.com/watch?v=MkiUBJcgdUY</td>\n",
       "      <td>01:05:06</td>\n",
       "      <td>MkiUBJcgdUY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:12:45</td>\n",
       "      <td>course grading</td>\n",
       "      <td>Mod-01 Lec-01 Foundation of Scientific Computi...</td>\n",
       "      <td>Foundation of Scientific Computing</td>\n",
       "      <td>https://www.youtube.com/watch?v=MkiUBJcgdUY</td>\n",
       "      <td>01:05:06</td>\n",
       "      <td>MkiUBJcgdUY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>00:20:57</td>\n",
       "      <td>relationship between computing and science</td>\n",
       "      <td>Mod-01 Lec-01 Foundation of Scientific Computi...</td>\n",
       "      <td>Foundation of Scientific Computing</td>\n",
       "      <td>https://www.youtube.com/watch?v=MkiUBJcgdUY</td>\n",
       "      <td>01:05:06</td>\n",
       "      <td>MkiUBJcgdUY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>00:22:37</td>\n",
       "      <td>implemntation</td>\n",
       "      <td>Mod-01 Lec-01 Foundation of Scientific Computi...</td>\n",
       "      <td>Foundation of Scientific Computing</td>\n",
       "      <td>https://www.youtube.com/watch?v=MkiUBJcgdUY</td>\n",
       "      <td>01:05:06</td>\n",
       "      <td>MkiUBJcgdUY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>00:24:45</td>\n",
       "      <td>scientific computing uses</td>\n",
       "      <td>Mod-01 Lec-01 Foundation of Scientific Computi...</td>\n",
       "      <td>Foundation of Scientific Computing</td>\n",
       "      <td>https://www.youtube.com/watch?v=MkiUBJcgdUY</td>\n",
       "      <td>01:05:06</td>\n",
       "      <td>MkiUBJcgdUY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shift index topic shifts(ends)                                       label  \\\n",
       "0            0           00:11:17          Syllabus , Textbook and references   \n",
       "1            1           00:12:45                              course grading   \n",
       "2            2           00:20:57  relationship between computing and science   \n",
       "3            3           00:22:37                               implemntation   \n",
       "4            4           00:24:45                   scientific computing uses   \n",
       "\n",
       "                                               video  \\\n",
       "0  Mod-01 Lec-01 Foundation of Scientific Computi...   \n",
       "1  Mod-01 Lec-01 Foundation of Scientific Computi...   \n",
       "2  Mod-01 Lec-01 Foundation of Scientific Computi...   \n",
       "3  Mod-01 Lec-01 Foundation of Scientific Computi...   \n",
       "4  Mod-01 Lec-01 Foundation of Scientific Computi...   \n",
       "\n",
       "                             subject   \\\n",
       "0  Foundation of Scientific Computing   \n",
       "1  Foundation of Scientific Computing   \n",
       "2  Foundation of Scientific Computing   \n",
       "3  Foundation of Scientific Computing   \n",
       "4  Foundation of Scientific Computing   \n",
       "\n",
       "                                  youtube link    length     video id  \n",
       "0  https://www.youtube.com/watch?v=MkiUBJcgdUY  01:05:06  MkiUBJcgdUY  \n",
       "1  https://www.youtube.com/watch?v=MkiUBJcgdUY  01:05:06  MkiUBJcgdUY  \n",
       "2  https://www.youtube.com/watch?v=MkiUBJcgdUY  01:05:06  MkiUBJcgdUY  \n",
       "3  https://www.youtube.com/watch?v=MkiUBJcgdUY  01:05:06  MkiUBJcgdUY  \n",
       "4  https://www.youtube.com/watch?v=MkiUBJcgdUY  01:05:06  MkiUBJcgdUY  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_videos = pd.read_csv(topic_dataset_path)\n",
    "df_videos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Find the number of topics in each video'''\n",
    "n_video_topic = df_videos.groupby(['video id'],as_index=False)['shift index'].max().sum().values.tolist()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Set the training set as a whole text to train the lda'''\n",
    "text = np.concatenate([[brth for brth in transcripts_jsons[trs]]\n",
    "                       for trs in transcripts_jsons.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'hello my name is Tommy and welcome to',\n",
       " 'start': 0.35,\n",
       " 'duration': 5.02}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.shape\n",
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_handler =  CreateBlocks(text)\n",
    "blocks = block_handler.partion_by_sliding_windows(20,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1250 into shape (20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-dd76dd14dd35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1250 into shape (20)"
     ]
    }
   ],
   "source": [
    "#blocks = np.array(blocks).reshape(-1,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(blocks)\n",
    "corpus = [id2word.doc2bow(doc) for doc in blocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''You need to train the LDA model you need to make here some loops and stabilizing params'''\n",
    "# low alpha means each document is only represented by a small number of topics, and vice versa\n",
    "# low eta means each topic is only represented by a small number of words, and vice versa\n",
    "# https://www.kaggle.com/ktattan/lda-and-document-similarity\n",
    "\n",
    "lda = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                                  num_topics=n_video_topic,\n",
    "                                                  id2word=id2word#,\n",
    "                                                  #alpha=vectorizing_params['alpha']#, # consider this to be auto\n",
    "                                                  #eta=vectorizing_params['eta'],\n",
    "                                                  #chunksize=vectorizing_params['chunksize'],\n",
    "                                                  #minimum_probability=vectorizing_params['minimum_probability'],\n",
    "                                                  #passes=10\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = '../models/LDA MODELS/lda_model'\n",
    "lda.save(my_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lda = gensim.models.ldamodel.LdaModel.load(my_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.ldamodel.LdaModel at 0x1d011580348>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "A problem a rised when we try to classify new text without a known words to the model\n",
    "since it's a bag of words, It's can be problematic.\n",
    "And the prediction of new data is getting the distribution of topics in a document\n",
    "One way to solve it is to run it on a lot of external corpus but this is for a another resreach\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
