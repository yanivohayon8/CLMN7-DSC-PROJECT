{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.data.docx  import read_docx,process_docx,find_content\n",
    "import os \n",
    "import glob\n",
    "from statistics import mode\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Defining CONSTS'''\n",
    "docx_path = '../data/raw/docx'\n",
    "groundbase_dir = '../data/raw/groundbase'\n",
    "transcripts_dir = os.path.join(groundbase_dir,'transcripts')\n",
    "topic_dataset_path = os.path.join(groundbase_dir,'dataset.csv')\n",
    "transcript_filespath = glob.glob(groundbase_dir + '/transcripts/*.json')\n",
    "\n",
    "videos_ids = list(map(lambda fl: fl.split('\\\\')[-1].split('.')[0],glob.glob(docx_path + '/*')))\n",
    "\n",
    "desired_videos = ['zWg7U0OEAoE']\n",
    "videos_ids = list(filter(lambda x: x in desired_videos,videos_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_txt_bigger(full_text,font_sizes):\n",
    "    most_common_font_ = mode(font_sizes)\n",
    "    data = [txt for txt,sz in zip(full_text,font_sizes)if sz > most_common_font_]\n",
    "    #indexes = [i for i,(txt,sz) in enumerate(zip(full_text,font_sizes)) if sz > most_common_font_]\n",
    "    return data#,indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_chapters_format_first_five(doc_bigger,key_word_ = 'Chapter'):\n",
    "    topic_titles = []\n",
    "    p_subsection = re.compile(r'((\\d+\\.)+\\d*\\t[A-Za-z0-9? ]+)')\n",
    "    p_Start_Section = re.compile('{} \\d?'.format(key_word_))\n",
    "    for i,doc in enumerate(doc_bigger):\n",
    "        matching = p_Start_Section.match(doc)\n",
    "\n",
    "        if matching is not None:\n",
    "            topic_titles.append(doc_bigger[i+1])\n",
    "\n",
    "        matching = p_subsection.match(doc)\n",
    "        if matching is not None:            \n",
    "            topic_titles.append(doc)\n",
    "    return topic_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' total_corpus = []\\n    chapter_corpus = \"\"\\n    chapter_index = 1\\n    docx_chapter_index  = [full_text.index(ch) for ch in titles]\\n    full_text = full_text[docx_chapter_index[0]:]\\n    print(\"next_chaper is %s \"%(chapter_index))\\n    for i,line in enumerate(full_text):\\n        # if we reach to a new chapter \\n        if i == docx_chapter_index[chapter_index]:\\n            total_corpus.append(chapter_corpus[1:])\\n            chapter_corpus = \"\"\\n            chapter_index+=1\\n            print(\"next_chaper is %s \"%(chapter_index))\\n            break\\n        else:\\n            print(line)\\n            chapter_corpus = chapter_corpus + \". \" + line\\n    return total_corpus'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_section_corpus(full_text,titles):\n",
    "    docx_sec_indexes = [full_text.index(ch) for ch in titles]\n",
    "    crop = [full_text[docx_sec_indexes[i]:docx_sec_indexes[i+1]] for i in range(len(titles) - 1)]\n",
    "    crop.append(full_text[docx_sec_indexes[-1]:])\n",
    "    return crop\n",
    "\n",
    "\"\"\"    sections_corpus = []\n",
    "    docx_sec_indexes = [full_text.index(ch) for ch in titles]\n",
    "    text = full_text[docx_sec_indexes[0]:]\n",
    "    sec_text = \"\"\n",
    "    sec_index = 0\n",
    "    docx_next_sec_index = docx_sec_indexes[sec_index + 1]\n",
    "    #print(text)\n",
    "    for index,line in enumerate(text):\n",
    "        if index == docx_next_sec_index:\n",
    "            print(index)\n",
    "            sections_corpus.append(sec_text)\n",
    "            sec_text = \"\"\n",
    "            sec_index += 1\n",
    "            docx_next_sec_index = docx_sec_indexes[sec_index + 1]\n",
    "        else:\n",
    "            sec_text = sec_text +'. '+ line\n",
    "    return sections_corpus\n",
    "\"\"\"\n",
    "\"\"\" total_corpus = []\n",
    "    chapter_corpus = \"\"\n",
    "    chapter_index = 1\n",
    "    docx_chapter_index  = [full_text.index(ch) for ch in titles]\n",
    "    full_text = full_text[docx_chapter_index[0]:]\n",
    "    print(\"next_chaper is %s \"%(chapter_index))\n",
    "    for i,line in enumerate(full_text):\n",
    "        # if we reach to a new chapter \n",
    "        if i == docx_chapter_index[chapter_index]:\n",
    "            total_corpus.append(chapter_corpus[1:])\n",
    "            chapter_corpus = \"\"\n",
    "            chapter_index+=1\n",
    "            print(\"next_chaper is %s \"%(chapter_index))\n",
    "            break\n",
    "        else:\n",
    "            print(line)\n",
    "            chapter_corpus = chapter_corpus + \". \" + line\n",
    "    return total_corpus\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vid in videos_ids:\n",
    "    doc_path = glob.glob(os.path.join(docx_path,vid + '/*.docx'))[0]\n",
    "    doc_name = doc_path.split('\\\\')[-1].split('.')[0]\n",
    "    full_text,font_sizes = read_docx(doc_path)\n",
    "    bigger_doc = get_txt_bigger(full_text,font_sizes)\n",
    "    titles = find_chapters_format_first_five(bigger_doc)\n",
    "    chapter_corpus = find_section_corpus(full_text,titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "85\n"
     ]
    }
   ],
   "source": [
    "print(len(titles))\n",
    "print(len(chapter_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chapter_corpus[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[full_text.index(ch) for ch in titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chapter_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.docx  import find_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vid in videos_ids:\n",
    "    doc_path = glob.glob(os.path.join(docx_path,vid + '/*.docx'))[0]\n",
    "    doc_name = doc_path.split('\\\\')[-1].split('.')[0]\n",
    "    full_text,font_sizes = read_docx(doc_path)\n",
    "    vika = find_content('Dsa',full_text,font_sizes,main_chapter_keyword='Chapter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'corpus': None,\n",
       " 'titles': ['Introduction',\n",
       "  '1.1\\tWhat this book is, and what it isnâ€™t',\n",
       "  '1.2\\tAssumed knowledge',\n",
       "  '1.2.1\\tBig Oh notation',\n",
       "  '1.2.2\\tImperative programming language',\n",
       "  '1.2.3\\tObject oriented concepts',\n",
       "  '1.3\\tPseudocode',\n",
       "  '1.4\\tTips for working through the examples',\n",
       "  '1.5\\tBook outline',\n",
       "  '1.6\\tTesting',\n",
       "  '1.7\\tWhere can I get the code?',\n",
       "  '1.8\\tFinal messages',\n",
       "  'Linked Lists',\n",
       "  '2.1\\tSingly Linked List',\n",
       "  '2.1.1\\tInsertion',\n",
       "  '2.1.2\\tSearching',\n",
       "  '2.1.3\\tDeletion',\n",
       "  '2.1.4\\tTraversing the list',\n",
       "  '2.1.5\\tTraversing the list in reverse order',\n",
       "  '2.2\\tDoubly Linked List',\n",
       "  '2.2.1\\tInsertion',\n",
       "  '2.2.2\\tDeletion',\n",
       "  '2.2.3\\tReverse Traversal',\n",
       "  '2.3\\tSummary',\n",
       "  'Binary Search Tree',\n",
       "  '3.1\\tInsertion',\n",
       "  '3.2\\tSearching',\n",
       "  '3.3\\tDeletion',\n",
       "  '3.4\\tFinding the parent of a given node',\n",
       "  '3.5\\tAttaining a reference to a node',\n",
       "  '3.6\\tFinding the smallest and largest values in the binary search tree',\n",
       "  '3.7\\tTree Traversals',\n",
       "  '3.7.1\\tPreorder',\n",
       "  '3.7.2\\tPostorder',\n",
       "  '3.7.3\\tInorder',\n",
       "  '3.7.4\\tBreadth First',\n",
       "  '3.8\\tSummary',\n",
       "  'Heap',\n",
       "  '4.1\\tInsertion',\n",
       "  '4.2\\tDeletion',\n",
       "  '4.3\\tSearching',\n",
       "  '4.4\\tTraversal',\n",
       "  '4.5\\tSummary',\n",
       "  'Sets',\n",
       "  '5.1\\tUnordered',\n",
       "  '5.1.1\\tInsertion',\n",
       "  '5.2\\tOrdered',\n",
       "  '5.3\\tSummary',\n",
       "  'Queues',\n",
       "  '6.1\\tA standard queue',\n",
       "  '6.2\\tPriority Queue',\n",
       "  '6.3\\tDouble Ended Queue',\n",
       "  '6.4\\tSummary',\n",
       "  'AVL Tree',\n",
       "  '7.1\\tTree Rotations',\n",
       "  '7.2\\tTree Rebalancing',\n",
       "  '7.3\\tInsertion',\n",
       "  '7.4\\tDeletion',\n",
       "  '7.5\\tSummary',\n",
       "  'Sorting',\n",
       "  '8.1\\tBubble Sort',\n",
       "  '8.2\\tMerge Sort',\n",
       "  '8.3\\tQuick Sort',\n",
       "  '8.4\\tInsertion Sort',\n",
       "  '8.5\\tShell Sort',\n",
       "  '8.6\\tRadix Sort',\n",
       "  '8.7\\tSummary',\n",
       "  'Numeric',\n",
       "  '9.1\\tPrimality Test',\n",
       "  '9.2\\tBase conversions',\n",
       "  '9.3\\tAttaining the greatest common denomina-tor of two numbers',\n",
       "  '9.4\\tComputing the maximum value for a num-ber of a speciflc base consisting of N digits',\n",
       "  '9.5\\tFactorial of a number',\n",
       "  '9.6\\tSummary',\n",
       "  'Searching',\n",
       "  '10.1\\tSequential Search',\n",
       "  '10.2\\tProbability Search',\n",
       "  '10.3\\tSummary',\n",
       "  'Strings',\n",
       "  '11.1\\tReversing the order of words in a sentence',\n",
       "  '11.2\\tDetecting a palindrome',\n",
       "  '11.3\\tCounting the number of words in a string',\n",
       "  '11.4\\tDetermining the number of repeated words within a string',\n",
       "  '11.5\\tDetermining the flrst matching character between two strings',\n",
       "  '11.6\\tSummary'],\n",
       " 'main titles': ['Introduction',\n",
       "  'Linked Lists',\n",
       "  'Binary Search Tree',\n",
       "  'Heap',\n",
       "  'Sets',\n",
       "  'Queues',\n",
       "  'AVL Tree',\n",
       "  'Sorting',\n",
       "  'Numeric',\n",
       "  'Searching',\n",
       "  'Strings']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
