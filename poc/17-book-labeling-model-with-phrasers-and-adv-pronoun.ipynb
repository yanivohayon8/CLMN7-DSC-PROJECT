{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.data.docx  import read_docx,process_docx,find_content\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from src.models.pipeline import pipeline\n",
    "from functools import reduce\n",
    "import heapq\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim import models\n",
    "from gensim import similarities\n",
    "import re\n",
    "import statistics\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set()\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ BOOKS OF VIDEOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Defining CONSTS'''\n",
    "docx_path = '../data/raw/docx'\n",
    "groundbase_dir = '../data/raw/groundbase'\n",
    "transcripts_dir = os.path.join(groundbase_dir,'transcripts')\n",
    "topic_dataset_path = os.path.join(groundbase_dir,'dataset.csv')\n",
    "transcript_filespath = glob.glob(groundbase_dir + '/transcripts/*.json')\n",
    "lemmatizing_method ='lemma' #'stemm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_ids = list(map(lambda fl: fl.split('\\\\')[-1].split('.')[0],glob.glob(docx_path + '/*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_videos =['zWg7U0OEAoE']#['7kLHJ-F33GI','RIawrYLVdIw','7snJ1mx1EMQ','zWg7U0OEAoE','tORLeHHtazM'] #['zWg7U0OEAoE','tORLeHHtazM'] #['7kLHJ-F33GI','RIawrYLVdIw','7snJ1mx1EMQ']\n",
    "videos_ids = list(filter(lambda x: x in desired_videos,videos_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video_docx = [glob.glob(os.path.join(docx_path,vid + '/*.docx'))[0] for vid in videos_ids]\n",
    "#docx_db =[read_docx(path) for path in video_docx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_read = {\n",
    "    'statbook':'statbook',\n",
    "    'Dsa':'Dsa'\n",
    "}\n",
    "\n",
    "docxs_chapter_keyword = {\n",
    "    'statbook':'Topic',\n",
    "    'Dsa': 'Chapter'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_to_paper = {}\n",
    "paper_content ={}\n",
    "for vid in videos_ids:\n",
    "    doc_path = glob.glob(os.path.join(docx_path,vid + '/*.docx'))[0]\n",
    "    doc_name = doc_path.split('\\\\')[-1].split('.')[0]\n",
    "    video_to_paper[vid] = doc_name    \n",
    "    if doc_name not in paper_content.keys():    \n",
    "        full_text,font_sizes = read_docx(doc_path)\n",
    "        paper_content[doc_name] = find_content(f_read[doc_name],\n",
    "                                               full_text,\n",
    "                                               font_sizes,\n",
    "                                               docxs_chapter_keyword[doc_name],\n",
    "                                              lemmatizing=lemmatizing_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESTORE RESULTS FROM TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Select transcript for only wanted videos'''\n",
    "transcript_filespath = list(filter(lambda x: x.split('\\\\')[-1].split('.')[0] in videos_ids,transcript_filespath))\n",
    "\n",
    "'''Read the transcript'''\n",
    "transcripts_jsons = {}\n",
    "for fl in transcript_filespath:\n",
    "    with open(fl,encoding=\"utf8\") as f:\n",
    "        transcript =ast.literal_eval(f.read()) #json.load(f)\n",
    "        vid = fl.split('\\\\')[-1].split('.')[0]\n",
    "        #print(vid)\n",
    "        transcripts_jsons[vid] = transcript\n",
    "#print(transcripts_jsons)\n",
    "\n",
    "'''Read the videos metadata to perform on them the segmentation'''\n",
    "df_videos = pd.read_csv(topic_dataset_path)\n",
    "\n",
    "''' Transfer topic shifts time to seconds units instead HH:MM:SS'''\n",
    "def topic_shifts_seconds(topic_shifts):\n",
    "    tp_shift_sec=[]\n",
    "    for tp in topic_shifts:\n",
    "        intervals = tp.split(':')\n",
    "        seconds = int(intervals[2])\n",
    "        minutes = int(intervals[1]) * 60\n",
    "        hours = int(intervals[0]) * 60 *60\n",
    "        tp_shift_sec.append(seconds + minutes + hours)\n",
    "    return tp_shift_sec\n",
    "for video_id in transcripts_jsons.keys():    \n",
    "    df_videos.at[df_videos['video id'] == video_id,'topic shifts(ends)'] =\\\n",
    "    topic_shifts_seconds(\\\n",
    "                         df_videos[df_videos['video id'] == \\\n",
    "                                   video_id]['topic shifts(ends)'])\n",
    "    \n",
    "\n",
    "'''Get parameters from training'''\n",
    "df_results = pd.read_csv('../data/processed/bayesian_opt/phrases/lemmas_adv_propn.csv')\n",
    "n_largest_res = 3\n",
    "pipeline_results = df_results[df_results['video'].isin(videos_ids)]\\\n",
    "                .groupby('video')[['video','workflow','params','max_target']]\\\n",
    "                .apply(lambda grp: grp.nlargest(n_largest_res,'max_target')).values.tolist()\n",
    "\n",
    "pipeline_results = pipeline_results[:-1]#this is for zWg7U0OEAoE\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def boundryevaluation(curresults,ground_base,accurrcy_shift = 30):\n",
    "        true_positive = 0\n",
    "        false_negative = 0\n",
    "        false_positive = 0 \n",
    "        true_positive_list_debug = []\n",
    "        #false_negative_list_debug = []\n",
    "        false_positive_list_debug = []\n",
    "        results = curresults[:]\n",
    "        \n",
    "        \n",
    "        #print('curresults %s' %(curresults))\n",
    "        #print('ground_base %s ' %(ground_base))\n",
    "        \n",
    "        for grb in ground_base:\n",
    "            is_false_positive = True\n",
    "            for res in results:     \n",
    "                if abs(res - grb) < accurrcy_shift:\n",
    "                    is_false_positive = False\n",
    "                    true_positive_list_debug.append(res)\n",
    "                    true_positive+=1\n",
    "                    results.remove(res)\n",
    "                    break   \n",
    "            if is_false_positive:\n",
    "                false_positive_list_debug.append(grb)\n",
    "                false_positive+=1\n",
    "                \n",
    "        #print(\"TP: \" + str(true_positive_list_debug))\n",
    "        #print(\"FP: \" + str(false_positive_list_debug))\n",
    "        #print(\"FN: \" + str(curresults))\n",
    "        #print('true_positive : %s ' %(true_positive))\n",
    "        false_negative = len(results) # make sure the true positive are removed from here \n",
    "        recall_rate = true_positive/(true_positive + false_negative )\n",
    "        precision_rate = true_positive/(true_positive + false_positive)\n",
    "        #print(\"TP: %s , FP: %s, FN: %s\" %(true_positive,false_positive,false_negative))\n",
    "        #print(\"precision rate : %s, recall rate : %s \" % (precision_rate,recall_rate))\n",
    "        return precision_rate\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "running trial 5 for vid zWg7U0OEAoE desired precision 0.5384615384615384 \n",
      "output precision 0.38461538461538464 \n",
      "new high percision caught\n",
      "##################################################\n",
      "running trial 4 for vid zWg7U0OEAoE desired precision 0.5384615384615384 \n",
      "output precision 0.3076923076923077 \n",
      "##################################################\n",
      "running trial 3 for vid zWg7U0OEAoE desired precision 0.5384615384615384 \n",
      "output precision 0.38461538461538464 \n",
      "##################################################\n",
      "running trial 2 for vid zWg7U0OEAoE desired precision 0.5384615384615384 \n",
      "output precision 0.38461538461538464 \n",
      "##################################################\n",
      "running trial 1 for vid zWg7U0OEAoE desired precision 0.5384615384615384 \n",
      "output precision 0.23076923076923078 \n",
      "##################################################\n",
      "running trial 5 for vid zWg7U0OEAoE desired precision 0.4615384615384616 \n",
      "output precision 0.46153846153846156 \n",
      "new high percision caught\n",
      "##################################################\n",
      "running trial 4 for vid zWg7U0OEAoE desired precision 0.4615384615384616 \n",
      "output precision 0.46153846153846156 \n",
      "##################################################\n",
      "running trial 3 for vid zWg7U0OEAoE desired precision 0.4615384615384616 \n",
      "output precision 0.46153846153846156 \n",
      "##################################################\n",
      "running trial 2 for vid zWg7U0OEAoE desired precision 0.4615384615384616 \n",
      "output precision 0.46153846153846156 \n",
      "##################################################\n",
      "running trial 1 for vid zWg7U0OEAoE desired precision 0.4615384615384616 \n",
      "output precision 0.46153846153846156 \n"
     ]
    }
   ],
   "source": [
    "videos_division = {}\n",
    "\n",
    "for vid in [videos_ids[-1]]:\n",
    "    vid_results = list(filter(lambda x: x[0] == vid,pipeline_results))\n",
    "    max_precision = 0\n",
    "    vid_words = None\n",
    "    vid_shifts = None\n",
    "    for result in vid_results:\n",
    "        '''From the get optimized by bayesian we get that for the video '''\n",
    "        vid = result[0]\n",
    "        params = ast.literal_eval(result[2]) #{'n_clusters': 18, 'sim_thresh': 0.6, 'step_size': 49, 'window_size': 150}\n",
    "        #print(params)\n",
    "        for key in ['n_clusters','step_size','window_size']:\n",
    "            params[key] = int(params[key])# - 1\n",
    "        workflow = result[1] #'sliding_window-tfidf-cosine-median_(3,3)-spectral_clustering'\n",
    "        \n",
    "        shifts = df_videos.loc[df_videos['video id'] == vid,'topic shifts(ends)'].values.tolist()\n",
    "        groundbase = shifts[:-1]\n",
    "        transcripts = transcripts_jsons[vid]\n",
    "        #print(grounbase)\n",
    "        _pipeline = workflow.split('-')\n",
    "        filter_type = None\n",
    "        mask_shape = None\n",
    "        filtering = _pipeline[3]\n",
    "        if filtering != 'None':\n",
    "            filter_type = filtering.split('_')[0]\n",
    "            mask_shape = ast.literal_eval(filtering.split('_')[1])\n",
    "        '''This running may not work at first time do not give up and run it couple of times'''\n",
    "\n",
    "        '''print('Running the following %s for video %s with params %s %s %s'\n",
    "              %(workflow, vid,params,filter_type,mask_shape))'''\n",
    "        #print(vid_results[1])\n",
    "        #print(str(filter_type) + \" \" + str(mask_shape))\n",
    "        shift_times,topic_words = (None,None)\n",
    "        n_trials = 5\n",
    "        while shift_times is None and topic_words is None and n_trials > 0:\n",
    "            print('##################################################')\n",
    "            print(\"running trial %s for vid %s desired precision %s \"%(n_trials,vid,result[3]))\n",
    "            n_trials= n_trials - 1\n",
    "            shift_times,topic_words = pipeline.run_for_baye(groundbase,\n",
    "                                                            transcripts,\n",
    "                                                            slicing_method='sliding_window',\n",
    "                                                            window_size=params['window_size'],#59\n",
    "                                                            step_size_sd= params['step_size'], #10\n",
    "                                  vector_method='tfidf',vectorizing_params=None,\n",
    "                                  similarity_method='cosine',\n",
    "                                  filter_params={\"filter_type\":filter_type,\n",
    "                                                 \"mask_shape\":mask_shape,\n",
    "                                                 \"sim_thresh\": params['sim_thresh'], #0.5160973480326474 \n",
    "                                                 \"is_min_thresh\":True\n",
    "                                                 },\n",
    "                                 clustering_params={\n",
    "                                         'algorithm':'spectral_clustering',\n",
    "                                         'n_clusters':params['n_clusters'] #14\n",
    "                                         },\n",
    "                                        accurrcy_shift=30,\n",
    "                                        return_value='division') or (None,None)\n",
    "\n",
    "            if shift_times is not None:\n",
    "                pr = boundryevaluation(shift_times,groundbase,accurrcy_shift=30)\n",
    "                print(\"output precision %s \" %(pr))\n",
    "                \n",
    "                if pr > max_precision:\n",
    "                    print(\"new high percision caught\")\n",
    "                    max_precision = pr \n",
    "                    vid_words = topic_words\n",
    "                    shift_times.append('end')\n",
    "                    vid_shifts = shift_times \n",
    "                if pr < result[3]:\n",
    "                    shift_times,topic_words = (None,None)    \n",
    "\n",
    "    videos_division[vid] = {'topic_words':vid_words,'topic_shift':vid_shifts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#videos_division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACT MAIN CHAPTERS OF BOOKS AND ORAGANIZE THE PAPER AS DIFFERENT DOCUMENTS GROUPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['corpus', 'titles', 'main titles'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_content[doc_name].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Find the following for each paper:\n",
    "    1) main chapter title index. for example [10,15....]\n",
    "    2) range of subsection within each main chapter . for example [(0,9),(11,14)...]\n",
    "    \n",
    "    '''\n",
    "\n",
    "paper_mainchapter_indexes = {}\n",
    "paper_sec_within_main_indexes = {}\n",
    "paper_mains_as_one_doc = {}\n",
    "paper_subsec_as_one_doc = {}\n",
    "\n",
    "for doc_name in paper_content.keys():\n",
    "    '''Find the main chapter indexes in the list of the overall titles'''\n",
    "    mainchapter_indexes = [paper_content[doc_name]['titles'].index(ch_title)\n",
    "                           for ch_title in paper_content[doc_name]['main titles']]\n",
    "    '''Find the subsection indexes range within each main chapter '''\n",
    "    subsec_mainchapter_indexes = [range(mainchapter_indexes[index],mainchapter_indexes[index + 1])\n",
    "                                  for index in range(len(mainchapter_indexes) - 1)]\n",
    "    subsec_mainchapter_indexes.append(range(mainchapter_indexes[-1],\n",
    "                                            len(paper_content[doc_name]['titles'])))\n",
    "    paper_mainchapter_indexes[doc_name] = mainchapter_indexes\n",
    "    paper_sec_within_main_indexes[doc_name] = subsec_mainchapter_indexes\n",
    "    \n",
    "    \n",
    "    '''Making each chapter as a one documents'''\n",
    "    \n",
    "    '''Union all the documents in a section into single document'''\n",
    "    paper_subsec_as_one_doc[doc_name] = [list(reduce(lambda doc,acc:doc + acc,sec,[]))\n",
    "                                         for sec in paper_content[doc_name]['corpus']]\n",
    "    '''Union all the sub section in a main chapter into one document'''\n",
    "    paper_mains_as_one_doc[doc_name] = [list(reduce(lambda acc,s_i:\n",
    "                                                    paper_subsec_as_one_doc[doc_name][s_i]+acc,subsec_indexes,[]))\n",
    "                                        for subsec_indexes in paper_sec_within_main_indexes[doc_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paper_subsec_as_one_doc['statbook'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flnal\n"
     ]
    }
   ],
   "source": [
    "'''Debug'''\n",
    "\"\"\"\n",
    "print(paper_content['statbook']['main titles'])\n",
    "print((paper_content['statbook']['titles']))\n",
    "print(len(paper_content['statbook']['titles']))# \n",
    "print(len(paper_content['statbook']['corpus']))#members of each element:section corpus\n",
    "print(len(paper_content['statbook']['corpus'][0]))#members of each element: documents\n",
    "print(len(paper_content['statbook']['corpus'][0][0])) #of each element words\n",
    "print(paper_sec_within_main_indexes['statbook'])\n",
    "\n",
    "\n",
    "#debug\n",
    "print(sum([len(paper_subsec_as_one_doc['statbook'][s]) for s in range(0,10)]))\n",
    "print(len(paper_mains_as_one_doc['statbook'][0]))\n",
    "print(len(paper_mains_as_one_doc['statbook']))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"#print(len(paper_subsec_as_one_doc['statbook']))\n",
    "print((subsec_mainchapter_indexes))\n",
    "print(len(paper_content['Dsa']['titles']))\n",
    "print(len(paper_subsec_as_one_doc[doc_name]))\n",
    "print(len(paper_sec_within_main_indexes[doc_name]))\n",
    "print(paper_content['Dsa']['titles'][-1])\n",
    "print(paper_subsec_as_one_doc[doc_name][-2])\n",
    "\"\"\"\n",
    "\"\"\"print(paper_content['Dsa']['main titles'][0])\n",
    "print(len(paper_mains_as_one_doc['Dsa'][0][0]))\n",
    "print((paper_mains_as_one_doc['Dsa'][0][0]))\n",
    "#print(len(paper_sec_within_main_indexes['Dsa'][0][0]))\n",
    "print(len(paper_subsec_as_one_doc['Dsa'][0]))\n",
    "print((paper_subsec_as_one_doc['Dsa'][0][0]))\n",
    "print(len(videos_division['tORLeHHtazM']['topic_words'][0][0]))\n",
    "print((videos_division['tORLeHHtazM']['topic_words'][0][0]))\"\"\"\n",
    "\n",
    "#paper_content['Dsa']['corpus']\n",
    "print((paper_mains_as_one_doc['Dsa'][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Find phrasers of books  '''\n",
    "paper_phrasers = {}\n",
    "for doc_name in paper_mains_as_one_doc.keys():\n",
    "    paper_phrasers[doc_name] = list(set(reduce(lambda acc,x: acc+x,\n",
    "                                      [[w for w in ch if '_' in w]\n",
    "                                      for ch in paper_mains_as_one_doc[doc_name]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paper_phrasers['Dsa']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIND CORRELATION BETWEEN MAIN CHAPTERES AND FOUNDED TOPICS IN THE VIDEO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_words_of_topic(topic_words,chapter_titles=None):\n",
    "    for tp_i,tp_words in enumerate(topic_words):\n",
    "        #\n",
    "        raw_text = ' '.join(tp_words)\n",
    "        myvectorizer = CountVectorizer()\n",
    "        mytf = myvectorizer.fit_transform([raw_text]).toarray()\n",
    "        #print(mytf)\n",
    "        maxes = heapq.nlargest(3,mytf[0])\n",
    "        indexes = []\n",
    "        for i,bal in enumerate(mytf[0]):\n",
    "            if bal in maxes:\n",
    "                indexes.append(i)\n",
    "        ws = [myvectorizer.get_feature_names()[_] for i,_ in enumerate(indexes)]\n",
    "        \n",
    "        if chapter_titles is None:\n",
    "            print('top words for topic %s are %s' %(tp_i,ws))\n",
    "        else:\n",
    "            print('top words for topic %s are %s' %(chapter_titles[tp_i],ws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "import spacy\n",
    "from nltk.stem import PorterStemmer\n",
    "stop_words = stopwords.words('english')\n",
    "nlp = spacy.load('en',disable=['parser','ner'])\n",
    "allowed_postags=['NOUN', 'ADJ', 'VERB','PROPN','ADV']#['NOUN', 'ADJ', 'VERB','ADV']#['NOUN', 'ADJ', 'VERB','PROPN']# #['NOUN', 'ADJ', 'VERB']\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emphasize_title(doc_name,book_chapters,titles,factor_enrich = 20,lemmatizing = \"lemma\"):\n",
    "    chapters_enriched = book_chapters[:]\n",
    "    \n",
    "    for index,tl in enumerate(titles):\n",
    "        tl_text_no_punc = simple_preprocess(tl,deacc=True) \n",
    "        tokenized_text_non_stop_words = [ word for word in tl_text_no_punc \n",
    "                                         if word not in stop_words]\n",
    "        \"\"\"text_non_stop_words = ' '.join(tokenized_text_non_stop_words)\n",
    "        tokenized_lemmas = nlp(text_non_stop_words)\n",
    "        tokenized_lemmas = [token.lemma_ for token in tokenized_lemmas \\\n",
    "                            if token.pos_ in allowed_postags]\"\"\"\n",
    "        \n",
    "        if lemmatizing == \"stemm\":\n",
    "            tokenized_lemmas = [porter.stem(w) for w in tokenized_text_non_stop_words]\n",
    "        else:\n",
    "            text_non_stop_words = ' '.join(tokenized_text_non_stop_words)\n",
    "            tokenized_lemmas = nlp(text_non_stop_words)\n",
    "            tokenized_lemmas = [token.lemma_ for token in tokenized_lemmas \\\n",
    "                                if token.pos_ in allowed_postags]\n",
    "\n",
    "        \n",
    "        \n",
    "        tokenized_lemmas_ph = '_'.join(tokenized_lemmas)#reduce(lambda acc,x: acc+x,\n",
    "        #print('tokenized_lemmas_ph %s' %(tokenized_lemmas_ph))\n",
    "        \n",
    "        if tokenized_lemmas_ph in paper_phrasers[doc_name]:\n",
    "            tokenized_lemmas =[tokenized_lemmas_ph]\n",
    "        \n",
    "        chapters_enriched[index] = chapters_enriched[index] + tokenized_lemmas * factor_enrich\n",
    "    return chapters_enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_chapter_corr_tfidf(paper_name,book_chapters,\n",
    "                                 vid_topics_words,vid_topics_shift,\n",
    "                                 dispaly_titles,pre_labeled_title=None):\n",
    "    raw_book_video = []\n",
    "    for tp_vid in vid_topics_words:\n",
    "        raw_book_video = raw_book_video + [tp_vid]\n",
    "    \n",
    "    for ch in book_chapters:\n",
    "        raw_book_video = raw_book_video + [ch]\n",
    "\n",
    "    # creating dictionary of all of the words in the corpus of the video and the paper\n",
    "    #print(len(raw_book_video))\n",
    "    dictionary = Dictionary(raw_book_video)\n",
    "    #dictionary = Dictionary(book_chapters)\n",
    "    \n",
    "    #ch_dict = Dictionary(book_chapters)\n",
    "    #vid_dict = Dictionary(vid_topics_words)\n",
    "    \n",
    "    the_dictionary = dictionary\n",
    "    \n",
    "    #whole_corpus = vid_topics_words + book_chapters\n",
    "    #bgw_corpus = [dictionary.doc2bow(doc) for doc in whole_corpus]\n",
    "    bgw_chapter = [the_dictionary.doc2bow(doc) for doc in book_chapters]\n",
    "    bgw_vids = [the_dictionary.doc2bow(doc) for doc in vid_topics_words]\n",
    "    \n",
    "    '''Calculate the pivot '''\n",
    "    _tmp =  [len(list(set([w for w in ch]))) for ch in book_chapters]\n",
    "    book_pivot = sum(_tmp)/len(_tmp)\n",
    "    _tmp = [len(list(set([w for w in ch]))) for ch in vid_topics_words]\n",
    "    vid_pivot = sum(_tmp)/len(_tmp)\n",
    "    \n",
    "    tf_idf_model_ch = models.TfidfModel(bgw_chapter,\n",
    "                                        dictionary=the_dictionary#,\n",
    "                                        #pivot=book_pivot#,\n",
    "                                        #slope=0.8,\n",
    "                                        #smartirs='nnc'\n",
    "                                       ) #,\n",
    "    tf_idf_model_vid = models.TfidfModel(bgw_vids,\n",
    "                                         dictionary=the_dictionary#,\n",
    "                                         #pivot=vid_pivot#,\n",
    "                                         #slope=0.4\n",
    "                                        )#,smartirs='lfc'\n",
    "    \n",
    "    index_sim = similarities.SparseMatrixSimilarity(tf_idf_model_ch[bgw_chapter],\n",
    "                                                    num_features=len(the_dictionary))\n",
    "    \n",
    "    correlation = [[s for s in index_sim[tf_idf_model_vid[doc]]] for doc in bgw_vids]\n",
    "    #print(tf_idf_model[bgw_vids])\n",
    "    \n",
    "    # find the top n words in the topic (in the video)\n",
    "    #print('$$$$$$$$$$$$$$top words of video topic$$$$$$$$$$$$$$')\n",
    "    #find_top_words_of_topic(videos_division[vid]['topic_words'])\n",
    "    #print('$$$$$$$$$$$$$$top words of book chapters$$$$$$$$$$$$$$')\n",
    "    #find_top_words_of_topic(book_chapters,chapter_titles=dispaly_titles)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # normalizing the correlation between each topic and chapter \n",
    "    for i_t in range(len(correlation)):\n",
    "        sum_ = sum(correlation[i_t])\n",
    "        for ch_index in range(len(correlation[i_t])):\n",
    "            correlation[i_t][ch_index] = correlation[i_t][ch_index]/sum_\n",
    "    \n",
    "    corr_as_row = reduce(lambda x,y: x+y,correlation,[] ) # to get the global max in min\n",
    "    sns.heatmap(correlation,vmin=min(corr_as_row),vmax=max(corr_as_row))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # find the cha\n",
    "    ch_matching_top = []\n",
    "    #print(len(correlation[0]))\n",
    "    \n",
    "    \n",
    "    for i,corr in enumerate(correlation):\n",
    "        max_cor = max(corr) # max correlation with that topic\n",
    "        shift = vid_topics_shift[i]\n",
    "        founded_title = dispaly_titles[corr.index(max_cor)]\n",
    "        #ch_matching_top.append(paper_mainchapter_indexes[paper_name][corr.index(max_cor)])\n",
    "        ch_matching_top.append(founded_title)\n",
    "\n",
    "    \n",
    "    \n",
    "    hit = 0 \n",
    "    miss = 0\n",
    "    \n",
    "    if pre_labeled_title is not None:\n",
    "        print(vid)\n",
    "        shifts = df_videos.loc[df_videos['video id'] == vid,'topic shifts(ends)'].values.tolist()\n",
    "        groundbase = shifts#[:-1] # not removing the end string - modify it in the next lines\n",
    "        vid_topics_shift[-1] = groundbase[-1] # converting the 'end' string to \n",
    "        df_vid_results = pd.DataFrame(columns=['Video',\n",
    "                                               'Video Shift',\n",
    "                                               'Founded Title',\n",
    "                                               'Similarity Ratio',\n",
    "                                               'Chapter Section',\n",
    "                                               'Prelabeled Title',\n",
    "                                               'Labeling Confidence'])\n",
    "        for i,corr in enumerate(correlation):\n",
    "            max_cor = max(corr) # max correlation with that topic\n",
    "            shift = vid_topics_shift[i]\n",
    "            closest_grb_index = 0\n",
    "            for grb_i in range(len(groundbase)):\n",
    "                if abs(int(groundbase[grb_i])- shift) < abs(int(groundbase[closest_grb_index]) - shift):\n",
    "                    closest_grb_index = grb_i\n",
    "            \n",
    "            founded_title = dispaly_titles[corr.index(max_cor)]\n",
    "            df_vid_results = df_vid_results.append({\n",
    "                                   'Video' :vid,\n",
    "                                   'Video Shift': sec_to_min(shift),\n",
    "                                   'Founded Title':founded_title,\n",
    "                                   'Similarity Ratio':max_cor,\n",
    "                                   'Chapter Section':pre_labeled_title[closest_grb_index][0],\n",
    "                                   'Prelabeled Title':pre_labeled_title[closest_grb_index][1],\n",
    "                                   'Labeling Confidence':pre_labeled_title[closest_grb_index][2]},ignore_index=True)\n",
    "\n",
    "        display(HTML(df_vid_results[['Video Shift',\n",
    "                                    'Founded Title',\n",
    "                                    'Similarity Ratio',\n",
    "                                    'Chapter Section',\n",
    "                                    'Prelabeled Title',\n",
    "                                    'Labeling Confidence']].to_html()))\n",
    "    else:\n",
    "        for i,corr in enumerate(correlation):\n",
    "            max_cor = max(corr) # max correlation with that topic\n",
    "            shift = vid_topics_shift[i]\n",
    "            print (\" video_shift index %s at %s , chapter title %s ( index %s) \" \n",
    "                   %(i,\n",
    "                     sec_to_min(shift),\n",
    "                     dispaly_titles[corr.index(max_cor)],\n",
    "                     corr.index(max_cor)\n",
    "                     ))\n",
    "\n",
    "    return ch_matching_top,correlation\n",
    "\n",
    "def find_dominent_main_chapter(ch_tp_corr,titles,correlation):\n",
    "    \n",
    "    '''Find the frequency of each chapter'''\n",
    "    chapter_matching_counts_max = [max([ch_tp_corr.count(ch) for ch in ch_tp_corr])]\n",
    "    for max_count in chapter_matching_counts_max:\n",
    "        #print(\"####### #######\")\n",
    "        '''Find the most frequent chapter'''\n",
    "        #print(([ch for ch in ch_tp_corr if ch_tp_corr.count(ch) == max_count]))\n",
    "        dominent_chapters = list(set([ch for ch in ch_tp_corr if ch_tp_corr.count(ch) == max_count]))\n",
    "        #print(dominent_chapters)\n",
    "        \n",
    "        # if we have absulote majority on topic\n",
    "        if len(dominent_chapters) == 1:\n",
    "            return dominent_chapters[0]\n",
    "        else:\n",
    "            \"\"\"max_value = 0\n",
    "            title_max =None\n",
    "            for j,ch in dominent_chapters:\n",
    "                cor = sum(ch_tp_corr[j])\n",
    "                if cor > max_value:\n",
    "                    max_value= cor\n",
    "                    title_max = ch\n",
    "            return title_max\"\"\"\n",
    "            \n",
    "            # draw between topics, decide which one by taking this with the high variance\n",
    "            index_winner = 0\n",
    "            df_ch_corr = pd.DataFrame.from_records(correlation)\n",
    "            for j_dom in range(len(dominent_chapters)):\n",
    "                first = df_ch_corr.var()[titles.index(dominent_chapters[index_winner])]\n",
    "                #print(first)\n",
    "                second = df_ch_corr.var()[titles.index(dominent_chapters[j_dom])]\n",
    "                #print(second)\n",
    "                if first > second:\n",
    "                    index_winner = j_dom\n",
    "            return (dominent_chapters[index_winner])\n",
    "        \n",
    "            \n",
    "        \n",
    "def sec_to_min(seconds):\n",
    "    if seconds == 'end':\n",
    "        return 'end'\n",
    "    return (\"%02d:%02d\"%(seconds//60,seconds%60))\n",
    "\n",
    "# correlations : correaltions of all levels\n",
    "def measure_confidence(vid,correlations):\n",
    "    n_vid_topic = len(correlations[0]) # number of video topics that were found\n",
    "    topics_errs = []\n",
    "    for topic_index in range(n_vid_topic):\n",
    "        topic_pr = 0\n",
    "        for map_index,correlation_map in enumerate(correlations):\n",
    "            '''Calculate soft max on the correlation of the current topic to the chapters'''\n",
    "            #print('correlation %s map %s' % (topic_index,correlation_map[topic_index]))\n",
    "            sum_ = sum(correlation_map[topic_index])\n",
    "            max_corr_ch_val = max(correlation_map[topic_index])\n",
    "            #most_corr_ch_index = correlation_map[topic_index].index(max_corr_ch_val)\n",
    "            most_corr_ch_val = max_corr_ch_val/sum_\n",
    "            #print('max_val : %s sum_ : %s value from softmax : %s '%(max_corr_ch_val,sum_,most_corr_ch_val))\n",
    "            '''scaling the max value by the cosine value of the max correlated'''\n",
    "            most_corr_ch_val = most_corr_ch_val * max_corr_ch_val\n",
    "            '''adding and scaling the given value to the overall rate of the topic'''\n",
    "            topic_pr += (2**(-(map_index - 1))) * most_corr_ch_val\n",
    "        print(\"For topic number %s the confidence is %s \" % (topic_index,topic_pr))\n",
    "        topics_errs.append(topic_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''my hand tuning data frame'''\n",
    "\n",
    "df_tp_to_ch = pd.read_csv(os.path.join(groundbase_dir,'Topic to chapter.csv'))\n",
    "df_tp_to_ch  = df_tp_to_ch.replace({np.nan:None})\n",
    "#df_tp_to_ch.loc[df_tp_to_ch['video id'] == '7kLHJ-F33GI',\n",
    "#                ['chapter section','chapter title','chapter confidence']].values[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Form asked widely data frame'''\n",
    "\n",
    "df_google_form = pd.read_csv('../data/raw/forms/form-answers-poc.csv')\n",
    "\n",
    "#df_google_form.columns\n",
    "def test_results(myresults):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################ zWg7U0OEAoE ################\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAD/CAYAAADc8UyaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAfBklEQVR4nO3deZgdVbnv8W8naSCEISJjQERQXvScw6CIVwFFCCIoIAJyLihwENAH5YrCdQIkAUGPYxwAPUYFDicOoIIiUQxBZgjIpHL5iRoZQpgNhIRMvff9o6p1s+l01e7eq1Nd+X186nHX9K7VpHv16lVrvdXTbDYxM7PqGbOqK2BmZgNzA21mVlFuoM3MKsoNtJlZRbmBNjOrKDfQZmYV5QbazKyixhVdEBHbAYcAWwAN4BHgV5JuT1w3M7PV2qA96Ig4AfhhvnsbcEf++TsRcXLKipmZre56BltJGBECdpK0uO342sAdkrZLXD8zs9VW0RDHCqB3gOPjgeWdFvbMUXslXVf+ntlrpAzPHc/+NWn8SeNfmjQ+wBh6ksZff9z4pPFvefJPSeMDzN9/66TxvzZn86Tx913+fNL4AJ8dtyx5Gb948IphfbMuf/Kvpdub3g23TvuDMURFDfTZwJ0RcTUwH2gCk4A9gVMT183MbOgafau6BsM26Bi0pBnAbsD1wGJgaf55d0k/HOxeM7NVqtkov1VU4SwOSY8AF41AXczMuqdR3Ya3rMIG2sxsNGpWuGdclhtoM6unvhWrugbD5gbazOqpBg8JR7SBfvJ3aYtb1kz7G3PDNddPGv+1a22WND7ANw5N+2fffjOeTRr/kE12Thof4Kzb0k7XvKfxZNL4N4xNGh6A5/s6nmU78jzEYWZWUX5IaGZWTX5IaGZWVe5Bm5lV1GgYJy/gBtrM6slDHGZmFeUhDjOziqp7DzoithzsvKQHu1sdM7MuWQ160L8EXkX2mqv2fKlNIG3iXDOzIWo26v+QcFey9KInSLpxBOpjZtYdde9BS3o2Io4DjgXcQJvZ6JFoDDoiDgdOI3vb1DRJ57adPwiYCowle5fr8ZKW5UPGFwMbAwKOkPTcYGUNmrAfQNIcSccP6SsxM1tVGn3lt5IiYnOyN03tBuwIHB8Rr2k5PwH4JrC3pH8B1gKOzk+fB5yXv8v1duD0ovIKG2gzs1EpzRtVJgOzJT0taRFwKXBI/8n82FaSHstfrr0x8PeI6AXenF8PcAFwaFFhnmZnZvXUwRh0REwEJg5waoGkBS37k8jez9pvPrBL6w2SlkfEvmTDGfOAq4ANgWclrWi5b4uierkHbWb11Lei/AYnAXMH2E5qizqGbAZbvx7gRb8JJM2U9FLgCuD8Ae5joPvajWgPerMPbJM0/npfTDst+4metL/PnmgsSRofYPlfFyWNv8m4tDmzr1t4f9L4ALuum/b7dPOx6ySNf++yJ5LGB1ijZxT88d3ZLI5pZMMO7Ra07T8M7N6yvynZNGQAImIDYGdJV+WH/gf4EfA4sH5EjJXUB2zWet/KjIL/ymZmnWs2yz/8y4cx2hvjgcwCpkTERsAi4GCgdRJFD3BxROycL+Q7FLghH/a4HjgMmAEcCcwsKsxDHGZWT41G+a0kSfOAU4FrgLuAGZLmRMSVeaP8FFmDfUVE3A0E8In89hPIZn3cS9YLP62oPPegzayeEs2DljSDrBfcemy/ls+XAZcNcN8DwB6dlOUG2szqqQYrCQuHOCLiwIg4MSK2aTvuxStmVl2dzeKopEEb6Ij4PHAisC1wY0S8t+X0B1NWzMxsWNIsVBlRRT3odwBvl3Qi2aD2WRHRv/qlPbudmVl1JHhIONKKxqB7yCdXS7o/It4J/CYinuDFk67NzKqjwg1vWUU96EuA30bELgCS/kg2r+/HQNrZ/GZmw1H3IQ5JU4EpwMKWYzcCrwO+n7RmZmbDUYOHhIXT7CRdPcCxh3jxGnUzs+qowRCH50GbWT1VeOiiLDfQZlZP7kGbmVWUG+jONP/+TNL4Dy77e9L4e4/fKmn8PzcGfT1ZV+xx47Kk8V+zZtrp8ceuu33S+AD3/POZeBL/2pyQNH5f74ZJ4wM82kibtrYrmqN/JrB70GZWTyuqOzujLDfQZlZPfkhoZlZRHoM2M6soj0GbmVXU6tCDjohXAYskPRIRxwLbk71j68fJa2dmNlQ1aKCL8kF/FPg1cHNEfA/4d+A+4P0RcfoI1M/MbEiafX2lt6oq6kEfA7wG2AT4I7ChpCURMR24DTgrcf3MzIam7j3o/PzS/GWHX5K0pOWcx6/NrLrqnm4U+AlwbUSMlTQFICJ2AG4AfpS4bmZmQ9dolt8qatBesKTPRMSbJbUO0iwBzpA0M23VzMyGoQZDHGXyQV/Xti9AyWpkZtYNFX74V5bHkc2snlaHHrSZ2ahU4bHlstxAm1k9VXh2Rlkj2kD/1/S0uYKf61tSfNEw3N9Imye4bwS+oc5pvjxp/C/1PZk0/t+aaXOKA8w+5w1J4x96+u+Txu8tnJw1fGNI+7PcFe5Bm5lVU9Nj0GZmFeVZHGZmFZVoiCMiDgdOA3qBaZLObTt/IDAV6AHmAv8h6e8t53cCbpG0ZlFZ6QerzMxWhUaj/FZSRGwOnA3sBuwIHB8Rr2k5vx5wPvAOSTsA9wBTWs6vDXwDWKNMeW6gzaye0iz1ngzMlvS0pEXApcAhLed7gQ9Jmpfv3wNs2XL+y8C0soV1NMQREV+WdHIn95iZrRIdzIqKiInAxAFOLZC0oGV/EjC/ZX8+sEv/jqSngJ/lMccDnyTrMRMRBwBrS7o0IkrVa6UNdJ7/ud0BEfGSvCLHlCrBzGxV6KxnfBJwxgDHp9IyREE26tAauAd40W+CiFifrKG+W9KFEbEp2bj15E4qNVgP+mngSLLxlv7fIHsB13ZSgJnZqtBc0dEsjmnABQMcX9C2/zCwe8v+psAjrRdExGZkLzqZDXw0P/xO4KXAdf2954i4C9hd0koXWKy0gZZ0SkTMBD4LfErSbyPiJEkXruweM7PK6KAHnQ9jtDfGA5kFTImIjYBFwMHA8f0nI2Is8Avgx5I+2xJ/OjC95bqmpB2LCitKN3p1RNwJfCsi3gmMLfEFmJmteglW5kqaFxGnAteQzcSYLmlORFwJfAZ4GfBaYFxE9D88vF3SsUMpr0y60aeB97S8MNbMrPoSzYOWNAOY0XZsv/zj7ZSYHSep1Fr50rM42rvoZmZV1nQuDjOziursIWEluYE2s3pyD7ozP+2bX3zRMKwzdq2k8f+85PGk8SevvXXS+ABTxz5SfNEwPLUkbUrWg9cpN8F/OMbu/b6k8XXKkUnjn9m7XdL4AH9YYxQ0fm6gzcyqqdl0A21mVk3uQZuZVZQbaDOzamqu8BtVzMyqafS3z4M30BHxekm35Z/3AvYDlgM/k3TrCNTPzGxI6rBQpWhJ4rcBIuJDZNmeHgIeA74dER9OXDczs6FLk7B/RJUd4jgO2CNPRk1ETAduA76ZqmJmZsNS9yEOoDcixgBPAUtbji+jFl++mdXV6jDE8STwIBDkveWI2BO4EbgkbdXMzIauuaJZequqonzQbwWI7BUAL8kPLwXOkPTLxHUzMxu6GvyNX2oMWpJaPt+YrjpmZt2RIF//iPM8aDOrJzfQZmbV5B60mVlFNVes6hoM34g20Of0vaT4omH4+NinksZ/atmzSeM/1lySND7AR9kiafyPrbgzafznSP+WjMbcu5LGf9X4TZLGP2Vh2voDbNOzafIyhss9aDOzinIDbWZWVc1SL86uNDfQZlZL7kGbmVVUs+EetJlZJTX6VoMGOiL2AW6VtCAijgR2AX4n6fvJa2dmNkR1GOIYNFlSREwDPg2sFRFnAe8F/ggcFBFfG4H6mZkNSbPRU3qrqqJsdnsDe0p6FHgHsL+k84GDgLelrpyZ2VA1m+W3qioa4lgMbAzMJ3ubygSybHYTgBqs0zGzuqpyz7isogb6TOC2iPghMBe4NiJmAfsAX0hdOTOzoar9Q0JJv4iIP5ANabwSuBlYCBwtac4I1M/MbEhS9aAj4nDgNKAXmCbp3JVcdxEwW9IF+f5WwEXAesAC4ChJDwxWVuEsDklzga90UH8zs1WumWAlYURsDpwNvI5suPemiLhG0r0t10wie+H2XsDsltvPAn4g6fyIODGP897Byit6SGhmNio1G+W3Dkwm6xU/LWkRcClwSNs1RwCXAz9uOz6WrPcM2XO854sK80IVM6ulRgc96IiYCEwc4NQCSQta9ieRTZroN59sbcg/SPpiHnO3tlink/W4/w+wBvDGonqNaAN9xVq9SeOPW572D4Ktxm+cNP5jK55LGh/gu2PTpjRdf40JSeMvGYHXZIyNwp+bYVncSLvG6z3r/1vS+AAPNRcnL2O4OhziOAk4Y4DjU4EpLftjgNaJeT2Uf3fLhcDxki6PiIOBn0XE9pJWOtHPQxxmVkuNvp7SGzANeMUA27S2sA8Dm7Xsbwo8UlSXiNgI2E7S5QCSfpLfu+Fg93mIw8xqqZNZHLpfC8hmVhSZBUzJG9xFwMHA8SXuexJYEhG7S7o+InYFFkp6YrCb3IM2s1pqNHtKb2VJmgecClwD3AXMkDQnIq6MiJ0Hua8JvBv4UkTcQ7aO5OCi8tyDNrNaSjHNDkDSDGBG27H9Brju6Lb9OcAbOinLDbSZ1VKVc2yUVZTN7usRkfZNr2ZmCaQY4hhpRWPQRwK3RMS7R6IyZmbd0mj0lN6qqqiBnkuWh+MjEXFrRBwWEeNHoF5mZsOyOvSgm5LulfQWsieXBwNzI+K6iJhRcK+Z2SrTbPaU3qqq6CHhP2ouaRYwKyJ6ge2BrVNWzMxsOKrcMy6rqIH+ZvsBScuB3+WbmVkl1WASR2E+6O+OVEXMzLqprzH61+F5HrSZ1VINXurtBtrM6qlJ/cegzcxGpUYNBqFHtIH+zJFp/4sddWHaXMQLGkuTxt9+bPpFm/ObafNBP5h4fe2c5x9OGh/gUzufmjT+SSvS5hW/atyKpPEBHlz+TPIyhqvhHrSZWTV5iMPMrKL63ECbmVWTZ3GYmVWUG2gzs4paLcagI2JP4HlJN0fEycAewG3A5yUtS1w/M7MhqXAW0dIGbaAj4gvAm4HeiJhL9lfD+cD+wLnAcclraGY2BKvDNLt9gR2ANYEHgUmSlkfETLIXJpqZVVLfqq5AF5RJN7o+sA4wAVgPeAoYD6yRtmpmZkPX6Kl/D/rzwJ/JGuqPA7+JiFnAZOB7ietmZjZkNVjpPfgbVSRdDGwBbCnpm8BRwOPAJyR9cQTqZ2Y2JI0OtqoqnMUh6fmWz78Hfp+0RmZmXVD7WRxmZqOVl3qbmVWUe9Adai5Nu65lDcYmjZ/afY1nk5fRTJwO9OxxkTT+53ggaXyA48f/PWn8tz7zUNL4b1tru6TxAR5d8nTyMoarymPLZbkHbWa1VIdZHG6gzayWPMRhZlZRHuIwM6uoPvegzcyqKVUPOiIOB04DeoFpks5dyXUXAbMlXZDv7wp8lSxNxlPAMZIGfepdJt3ou4B3AZsCy4C/AD+WdHPZL8jMbKSlaKAjYnPgbOB1wFLgpoi4RtK9LddMAr4N7AXMbrn9f4ADJN0TEccAXwcOHKy8onSjnwL+F/Ar4ADgFrJG+nsR8RVJ3+nw6zMzGxGdzOKIiInAxAFOLZC0oGV/Mlmv+On8vkuBQ4AzW645AricrJfcH39N4DRJ9+SH7gFOLKrXoLk4gMOAd0k6HzgImCzpS2SN9seKgpuZrSqNnvIbcBIwd4DtpLawk4D5LfvzyfIV/YOkL0qa3nZsaZ7biIgYA0wBLiv6GoqGONYC1gYWkaUYfWl+/Dnq8ZDUzGqqwwZqGnDBAMcXtO2P4YWd855OioqINYALydrec4quL2qgLwBujIhfA/sA34+ILcm67zPKVsrMbKR1krA/H8Zob4wH8jCwe8v+psAjZcqIiHWAn5MNfRwoaXnRPUXpRj8PnAw8AXxM0jTgaeBISWeXqZSZ2arQ4RBHWbOAvSJio4hYGziY7BldGReT5dc/TNLSMjeUSTd6NXB1y/5zOOWomVVcijFYSfMi4lTgGrLpctMlzYmIK4HPSLp9oPsiYieyGRv3AndEBMAjkvYbrDzPgzazWkqVi0PSDNqGeAdqaCUd3fL5Tug8/6kbaDOrpUYN0iW5gTazWlod3urdVY/8fHHS+PcvTxs/ejdMGv/RxqKk8QG2GzvQXPzu+fOYtAkQJve8LGl8gDnPpM0rvl5v2lzKNy5KnzP74xN2SF7GcNVhHrB70GZWS043amZWUR6DNjOrqNHfPLuBNrOa8hi0mVlF9dWgD+0G2sxqyT1oM7OKWi0eEkbEPsChZDlPG2SZm2ZK+kniupmZDdnob56L36hyJrALWRam+WRryTcF3h8Rb5R0Svoqmpl1bnUY4jgMeLWkF3ytEfED4A+AG2gzq6Q6PCQseuXVEtpe55J7OdkLE83MKqlBs/RWVUU96JOB6yPiT2RDHE2yd3JtCxydtmpmZkNX3Wa3vEEbaEmzIsssvQtZwzyG7JUvt5Z9I4CZ2apQ5Z5xWUUPCbfMP/4t3/ptEhFIejBRvczMhmV1eEj4S+BVZFPr2nNDNYGtOynsqufSpuucMObRpPEfWPFM0vh7j9s0aXyAy5amTUU5b/GTSePvsN5WSeMDPNw7Pmn824/t6MemY8dcuCRpfIBNllW/d9qsew8a2BW4HjhB0o0jUB8zs66o/SwOSc8CxwFHjUx1zMy6o9HBVlVl3uo9B5gzAnUxM+uaRnP096Cdi8PMamn0N89uoM2spmo/zc7MbLRaHWZxmJmNSivcQJuZVVPte9AR8ebBzku6rrvVMTPrjipPnyurqAf9GeCNwK0MvJJwzxSVMjMbruZqMM1uX+AaYJqkn49AfczMuqIOsziKVhIuB44B3jQy1TEz644+mqW3qiqzkvBPwCdHoC5mZl2TqgcdEYcDpwG9ZKML57ad3xGYDqwHXAd8UNKKiNgsPz4JWAwcIelvg5VVNt3ogJxu1MyqKsUYdERsDpwNvI7srVI3RcQ1ku5tuexi4FhJt0TEd8nyGZ0P/DdwqaRvRcQHgf8ke63gSo1oulEzs5HSySyOiJgITBzg1AJJC1r2JwOzJT2d33cpcAhwZr7/cmC8pFvy6y8ApkbEJcAOwN758e8DVxfVa0TTjR57+XuGG2JQt737wqTx5yx+KGn8n/Wlz+N7as9WSeOfvuaypPHnLnkiaXyAfce/Omn8j12U9mVEtzz316TxAV667nbJyzh0mPd3OA/6JOCMAY5PBaa07E8ie/1fv/lkb5wa7PwWwDbAg8CXI2J34FHgw0WVcrpRM6ulDl8aOw14xQDbtLawY3hhHqYeXthZX9n5ccBOZL3v1wOXA4U9SqcbNbNa6muWH+TIhzEWFF6YvZN195b9TcmGgFvPbzbA+UeBhZKuyI/PAL5eVNigPWgzs9Gq2cH/OjAL2CsiNoqItYGDgV/1n5T0ALAkInbND70PmCnpL8DDEbFvfnx/4HdFhbmBNrNaajSbpbeyJM0DTiVbwHcXMEPSnIi4MiJ2zi87AvhqRNwHrMM/e8rvBj4REX8APkK2xmRQTpZkZrWUavmJpBlkQxStx/Zr+Xw3L3xw2H9cwB6dlOUG2sxqqQ5Lvd1Am1kt1b6BjohxwIeALYHLJF3fcm6KpClpq2dmNjSdzOKoqqKHhN8mm7v3CHBRRHy65dwByWplZjZMiWZxjKiiIY6dJe0AEBEXAbMiYrGkabx46beZWWXUIR90UQ96TERMAJD0BLAfcFJEHEE93mpuZjXV4UrCSipqoL8B3BERe8E/5gC+HTgHSJuwwMxsGJrNZumtqopycfwX8E7g/pZj9wH/CnwqbdXMzIauj0bprarK5INe2vK51U9TVcrMbLg6WSFYVc4HbWa1VOXZGWWNaD7oLx70o+GGGNS2rJU0/p96JySNv23vBknjAxz35K1J42+z7mbFFw3D5r3rJ40PcMxb5hdfNAxTr98oafzp49I/Hjp92WPJyxiuOvSgnQ/azGppdZgH7XzQZjYq1aEH7VwcZlZLdVjq7QbazGqpykMXZbmBNrNaaroHbWZWTVVewl1WYQMdEZPJXqZ4F9nrx7cHbgC+LKkvae3MzIaoyku4yypaSfifZHOh1ydbrPIY8C3gELLXkZ+YuoJmZkOxOvSg3wH8G7AB8BdgA0mNiJgJ3Jm6cmZmQ9XXGP1j0GXe6r2mpKeAUyT1f8XrAr3pqmVmNjx1WKhS1ECfC9wdEWMlTQeIiDcBd5MNcZiZVdLqkG70fGCftoeBDwLvlPSdpDUzMxuGOiTsL5NutDFAqtGFEbGlpAfTVc3MbOiq3DMuy+lGzayW6vCQsGew3zIRsR5dTDe68IR9k/5K2/uy51OGZ0Uz7bTvm275WtL4ALN3+ULS+GeNezxpfC18OGl8gOM22Dlp/EsXKWn8uc88mjT+SFmxbN6wXky9/jrblG5vnnnuL5V8CbbTjZpZLdXhIaHTjZpZLTndqJlZRVV5fnNZbqDNrJbcgzYzq6hGonSjEXE4cBrZauppks5tO78jMB1YD7gO+KCkFfl05YuBjQEBR0h6brCyyiz1NjMbdVI8JIyIzYGzgd2AHYHjI+I1bZddDHxY0rZk05OPy4+fB5wnaTvgduD0ovLcgzazWuqw4Z0ITBzg1AJJC1r2JwOzJT2d33cpWXbPM/P9lwPjJd2SX38BMDUipgNvBt7Vcvxa4BOD1avjBjoifiDpf3d6H8C6581MOtfwlvNSRq+Htz/2w7Txk0avh8+t6gqsJpZ3MI86IqYAZwxwaipZHvx+k4D5LfvzgV0Kzm8BbAg8K2lF2/FBFS31vgZe9Ch054iYDSBpz6ICzMxGgWlkvdp2C9r2x/DCNrEHaJQ4336ctvsGVNSD/glZF/x0YG5e2HfIfquYmdVCPozR3hgP5GFg95b9TclSYbSe32yA848D6+eZQfvya1rvG1DRSsJvAvsAxwAvl/RbYKGkayVdW/y1mJnVyixgr4jYKCLWBg4GftV/UtIDwJKI2DU/9D5gpqTlZGkzDsuPHwnMLCqscBaHpHvJBsZ3iIhLgDU7+GLMzGpD0jzgVOAasve0zpA0JyKujIj+JC5HAF+NiPuAdYCv58dPIJv1cS9ZL/y0ovIGTZbULiL2Bv5d0vtL32RmZkNSlM2uPQ/0CzgftJlZOkPJB93MPzsftJlZQkUN9K50MR+0mZmV53zQZmYV1dFDwpFSlIykS2WsB9xE9gLcvyWIfwbwnnz3l5I+3uX4Z5ItMW0C35X0lW7GbynnS8CGko5OEPsassQxy/NDH5B0axfj70+2OmwCcJWkj3Qrdh7/WODDLYdeAfy3pA+v5JahlPFe4FP57kxJp3Qrdh7/k8B/AEuBH0k6u0txX/DzFRGTga8A4/NyCmcwWAWTJZVMRjLcMt4A3ABs2824LfEnA28DdiL7Gl4XEQd1Mf5bgD2B7YGdgRMjIroVv6WcvUj011NE9JD9999B0o751s3GeWvgW2S5D7YHXhsR+3YrPoCk6f11J5ta9TgvXBY8LPk8268DbwF2AHbPv7e6FX8ycDjwerLv1TdExLu7EPcFP18RMR74HnAg8Grg9d3+t6iryjXQtCQjkbQI6E9G0k3HAR+ixEqeIZoPnCxpWT5B/f8Bg86I6US+SOit+br+jcmeJSzqVnyAiNiA7BflOd2M21pE/v9XRcTdEdG1XmfuILKe2sP5v8FhQNd+AQzgfODTkp7sYsyxZD+jE8j+muwFuvnizZ2AX0t6Nl/d9iv+mcxnONp/vnYB7pc0N/+evRg4tAvl1F4Vs9kVJSMZNknHAiTodPbH/2P/54h4FdlQx64rv2NIZSyPiKnAKcAlwLxuxge+TTYh/2VdjtvvJcDVwIlkDc9vI0KSftOl+K8ElkXEz8l+OV5BifSOQ5H3RMdLuqSbcSUtjIjTgfuAxWTZz27qYhF3kC2o+Fwe/wC60Gkb4OdrZQmErEAVe9BFyUhGjYj4F+A3wP+VdH+340s6A9iIrBE9ruDy0vKx1YckXd2tmO0k3SzpSEnP5L3O7wL7dbGIcWR/jb0feCPwBtI97P4A2fhqV0XE9uRpFsgauT6yX8hdkf/7XgD8lqz3fAOwrFvxW9TmZ3qkVbGBXlmykVElX4t/NfBJSRd2OfZ2+VsbkLQY+CnZOGu3HAa8LSLuIstze0BEfLWL8YmI3fIx7n49/PNhYTc8CsyS9ISk54Gf0eW/xAAiYg2yMeKfdzs2WR6cqyU9LmkpWWO6R7eCR8S6wE8kbS9pD7IHhX/pVvwWtfiZXhWqOMQxC5gSERuRjaseDBy/aqvUmYh4GXAZcJik2QmK2JosCfhuZD2TA8kewnSFpL37P0fE0cAekj7arfi5icCZEfEmsiGOo4APdjH+FcCFeSL2hcC+ZP8m3bY98Kf8eUm33Q18ISImkA1B7A/c1sX4rwAuynNITCD7ayNFGodbgYiIV5JlxTycLn6/1lnletArS0ayamvVsVOAtYCvRMRd+da1xkfSlWSrPO8EfgfcJCltJv4uk3QFL/wavifp5i7GvxX4Atmf7fcCDwDf71b8FluT9RC7TtJVwA/I/vvcQ/aL7PNdjH8PWUrhe4A5ZFNau74gTdIS4Oi8rHvJxtQv7XY5dVTJedBmZlbBHrSZmWXcQJuZVZQbaDOzinIDbWZWUW6gzcwqyg20mVlFuYE2M6soN9BmZhX1/wEKTPjuCUcptwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " video_shift index 0 at 03:33 , chapter title Introduction ( index 0) \n",
      " video_shift index 1 at 06:24 , chapter title Sets ( index 4) \n",
      " video_shift index 2 at 09:06 , chapter title Introduction ( index 0) \n",
      " video_shift index 3 at 12:05 , chapter title Introduction ( index 0) \n",
      " video_shift index 4 at 15:22 , chapter title Sorting ( index 7) \n",
      " video_shift index 5 at 19:43 , chapter title Sorting ( index 7) \n",
      " video_shift index 6 at 24:02 , chapter title Sorting ( index 7) \n",
      " video_shift index 7 at 27:15 , chapter title Sorting ( index 7) \n",
      " video_shift index 8 at 30:47 , chapter title Introduction ( index 0) \n",
      " video_shift index 9 at 36:32 , chapter title Introduction ( index 0) \n",
      " video_shift index 10 at 41:34 , chapter title Introduction ( index 0) \n",
      " video_shift index 11 at 46:15 , chapter title Numeric ( index 8) \n",
      " video_shift index 12 at 50:29 , chapter title Introduction ( index 0) \n",
      " video_shift index 13 at 52:45 , chapter title Sorting ( index 7) \n",
      " video_shift index 14 at end , chapter title Heap ( index 3) \n",
      "By the majority vote, the dominent chapter choosed is Introduction \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zWg7U0OEAoE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Shift</th>\n",
       "      <th>Founded Title</th>\n",
       "      <th>Similarity Ratio</th>\n",
       "      <th>Chapter Section</th>\n",
       "      <th>Prelabeled Title</th>\n",
       "      <th>Labeling Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03:33</td>\n",
       "      <td>1.5\\tBook outline</td>\n",
       "      <td>0.309397</td>\n",
       "      <td>1.1</td>\n",
       "      <td>What this book is about</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>06:24</td>\n",
       "      <td>1.2.1\\tBig Oh notation</td>\n",
       "      <td>0.390468</td>\n",
       "      <td>1.2.1</td>\n",
       "      <td>Big oh notation</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09:06</td>\n",
       "      <td>1.3\\tPseudocode</td>\n",
       "      <td>0.336209</td>\n",
       "      <td>1.2.1</td>\n",
       "      <td>Big oh notation</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12:05</td>\n",
       "      <td>1.3\\tPseudocode</td>\n",
       "      <td>0.333323</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Pseudocode</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15:22</td>\n",
       "      <td>1.3\\tPseudocode</td>\n",
       "      <td>0.371853</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Pseudocode</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19:43</td>\n",
       "      <td>1.3\\tPseudocode</td>\n",
       "      <td>0.377012</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24:02</td>\n",
       "      <td>1.3\\tPseudocode</td>\n",
       "      <td>0.579019</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27:15</td>\n",
       "      <td>1.3\\tPseudocode</td>\n",
       "      <td>0.381248</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30:47</td>\n",
       "      <td>1.4\\tTips for working through the examples</td>\n",
       "      <td>0.332039</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36:32</td>\n",
       "      <td>1.2.1\\tBig Oh notation</td>\n",
       "      <td>0.367246</td>\n",
       "      <td>1.2.1</td>\n",
       "      <td>Big oh notation</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>41:34</td>\n",
       "      <td>1.2.1\\tBig Oh notation</td>\n",
       "      <td>0.462148</td>\n",
       "      <td>1.2.1</td>\n",
       "      <td>Big oh notation</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>46:15</td>\n",
       "      <td>1.3\\tPseudocode</td>\n",
       "      <td>0.457416</td>\n",
       "      <td>1.2.1</td>\n",
       "      <td>Big oh notation</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50:29</td>\n",
       "      <td>1.2.1\\tBig Oh notation</td>\n",
       "      <td>0.418937</td>\n",
       "      <td>1.2.1</td>\n",
       "      <td>Big oh notation</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>52:45</td>\n",
       "      <td>1.2.1\\tBig Oh notation</td>\n",
       "      <td>0.577657</td>\n",
       "      <td>1.2.1</td>\n",
       "      <td>Big oh notation</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>53:30</td>\n",
       "      <td>1.2.1\\tBig Oh notation</td>\n",
       "      <td>0.375986</td>\n",
       "      <td>1.2.1</td>\n",
       "      <td>Big oh notation</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chapters_matching_topics = {}\n",
    "#for vid in videos_ids:\n",
    "for vid in [videos_ids[-1]]:\n",
    "    print('################ %s ################' % (vid))\n",
    "    paper_name = video_to_paper[vid]\n",
    "    correlations_levels = []\n",
    "    \n",
    "    #################################################\n",
    "    '''Extracting the prelabeled topics to chapters'''\n",
    "    #################################################\n",
    "    '''Extracting all pre labeled topics '''\n",
    "    pre_labeled_titles = df_tp_to_ch.loc[df_tp_to_ch['video id'] == vid,\n",
    "                        ['chapter section','chapter title','chapter confidence']].values.tolist()\n",
    "    \n",
    "    '''Extracting prelabel for main titles'''\n",
    "    '''level = 0 \n",
    "    pre_labeled_main_titles = []\n",
    "    for label in pre_labeled_titles:\n",
    "        # if no correlation was given \n",
    "        main_section = None\n",
    "        main_section_tl = None\n",
    "        if label[0] is not None:\n",
    "            main_section = int(str(label[0]).split('.')[level])\n",
    "            main_section_tl = paper_content[paper_name]['main titles'][main_section -1]\n",
    "        pre_labeled_main_titles.append([main_section,\n",
    "                                        main_section_tl,\n",
    "                                        label[2]])'''\n",
    "    \n",
    "    \n",
    "    '''Finding the correlation between topic and main chapters'''\n",
    "    main_matching_topic,correlation = get_topic_chapter_corr_tfidf(paper_name,\n",
    "                                 paper_mains_as_one_doc[paper_name],\n",
    "                                 videos_division[vid]['topic_words'],\n",
    "                                 videos_division[vid]['topic_shift'],\n",
    "                                 paper_content[paper_name]['main titles']\n",
    "                                                                  )\n",
    "    \n",
    "    correlations_levels.append(correlation)\n",
    "    #print(main_matching_topic)\n",
    "    dominet_chapter =  find_dominent_main_chapter(main_matching_topic,\n",
    "                                                  paper_content[paper_name]['main titles'],\n",
    "                                                 correlation)\n",
    "    print('By the majority vote, the dominent chapter choosed is %s ' %(dominet_chapter))\n",
    "    \n",
    "    #Searching for each topic the most correlated \n",
    "    #subsection to a topic within the dominent main chapter '''\n",
    "    dom_main_cha_index = paper_content[paper_name]['main titles'].index(dominet_chapter)\n",
    "    dom_subsec_text = [paper_subsec_as_one_doc[paper_name][s_i] for s_i in\n",
    "                      paper_sec_within_main_indexes[paper_name][dom_main_cha_index]]\n",
    "    dom_subsec_titles = [paper_content[paper_name]['titles'][tl]\n",
    "                         for tl in paper_sec_within_main_indexes[paper_name][dom_main_cha_index]]\n",
    "    \n",
    "    dom_subsec_text = emphasize_title(paper_name,dom_subsec_text,\n",
    "                                      dom_subsec_titles,lemmatizing = lemmatizing_method)\n",
    "    \n",
    "    subsec_matching_topic,correlation = get_topic_chapter_corr_tfidf(paper_name,\n",
    "                                 dom_subsec_text,\n",
    "                                 videos_division[vid]['topic_words'],\n",
    "                                 videos_division[vid]['topic_shift'],\n",
    "                                 dom_subsec_titles,\n",
    "                                 pre_labeled_title = pre_labeled_titles)\n",
    "    \n",
    "    correlations_levels.append(correlation)\n",
    "    #measure_confidence(vid,correlations_levels)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########number ch 1##########3\n",
      "most common chapter : 1.1 What this book is, and what it isn’t \n",
      "rating 1 \n",
      "#########number ch 2##########3\n",
      "most common chapter : 1.2.1 Big Oh notation \n",
      "rating 3 \n",
      "#########number ch 3##########3\n",
      "most common chapter : 1.2.1 Big Oh notation \n",
      "rating 3 \n",
      "#########number ch 4##########3\n",
      "most common chapter : 1.2.1 Big Oh notation \n",
      "rating 2 \n",
      "#########number ch 5##########3\n",
      "most common chapter : 1.3 Pseudocode \n",
      "rating 3 \n",
      "#########number ch 6##########3\n",
      "most common chapter : 1.2.3. Object oriented concepts \n",
      "rating 4 \n",
      "#########number ch 7##########3\n",
      "most common chapter : 1.4 Tips for working through the examples \n",
      "rating 2 \n",
      "#########number ch 8##########3\n",
      "most common chapter : 1.2.2 Imperative programming language \n",
      "rating 2 \n",
      "#########number ch 9##########3\n",
      "most common chapter : 1.2.3. Object oriented concepts \n",
      "rating 2 \n",
      "#########number ch 10##########3\n",
      "most common chapter : 1.2.2 Imperative programming language \n",
      "rating 2 \n",
      "#########number ch 11##########3\n",
      "most common chapter : 1.2.3. Object oriented concepts \n",
      "rating 1 \n",
      "#########number ch 12##########3\n",
      "most common chapter : 1.1 What this book is, and what it isn’t \n",
      "rating 1 \n",
      "#########number ch 13##########3\n",
      "most common chapter : 1.2.1 Big Oh notation \n",
      "rating 4 \n",
      "#########number ch 14##########3\n",
      "most common chapter : 1.2.1 Big Oh notation \n",
      "rating 2 \n",
      "#########number ch 15##########3\n",
      "most common chapter : 1.2.1 Big Oh notation \n",
      "rating 4 \n",
      "#########number ch 16##########3\n",
      "most common chapter : 1.1 What this book is, and what it isn’t \n",
      "rating 1 \n",
      "#########number ch 17##########3\n",
      "most common chapter : 1.2.1 Big Oh notation \n",
      "rating 4 \n",
      "#########number ch 18##########3\n",
      "most common chapter : 1.1 What this book is, and what it isn’t \n",
      "rating 3 \n"
     ]
    }
   ],
   "source": [
    "form_mapping_indexes = range(1,19)\n",
    "form_confidece_indexes = range(20,38)\n",
    "#print(df_google_form.columns[form_mapping_indexes])\n",
    "#print(df_google_form.columns[form_confidece_indexes])\n",
    "#print(len(df_google_form.columns[form_mapping_indexes]))\n",
    "#print(len(df_google_form.columns[form_confidece_indexes]))\n",
    "n_topics = len(form_mapping_indexes)\n",
    "for ch,rating in zip(form_mapping_indexes,\n",
    "                     form_confidece_indexes):\n",
    "    print(\"#########number ch %s##########3\"% (ch))\n",
    "    print(\"most common chapter : %s \" % (df_google_form.iloc[:,ch].mode()[0]))\n",
    "    print(\"rating %s \" %(df_google_form.iloc[:,rating].mode()[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
