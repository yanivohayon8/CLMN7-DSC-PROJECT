{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from pyyoutube import Api\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import numpy as np\n",
    "import os \n",
    "from gensim.test.utils import get_tmpfile\n",
    "import json\n",
    "import glob\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "import spacy\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_ID = 'PL2B42F74062A70327'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts_path = '../data/raw/transcripts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_path = '../data/raw/transcripts/playlists/' + playlist_ID + '.json'\n",
    "\n",
    "if os.path.isfile(playlist_path):\n",
    "    with open(playlist_path,'r') as f:\n",
    "        videos_id = json.load(f)\n",
    "else:\n",
    "    api = Api(api_key=\"AIzaSyCw0j0aCe0y_T42q3RLBoVtGXlTOMGGaSM\")\n",
    "    videos_id = api.get_playlist_items(playlist_id=playlist_ID,count=None)\n",
    "    videos_id = [ video.snippet.resourceId.videoId for video in videos_id.items]\n",
    "    '''write to a file over here and in the next time won't call the api'''\n",
    "    with open(playlist_path,'w')as f:\n",
    "        json.dump(videos_id,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = []\n",
    "\n",
    "for vid in videos_id:\n",
    "    if len(glob.glob('../data/raw/transcripts/*/' + vid+'.json')) == 0:\n",
    "        with open(os.path.join(transcripts_path,vid+'.json'),'r') as f:\n",
    "            transcripts.append(json.load(f))\n",
    "    else:            \n",
    "        for transcript in YouTubeTranscriptApi.list_transcripts(vid):\n",
    "            if transcript.language_code == 'en' and transcript.is_generated is False:\n",
    "                tr = transcript.fetch()\n",
    "                with open(os.path.join(transcripts_path,vid+'.json'),'w') as f:\n",
    "                    json.dump(tr,f)\n",
    "                transcripts.append(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''expiriment to doc2vec by only the video transcripts'''\n",
    "#trs = transcripts[0]# experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Trying to find pdf files and then bulid the doc2vec model'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Trying to find pdf files and then bulid the doc2vec model'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "trs = np.concatenate(transcripts,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': 'First of all, let us talk about the scope\\nand syllabus of this course titled Foundation',\n",
       " 'start': 16.32,\n",
       " 'duration': 7.29}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(trs))\n",
    "trs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [tr['text'] for tr in trs]\n",
    "text = ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1338984"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "corpus = []\n",
    "while i < len(text):\n",
    "    next_sent = \"\"\n",
    "    while i < len(text) and text[i] !='.':\n",
    "        #next_sent.append(text[i])\n",
    "        next_sent += text[i]\n",
    "        i+=1\n",
    "    corpus.append(next_sent)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First of all, let us talk about the scope\\nand syllabus of this course titled Foundation of\\nScientific Computing'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10156"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Preparing the text for modeling'''\n",
    "''' This code is inspired from the CreateBlock Class - notice for changes if there are applied there'''\n",
    "stop_words = stopwords.words('english')\n",
    "nlp = spacy.load('en',disable=['parser','ner'])\n",
    "allowed_postags=['NOUN', 'ADJ', 'VERB']\n",
    "raw_data = [cr.split(' ') for cr in corpus]\n",
    "documents = []\n",
    "for index,doc in enumerate(raw_data):\n",
    "    doc_text_no_punc = simple_preprocess(' '.join(doc),deacc=True) \n",
    "    tokenized_text_non_stop_words = [ word for word in doc_text_no_punc \\\n",
    "                                     if word not in stop_words]\n",
    "    text_non_stop_words = ' '.join(tokenized_text_non_stop_words)\n",
    "    tokenized_lemmas = nlp(text_non_stop_words)\n",
    "    tokenized_lemmas = [token.lemma_ for token in tokenized_lemmas \\\n",
    "                        if token.pos_ in allowed_postags]\n",
    "    documents.append(gensim.models.doc2vec.TaggedDocument(tokenized_lemmas,[index]))\n",
    "    #documents.append(gensim.models.doc2vec.TaggedDocument(tokenized_text_non_stop_words,[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['first', 'let', 'us', 'talk', 'scope', 'syllabus', 'course', 'titled', 'foundation', 'scientific', 'computing'], tags=[0]),\n",
       " TaggedDocument(words=['offered', 'science', 'elective', 'course', 'third', 'year', 'final', 'year', 'undergraduate', 'students'], tags=[1])]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''creating the model'''\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=20,min_count=2,epochs=40)\n",
    "'''Building the vocubolary'''\n",
    "model.build_vocab(documents)\n",
    "model.train(documents,total_examples=model.corpus_count,epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../models/doc2vec/' + playlist_ID\n",
    "#fname = get_tmpfile(path)\n",
    "model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer_vector(['let', 'talk', 'scope', 'course', 'title', 'foundation']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "for doc_id,blk in enumerate(blocks):\n",
    "    inferred_vector = model.infer_vector(blk)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = gensim.models.doc2vec.Doc2Vec.load('../models/doc2vec/' + playlist_ID)  # you can continue training with the loaded model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
