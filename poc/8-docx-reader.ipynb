{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "from docx import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_italic_bold_docx(doc_path):\n",
    "    document = Document(doc_path)\n",
    "    bolds=[]\n",
    "    italics=[]\n",
    "    full_text = []\n",
    "    font_sizes = []\n",
    "    for para in document.paragraphs:\n",
    "        #print(\"next paragraph:\")\n",
    "        #rint(para.text)\n",
    "        for run in para.runs:\n",
    "            #print('next run')\n",
    "            #print(run.text)\n",
    "            full_text.append(run.text)\n",
    "            font_sizes.append(run.font.size)\n",
    "            if run.italic :\n",
    "                italics.append(run.text)\n",
    "            if run.bold :\n",
    "                bolds.append(run.text)\n",
    "\n",
    "    return {'bold_phrases':bolds,'italic_phrases':italics,'full_text':full_text,'font_sizes':font_sizes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def get_txt_bigger(docx_json):\\n    most_common_font_ = mode(docx_json['font_sizes'])\\n    tmp_indexes = [i for i,sz in enumerate(docx_json['font_sizes']) if sz > most_common_font_]\\n    tmp_font_sizes = docx_json['font_sizes'][tmp_indexes]\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_txt_bigger(docx_json):\n",
    "    most_common_font_ = mode(docx_json['font_sizes'])\n",
    "    #return [txt for txt,sz in zip(docx_json['full_text'],docx_json['font_sizes']) if sz > most_common_font_]\n",
    "    return [txt for txt,sz in zip(docx_json['full_text'],docx_json['font_sizes']) if sz > most_common_font_],[i for i,(txt,sz) in enumerate(zip(docx_json['full_text'],docx_json['font_sizes'])) if sz > most_common_font_]\n",
    "\n",
    "\"\"\"def get_txt_bigger(docx_json):\n",
    "    most_common_font_ = mode(docx_json['font_sizes'])\n",
    "    tmp_indexes = [i for i,sz in enumerate(docx_json['font_sizes']) if sz > most_common_font_]\n",
    "    tmp_font_sizes = docx_json['font_sizes'][tmp_indexes]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_firstfive_doc = read_italic_bold_docx('../data/raw/pdf/7kLHJ-F33GI/statistics_firstfive.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_firstfive_doc_bigger,statistics_firstfive_doc_bigger_indexes = get_txt_bigger(statistics_firstfive_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#statistics_firstfive_doc_bigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_txt_biggest(docx_json):\n",
    "    max_common_font_ = max(docx_json['font_sizes'])\n",
    "    return [txt for txt,sz in zip(docx_json['full_text'],docx_json['font_sizes']) if sz == max_common_font_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An Introduction to',\n",
       " 'Statistics',\n",
       " 'Contents',\n",
       " 'Descriptive Statistics',\n",
       " 'Graphs and Displays',\n",
       " 'Probability',\n",
       " 'Probability Distributions',\n",
       " 'The Population Mean',\n",
       " 'Index']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_txt_biggest(statistics_firstfive_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_chapters_format_first_five(statistics_firstfive_doc_bigger,key_word_ = 'Chapter'):\n",
    "    topic_titles = []\n",
    "    p_subsection = re.compile(r'((\\d\\.)+\\d*\\t[A-Za-z0-9? ]+)')\n",
    "    p_Start_Section = re.compile('{} \\d?'.format(key_word_))\n",
    "    for i,doc in enumerate(statistics_firstfive_doc_bigger):\n",
    "        matching = p_Start_Section.match(doc)\n",
    "\n",
    "        if matching is not None:\n",
    "            topic_titles.append(statistics_firstfive_doc_bigger[i+1])\n",
    "\n",
    "        matching = p_subsection.match(doc)\n",
    "        if matching is not None:            \n",
    "            topic_titles.append(doc)\n",
    "    return topic_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters_first_five = find_chapters_format_first_five(statistics_firstfive_doc_bigger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_chapters_format_statbooks(lines,key_word_ = 'Chapter'):\n",
    "    topic_titles = []\n",
    "    p_Start_Section = re.compile('{} \\d?'.format(key_word_))\n",
    "    p_subsection = re.compile(r'^((\\d+\\.)+\\d*)$')\n",
    "    p_words = re.compile('[A-Za-z]+')\n",
    "    new_lines = []\n",
    "    for i,doc in enumerate(lines):\n",
    "        matching = p_Start_Section.match(doc)\n",
    "\n",
    "        if matching is not None:\n",
    "            topic_titles.append(lines[i+1])\n",
    "\n",
    "        matching = p_subsection.match(doc)\n",
    "        if matching is not None:\n",
    "            matching = p_words.match(lines[i+1])\n",
    "            if matching is not None:\n",
    "                #lines[i:i+1] = [''.join(lines[i:i+1])]\n",
    "                #topic_titles.append(lines[i])\n",
    "                new_title = (\"%s %s\" %(lines[i],lines[i+1]))\n",
    "                topic_titles.append(new_title)\n",
    "                new_lines.append(new_title)\n",
    "        new_lines.append(doc)\n",
    "    return topic_titles,new_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_statbook_doc = read_italic_bold_docx('../data/raw/pdf/7kLHJ-F33GI/statbook.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Displaying Data',\n",
       " '1.1 Types of Data',\n",
       " '1.2 Categorical Data',\n",
       " '1.2.1 Pie Chart',\n",
       " '1.2.2 Bar Charts',\n",
       " '1.3 Two-way Tables',\n",
       " '1.4 Histograms and the Empirical Cumulative Distribution Function',\n",
       " '1.5 Scatterplots',\n",
       " '1.6 Time Plots',\n",
       " '1.7 Answers to Selected Exercises',\n",
       " 'Describing Distributions with Numbers',\n",
       " '2.1 Measuring Center',\n",
       " '2.1.1 Medians',\n",
       " '2.1.2 Means',\n",
       " '2.2 Measuring Spread',\n",
       " '2.2.1 Five Number Summary',\n",
       " '2.2.2 Sample Variance and Standard Deviation',\n",
       " '2.3 Quantiles and Standardized Variables',\n",
       " '2.4 Quantile-Quantile Plots',\n",
       " '2.5 Answers to Selected Exercises',\n",
       " 'Correlation and Regression',\n",
       " '3.1 Covariance and Correlation',\n",
       " '3.2 Linear Regression',\n",
       " '3.2.1 Transformed Variables',\n",
       " '3.3 Extensions',\n",
       " '3.3.1 Nonlinear Regression',\n",
       " '3.3.2 Multiple Linear Regression',\n",
       " '3.4 Answers to Selected Exercises',\n",
       " 'Producing Data',\n",
       " '4.1 Preliminary Steps',\n",
       " '4.2 Professional Ethics',\n",
       " '4.3 Formal Statistical Procedures',\n",
       " '4.3.1 Observational Studies',\n",
       " '4.3.2 Randomized Controlled Experiments',\n",
       " '4.3.3 Natural experiments',\n",
       " '4.4 Case Studies',\n",
       " '4.4.1 Observational Studies',\n",
       " '4.4.2 Experiments',\n",
       " 'The Basics of Probability',\n",
       " '5.2 Equally Likely Outcomes and the Axioms of Probability',\n",
       " '5.3 Consequences of the Axioms',\n",
       " '5.4 Counting',\n",
       " '5.4.1 Fundamental Principle of Counting',\n",
       " '5.4.2 Permutations',\n",
       " '5.4.3 Combinations',\n",
       " '5.5 Answers to Selected Exercises',\n",
       " 'Conditional Probability and Independence',\n",
       " '6.1 Restricting the Sample Space - Conditional Probability',\n",
       " '6.3 The Law of Total Probability',\n",
       " '6.4 Bayes formula',\n",
       " 'Random Variables and Distribution Functions',\n",
       " '7.2 Distribution Functions',\n",
       " '7.3 Properties of the Distribution Function',\n",
       " '7.3.1 Discrete Random Variables',\n",
       " '7.3.2 Continuous Random Variables',\n",
       " '7.4 Mass Functions',\n",
       " '7.5 Density Functions',\n",
       " '7.7 Joint and Conditional Distributions',\n",
       " '7.7.1 Discrete Random Variables',\n",
       " '7.7.2 Continuous Random Variables',\n",
       " '7.7.3 Independent Random Variables',\n",
       " '7.8 Simulating Random Variables',\n",
       " '7.8.1 Discrete Random Variables and the sample Command',\n",
       " '7.8.2 Continuous Random Variables and the Probability Transform',\n",
       " '7.9 Answers to Selected Exercises',\n",
       " 'The Expected Value',\n",
       " '8.1 Definition and Properties',\n",
       " '8.2 Discrete Random Variables',\n",
       " '8.5 Summary',\n",
       " '8.8.1 Equivalent Conditions for Independence',\n",
       " '8.9 Quantile Plots and Probability Plots',\n",
       " '8.10 Answers to Selected Exercises',\n",
       " 'Examples of Mass Functions and Densities',\n",
       " '9.1 Examples of Discrete Random Variables',\n",
       " '9.2 Examples of Continuous Random Variables',\n",
       " '9.3 More on Mixtures',\n",
       " '9.4 R Commands',\n",
       " '9.5 Summary of Properties of Random Variables',\n",
       " '9.5.1 Discrete Random Variables',\n",
       " '9.6 Answers to Selected Exercises',\n",
       " 'The Law of Large Numbers',\n",
       " '10.3 Importance Sampling',\n",
       " '10.4 Answers to Selected Exercises',\n",
       " 'The Central Limit Theorem',\n",
       " '11.2 The Classical Central Limit Theorem',\n",
       " '11.2.1 Bernoulli Trials and the Continuity Correction',\n",
       " '11.5 Summary of Normal Approximations',\n",
       " '11.5.1 Sample Sum',\n",
       " '11.5.3 Sample Proportion',\n",
       " '11.5.4 Delta Method',\n",
       " '11.6 Answers to Selected Exercises',\n",
       " 'Overview of Estimation',\n",
       " '12.2 Classical Statistics',\n",
       " '12.3 Bayesian Statistics',\n",
       " '12.4 Answers to Selected Exercises',\n",
       " 'Method of Moments',\n",
       " '13.2 The Procedure',\n",
       " '13.3 Examples',\n",
       " 'Unbiased Estimation',\n",
       " '14.2 Computing Bias',\n",
       " '14.3 Compensating for Bias',\n",
       " '14.4 Consistency',\n",
       " '14.5 Cramer´-Rao Bound',\n",
       " '14.6 A Note on Exponential Families and Efficient Estimators',\n",
       " '14.7 Answers to Selected Exercises',\n",
       " 'Maximum Likelihood Estimation',\n",
       " '15.2 Examples',\n",
       " '15.3 Summary of Estimators',\n",
       " '15.4 Asymptotic Properties',\n",
       " '15.5 Comparison of Estimation Procedures',\n",
       " '15.6 Multidimensional Estimation',\n",
       " '15.7 The Case of Exponential Families',\n",
       " '15.8 Choice of Estimators',\n",
       " '15.9 Technical Aspects',\n",
       " '15.10 Answers to Selected Exercises',\n",
       " 'Interval Estimation',\n",
       " '16.1 Classical Statistics',\n",
       " '16.1.1 Means',\n",
       " '16.1.2 Linear Regression',\n",
       " '16.1.3 Sample Proportions',\n",
       " '16.1.4 Summary of Standard Confidence Intervals',\n",
       " '16.1.5 Interpretation of the Confidence Interval',\n",
       " '16.1.6 Extensions on the Use of Confidence Intervals',\n",
       " '16.2 The Bootstrap',\n",
       " '16.3 Bayesian Statistics',\n",
       " '16.4 Answers to Selected Exercises',\n",
       " 'Simple Hypotheses',\n",
       " '17.1 Overview and Terminology',\n",
       " '17.2 The Neyman-Pearson Lemma',\n",
       " '17.2.1 The Receiver Operating Characteristic',\n",
       " '17.3 Examples',\n",
       " '17.4 Summary',\n",
       " '17.5 Proof of the Neyman-Pearson Lemma',\n",
       " '17.6 An Brief Introduction to the Bayesian Approach',\n",
       " '17.7 Answers to Selected Exercises',\n",
       " 'Composite Hypotheses',\n",
       " '18.1 Partitioning the Parameter Space',\n",
       " '18.2 The Power Function',\n",
       " '18.3 The p-value',\n",
       " '18.4 Distribution of p-values and the Receiving Operating Characteristic',\n",
       " '18.5 Multiple Hypothesis Testing',\n",
       " '18.5.1 Familywise Error Rate',\n",
       " '18.5.2 False Discovery Rate',\n",
       " '18.6 Answers to Selected Exercises',\n",
       " 'Extensions on the Likelihood Ratio',\n",
       " '19.1 One-Sided Tests',\n",
       " '19.2 Likelihood Ratio Tests',\n",
       " '19.3 Chi-square Tests',\n",
       " '19.4 Answers to Selected Exercises',\n",
       " 'Procedures',\n",
       " '20.1 Guidelines for Using the t Procedures',\n",
       " '20.2 One Sample t Tests',\n",
       " '20.3 Correspondence between Two-Sided Tests and Confidence Intervals',\n",
       " '20.4 Matched Pairs Procedures',\n",
       " '20.5 Two Sample Procedures',\n",
       " '20.6 Summary of Tests of Significance',\n",
       " '20.6.1 General Guidelines',\n",
       " '20.6.2 Test for Population Proportions',\n",
       " '20.6.3 Test for Population Means',\n",
       " '20.7 A Note on the Delta Method',\n",
       " '20.8 The t Test as a Likelihood Ratio Test',\n",
       " '20.9 Non-parametric alternatives',\n",
       " '20.9.1 Permutation Test',\n",
       " '20.9.2 Mann-Whitney or Wilcoxon Rank Sum Test',\n",
       " '20.9.3 Wilcoxon Signed-Rank Test',\n",
       " '20.10 Answers to Selected Exercises',\n",
       " 'Goodness of Fit',\n",
       " '21.2 Contingency tables',\n",
       " '21.3 Applicability and Alternatives to Chi-squared Tests',\n",
       " '21.4 Answer to Selected Exercise',\n",
       " 'Analysis of Variance',\n",
       " '22.1 Overview',\n",
       " '22.2 One Way Analysis of Variance',\n",
       " '22.3 Contrasts',\n",
       " '22.4 Two Sample Procedures',\n",
       " '22.5 Kruskal-Wallis Rank-Sum Test',\n",
       " '22.6 Answer to Selected Exercises']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics_statbook_doc_bigger,statistics_statbook_doc_bigger_indexes = get_txt_bigger(statistics_statbook_doc)\n",
    "chapter_statistics_statbook,new_lines_statistics_statbook = find_chapters_format_statbooks(statistics_statbook_doc_bigger,key_word_='Topic')\n",
    "chapter_statistics_statbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An Introduction to',\n",
       " 'Statistics',\n",
       " 'Keone Hon',\n",
       " '<',\n",
       " '>',\n",
       " 'Contents',\n",
       " 'Chapter 1',\n",
       " 'Descriptive Statistics',\n",
       " '1.1\\tDescriptive vs. Inferential',\n",
       " '1.2\\tMeans, Medians, and Modes',\n",
       " '1.3\\tVariability',\n",
       " '2',\n",
       " '2',\n",
       " '1.4\\tLinear Transformations',\n",
       " 't',\n",
       " 't',\n",
       " '1',\n",
       " '2',\n",
       " 'n',\n",
       " '1',\n",
       " '2',\n",
       " 'n',\n",
       " 'a',\n",
       " '+',\n",
       " 'a',\n",
       " '+',\n",
       " '· · ·',\n",
       " '+',\n",
       " 'a',\n",
       " '+',\n",
       " 'cn',\n",
       " '=',\n",
       " 'µ',\n",
       " '+',\n",
       " 'c',\n",
       " 't',\n",
       " 'a',\n",
       " '+',\n",
       " 'a',\n",
       " '+',\n",
       " '+',\n",
       " 'a',\n",
       " '·',\n",
       " 'c',\n",
       " '=',\n",
       " 'µ',\n",
       " '·',\n",
       " 'c',\n",
       " '1.5\\tPosition',\n",
       " '1.6\\tDispersion Percentages',\n",
       " '1',\n",
       " '6',\n",
       " 'k',\n",
       " '1',\n",
       " '15−20.6',\n",
       " '1.75',\n",
       " '1',\n",
       " 'Chapter 2',\n",
       " 'Graphs and Displays',\n",
       " '2.1\\tHistograms',\n",
       " '2.1.1\\tIntroduction',\n",
       " '21',\n",
       " 'x',\n",
       " '2.1.2\\tMedians, Modes, and Means Revisited',\n",
       " '2.1.3\\tz-Scores and Percentile Ranks Revisited',\n",
       " '2.2\\tStem and Leaf Displays',\n",
       " '2.3\\tFive Number Summaries and Box and Whisker Displays',\n",
       " 'Chapter 3',\n",
       " 'Probability',\n",
       " '3.1\\tIntroduction',\n",
       " '0',\n",
       " 'n',\n",
       " 'k',\n",
       " '3.2\\tRandom Variables',\n",
       " '3.2.1\\tDefinition',\n",
       " '1',\n",
       " '5',\n",
       " '1',\n",
       " '3',\n",
       " '1',\n",
       " '6',\n",
       " '20',\n",
       " '1',\n",
       " '1',\n",
       " '3',\n",
       " '3.2.2\\tExpected Value',\n",
       " '1',\n",
       " '2',\n",
       " 'n',\n",
       " '1',\n",
       " '2',\n",
       " 'n',\n",
       " '3.2.3\\tVariance and Standard Deviation',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '3.2.4\\t“Shortcuts” for Binomial Random Variables',\n",
       " '2',\n",
       " 'Chapter 4',\n",
       " 'Probability Distributions',\n",
       " '4.1\\tBinomial Distributions',\n",
       " '2',\n",
       " '4.2\\tPoisson Distributions',\n",
       " '4.2.1\\tDefinition',\n",
       " '4.2.2\\tAs an Approximation to the Binomial',\n",
       " '1',\n",
       " '6',\n",
       " '120',\n",
       " '10',\n",
       " '4.3\\tNormal Distributions',\n",
       " '4.3.1\\tDefinition and Properties',\n",
       " '4.3.2\\tTable of Normal Curve Areas',\n",
       " '$2.75',\n",
       " '−',\n",
       " '$2.00',\n",
       " '$1.75',\n",
       " '−',\n",
       " '$2.00',\n",
       " '$1.13',\n",
       " '−',\n",
       " '$2.00',\n",
       " '$3.20',\n",
       " '−',\n",
       " '$2.00',\n",
       " '$3.15',\n",
       " '−',\n",
       " '$2.00',\n",
       " '4.3.3\\tWorking Backwards',\n",
       " '4.3.4\\tAs an Approximation to the Binomial',\n",
       " '69.5−62.7',\n",
       " 'Chapter 5',\n",
       " 'The Population Mean',\n",
       " '5.1\\tThe Distribution of Sample Means',\n",
       " 'n',\n",
       " '5.2\\tConfidence Interval Estimatess',\n",
       " 'x',\n",
       " 'x',\n",
       " '5.3\\tChoosing a Sample Size',\n",
       " 'x',\n",
       " 'x',\n",
       " 'n',\n",
       " 'x',\n",
       " 'n',\n",
       " 'x',\n",
       " '5.4\\tThe Hypothesis Test',\n",
       " '0',\n",
       " 'a',\n",
       " '◦',\n",
       " '◦',\n",
       " '0',\n",
       " 'a',\n",
       " '◦',\n",
       " '◦',\n",
       " '5.5\\tMore on Errors',\n",
       " '5.5.1\\tType I Errors and ',\n",
       " 'α',\n",
       " '-Risks',\n",
       " '2',\n",
       " '5.5.2\\tType II Errors and ',\n",
       " 'β',\n",
       " '-Risks',\n",
       " '5.6\\tComparing Two Means',\n",
       " '5.6.1\\tConfidence Interval Estimates',\n",
       " '1',\n",
       " '2',\n",
       " 'Index']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the indexes of the titles\n",
    "statistics_firstfive_doc_bigger_indexes\n",
    "statistics_firstfive_doc_bigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_index_statistics_firstfive = [statistics_firstfive_doc['full_text'].index(ch) for ch in chapters_first_five]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' An Introduction to. Statistics. Keone Hon. <. >. Contents. 1. 2. Chapter 1',\n",
       " ' Descriptive Statistics',\n",
       " ' 1.1\\tDescriptive vs. Inferential. There are two main branches of statistics: descriptive and inferential. Descrip-tive statistics is used to say something about a set of information that has been collected only. Inferential statistics is used to make predictions or comparisons about a larger group (a population) using information gathered about a small part of that population. Thus, inferential statistics involves generalizing beyond the data, something that descriptive statistics does not do.. Other distinctions are sometimes made between data types.. Discrete data are whole numbers, and are usually a count of objects. (For instance, one study might count how many pets diﬀerent families own; it wouldn’t make sense to have half a goldfish, would it?). Measured data, in contrast to discrete data, are continuous, and thus may take on any real value. (For example, the amount of time a group of chil-dren spent watching TV would be measured data, since they could watch any number of hours, even though their watching habits will probably be some multiple of 30 minutes.). Numerical data are numbers.. Categorical data have labels (i.e. words). (For example, a list of the prod-ucts bought by diﬀerent families at a grocery store would be categorical data, since it would go something like {milk, eggs, toilet paper, . . . }.)',\n",
       " ' 1.2\\tMeans, Medians, and Modes. In everyday life, the word “average” is used in a variety of ways - batting averages, average life expectancies, etc. - but the meaning is similar, usually. 3. the center of a distribution. In the mathematical world, where everything must be precise, we define several ways of finding the center of a set of data:. Definition 1: median.. The median is the middle number of a set of numbers arranged in numerical order. If the number of values in a set is even, then the median is the sum of the two middle values, divided by 2.. The median is not aﬀected by the magnitude of the extreme (smallest or largest) values. Thus, it is useful because it is not aﬀected by one or two abnormally small or large values, and because it is very simple to calculate. (For example, to obtain a relatively accurate average life of a particular type of lightbulb, you could measure the median life by installing several bulbs and measuring how much time passed before half of them died. Alternatives would probably involve measuring the life of each bulb.). Definition 2: mode.. The mode is the most frequent value in a set. A set can have more than one mode; if it has two, it is said to be bimodal.. ——————————–. Example 1:. The mode of {1, 1, 2, 3, 5, 8} is 1.. The modes of {1, 3, 5, 7, 9, 9, 21, 25, 25, 31} are 9 and 25. Thus, the set is bimodal.. ——————————–. The mode is useful when the members of a set are very diﬀerent - take, for example, the statement “there were more Ds on that test than any other letter grade” (that is, in the set {A, B, C, D, E}, D is the mode). On the other hand, the fact that the mode is absolute (for example, 2.9999 and 3 are considered just as diﬀerent as 3 and 100 are) can make the mode a poor choice for determing a “center”. For example, the mode of the set {1, 2.3, 2.3, 5.14, 5.15, 5.16, 5.17, 5.18, 10.2} is 2.3, even though there are many values that are close to, but not exactly equal to, 5.16.. Definition 3: mean.. The mean is the sum of all the values in a set, divided by the number of values. The mean of a whole population is usually denoted by µ, while the mean of a sample is usually denoted by x. (Note that this is the arithmetic mean; there are other means, which will be discussed later.). . 4. . The mean is sensitive to . any.  change in value, unlike the median and mode, where a change to an extreme (in the case of a median) or uncommon (in the case of a mode) value usually has no eﬀect.. One disadvantage of the mean is that a small number of extreme values can distort its value. For example, the mean of the set . {. 1, 1, 1, 2, 2, 3, 3, 3, 200. }.  is 24, even though almost all of the members were very small. A variation called the . trimmed mean. , where the smallest and largest quarters of the values are removed before the mean is taken, can solve this problem.',\n",
       " ' 1.3\\tVariability. Definition 4: range. .. The range is the diﬀerence between the largest and smallest values of a set.. The range of a set is simple to calculate, but is not very useful because it depends on the extreme values, which may be distorted. An alternative form, similar to the trimmed mean, is the interquartile range, or IQR, which is the range of the set with the smallest and largest quarters removed. If Q1 and Q3 are the medians of the lower and upper halves of a data set (the values that split the data into quarters, if you will), then the IQR is simply Q3 . −.  Q1.. The IQR is useful for determining outliers, or extreme values, such as the element . {. 200. }.  of the set at the end of section . . An outlier is said to be a number more than 1.5 IQRs below Q1 or above Q3.. Definition 5: variance. .. The variance is a measure of how items are dispersed about their mean. The variance σ. 2.  of a whole population is given by the equation. . The variance s. 2.  of a sample is calculated diﬀerently:. . Definition 6: standard deviation. .. The standard deviation σ (or s for a sample) is the square root of the variance. (Thus, for a population, the standard deviation is the. 5. square root of the average of the squared deviations from the mean. For a sample, the standard deviation is the square root of the sum of the squared deviations from the mean, divided by the number of samples minus 1. Try saying that five times fast.). Definition 7: relative variability.. The relative variability of a set is its standard deviation divided by its mean. The relative variability is useful for comparing several variances.',\n",
       " ' 1.4\\tLinear Transformations. A linear transformation of a data set is one where each element is increased by or multiplied by a constant. This aﬀects the mean, the standard deviation, the . IQR. , and other important numbers in diﬀerent ways.. Addition. If a constant . c.  is added to each member of a set, the mean will be . c.  more than it was before the constant was added; the standard deviation and variance will not be aﬀected; and the . IQR.  will not be aﬀected. We will prove these facts below, letting . µ.  and . σ.  be the mean and standard deviation, respectively, before adding . c. , and . µ. t.  and . σ. t.  be the mean and standard devia-tion, respectively, after the transformation. Finally, we let the original set be {. a. 1. , a. 2. , . . . , a. n. }, so that the transformed set is {. a. 1.  + . c, a. 2.  + . c, . . . , a. n.  + . c. }.. . a. 1 . +.  . a. 2 . +.  . · · ·.  . +.  . a. n . +.  . cn.  . =.  . µ.  . +.  . c. nn. . where we use the result of the first equation to replace . µ. t.  with . µ. +. c.  in the second equation. Since the variance is just the square of the standard deviation, the fact that the standard deviation is not aﬀected means that the variance won’t be, either.. Multiplication.. Another type of transformation is multiplication. If each member of a set is multiplied by a constant . c. , then the mean will be . c.  times its value before the constant was multiplied; the standard deviation will be |. c. | times its value before. 6. the constant was multiplied; and the . IQR.  will be |. c. | times its value. Using the same notation as before, we have. . a. 1 . +.  . a. 2 . +.  . · · ·.  . +.  . a. n . ·.  . c.  . =.  . µ.  . ·.  . c.  . n. ',\n",
       " ' 1.5\\tPosition. There are several ways of measuring the relative position of a specific member of a set. Three are defined below:. Definition 8: simple ranking.. As the name suggests, the simplest form of ranking, where objects are arranged in some order and the rank of an object is its position in the order.. Definition 9: percentile ranking.. The percentile ranking of a specific value is the percent of scores/values that are below it.. Definition 10: z-score.. The z-score of a specific value is the number of standard deviations it is from the mean. Thus, the . z. -score of a value . x.  is given by the equation. . ——————————–. Example 2:. In the set of grade point averages {1.1, 2.34, 2.9, 3.14, 3.29, 3.57, 4.0}, the value 3.57 has the simple ranking of 2 out of 7 and the percentile ranking of. 7. ——————————–. Conversely, if given a . z. -score, we can find a corresponding value, using the equation. ——————————–. Example 3:. The citizens of Utopia work an average (mean) of 251 days per year, with a standard deviation of 20 days. How many days correspond to a . z. -score of 2.3?. Since each . z.  corresponds to one standard deviation, a . z. -score of 2.3 means that the desired value is 2.3 standard deviations more than the mean, or 251 + 2. .. 3 · 20 = 297.. ——————————–',\n",
       " ' 1.6\\tDispersion Percentages. Theorem 1: empirical rule. For data with a “bell-shaped” graph, about 68% of the values lie within one standard deviation of the mean, about 95% lie withing two standard deviations, and over 99% lie within three standard deviations of the mean.. Note that since 99% of the data fall within a span of six standard deviations (. z. -scores of -3 to +3), the standard deviation of a set of values that are somewhat bell-shaped should be about . 1. 6.  of the range. This can be useful in checking for arithmetic errors.. Theorem 2: Chebyshev’s Theorem. For any set of data, at least 1− . k. 1. 2.  of the values lie within . k.  standard deviations of the mean (that is, have . z. -scores between −. k.  and +. k. ).. . ——————————–. Example 4:. Matt reads at an average (mean) rate of 20.6 pages per hour, with a standard deviation of 3.2. What percent of the time will he read between 15 and 26.2 pages per hour?. 8. 15 pages per hour corresponds to a z-score of . 15−20.6.  = −1.75, and 26.2 pages. 3.2. per hour corresponds to a z-score of . 26.2−20.6.   = 1.75. Chebyshev’s Theorem. 3.2. says that 1 − . 1.75. 1. 2.  = .673 of the values will be within 1.75 standard deviations, so 67.3% of the time, Matt’s reading speed will be between 15 and 26.2 pages per hour.. . ——————————–. 9. Chapter 2',\n",
       " ' Graphs and Displays',\n",
       " ' 2.1\\tHistograms',\n",
       " ' 2.1.1\\tIntroduction. Definition 11: histogram.. A histogram is a graphical representation of data, where relative frequencies are represented by relative areas. A histogram’s height at a specific point represents the relative frequency of a certain item.. A histogram is similar to a bar graph, except the sides of the bars are widened until there is no space between bars:. . A histogram isn’t limited to displaying frequencies. The y-axis (vertical axis) may labeled with relative frequencies. To determine relative frequency, we use the simple formula. In the example we used above, the total is 3 + 1 + 4 + 1 + 5 + 4 + 2 + 3 = 23, so the relative frequencies are as follows:. 10. x-value\\tfrequency. \\t. relative frequency. . 33/23 ≈ .13. 11/23 ≈ .04. 44/23 ≈ .17. 11/23 ≈ .04. 55/23 ≈ .22. 44/23 ≈ .17. 22/23 ≈ .09. 33/23 ≈ .13. The resulting histogram is shown below. Note that it has the same shape as the histogram labeled with actual frequencies. This is true in general.. . If we were given a histogram with an unlabeled y-axis, we could still determine the relative frequencies of the items because the relative frequency is equal to the fraction of the total area that a certain column covers.. ——————————–. Example 5:. Determine the relative frequency of items A-H using the histogram below:. . We cut the histogram up into rectangles of equal area:. 11. . There are 21 rectangles in all. So if an item has an area of x rectangles, it will have relative frequency . 21. x.  .. . . 55/21 ≈ .24. 33/21 ≈ .14. 11/21 ≈ .05. 11/21 ≈ .05. 44/21 ≈ .19. 33/21 ≈ .14. ——————————–',\n",
       " ' 2.1.2\\tMedians, Modes, and Means Revisited. Histograms can be used to show the median, mode, and mean of a distribution. Since the mode is the most frequent value, it is the point on the histogram where the graph is highest. Since the median is in the middle of a distribution (so it divides the distribution in half), it may be represented by the line that divides the area of the histogram in half. Finally, the mean is a line that passes through the center of gravity of the histogram.. If the mean is less than the median, then the distribution is said to be skewed to the left. It will be spread widely to the left. Here is an example of a distribution that is skewed to the left:. . 12. Conversely, if the mean is greater than the median, then the distribution is skewed to the right, and it will be spread widely to the right. Here is an example of a distribution that is skewed to the right:. ',\n",
       " ' 2.1.3\\tz-Scores and Percentile Ranks Revisited. Earlier, we exchanged frequency for relative frequency on the vertical axis of a histogram. In the same spirit, we can label the horizontal axis in terms of z-scores rather than with the names of the items in the set.. One common way that data is given is through percentile rankings. With this information, we can construct a histogram:. ——————————–. Example 6:. Construct a histogram using the following data:. . 50. 80. 95. 100. From −∞to − 3, the relative frequency is 0.05. From −3 to −2, the relative frequency increases from 0.05 to 0.15, so the relative frequency at between −3 and −2 is 0.1. From −2 to −1, the relative frequency increases from 0.15 to 0.3, so the relative frequency between the two is 0.15. Using similar reasoning, we obtain the following:. 13. Plotting these values on a histogram, we obtain. . ——————————–',\n",
       " ' 2.2\\tStem and Leaf Displays. A stem and leaf display is similar to a histogram, since it shows how many values in a set fall under a certain interval. However, it has even more information - it shows the actual values within the interval. The following example demonstrates a stem and leaf display:. ——————————–. Example 7:. Here is a stem and leaf display of the set {10, 14, 19, 22, 25, 25, 28, 31, 33, 39, 39, 40, 40, 40, 41, 44, 45}:. . Stems\\tLeaves. 0 4 9. 22558. 31399. 4000145. ——————————–. If we draw a line around the stem and leaf display, the result is a histogram, albeit one whose orientation is diﬀerent from the kind we are used to seeing:. 14. . The stems and leaves need not be single digits, although all leaves should be the same size in order to make the display accurate.',\n",
       " ' 2.3\\tFive Number Summaries and Box and Whisker Displays. The five-number summary is a group of five numbers that help describe the shape and variation of a distribution. These five numbers are Q2, the median of the set; Q1, the median of the lower half of the set; Q3, the median of the upper half of the set, and the maximum and minimum numbers that are not outliers. (See section . for the definition of an outlier.). The box and whisker display is a graphical representation of the five-number summary. Horizontal lines are drawn at Q1, Q2, and Q3; a box is then drawn around these lines, forming a double box with a shared side. Two perpendicular lines (”whiskers”) are drawn from the top and bottom of the box to the max-imum and minimum non-outliers. Any outliers are then plotted as individual points.. The diagram below shows the basic box and whisker format.. . Note that because a median splits a set in half, the top whisker represents the top quarter, the top box represents the second quarter, the bottom box represents the third quarter, and the bottom whisker represents the bottom quarter.. 15. Chapter 3',\n",
       " ' Probability',\n",
       " ' 3.1\\tIntroduction. Definition 12: probability.. The probability of a specific event is a mathematical statement about the likelihood that it will occur. All probabilities are numbers be-tween 0 and 1, inclusive; a probability of 0 means that the event will never occur, and a probability of 1 means that the event will always occur.. The sum of the probabilities of all possible outcomes of any event is 1. (This is because something will happen, so the probability of some outcome occurring is 1.). Definition 13: complimentary event.. With respect to an event E, the complimentary event, denoted E. 0. , is the event that E does not occur. For example, consider the event that it will rain tomorrow. The compliment of this event is the event that it will not rain tomorrow.. Since an event must either occur or not occur, from above, it must be the case that. Definition 14: mutually exclusive.. Two or more events are mutually exclusive if they cannot occur simultaneously.. Two events A and B are mutually exclusive if A . ∪.  B = 0 - that is, if they have no members in common.. 16. ——————————–. Example 8:. Let A = the event that it is Monday, B = the event that it is Tuesday, and C = the event that it is the year 2004.. A and B are mutually exclusive events, since it cannot be both Monday and Tuesday at the same time. A and C are not mutually exclusive events, since it can be a Monday in the year 2004.. ——————————–. Theorem 3: Principle of Inclusion and Exclusion. Recall that when two events A and B are mutually exclusive P (A ∩ B) = 0. Using this fact and the Principle of Inclusion and Exclusion (PIE), we conclude that when two events are mutually exclusive, the probability that both of them will occur (P (A . ∪.  B)) is P (A) + P (B).. Definition 15: independent.. Two events are said to be independent if the chance that each one occurs is not aﬀected by the outcome of any of the others.. ——————————–. Example 9:. Suppose that two dice are rolled. The outcome of either die will not aﬀect the outcome of the other die, so the two dice are independent. On the other hand, the event that John Kerry will become president of the U.S. and the event that John Edwards will become vice president are not independent, since the two are (were?) running mates, so if one is elected, so is the other.. ——————————–. Theorem 4: Independence Principle. If two events are independent, then the probability that both will occur is equal to the product of their individual probabilities. In other words, if A and B are independent, then. 17. Definition 16: factorial.. The factorial of an integer n is defined as the product of all the positive integers from 1 to n, that is. n!. \\t. (read “n factorial”) = n · (n − 1) · (n − 2) · · · 3 · 2 · 1\\t(3.4). 0! is defined to be 1.. Definition 17: combination.. A combination is a set of unordered (i.e. order does not matter) items. If we are to choose k distinct objects from a total of n objects, then there are . n. k.  diﬀerent combinations, where. Formula 1: Binomial Formula. Suppose that an event occurs with probability p. Then the prob-ability that it will occur exactly x times out of a total of n trials is. ——————————–. Example 10:. Derive a formula for calculating P(x) (the probability of x successes out of n trials, where the probability of each success is p) in terms of x, n, p, and P (x−1).. The probability of x − 1 successes is, using the binomial formula,. The probability of x successes is, again using the binomial formula,. 18. We want to find an expression K such that P (x − 1) · K = P (x). Thus,. . ——————————–',\n",
       " ' 3.2\\tRandom Variables',\n",
       " ' 3.2.1\\tDefinition. Definition 18: random variable.. A variable that may take on diﬀerent values depending on the out-come of some event.. ——————————–. Example 11:. On the AP Statistics exam, . 1. 5.  of the class received an 5, . 1. 3.  received a 4, . 1. 6.  received a 3, . 20. 1.  received a 2, and . 1. 3.  received an 1. If x represents the score of a randomly chosen student in the class, then x is a random variable that takes the values 1, 2, 3, 4, and 5.. . ——————————–. A random variable may be discrete (it takes on a finite number of values) or continuous (it can take on any value in a certain interval, that is, an infinite number of values).. Definition 19: probability distribution.. A list or formula that gives the probability for each discrete value of a random variable.. 19',\n",
       " ' 3.2.2\\tExpected Value. Definition 20: expected value. .. The expected value (also called the mean) of a random variable is the sum of the product of each possible value and its corresponding probability. In mathematical terms, if the random variable is X, the possible values are x. 1. , x. 2. , . . . x. n. , and the corresponding probabilities are P (x. 1. ), P (x. 2. ), . . . , P (x. n. ) then. ——————————–. Example 12:. Investing in Sharma Furniture Co. has a . 60%.  chance of resulting in a $10,000 gain and a . 40%.  chance of resulting in a $3,000 loss. What is the expected value of investing in Sharma Furniture Co.?. E(X) = .6 . ·.  10000 + .4 . · −. 3000 = 6000 . −.  1200 = 4800. Thus, the expected value is $4,800.. ——————————–',\n",
       " ' 3.2.3\\tVariance and Standard Deviation. Definition 21: variance of a discrete random variable. .. The variance σ. 2.  of a random variable, which takes on discrete values x and has mean µ, is given by the equation. Definition 22: standard deviation of a discrete random vari-able. .. The standard deviation σ of a discrete random variable is equal to. √. . the square root of the variance, i.e. σ =. \\t. σ. 2. .. ——————————–. Example 13:. In a contest sponsored by Hansen sodas, you win a prize if the cap on your bottle of sodas says “WINNER”; however, you may only claim one prize. Eager to win, you blow all your savings on sodas; as a result, you have a 0.05% chance of winning $1,000,000, a 1% chance of winning $20,000, and a 90% chance of winning $10. Ignoring the money you spent on sodas, what is your expected. 20. value and standard deviation?. First, we calculate the mean.. = 1000000 · 0. .. 0005 + 0. .. 01 · 20000 + 0. .. 9 · 10 = 500 + 200 + 9 = 709. Now, the variance.. σ. 2. \\t. =. \\t. 1000000. 2.  · 0. .. 0005 + 20000. 2.  · 0. .. 01 + 10. 2.  · . .. 9 − 709. 2. 500000000 + 4000000 + 90 − 502681. 503497409. Finally, the standard deviation.. √. . =  503497409 ≈ 22438. The standard deviation is over $22,000! Although the expected value looks nice, there’s a good chance that you’ll get a not-so-good amount of money.. ——————————–. 3.2.4\\t“Shortcuts” for Binomial Random Variables. The past examples required a fair amount of arithmetic. To save time, there are simpler ways to find expected values, variances, and standard deviations of binomial random variables (that is, random variables with only two outcomes).. Theorem 5: Mean and Standard Deviation of a Binomial In a situation with two outcomes where the probability of an out-come O is . p.  and there are . n.  trials, the expected number of Os is . np. . That is,. Furthermore, the variance . σ. 2.  is given by the equation. and the standard deviation . σ.  by the equation. p. . σ . =. \\tnp. (1.  . −.  p. ). \\t. (3.12). 21. Chapter 4',\n",
       " ' Probability Distributions',\n",
       " ' 4.1\\tBinomial Distributions. Previously, we computed the probability that a binomial event (one with two possible outcomes for each trial) would occur. In the same way, we can compute the probability of every possible combination of outcomes and create a table or histogram from it.. ——————————–. Example 14:. On a five-item true or false test, Simon has an 80% chance of choosing the cor-rect answer for any of the questions. Find the complete probability distribution for the number of correct answers that Simon can get. Then determine the mean and standard deviation of the probability distribution.. 22. Note that 0. .. 00032 + 0. .. 0064 + 0. .. 0512 + 0. .. 2048 + 0. .. 4096 + 0. .. 32768 = 1.. The expected value may be calculated in two ways: . µ.  = . np.  = 5 · 0. .. 8 = 4 or. = 0 · 0. .. 00032 + 1 · 0. .. 0064 + 2 · 0. .. 0512 + 3 · 0. .. 2048 + 4 · 0. .. 4096 + 5 · 0. .. 32768 = 4. In either case, the answer is the same.. The variance is . σ. 2.  = . np. (1−. p. ) = 5·0. .. 8·(1−0. .. 8) = 0. .. 8, so the standard deviation. √. . is . σ.  =. \\t. 0. .. 8 ≈ 0. .. 894.. ——————————–. Binomial distributions are often used in quality control systems, where a small number of samples are tested out of a shipment, and the shipment is only accepted if the number of defects found among the sampled units falls below a specified number. In order to analyze whether a sampling plan eﬀectively screens out shipments containing a great number of defects and accepts shipments with very few defects, one must calculate the probability that a shipment will be accepted given various defect levels.. ——————————–. Example 15:. A sampling plan calls for twenty units out of a shipment to be sampled. The shipment will be accepted if and only if the number of defective units is less than or equal to one. What is the probability that a shipment with defect level . n.  will be accepted for . n.  = 0. .. 05. ,.  0. .. 10. ,.  0. .. 15. ,.  0. .. 20. ,.  0. .. 25. ,.  0. .. 30?. ——————————–. 23',\n",
       " ' 4.2\\tPoisson Distributions',\n",
       " ' 4.2.1\\tDefinition. Definition 23: Poisson distribution.. In a binomial distribution, when the number of trials n is large and the probability of success p is small, the distribution approaches the Poisson distribution. In the Poisson distribution, the probability of x successes is given by the equation. where µ is the mean.. At first, the requirement that n be large, p be small, and the mean (np) be a known, moderate number seems overly restrictive. However, there are many cases where this occurs. For example, a grocer might sell 5 heads of lettuce each day. It’s impractical to say how many heads of lettuce he didn’t sell, because we do not know how many customers visited his store or how many they could have bought (and there is really no way to determine the latter). However, we can assume that there were many chances for someone to buy a head of lettuce, so n is very large. The chance of someone buying a head of lettuce at any given moment is very small, so p is small. Finally, the mean, 5 heads of lettuce per day, is known. Thus, the Poisson distribution could probably be used to describe this situation.. Here is another application of the Poisson distribution:. ——————————–. Example 16:. The Morgan household gets an average of 3 telephone calls per day. Using the Poisson distribution, find the probability of n phone calls for 0 ≤ n ≤ 6 in one day. Then find the probability of n phone calls in half a day for 0 ≤ n ≤ 3.. 24. Notice that P (0) + P (1) + P (2) + P (3) + P (4) + P (5) + P (6) ≈ 0.96, not 1. This is because there is still a small probability of 7, 8, etc. calls.. In half a day, we can expect an average of 1.5 calls per day. (It’s okay to have a non-integral mean, although it is true that the number of successes, x, must be an integer.) Thus,. ——————————–',\n",
       " ' 4.2.2\\tAs an Approximation to the Binomial. Earlier we stated that the Poisson distribution was useful because it only re-quired knowing the mean. However, even if we do know n and p, we can still use the Poisson distribution as an approximation. In general, if n ≥ 20 and p ≤ 0.05, the approximation will be “close” (of course, “close” is a relative term).. ——————————–. Example 17:. A standard die is rolled 120 times. What is the probability of exactly 10 sixes?. 15? 20? 25?. In this case, we know n (it’s 120) and p (it’s . 1. 6.  ). However, using the binomial formula would require calculating very large and very small numbers - for the first one, . 120. 10.  . (For the record, it’s 116068178638776. Try to remember that!) Instead, we’ll use the Poisson approximation, even though we will sacrifice some accuracy as p 6≤0.05.. 25. ——————————–',\n",
       " ' 4.3\\tNormal Distributions',\n",
       " ' 4.3.1\\tDefinition and Properties. The normal curve is a bell-shaped, symmetrical graph with an infinitely long base. The mean, median, and mode are all located at the center.. . A value is said to be normally distributed if its histogram is the shape of the normal curve. The probability that a normally distributed value will fall between the mean and some z-score z is the area under the curve from 0 to z:. 26. ',\n",
       " ' 4.3.2\\tTable of Normal Curve Areas. The area from the mean to z-score z is given in the table below:. 27. $0.50. ——————————–. Example 18:. The price of a gallon of gasoline at the gasoline stations in Nevada is normally distributed with a mean of $2.00 and a standard deviation of $0.50.. What is the probability that at a randomly chosen gasoline station in Nevada, the price of gasoline will be between $2.00 and $2.75?. The z-score of $2.00 is 0, and the z-score of $2.75 is . $2.75.  . −.  . $2.00.  = 1.5. Ac-. . cording to the table above, the area between 0 and 1.5 is 0.4332 of the total area, so the probability is 0.4332.. What is the probability that at a randomly chosen gasoline station in Nevada, the price of gasoline will be between $1.25 and $2.00?. The z-score of $1.25 is . $1.75.  . −.  . $2.00.  = −1.5, and the z-score of $2.00 is 0. But $0.50. . since the normal curve is symmetric, the area between −1.5 and 0 is the same as the area between 0 and 1.5, which is, as before, 0.4332 of the total area. Thus the probability is also 0.4332.. What percent of the gasoline stations have prices between $1.13 and $3.20?. The z-score of $1.13 is . $1.13.  . −.  . $2.00.  = −1.74, and the z-score of $3.20 is $0.50. . $3.20.  . −.  . $2.00.  = 2.40. The area between -1.74 and 2.40 is equal to the area be-$0.50. . tween -1.74 and 0 plus the area between 0 and 2.40, which is 0.4591 + 0.4918 = 0.9509 ≈ 95.1%.. What is the probability that a randomly chosen gas station will have prices greater than $3.15 per gallon?. The z score of $3.15 is . $3.15.  . −.  . $2.00.  = 2.30. We want to find the probability $0.50. . P (greater than 2.30). But how can we do this? 0 isn’t greater than 2.30, so it appears that we can’t use the probabilities from the above table.. Appearances can be deceiving. First, note that, in terms of z-scores, P (between 0 and 2.30) + P (greater than 2.30) = P (greater than 0). Thus, P (greater than 2.30) = P (greater than 0) - P (between 0 and 2.30).. The probability that the gas station will be between 0 and 2.30 is 0.4893, and the probability that the gas station will be greater than 0 is 0.5, so the probability that the gas station will be greater than 2.30 is 0.5 − 0.4893 = 0.0107. ——————————–. 28',\n",
       " ' 4.3.3\\tWorking Backwards. In the previous examples, we found percentages and probabilities given raw data. We can work in the reverse direction just as easily. For example, suppose we wanted to know what . z. -score 90% of a normal distribution was greater than. Thus, we want 10% to be less than some score . z. , or 40% to be between . z.  and 0. Looking at the table, we see that a . z. -score of 1.28 corresponds to 0.3997, which is very close to 0.4, so . z.  is -1.28. Thus, 90% of the normal distribution has a . z.  score greater than -1.28. Working similarly, we obtain the following facts:. 90% of the normal distribution is between . z. -scores of -1.645 and 1.645.. 95% of the normal distribution is between . z. -scores of -1.96 and 1.96.. 99% of the normal distribution is between . z. -scores of -2.58 and 2.58.. 90% of the normal distribution is less than the . z. -score of 1.28, and 90% of the normal distribution is greater than the . z. -score of -1.28.. 95% of the normal distribution is less than the . z. -score of 1.645, and 95% of the normal distribution is greater than the . z. -score of -1.645.. 99% of the normal distribution is less than the . z. -score of 2.33, and 99% of the normal distribution is greater than the . z. -score of -2.33.. 68.26% of the normal distribution is between . z. -scores of -1 and 1.. 95.44% of the normal distribution is between . z. -scores of -2 and 2.. 99.74% of the normal distribution is between . z. -scores of -3 and 3.. If we do not know the mean or standard deviation, we can also work backward to find it.. ——————————–. Example 19:. A normal distribution has a mean of 36, and 19% of the values are above 50. What is the standard deviation?. Since 0.19 of the distribution is above 50, 0.31 of the distribution is between 36 (the mean) and 50. Looking at the table of normal curve areas, 0.31 corresponds to a . z. -score of 0.88, so 50 is 0.88 standard deviations above the mean. Thus, 50 = 36 + 0. .. 88. σ. , or 0. .. 88. σ.  = 14. Therefore . σ.  = 15. .. 91.. ——————————–. 29',\n",
       " ' 4.3.4\\tAs an Approximation to the Binomial. The normal may also be viewed as a limiting case to the binomial, so we may use it to approximate the value of a binomial for large . n. . However, because the binomial only takes values at integers, whereas the normal is a continuous curve, we will represent an integer value with a unit-long interval centered at that integer. (For example, 4 would be represented by the interval from 3.5 to 4.5.). ——————————–. Example 20:. Shaquille O’Neal averages 0.627 on free throws. What is the probability that out of 100 attempts, he will have made exactly 70 of them?. Then, recalling that we will represent 70 with the interval from 69.5 to 70.5, we. calculate some . z. -scores. The . z. -score of 69.5 is . 69.5−62.7.  = 1. .. 405, and the . z. -score. 4.84. of 70.5 is . 70.5−62.7.  = 1. .. 612. The area from 0 to 1.612 is 0.4463 and the area. 4.84. from 0 to 1.405 is 0.4207, so the final probability is 0. .. 4463 − 0. .. 4207 = 0. .. 0256.. ——————————–. In general, the normal is considered a “good” approximation when both . np.  and . n. (1.  . −.  p. ) are greater than 5.. 30. Chapter 5',\n",
       " ' The Population Mean. Oftentimes it is impossible or impractical to survey an entire population. For example, a manufacturer cannot test every battery, or it wouldn’t have any to sell. Instead, a sample must be taken and tested. This gives birth to many questions: what size sample should be taken to be accurate? How accurate is accurate? How can we ensure that a sample is representative of a population? What conclusions can we draw about the population using the sample? And so on. In this section, we’ll discuss samples and answer some of these questions.',\n",
       " ' 5.1\\tThe Distribution of Sample Means. As mentioned before, we want to estimate a population’s mean by surveying a small sample. If the sample is very small, say it contains one member, then the mean of the sample is unlikely to be a good estimate of the population. As we increase the number of members, the estimate will improve. Thus, bigger sample size generally results in a sample mean that is closer to the population mean.. Similarly, if we survey individual members of a population, their values are unlikely to be normally distributed - individuals can easily throw things oﬀ with widely varying values. However, if we take several samples, then the sample means are likely to be normally distributed, because the individuals in each sample will generally balance each other out.. Theorem 6: Central Limit Theorem. Start with a population with a given mean . µ.  and standard deviation. σ. . Take samples of size.  n. , where.  n . is a suﬃciently large (generally.  . at least 30) number, and compute the mean of each sample.. The set of all sample means will be approximately normally distributed.. 31. • The mean of the set of samples will equal . µ. , the mean of the population.. • The standard deviation, . σ. x. , of the set of sample means will be. . σ. approximately √. n.  .. . ——————————–. Example 21:. Foodland shoppers have a mean $60 grocery bill with a standard deviation of $40. What is the probability that a sample of 100 Foodland shoppers will have a mean grocery bill of over $70?. Since the sample size is greater than 30, we can apply the Central Limit Theo-rem. By this theorem, the set of sample means of size 100 has mean $60 and stan-. . Since the set of sample means of size 100 is normally distributed, we can com-pare a . z. -score of 2.5 to the table of normal curve areas. The area between . z.  = 0 and . z.  = 2. .. 5 is 0.4938, so the probability is 0.5 - 0.4938 = 0.0062.. ——————————–',\n",
       " ' 5.2\\tConfidence Interval Estimatess. We can find the probability that a sample lies within a certain interval of the population mean by using the central limit theorem and the table or normal curve areas. But this is the same as the probability that the population mean lies within a certain interval of a sample. Thus, we can determine how con-fident we are that the population mean lies within a certain interval of a sample mean.. ——————————–. Example 22:. At a factory, batteries are produced with a standard deviation of 2.4 months. In a sample of 64 batteries, the mean life expectancy is 12.35. Find a 95% confidence interval estimate for the life expectancy of all batteries produced at the plant.. Since the sample has . n.  larger than 30, the central limit theorem applies. Let. the standard deviation of the set of sample means of size 64 be . σ. x. . Then by the . σ. x. . central limit theorem, 2. .. 4 = √. \\t. , so . σ. x.  = 0. .. 3 months.. . 64. 32. Looking at the table of normal curve areas (or referring to section . ), 95% of the normal curve area is between the z-scores of -1.96 and 1.96. Since the standard deviation is 0.3, a z-score of . −. 1.96 represents a raw score of -0.588 months, and a z-score of 1.96 represents a raw score of 0.588 months. So we have 95% confidence that the life expectancy will be between 12.35 . −.  0.588 = 11.762 months and 12.35 + 0.588 = 12.938 months.. ——————————–. If we do not know σ (the standard deviation of the entire population), we use s (the standard deviation of the sample) as an estimate for σ. Recall that s is defined as. . where x takes on each individual value, x is the sample mean, and n is the sample size.. ',\n",
       " ' 5.3\\tChoosing a Sample Size. Note that as the degree of confidence increases, the interval must become larger; conversely, as the degree of confidence decreases the interval becomes more precise. This is true in general; if we want to be more sure that we are right, we sacrifice precision, and if we want to be closer to the actual value, we are less likely to be right.. There is a way to improve both the degree of confidence and the precision of the interval: by increasing the sample size. So it seems like greater sample size is always desirable; however, in the real world, increasing the sample size costs time and money.. Generally, we will be asked to find the minimum sample size that will result in a desired confidence level and range.. ——————————–. Example 23:. A machine fills plastic bottles with Mountain Dew brand soda with a standard deviation of 0.04 L. How many filled bottles should be tested to determine the mean volume of soda to an accuracy of 0.01 L with 95% confidence?. σ. Let σ. x.   be the standard deviation of the sample.  Since σ. x.   = . √. n.  , we have. . 0.04L. σ. x.  =. \\t. √. n.  . . Also, since 95% confidence corresponds to.  . z-scores from -1.96 to. . 33. 1.96 on the normal curve, we have 0. .. 01. L.  = . σ. x.  · 1. .. 96. Substituting, we obtain. . . So at least 62 bottles should be tested.. ——————————–',\n",
       " ' 5.4\\tThe Hypothesis Test. Oftentimes we want to determine whether a claim is true or false. Such a claim is called a hypothesis.. Definition 24: null hypothesis.. A specific hypothesis to be tested in an experiment. The null hy-pothesis is usually labeled . H. 0. .. Definition 25: alternative hypothesis.. A hypothesis that is diﬀerent from the null hypothesis, which we usu-ally want to show is true (thereby showing that the null hypothesis is false). The alternative hypothesis is usually labeled . H. a. .. If the alternative involves showing that some value is greater than or less than a number, there is some value . c.  that separates the null hypothesis rejection region from the fail to reject region. This value is known as the critical value.. The null hypothesis is tested through the following procedure:. Determine the null hypothesis and an alternative hypothesis.. Pick an appropriate sample.. Use measurements from the sample to determine the likelihood of the null hypothesis.. Definition 26: Type I error.. If the null hypothesis is true but the sample mean is such that the null hypothesis is rejected, a Type I error occurs. The probability that such an error will occur is the . α.  risk.. 34. Definition 27: Type II error.. If the null hypothesis is false but the sample mean is such that the null hypothesis cannot be rejected, a Type II error occurs. The probability that such an error will occur is called the . β.  risk.. ——————————–. Example 24:. A government report claims that the average temperature on the planet Venus is at least 300. ◦.  C. You don’t believe this - you think the average temperature must be lower - so you carry out an experiment during which you will measure the temperature on Venus at 100 random times, then compute the mean of the measured temperatures. If the mean temperature is over 20. ◦.  C less than the report’s claim, then you will declare the report’s claim false.. Thus, the null hypothesis is . H. 0.  : . T.  = 300 and the alterative hypothesis is . H. a.  . :.  T < . 300. The value.  c . = 280 separates the rejection region from the fail.  . to reject region; that is, if . T <.  280, the null hypothesis will be rejected, and if. ≥ 280, then the null hypothesis will not be rejected.. Suppose that the actual temperature on Venus is indeed 300. ◦.  C (or greater), as the report stated. If the sample mean has . T.  ≥ 280, then the null hypothesis will correctly be accepted. If the sample mean has . T <.  280 then the null hypothesis will incorrectly be rejected; this is a Type I error. On the other hand, if the actual temperature on Venus is less than 300. ◦.  C, but the sample mean has. ≥ 280, then the null hypothesis will incorrectly be accepted; this is a Type II error. If the sample mean has . T <.  280, then the null hypothesis will correctly be rejected.. ——————————–',\n",
       " ' 5.5\\tMore on Errors',\n",
       " ' 5.5.1\\tType I Errors and . α. -Risks. We can calculate the . α. -risk (that is, the probability of a Type I error) by drawing the normal curve assuming that the null hypothesis is true, then determining the area of the region which corresponds to the probability that the test results in the rejection of the null hypothesis.. ——————————–. Example 25:. A school district claims that an average of $7,650 is being spent on each child. 35. each year. The state budget director, suspicious that some of the money allocated to the school district is not being spent on the schools, suspects that the figure is actually smaller. He will measure the exact amount of money spent on 36 students and wil reject the school district’s claim if the average amount spent is less than $7,200. If the standard deviation in amount spent per pupil is $1,200, what is the . α. -risk?. The α-risk is the probability that a Type I error, where the null hypothesis is true but is rejected, so to calculate it, we will look at the case where the null hypothesis . is.  true, i.e. µ = 7650. Since the sample size is over 30, we apply the central limit theorem. The standard deviation of a sample of size. . actual mean, which is 7650.\\tThus, the z-score that corresponds to 7200 is. 7200−7650.  = . −. 450.  = . −. 2.25. The area under the normal curve from . −. 2.25 to 0 is. 200. \\t. 200. 0.4878, so the area of the z-scores less than . −. 2.25 is . −. 0.0122. Thus, the α-risk is . −. 0.0122.. ——————————–. In the previous example, we calculated the α-risk given the critical value(s). However, it is often more useful to determine critical values given an acceptable α-risk level (called the . significance level.  of the test).. After we determine the critical values, it is a simple task to determine whether the sample mean (or, potentially, some other sample statistic) falls in the re-jection range or the fail to reject range. This is how we draw conclusions: by showing that the null hypothesis is improbable.. Definition 28: p-value. .. The p-value of a test is the smallest value of α for which the null hypothesis would be rejected. An alternative definition is the prob-ability of obtaining the experimental result if the null hypothesis is true. Smaller p-values mean more significant diﬀerences between the null hypothesis and the sample result.. ——————————–. Example 26:. A drug company claims that their medication will render a patient unconscious in an average of 5.76 minutes. A researcher decides to test this claim with 300 patients. He obtains the following data: . Σx.  . = 2789.  and . Σ(x.  − . x). 2.  . = 3128. . Should the drug company’s claim be rejected at a level of 10% significance?. . 36. We calculate the sample mean and sample standard deviation as follows:. . A level of 10% significance means that α = 0.1. Recall that a Type I error is one in which the null hypothesis is true but the data causes it to be rejected. So for our purposes, we will consider the case where the null hypothesis is true, and the time it takes to render a patient unconscious is 5.76 minutes. A Type I error will occur either if the sample mean is above or below 5.76, so we must consider both possibilites - this is called a two-sided, or two-tailed, test - the bottom 0.05 and the top 0.05.. According to the table of normal curve areas, between . −. 1.645 and 0, the area under the normal curve is 0.45, so if the z-score is less than . −. 1.645, the area is 0.05, as desired. Similarly, if the z-score is greater than 1.645, the area is also. 0.05. So a Type I error will occur if the z-score is less than . −. 1.645 or greater than 1.645. We must now convert to raw score. Since the mean of sample means is 5.76 and the standard deviation of sample means is 0.187, a z-score of . −. 1.645 corresponds to a raw score of 5.76+0.187(. −. 1.645) = 5.45, and a z-score of 1.645 corresponds to a raw score of 5.76 + 0.187(1.645) = 6.07. So the critical values of the experiment should be 5.45 and 6.07. Since 9.297 > 6.06, the claim should be rejected.. ——————————–',\n",
       " ' 5.5.2\\tType II Errors and . β. -Risks. The β-risk (that is, the probability of failing to reject the null hypothesis) diﬀers depending on the actual population statistic. We calculate it in a way similar to the calculation of the α-risk - by considering a possible actual value for the population, using this value as the center of the normal distribution, and calculating the area beyond the critical point that corresponds to the fail to reject zone.. ——————————–. Example 27:. A poll claims that children spend an average of 203 minutes per day watching television. A researcher believes this is too high and conducts a study of 144 patients. The sample standard deviation is 120 minutes. He will reject the. 37. claim if the sample mean is under 180 minutes per day. What is the probability of a Type II error if the actual average is 210? 175? 170?. The standard deviation of the sample means is. . The null hypothesis will not be rejected if the sample mean is above 180. Thus, we look for the probability of the sample mean being above 180 to determine the . β. -risk. If the actual average is 210 minutes, then the sample means will be normally distributed about 210, so the . z. -score of the critical. value, 180, is . 180−210.   = −3, which corresponds to a probability of 0.4987.. 10. Thus, the probability of the sample mean being less than 180 (i.e. rejection) is 0. .. 5 −0. .. 4987, and the probability of this not being the case (i.e. failure to reject) is 0. .. 5 + 0. .. 4987 = 0. .. 9987. This is the . β. -risk.. If the actual average is 175 minutes, then the sample means will be normally. distributed about 175, so the . z. -score of the critical value, 180, is . 180−175.  = 0. .. 5,. 10. which corresponds to a probability of 0.1915. Thus, the probability of the sample mean being greater than 180 is 0. .. 5 − 0. .. 1915 = . .. 3085.. If the actual average is 170 minutes, then the sample means will be normally. distributed about 170, so the . z. -score of the critical value, 170, is . 180−170.  = 1,. 10. which corresponds to a probability of 0.3413. This is the probability that the sample mean is between 170 and 180. Thus, the probability of the sample mean being greater than 180 is 0. .. 5 − 0. .. 3413 = . .. 1587.. ——————————–. In the past example, we were given a critical value. Instead, we may be given an acceptable . α. -risk, from which we can calculate the critical value. We can then use the critical value to calculate . β. -risks for possible actual values. In general, we can use the following pathway:. acceptable . α. -risk (significance level) ←→ critical value(s) −→ . β. -risk',\n",
       " ' 5.6\\tComparing Two Means']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_corpus = []\n",
    "chapter_corpus = \"\"\n",
    "chapter_index = 0 \n",
    "for i,line in enumerate(statistics_firstfive_doc['full_text']):\n",
    "    \n",
    "    if chapter_index == len(chapter_index_statistics_firstfive):\n",
    "        break\n",
    "    \n",
    "    # if we reach to a new chapter \n",
    "    if i == chapter_index_statistics_firstfive[chapter_index]:\n",
    "        total_corpus.append(chapter_corpus[1:])\n",
    "        chapter_corpus = \"\"\n",
    "        chapter_index+=1\n",
    "    chapter_corpus = chapter_corpus + \". \" + line\n",
    "total_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_index_statistics_statbook = [new_lines_statistics_statbook.index(ch) for ch in chapters_first_five]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_corpus = []\n",
    "chapter_corpus = \"\"\n",
    "chapter_index = 0 \n",
    "for i,line in enumerate(new_lines_statistics_statbook):\n",
    "    \n",
    "    if chapter_index == len(chapter_index_statistics_firstfive):\n",
    "        break\n",
    "    \n",
    "    # if we reach to a new chapter \n",
    "    if i == chapter_index_statistics_firstfive[chapter_index]:\n",
    "        total_corpus.append(chapter_corpus[1:])\n",
    "        chapter_corpus = \"\"\n",
    "        chapter_index+=1\n",
    "    chapter_corpus = chapter_corpus + \". \" + line\n",
    "total_corpus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
