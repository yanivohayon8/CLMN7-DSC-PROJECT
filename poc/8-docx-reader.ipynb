{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "from docx import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_italic_bold_docx(doc_path):\n",
    "    document = Document(doc_path)\n",
    "    bolds=[]\n",
    "    italics=[]\n",
    "    full_text = []\n",
    "    font_sizes = []\n",
    "    for para in document.paragraphs:\n",
    "        #print(\"next paragraph:\")\n",
    "        #rint(para.text)\n",
    "        for run in para.runs:\n",
    "            #print('next run')\n",
    "            #print(run.text)\n",
    "            full_text.append(run.text)\n",
    "            font_sizes.append(run.font.size)\n",
    "            if run.italic :\n",
    "                italics.append(run.text)\n",
    "            if run.bold :\n",
    "                bolds.append(run.text)\n",
    "\n",
    "    return {'bold_phrases':bolds,'italic_phrases':italics,'full_text':full_text,'font_sizes':font_sizes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def get_txt_bigger(docx_json):\\n    most_common_font_ = mode(docx_json['font_sizes'])\\n    tmp_indexes = [i for i,sz in enumerate(docx_json['font_sizes']) if sz > most_common_font_]\\n    tmp_font_sizes = docx_json['font_sizes'][tmp_indexes]\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_txt_bigger(docx_json):\n",
    "    most_common_font_ = mode(docx_json['font_sizes'])\n",
    "    #return [txt for txt,sz in zip(docx_json['full_text'],docx_json['font_sizes']) if sz > most_common_font_]\n",
    "    return [txt for txt,sz in zip(docx_json['full_text'],docx_json['font_sizes']) if sz > most_common_font_],[i for i,(txt,sz) in enumerate(zip(docx_json['full_text'],docx_json['font_sizes'])) if sz > most_common_font_]\n",
    "\n",
    "\"\"\"def get_txt_bigger(docx_json):\n",
    "    most_common_font_ = mode(docx_json['font_sizes'])\n",
    "    tmp_indexes = [i for i,sz in enumerate(docx_json['font_sizes']) if sz > most_common_font_]\n",
    "    tmp_font_sizes = docx_json['font_sizes'][tmp_indexes]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_firstfive_doc = read_italic_bold_docx('../data/raw/pdf/7kLHJ-F33GI/statistics_firstfive.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_firstfive_doc_bigger,statistics_firstfive_doc_bigger_indexes = get_txt_bigger(statistics_firstfive_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#statistics_firstfive_doc_bigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_txt_biggest(docx_json):\n",
    "    max_common_font_ = max(docx_json['font_sizes'])\n",
    "    return [txt for txt,sz in zip(docx_json['full_text'],docx_json['font_sizes']) if sz == max_common_font_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_txt_biggest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f8886889efbe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_txt_biggest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatistics_firstfive_doc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'get_txt_biggest' is not defined"
     ]
    }
   ],
   "source": [
    "get_txt_biggest(statistics_firstfive_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_chapters_format_first_five(statistics_firstfive_doc_bigger,key_word_ = 'Chapter'):\n",
    "    topic_titles = []\n",
    "    p_subsection = re.compile(r'((\\d\\.)+\\d*\\t[A-Za-z0-9? ]+)')\n",
    "    p_Start_Section = re.compile('{} \\d?'.format(key_word_))\n",
    "    for i,doc in enumerate(statistics_firstfive_doc_bigger):\n",
    "        matching = p_Start_Section.match(doc)\n",
    "\n",
    "        if matching is not None:\n",
    "            topic_titles.append(statistics_firstfive_doc_bigger[i+1])\n",
    "\n",
    "        matching = p_subsection.match(doc)\n",
    "        if matching is not None:            \n",
    "            topic_titles.append(doc)\n",
    "    return topic_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters_first_five = find_chapters_format_first_five(statistics_firstfive_doc_bigger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_chapters_format_statbooks(lines,key_word_ = 'Chapter'):\n",
    "    topic_titles = []\n",
    "    p_Start_Section = re.compile('{} \\d?'.format(key_word_))\n",
    "    p_subsection = re.compile(r'^((\\d+\\.)+\\d*)$')\n",
    "    p_words = re.compile('[A-Za-z]+')\n",
    "    new_lines = []\n",
    "    for i,doc in enumerate(lines):\n",
    "        matching = p_Start_Section.match(doc)\n",
    "\n",
    "        if matching is not None:\n",
    "            topic_titles.append(lines[i+1])\n",
    "\n",
    "        matching = p_subsection.match(doc)\n",
    "        if matching is not None:\n",
    "            matching = p_words.match(lines[i+1])\n",
    "            if matching is not None:\n",
    "                #lines[i:i+1] = [''.join(lines[i:i+1])]\n",
    "                #topic_titles.append(lines[i])\n",
    "                new_title = (\"%s %s\" %(lines[i],lines[i+1]))\n",
    "                topic_titles.append(new_title)\n",
    "                new_lines.append(new_title)\n",
    "        new_lines.append(doc)\n",
    "    return topic_titles,new_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_statbook_doc = read_italic_bold_docx('../data/raw/pdf/7kLHJ-F33GI/statbook.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_txt_bigger' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-86c4531bf9f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstatistics_statbook_doc_bigger\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstatistics_statbook_doc_bigger_indexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_txt_bigger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatistics_statbook_doc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mchapter_statistics_statbook\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnew_lines_statistics_statbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_chapters_format_statbooks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatistics_statbook_doc_bigger\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkey_word_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Topic'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mchapter_statistics_statbook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_txt_bigger' is not defined"
     ]
    }
   ],
   "source": [
    "statistics_statbook_doc_bigger,statistics_statbook_doc_bigger_indexes = get_txt_bigger(statistics_statbook_doc)\n",
    "chapter_statistics_statbook,new_lines_statistics_statbook = find_chapters_format_statbooks(statistics_statbook_doc_bigger,key_word_='Topic')\n",
    "chapter_statistics_statbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'statistics_firstfive_doc_bigger_indexes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8dd93b6f2114>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# finding the indexes of the titles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstatistics_firstfive_doc_bigger_indexes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mstatistics_firstfive_doc_bigger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'statistics_firstfive_doc_bigger_indexes' is not defined"
     ]
    }
   ],
   "source": [
    "# finding the indexes of the titles\n",
    "statistics_firstfive_doc_bigger_indexes\n",
    "statistics_firstfive_doc_bigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_index_statistics_firstfive = [statistics_firstfive_doc['full_text'].index(ch) for ch in chapters_first_five]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'statistics_firstfive_doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-504e91733da7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mchapter_corpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mchapter_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatistics_firstfive_doc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'full_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchapter_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchapter_index_statistics_firstfive\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'statistics_firstfive_doc' is not defined"
     ]
    }
   ],
   "source": [
    "total_corpus = []\n",
    "chapter_corpus = \"\"\n",
    "chapter_index = 0 \n",
    "for i,line in enumerate(statistics_firstfive_doc['full_text']):\n",
    "    \n",
    "    if chapter_index == len(chapter_index_statistics_firstfive):\n",
    "        break\n",
    "    \n",
    "    # if we reach to a new chapter \n",
    "    if i == chapter_index_statistics_firstfive[chapter_index]:\n",
    "        total_corpus.append(chapter_corpus[1:])\n",
    "        chapter_corpus = \"\"\n",
    "        chapter_index+=1\n",
    "    chapter_corpus = chapter_corpus + \". \" + line\n",
    "total_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_index_statistics_statbook = [new_lines_statistics_statbook.index(ch) for ch in chapters_first_five]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_corpus = []\n",
    "chapter_corpus = \"\"\n",
    "chapter_index = 0 \n",
    "for i,line in enumerate(new_lines_statistics_statbook):\n",
    "    \n",
    "    if chapter_index == len(chapter_index_statistics_firstfive):\n",
    "        break\n",
    "    \n",
    "    # if we reach to a new chapter \n",
    "    if i == chapter_index_statistics_firstfive[chapter_index]:\n",
    "        total_corpus.append(chapter_corpus[1:])\n",
    "        chapter_corpus = \"\"\n",
    "        chapter_index+=1\n",
    "    chapter_corpus = chapter_corpus + \". \" + line\n",
    "total_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<docx.text.paragraph.Paragraph at 0x1e214ce4188>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4288>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4308>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4388>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4408>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4208>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4588>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4608>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4688>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4488>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4508>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4788>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4808>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4888>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4908>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4988>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4a08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4a88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4b08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4b88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4c08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4c88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4d08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4d88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4e08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4e88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4f08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4f88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce4708>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce80c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce8148>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce81c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce8248>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce82c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce8348>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce83c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce8448>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce84c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce8548>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce85c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce8648>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce86c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce8748>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce87c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce8848>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce88c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce8948>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce89c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce8a48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce8ac8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce8b48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce8bc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce8c48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce8cc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce8d48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce8dc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce8e48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce8ec8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce8f48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ce8048>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cec088>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cec108>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cec188>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cec208>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cec288>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cec308>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cec388>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cec408>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cec488>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cec508>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cec588>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cec608>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cec688>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cec708>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cec788>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cec808>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cec888>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cec908>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cec988>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ceca08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214ceca88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cecb08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cecb88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cecc08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cecc88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cecd08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cecd88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cece08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cece88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cecf08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cecf88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cec048>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf20c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf2148>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf21c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf2248>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf22c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf2348>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf23c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf2448>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf24c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf2548>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf25c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf2648>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf26c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf2748>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf27c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf2848>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf28c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf2948>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf29c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf2a48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf2ac8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf2b48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf2bc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf2c48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf2cc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf2d48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf2dc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf2e48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf2ec8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf2f48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf2048>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6088>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6108>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6188>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6208>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6288>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6308>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6388>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6408>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6488>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6508>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6588>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6608>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6688>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6708>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6788>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6808>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6888>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6908>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6988>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6a08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6a88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6b08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6b88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6c08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6c88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6d08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6d88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6e08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6e88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6f08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6f88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cf6048>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfb0c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfb148>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfb1c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfb248>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfb2c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfb348>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfb3c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfb448>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfb4c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfb548>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfb5c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfb648>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfb6c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfb748>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfb7c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfb848>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfb8c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfb948>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfb9c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfba48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfbac8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfbb48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfbbc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfbc48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfbcc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfbd48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfbdc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfbe48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfbec8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfbf48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214cfb048>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00088>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00108>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00188>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00208>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00288>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00308>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00388>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00408>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00488>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00508>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00588>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00608>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00688>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00708>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00788>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00808>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00888>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00908>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00988>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00a08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00a88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00b08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00b88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00c08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00c88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00d08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00d88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00e08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00e88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00f08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00f88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d00048>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d040c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d04148>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d041c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d04248>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d042c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d04348>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d043c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d04448>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d044c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d04548>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d045c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d04648>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d046c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d04748>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d047c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d04848>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d048c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d04948>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d049c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d04a48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d04ac8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d04b48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d04bc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d04c48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d04cc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d04d48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d04dc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d04e48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d04ec8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d04f48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d04048>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09088>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09108>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09188>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09208>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09288>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09308>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09388>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09408>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09488>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09508>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09588>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09608>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09688>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09708>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09788>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09808>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09888>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09908>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09988>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09a08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09a88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09b08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09b88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09c08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09c88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09d08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09d88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09e08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09e88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09f08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09f88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d09048>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0d0c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0d148>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0d1c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0d248>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0d2c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0d348>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0d3c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0d448>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0d4c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0d548>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0d5c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0d648>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0d6c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0d748>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0d7c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0d848>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0d8c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0d948>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0d9c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0da48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0dac8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0db48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0dbc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0dc48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0dcc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0dd48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0ddc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0de48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0dec8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0df48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d0d048>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12088>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12108>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12188>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12208>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12288>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12308>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12388>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12408>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12488>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12508>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12588>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12608>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12688>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12708>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12788>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12808>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12888>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12908>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12988>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12a08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12a88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12b08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12b88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12c08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12c88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12d08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12d88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12e08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12e88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12f08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12f88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d12048>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d170c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d17148>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d171c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d17248>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d172c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d17348>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d173c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d17448>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d174c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d17548>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d175c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d17648>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d176c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d17748>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d177c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d17848>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d178c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d17948>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d179c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d17a48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d17ac8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d17b48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d17bc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d17c48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d17cc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d17d48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d17dc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d17e48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d17ec8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d17f48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d17048>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1b088>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1b108>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1b188>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1b208>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1b288>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1b308>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1b388>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1b408>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1b488>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1b508>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1b588>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1b608>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1b688>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1b708>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1b788>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1b808>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1b888>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1b908>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1b988>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1ba08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1ba88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1bb08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1bb88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1bc08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1bc88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1bd08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1bd88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1be08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1be88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1bf08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1bf88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d1b048>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d200c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d20148>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d201c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d20248>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d202c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d20348>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d203c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d20448>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d204c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d20548>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d205c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d20648>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d206c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d20748>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d207c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d20848>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d208c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d20948>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d209c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d20a48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d20ac8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d20b48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d20bc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d20c48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d20cc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d20d48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d20dc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d20e48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d20ec8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d20f48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d20088>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25088>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25108>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25188>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25208>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25288>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25308>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25388>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25408>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25488>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25508>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25588>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25608>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25688>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25708>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25788>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25808>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25888>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25908>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25988>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25a08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25a88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25b08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25b88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25c08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25c88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25d08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25d88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25e08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25e88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25f08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25f88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d25048>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d290c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d29148>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d291c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d29248>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d292c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d29348>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d293c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d29448>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d294c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d29548>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d295c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d29648>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d296c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d29748>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d297c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d29848>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d298c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d29948>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d299c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d29a48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d29ac8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d29b48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d29bc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d29c48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d29cc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d29d48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d29dc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d29e48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d29ec8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d29f48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d29048>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2e088>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2e108>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2e188>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2e208>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2e288>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2e308>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2e388>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2e408>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2e488>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2e508>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2e588>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2e608>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2e688>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2e708>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2e788>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2e808>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2e888>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2e908>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2e988>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2ea08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2ea88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2eb08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2eb88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2ec08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2ec88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2ed08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2ed88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2ee08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2ee88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2ef08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2ef88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d2e048>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d320c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d32148>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d321c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d32248>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d322c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d32348>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d323c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d32448>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d324c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d32548>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d325c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d32648>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d326c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d32748>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d327c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d32848>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d328c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d32948>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d329c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d32a48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d32ac8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d32b48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d32bc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d32c48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d32cc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d32d48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d32dc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d32e48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d32ec8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d32f48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d32048>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37088>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37108>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37188>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37208>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37288>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37308>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37388>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37408>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37488>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37508>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37588>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37608>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37688>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37708>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37788>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37808>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37888>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37908>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37988>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37a08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37a88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37b08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37b88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37c08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37c88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37d08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37d88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37e08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37e88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37f08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37f88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d37048>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3c0c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3c148>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3c1c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3c248>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3c2c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3c348>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3c3c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3c448>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3c4c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3c548>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3c5c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3c648>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3c6c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3c748>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3c7c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3c848>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3c8c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3c948>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3c9c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3ca48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3cac8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3cb48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3cbc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3cc48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3ccc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3cd48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3cdc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3ce48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3cec8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3cf48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d3c048>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40088>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40108>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40188>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40208>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40288>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40308>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40388>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40408>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40488>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40508>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40588>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40608>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40688>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40708>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40788>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40808>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40888>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40908>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40988>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40a08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40a88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40b08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40b88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40c08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40c88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40d08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40d88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40e08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40e88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40f08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40f88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d40048>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d440c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d44148>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d441c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d44248>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d442c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d44348>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d443c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d44448>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d444c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d44548>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d445c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d44648>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d446c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d44748>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d447c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d44848>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d448c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d44948>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d449c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d44a48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d44ac8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d44b48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d44bc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d44c48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d44cc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d44d48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d44dc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d44e48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d44ec8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d44f48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d44048>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4a088>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4a108>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4a188>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4a208>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4a288>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4a308>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4a388>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4a408>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4a488>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4a508>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4a588>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4a608>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4a688>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4a708>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4a788>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4a808>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4a888>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4a908>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4a988>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4aa08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4aa88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4ab08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4ab88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4ac08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4ac88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4ad08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4ad88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4ae08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4ae88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4af08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4af88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4a048>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4e0c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4e148>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4e1c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4e248>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4e2c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4e348>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4e3c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4e448>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4e4c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4e548>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4e5c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4e648>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4e6c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4e748>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4e7c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4e848>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4e8c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4e948>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4e9c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4ea48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4ea88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4eb08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4eb48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4ebc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4ec08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4ec88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4ecc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4ed48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4ed88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4ee08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4ee48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4eec8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4ef08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4ef88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d4e048>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214c4c988>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214c4c388>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214c4c488>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214c4ca48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214c4c808>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214c4c748>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214c4ca88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214c4cb08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214c4c8c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214c4cb88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214c4cbc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214c4cc48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214c4cc88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214c4cd08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214c4cd48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214c4cdc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214c4ce08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214c4cec8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214c4cf08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214c4cf88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214c4ce88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214c4cac8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214c4c408>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52188>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d521c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52208>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52108>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52088>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52388>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d523c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d522c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52448>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52488>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52308>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52508>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52548>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52348>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d525c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52148>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52588>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52648>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52408>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52248>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52708>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d524c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52688>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d527c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52288>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52748>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52888>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52608>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52808>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52948>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d526c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d528c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52a08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52788>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52988>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52ac8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52848>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52a48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52b88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52908>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52b08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52c48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52c08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52bc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52d08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52cc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52c88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52dc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52d88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52d48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52e88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52e48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52e08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52f48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52f08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52ec8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52fc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52a88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52f88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d529c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52b48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d52048>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d421c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42188>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42148>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42288>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42248>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42348>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42308>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42408>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d423c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d424c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42488>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42588>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42548>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42648>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42608>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42708>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d426c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d427c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42788>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42888>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42848>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42948>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42908>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42a08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d429c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42ac8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42a88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42b88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42b48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42c48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42c08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42d08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42cc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42dc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42d88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42e88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42e48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42f48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42f08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42fc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d420c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42048>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42108>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e214d42088>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96188>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96288>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96248>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96348>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96308>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96408>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d963c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d964c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96488>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96588>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96548>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96648>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96608>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96708>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d966c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d967c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96788>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96888>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96848>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96948>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96908>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96a08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d969c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96ac8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96a88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96b88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96b48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96c48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96c08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96d08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96cc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96dc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96d88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96e88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96e48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96f48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96f08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96fc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d960c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96048>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d96108>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d961c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9b188>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9b288>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9b248>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9b348>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9b308>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9b408>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9b3c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9b4c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9b488>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9b588>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9b548>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9b648>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9b608>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9b708>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9b6c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9b7c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9b788>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9b888>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9b848>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9b948>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9b908>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9ba08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9b9c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9bac8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9ba88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9bb88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9bb48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9bc48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9bc08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9bd08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9bcc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9bdc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9bd88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9be88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9be48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9bf48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9bf08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9bfc8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9b0c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9b048>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9b108>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9b1c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9f188>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9f288>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9f248>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9f348>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9f308>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9f408>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9f3c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9f4c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9f488>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9f588>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9f548>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9f648>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9f608>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9f708>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9f6c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9f7c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9f788>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9f888>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9f848>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9f948>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9f908>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9fa08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9f9c8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9fac8>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9fa88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9fb88>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9fb48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9fc48>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9fc08>,\n",
       " <docx.text.paragraph.Paragraph at 0x1e215d9fd08>,\n",
       " ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "michal = Document('../data/raw/docx/bTyxpoi2dmM/MIT6_042JF10_notes.docx')\n",
    "michal.paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mcs-ftl  2010/9/8  0:40  page i  #1\n",
      "\n",
      "Mathematics for Computer Science\n",
      "revised Wednesday 8\n",
      "th\n",
      " September, 2010, 00:40\n",
      "Eric Lehman\n",
      "Google Inc.\n",
      "F Thomson Leighton\n",
      "Department of Mathematics and CSAIL, MIT\n",
      "Akamai Technologies\n",
      "Albert R Meyer\n",
      "Massachusets Institute of Technology\n",
      "\n",
      "Copyright  2010, Eric Lehman, F Tom Leighton, \n",
      ". All rights reserved.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page ii  #2\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page iii  #3\n",
      "\n",
      "Contents\n",
      "\n",
      "Proofs\n",
      "Propositions  \n",
      "Induction  \n",
      "Number Theory  \n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page iv  #4\n",
      "\n",
      "iv\n",
      "\t\n",
      "Contents\n",
      "\n",
      "II  Structures\n",
      "Graph Theory  \n",
      "Directed Graphs  \n",
      "State Machines  \n",
      "Counting\n",
      "\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page v  #5\n",
      "\n",
      "v\n",
      "\t\n",
      "Contents\n",
      "9.7\tAsymptotic Notation\n",
      "\t\n",
      "10\tRecurrences\n",
      "\t\n",
      "11\tCardinality Rules\n",
      "\t\n",
      "12\tGenerating Functions\n",
      "\t\n",
      "13\tInfinite Sets\n",
      "\t\n",
      "\n",
      "IV Probability\n",
      "14\tEvents and Probability Spaces\n",
      "\t\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page vi  #6\n",
      "\n",
      "vi\n",
      "\t\n",
      "Contents\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 1  #7\n",
      "\n",
      "I\n",
      "\t\n",
      "Proofs\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 2  #8\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 3  #9\n",
      "\n",
      "Introduction\n",
      "This text explains how to use mathematical models and methods to analyze prob-lems that arise in computer science. The notion of a proof plays a central role in this work.\n",
      "Simply put, a proof is a method of establishing truth. Like beauty, truth some-times depends on the eye of the beholder, and it should not be surprising that what constitutes a proof differs among fields. For example, in the judicial system, legal truth is decided by a jury based on the allowable evidence presented at trial. In the business world, authoritative truth is specified by a trusted person or organization, or maybe just your boss. In fields such as physics and biology, scientific truth\n",
      "is confirmed by experiment. In statistics, probable truth is established by statistical analysis of sample data.\n",
      "Philosophical proof involves careful exposition and persuasion typically based on a series of small, plausible arguments. The best example begins with Cogito ergo sum, a Latin sentence that translates as I think, therefore I am. It comes from the beginning of a 17th century essay by the mathematician/philosopher, Rene Descartes, and it is one of the most famous quotes in the world: do a web search on the phrase and you will be flooded with hits.\n",
      "Deducing your existence from the fact that youre thinking about your existence is a pretty cool and persuasive-sounding idea. However, with just a few more lines of argument in this vein, Descartes \n",
      "to conclude that there is an infinitely beneficent God. Whether or not you believe in a beneficent God, youll probably agree that any very short proof of Gods existence is bound to be far-fetched. So\n",
      "\n",
      "Actually, only scientific falsehood can be demonstrated by an experimentwhen the experiment fails to behave as predicted. But no amount of experiment can confirm that the next experiment wont fail. For this reason, scientists rarely speak of truth, but rather of theories that accurately predict past, and anticipated future, experiments.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 4  #10\n",
      "\n",
      "4\n",
      "\t\n",
      "Part I\n",
      "\t\n",
      "Proofs\n",
      "even in masterful hands, this approach is not reliable. Mathematics has its own specific notion of proof.\n",
      "Definition. A mathematical proof of a proposition is a chain of logical deductions leading to the proposition from a base set of axioms.\n",
      "The three key ideas in this definition are highlighted: proposition, logical de-duction, and axiom. These three ideas are explained in the following chapters, beginning with propositions in Chapter \n",
      ". We will then provide lots of examples of proofs and even some examples of false proofs (that is, arguments that look like a proof but that contain missteps, or deductions that arent so logical when exam-ined closely). False proofs are often even more important as examples than correct proofs, because they are uniquely helpful with honing your skills at making sure each step of a proof follows logically from prior steps.\n",
      "Creating a good proof is a lot like creating a beautiful work of art. In fact, mathematicians often refer to really good proofs as being elegant or beautiful. As with any endeavor, it will probably take a little practice before your fellow students use such praise when referring to your proofs, but to get you started in the right direction, we will provide templates for the most useful proof techniques in Chapters \n",
      "and \n",
      ". We then apply these techniques in Chapter \n",
      "to establish some important facts about numbers; facts that form the underpinning of one of the worlds most widely-used cryptosystems.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 5  #11\n",
      "\n",
      "Propositions\n",
      "Definition. A proposition is a statement that is either true or false.\n",
      "For example, both of the following statements are propositions. The first is true and the second is false.\n",
      "Proposition 1.0.1. 2 + 3 = 5.\n",
      "Proposition 1.0.2. 1 + 1 = 3.\n",
      "Being true or false doesnt sound like much of a limitation, but it does exclude statements such as, Wherefore art thou Romeo? and Give me an A!.\n",
      "Unfortunately, it is not always easy to decide if a proposition is true or false, or even what the proposition means. In part, this is because the English language is riddled with ambiguities. For example, consider the following statements:\n",
      "You may have cake, or you may have ice cream.\n",
      "If pigs can fly, then you can understand the Chebyshev bound.\n",
      "If you can solve any problem we come up with, then you get an A for the course.\n",
      "Every American has a dream.\n",
      "What precisely do these sentences mean? Can you have both cake and ice cream or must you choose just one dessert? If the second sentence is true, then is the Chebyshev bound incomprehensible? If you can solve some problems we come up with but not all, then do you get an A for the course? And can you still get an A even if you cant solve any of the problems? Does the last sentence imply that all Americans have the same dream or might some of them have different dreams?\n",
      "Some uncertainty is tolerable in normal conversation. But when we need to formulate ideas preciselyas in mathematics and programmingthe ambiguities inherent in everyday language can be a real problem. We cant hope to make an exact argument if were not sure exactly what the statements mean. So before we start into mathematics, we need to investigate the problem of how to talk about mathematics.\n",
      "To get around the ambiguity of English, mathematicians have devised a special mini-language for talking about logical relationships. This language mostly uses ordinary English words and phrases such as or, implies, and for all. But\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 6  #12\n",
      "\n",
      "6\n",
      "\t\n",
      "Chapter 1\n",
      "\t\n",
      "Propositions\n",
      "mathematicians endow these words with definitions more precise than those found in an ordinary dictionary. Without knowing these definitions, you might sometimes get the gist of statements in this language, but you would regularly get misled about what they really meant.\n",
      "Surprisingly, in the midst of learning the language of mathematics, well come across the most important open problem in computer sciencea problem whose solution could change the world.\n",
      "\n",
      "1.1\n",
      "\t\n",
      "Compound Propositions\n",
      "In English, we can modify, combine, and relate propositions with words such as not, and, or, implies, and if-then. For example, we can combine three propositions into one like this:\n",
      "If all humans are mortal and all Greeks are human, then all Greeks are mortal.\n",
      "For the next while, we wont be much concerned with the internals of propositions whether they involve mathematics or Greek mortalitybut rather with how propo-sitions are combined and related. So well frequently use variables such as P and Q in place of specific propositions such as All humans are mortal and 2 C 3 D 5. The understanding is that these variables, like propositions, can take on only the values T (true) and F (false). Such true/false variables are sometimes called Boolean variables after their inventor, Georgeyou guessed itBoole.\n",
      "1.1.1\n",
      "\t\n",
      "NOT\n",
      ",\n",
      " AND\n",
      ", and\n",
      " OR\n",
      "We can precisely define these special words using truth tables.  For example, if\n",
      "denotes an arbitrary proposition, then the truth of the proposition \n",
      "NOT\n",
      ".P / is defined by the following truth table:\n",
      "\n",
      "P\n",
      "\t\n",
      "NOT\n",
      ".P /\n",
      "T\n",
      "\t\n",
      "F\n",
      "F\n",
      "\t\n",
      "T\n",
      "The first row of the table indicates that when proposition P is true, the proposition \n",
      "NOT\n",
      ".P / is false. The second line indicates that when P is false, \n",
      "NOT\n",
      ".P / is true. This is probably what you would expect.\n",
      "In general, a truth table indicates the true/false value of a proposition for each possible setting of the variables. For example, the truth table for the proposition\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 7  #13\n",
      "\n",
      "P \n",
      "AND\n",
      " Q has four lines, since the two variables can be set in four different ways:\n",
      "\n",
      "Q P \n",
      "AND\n",
      "Q\n",
      "According to this table, the proposition P \n",
      "AND\n",
      " Q is true only when P and Q are both true. This is probably the way you think about the word and.\n",
      "There is a subtlety in the truth table for P \n",
      "OR\n",
      " Q:\n",
      "\n",
      "Q P\n",
      "OR\n",
      "Q\n",
      "The third row of this table says that P \n",
      "OR\n",
      " Q is true even if both P and Q are true. This isnt always the intended meaning of or in everyday speech, but this is the standard definition in mathematical writing. So if a mathematician says, You may have cake, or you may have ice cream, he means that you could have both.\n",
      "If you want to exclude the possibility of both having and eating, you should use exclusive-or (\n",
      "XOR\n",
      "):\n",
      "\n",
      "Q P \n",
      "XOR\n",
      "Q\n",
      "1.1.2\n",
      "\t\n",
      "IMPLIES\n",
      "The least intuitive connecting word is implies. Here is its truth table, with the lines labeled so we can refer to them later.\n",
      "\n",
      "Q  P \n",
      "IMPLIES\n",
      " Q\n",
      "Lets experiment with this definition. For example, is the following proposition true or false?\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 8  #14\n",
      "\n",
      "8\n",
      "\t\n",
      "Chapter 1\n",
      "\t\n",
      "Propositions\n",
      "If the Riemann Hypothesis is true, then x\n",
      "2\n",
      "\t\n",
      "0 for every real number x.\n",
      "The Riemann Hypothesis is a famous unresolved conjecture in mathematics no one knows if it is true or false. But that doesnt prevent you from answering the question! This proposition has the form P \n",
      "IMPLIES\n",
      " Q where the hypothesis, P , is the Riemann Hypothesis is true and the conclusion, Q, is x\n",
      "2\n",
      " 0 for every real number x. Since the conclusion is definitely true, were on either line (tt) or line (ft) of the truth table. Either way, the proposition as a while is true!\n",
      "One of our original examples demonstrates an even stranger side of implications.\n",
      "If pigs can fly, then you can understand the Chebyshev bound.\n",
      "Dont take this as an insult; we just need to figure out whether this proposition is true or false. Curiously, the answer has nothing to do with whether or not you can understand the Chebyshev bound. Pigs cannot fly, so were on either line (ft) or line (ff) of the truth table. In both cases, the proposition is true!\n",
      "In contrast, heres an example of a false implication:\n",
      "If the moon shines white, then the moon is made of white cheddar.\n",
      "Yes, the moon shines white. But, no, the moon is not made of white cheddar cheese.\n",
      "So were on line (tf) of the truth table, and the proposition is false.\n",
      "The truth table for implications can be summarized in words as follows:\n",
      "An implication is true exactly when the if-part is false or the then-part is true.\n",
      "This sentence is worth remembering; a large fraction of all mathematical statements are of the if-then form!\n",
      "1.1.3\tIFF\n",
      "Mathematicians commonly join propositions in one additional way that doesnt arise in ordinary speech. The proposition P if and only if Q asserts that P and Q are logically equivalent; that is, either both are true or both are false.\n",
      "For example, the following if-and-only-if statement is true for every real number\n",
      ":\n",
      "x\n",
      "2\n",
      "\t4\t0\n",
      "\t\n",
      "iff\n",
      "\t\n",
      "jxj\n",
      "\t\n",
      "2\n",
      "For some values of x, both inequalities are true. For other values of x, neither inequality is true . In every case, however, the proposition as a whole is true.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 9  #15\n",
      "\n",
      "1.1.4\n",
      "\t\n",
      "Notation\n",
      "Mathematicians have devised symbols to represent words like \n",
      "AND\n",
      " and \n",
      "NOT\n",
      ".\n",
      "The most commonly-used symbols are summarized in the table below.\n",
      "For example, using this notation, If P \n",
      "AND NOT\n",
      ".Q/, then R would be written:\n",
      "\n",
      ".P ^Q/!\tR\n",
      "This symbolic language is helpful for writing complicated logical expressions com-pactly. But words such as \n",
      "OR\n",
      " and \n",
      "IMPLIES\n",
      " generally serve just as well as the symbols _ and !, and their meaning is easy to remember. We will use the prior notation for the most part in this text, but you can feel free to use whichever con-vention is easiest for you.\n",
      "1.1.5\n",
      "\t\n",
      "Logically Equivalent Implications\n",
      "Do these two sentences say the same thing?\n",
      "If I am hungry, then I am grumpy.\n",
      "If I am not grumpy, then I am not hungry.\n",
      "We can settle the issue by recasting both sentences in terms of propositional logic. Let P be the proposition I am hungry, and let Q be I am grumpy. The first sentence says P \n",
      "IMPLIES\n",
      " Q and the second says \n",
      "NOT\n",
      ".Q/ \n",
      "IMPLIES NOT\n",
      ".P /. We can compare these two statements in a truth table:\n",
      "Sure enough, the columns of truth values under these two statements are the same, which precisely means they are equivalent. In general, \n",
      "NOT\n",
      ".Q/ \n",
      "IMPLIES NOT\n",
      ".P /\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 10  #16\n",
      "\n",
      "10\n",
      "\t\n",
      "Chapter 1\n",
      "\t\n",
      "Propositions\n",
      "is called the contrapositive of the implication P \n",
      "IMPLIES\n",
      " Q. And, as weve just shown, the two are just different ways of saying the same thing.\n",
      "In contrast, the converse of P \n",
      "IMPLIES\n",
      " Q is the statement Q \n",
      "IMPLIES\n",
      " P .\n",
      "In terms of our example, the converse is:\n",
      "If I am grumpy, then I am hungry.\n",
      "This sounds like a rather different contention, and a truth table confirms this suspi-cion:\n",
      "Thus, an implication is logically equivalent to its contrapositive but is not equiva-lent to its converse.\n",
      "One final relationship: an implication and its converse together are equivalent to an iff statement. For example,\n",
      "If I am grumpy, then I am hungry, \n",
      "AND\n",
      "if I am hungry, then I am grumpy.\n",
      "are equivalent to the single statement:\n",
      "I am grumpy \n",
      "IFF\n",
      " I am hungry.\n",
      "Once again, we can verify this with a truth table:\n",
      "\n",
      "1.2\n",
      "\t\n",
      "Propositional Logic in Computer Programs\n",
      "Propositions and logical connectives arise all the time in computer programs. For example, consider the following snippet, which could be either C, C++, or Java:\n",
      "if ( x > 0 || (x <= 0 && y > 100) )\n",
      ":\n",
      ":\n",
      ":\n",
      "(further instructions)\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 11  #17\n",
      "\n",
      "The symbol || denotes \n",
      "OR\n",
      ", and the symbol && denotes \n",
      "AND\n",
      ". The further instructions are carried out only if the proposition following the word if is true. On closer inspection, this big expression is built from two simpler propositions. Let A be the proposition that x > 0, and let B be the proposition that y > 100. Then we can rewrite the condition A \n",
      "OR\n",
      " .\n",
      "NOT\n",
      ".A/ \n",
      "AND\n",
      " B/. A truth table reveals that this complicated expression is logically equivalent to A \n",
      "OR\n",
      " B.\n",
      "This means that we can simplify the code snippet without changing the programs behavior:\n",
      "if ( x > 0 || y > 100 )\n",
      ":\n",
      ":\n",
      ":\n",
      "(further instructions)\n",
      "Rewriting a logical expression involving many variables in the simplest form is both difficult and important. Simplifying expressions in software can increase the speed of your program. Chip designers face a similar challengeinstead of minimizing && and || symbols in a program, their job is to minimize the number of analogous physical devices on a chip. The payoff is potentially enormous: a chip with fewer devices is smaller, consumes less power, has a lower defect rate, and is cheaper to manufacture.\n",
      "\n",
      "1.3\n",
      "\t\n",
      "Predicates and Quantifiers\n",
      "1.3.1\n",
      "\t\n",
      "Propositions with Infinitely Many Cases\n",
      "Most of the examples of propositions that we have considered thus far have been straightforward in the sense that it has been relatively easy to determine if they are true or false. At worse, there were only a few cases to check in a truth table. Unfortunately, not all propositions are so easy to check. That is because some propositions may involve a large or infinite number of possible cases. For example, consider the following proposition involving prime numbers. (A prime is an integer greater than 1 that is divisible only by itself and 1. For example, 2, 3, 5, 7, and 11\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 12  #18\n",
      "\n",
      "12\n",
      "\t\n",
      "Chapter 1\n",
      "\t\n",
      "Propositions\n",
      "are primes, but 4, 6, and 9 are not. A number greater than 1 that is not prime is said to be composite.)\n",
      "Proposition 1.3.1. For every nonnegative integer, n, the value of n\n",
      "2\n",
      " C n C 41 is prime.\n",
      "It is not immediately clear whether this proposition is true or false. In such circumstances, it is tempting to try to determine its veracity by computing the value of\n",
      "for several values of n and then checking to see if they are prime. If any of the computed values is not prime, then we will know that the proposition is false. If all the computed values are indeed prime, then we might be tempted to conclude that the proposition is true.\n",
      "We begin the checking by evaluating p.0/ D 41, which is prime. p.1/ D 43 is also prime. So is p.2/ D 47, p.3/ D 53, . . . , and p.20/ D 461, all of which are prime. Hmmm. . . It is starting to look like p.n/ is a prime for every nonnegative integer n. In fact, continued checking reveals that p.n/ is prime for all n 39. The proposition certainly does seem to be true.\n",
      "But p.40/ D 40\n",
      "2\n",
      " C 40 C 41 D 41 41, which is not prime. So its not true that the expression is prime for all nonnegative integers, and thus the proposition is false!\n",
      "Although surprising, this example is not as contrived or rare as you might sus-pect. As we will soon see, there are many examples of propositions that seem to be true when you check a few cases (or even many), but which turn out to be false. The key to remember is that you cant check a claim about an infinite set by checking a finite set of its elements, no matter how large the finite set.\n",
      "Propositions that involve all numbers are so common that there is a special no-tation for them. For example, Proposition \n",
      "can also be written as\n",
      "Here the symbol 8 is read for all. The symbol N stands for the set of nonnegative integers, namely, 0, 1, 2, 3, . . . (ask your instructor for the complete list). The symbol 2 is read as is a member of, or belongs to, or simply as is in. The period after the N is just a separator between phrases.\n",
      "Here is another example of a proposition that, at first, seems to be true but which turns out to be false.\n",
      "\n",
      "The symbol WWD means equal by definition. Its always ok to simply write = instead of WWD, but reminding the reader that an equality holds by definition can be helpful.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 13  #19\n",
      "\n",
      "Proposition 1.3.2. a\n",
      "4\n",
      " C b\n",
      "4\n",
      " C c\n",
      "4\n",
      " D d \n",
      "4\n",
      " has no solution when a; b; c; d are positive integers.\n",
      "Euler (pronounced oiler) conjectured this proposition to be true in 1769. It was checked by humans and then by computers for many values of a, b, c, and d over the next two centuries. Ultimately the proposition was proven false in 1987 by Noam Elkies. The solution he found was a D 95800; b D 217519; c D 414560; d D 422481. No wonder it took 218 years to show the proposition is false!\n",
      "In logical notation, Proposition \n",
      "could be written,\n",
      "8a 2 Z\n",
      "C\n",
      " 8b 2 Z\n",
      "C\n",
      " 8c 2 Z\n",
      "C\n",
      " 8d 2 Z\n",
      "C\n",
      ": a\n",
      "4\n",
      " C b\n",
      "4\n",
      " C c\n",
      "4\n",
      "  d \n",
      "4\n",
      ":\n",
      "Here, Z\n",
      "C\n",
      " is a symbol for the positive integers. Strings of 8s are usually abbrevi-ated for easier reading, as follows:\n",
      "8a; b; c; d 2 Z\n",
      "C\n",
      ": a\n",
      "4\n",
      " C b\n",
      "4\n",
      " C c\n",
      "4\n",
      "  d \n",
      "4\n",
      ":\n",
      "The following proposition is even nastier.\n",
      "Proposition 1.3.3. 313.x\n",
      "3\n",
      " C y\n",
      "3\n",
      "/ D z\n",
      "3\n",
      " has no solution when x; y; z 2 Z\n",
      "C\n",
      ".\n",
      "This proposition is also false, but the smallest counterexample values for x, y, and z have more than 1000 digits! Even the worlds largest computers would not be able to get that far with brute force. Of course, you may be wondering why anyone would care whether or not there is a solution to 313.x\n",
      "3\n",
      " C y\n",
      "3\n",
      "/ D z\n",
      "3\n",
      " where x, y, and z are positive integers. It turns out that finding solutions to such equations is important in the field of elliptic curves, which turns out to be important to the study of factoring large integers, which turns out (as we will see in Chapter \n",
      ") to be im-portant in cracking commonly-used cryptosystems, which is why mathematicians went to the effort to find the solution with thousands of digits.\n",
      "Of course, not all propositions that have infinitely many cases to check turn out to be false. The following proposition (known as the Four-Color Theorem) turns out to be true.\n",
      "Proposition 1.3.4. Every map can be colored with 4 colors so that adjacent\n",
      "re-gions have different colors.\n",
      "The proof of this proposition is difficult and took over a century to perfect. Along the way, many incorrect proofs were proposed, including one that stood for 10 years\n",
      "\n",
      "2\n",
      "Two regions are adjacent only when they share a boundary segment of positive length. They are not considered to be adjacent if their boundaries meet only at a few points.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 14  #20\n",
      "\n",
      "14\n",
      "\t\n",
      "Chapter 1\n",
      "\t\n",
      "Propositions\n",
      "in the late 19th century before the mistake was found. An extremely laborious proof was finally found in 1976 by mathematicians Appel and Haken, who used a complex computer program to categorize the four-colorable maps; the program left a few thousand maps uncategorized, and these were checked by hand by Haken and his assistantsincluding his 15-year-old daughter. There was a lot of debate about whether this was a legitimate proof: the proof was too big to be checked without a computer, and no one could guarantee that the computer calculated correctly, nor did anyone have the energy to recheck the four-colorings of the thousands of maps that were done by hand. Within the past decade, a mostly intelligible proof of the Four-Color Theorem was found, though a computer is still needed to check the colorability of several hundred special maps.\n",
      "In some cases, we do not know whether or not a proposition is true. For exam-ple, the following simple proposition (known as Goldbachs Conjecture) has been heavily studied since 1742 but we still do not know if it is true. Of course, it has been checked by computer for many values of n, but as we have seen, that is not sufficient to conclude that it is true.\n",
      "Proposition 1.3.5 (Goldbach). Every even integer n greater than 2 is the sum of two primes.\n",
      "While the preceding propositions are important in mathematics, computer scien-tists are often interested in propositions concerning the correctness of programs and systems, to determine whether a program or system does what its supposed to do. Programs are notoriously buggy, and theres a growing community of re-searchers and practitioners trying to find ways to prove program correctness. These efforts have been successful enough in the case of CPU chips that they are now routinely used by leading chip manufacturers to prove chip correctness and avoid mistakes like the notorious Intel division bug in the 1990s.\n",
      "Developing mathematical methods to verify programs and systems remains an active research area. Well consider some of these methods later in the text.\n",
      "1.3.2\n",
      "\t\n",
      "Predicates\n",
      "A predicate is a proposition whose truth depends on the value of one or more vari-ables. Most of the propositions above were defined in terms of predicates. For example,\n",
      "n is a perfect square\n",
      "\n",
      "See \n",
      "The story of the Four-Color Proof is told in a well-reviewed popular (non-technical) book: Four Colors Suffice. How the Map Problem was Solved. Robin Wilson. Princeton Univ. Press, 2003, 276pp. ISBN 0-691-11533-8.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 15  #21\n",
      "\n",
      "is a predicate whose truth depends on the value of n. The predicate is true for n D 4 since four is a perfect square, but false for n D 5 since five is not a perfect square.\n",
      "Like other propositions, predicates are often named with a letter. Furthermore, a function-like notation is used to denote a predicate supplied with specific variable values. For example, we might name our earlier predicate P :\n",
      "P .n/ WWD n is a perfect square\n",
      "Now P .4/ is true, and P .5/ is false.\n",
      "This notation for predicates is confusingly similar to ordinary function notation.\n",
      "If P is a predicate, then P .n/ is either true or false, depending on the value of n.\n",
      "On the other hand, if p is an ordinary function, like n\n",
      "2\n",
      " Cn, then p.n/ is a numerical\n",
      "quantity. Dont confuse these two!\n",
      "1.3.3\n",
      "\t\n",
      "Quantifiers\n",
      "There are a couple of assertions commonly made about a predicate: that it is some-times true and that it is always true. For example, the predicate\n",
      "x\n",
      "2\n",
      "\t\n",
      "0\n",
      "is always true when x is a real number. On the other hand, the predicate\n",
      "true in English. The table below gives some general formats on the left and specific examples using those formats on the right. You can expect to see such phrases hundreds of times in mathematical writing!\n",
      "Always True\n",
      "For all n, P .n/ is true.\n",
      "P .n/ is true for every n.\n",
      "\n",
      "\n",
      "For all x 2 R, x\n",
      "2\n",
      "\t\n",
      "0.\n",
      "x\n",
      "2\n",
      "\t\n",
      "0 for every x 2 R.\n",
      "Sometimes True\n",
      "There exists an n such that P .n/ is true.\n",
      "P .n/ is true for some n.\n",
      "P .n/ is true for at least one n.\n",
      "\n",
      "\n",
      "All these sentences quantify how often the predicate is true. Specifically, an assertion that a predicate is always true, is called a universally quantified statement.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 16  #22\n",
      "\n",
      "16\n",
      "\t\n",
      "Chapter 1\n",
      "\t\n",
      "Propositions\n",
      "An assertion that a predicate is sometimes true, is called an existentially quantified statement.\n",
      "Sometimes English sentences are unclear about quantification:\n",
      "If you can solve any problem we come up with, then you get an A for the course.\n",
      "The phrase you can solve any problem we can come up with could reasonably be interpreted as either a universal or existential statement. It might mean:\n",
      "You can solve every problem we come up with,\n",
      "or maybe\n",
      "You can solve at least one problem we come up with.\n",
      "In the preceding example, the quantified phrase appears inside a larger if-then statement. This is quite normal; quantified statements are themselves propositions and can be combined with \n",
      "AND\n",
      ", \n",
      "OR\n",
      ", \n",
      "IMPLIES\n",
      ", etc., just like any other proposition.\n",
      "1.3.4\n",
      "\t\n",
      "More Notation\n",
      "There are symbols to represent universal and existential quantification, just as there are symbols for \n",
      "AND\n",
      " (^), \n",
      "IMPLIES\n",
      " (!), and so forth. In particular, to say that a predicate, P .x/, is true for all values of x in some set, D, we write:\n",
      "The universal quantifier symbol 8 is read for all, so this whole expression (\n",
      ") is read For all x in D, P .x/ is true. Remember that upside-down A stands for All.\n",
      "To say that a predicate P .x/ is true for at least one value of x in D, we write:\n",
      "The existential quantifier symbol 9, is read there exists. So expression (\n",
      ") is read, There exists an x in D such that P .x/ is true. Remember that backward E stands for Exists.\n",
      "The symbols 8 and 9 are always followed by a variabletypically with an in-dication of the set the variable ranges overand then a predicate, as in the two examples above.\n",
      "As an example, let Probs be the set of problems we come up with, Solves.x/ be the predicate You can solve problem x, and G be the proposition, You get an A for the course. Then the two different interpretations of\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 17  #23\n",
      "\n",
      "If you can solve any problem we come up with, then you get an A for the course.\n",
      "can be written as follows:\n",
      ".8x 2 Probs: Solves.x// \n",
      "IMPLIES\n",
      " G;\n",
      "or maybe\n",
      ".9x 2 Probs: Solves.x// \n",
      "IMPLIES\n",
      " G:\n",
      "1.3.5\tMixing Quantifiers\n",
      "Many mathematical statements involve several quantifiers. For example, Gold-bachs Conjecture states:\n",
      "Every even integer greater than 2 is the sum of two primes.\n",
      "Lets write this more verbosely to make the use of quantification clearer:\n",
      "For every even integer n greater than 2, there exist primes p and q such that n D p C q.\n",
      "Let Evens be the set of even integers greater than 2, and let Primes be the set of primes. Then we can write Goldbachs Conjecture in logic notation as follows:\n",
      "The proposition can also be written more simply as\n",
      "8n 2 Evens: 9p; q 2 Primes: p C q D n:\n",
      "1.3.6\n",
      "\t\n",
      "Order of Quantifiers\n",
      "Swapping the order of different kinds of quantifiers (existential or universal) usually changes the meaning of a proposition. For example, lets return to one of our initial, confusing statements:\n",
      "Every American has a dream.\n",
      "This sentence is ambiguous because the order of quantifiers is unclear. Let A be the set of Americans, let D be the set of dreams, and define the predicate H.a; d / to be American a has dream d . Now the sentence could mean that there is a single dream that every American shares:\n",
      "9 d 2 D: 8a 2 A: H.a; d /\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 18  #24\n",
      "\n",
      "18\n",
      "\t\n",
      "Chapter 1\n",
      "\t\n",
      "Propositions\n",
      "For example, it might be that every American shares the dream of owning their own home.\n",
      "Or it could mean that every American has a personal dream:\n",
      "8a 2 A: 9 d 2 D: H.a; d /\n",
      "For example, some Americans may dream of a peaceful retirement, while others dream of continuing practicing their profession as long as they live, and still others may dream of being so rich they neednt think at all about work.\n",
      "Swapping quantifiers in Goldbachs Conjecture creates a patently false state-ment; namely that every even number 2 is the sum of the same two primes:\n",
      "9 p; q 2 Primes: 8n 2 Evens: n D p C q:\n",
      "\n",
      "\n",
      "1.3.7\n",
      "\t\n",
      "Variables Over One Domain\n",
      "When all the variables in a formula are understood to take values from the same nonempty set, D, its conventional to omit mention of D. For example, instead of 8x 2 D 9y 2 D: Q.x; y/ wed write 8x9y: Q.x; y/. The unnamed nonempty set that x and y range over is called the domain of discourse, or just plain domain, of the formula.\n",
      "Its easy to arrange for all the variables to range over one domain. For exam-ple, Goldbachs Conjecture could be expressed with all variables ranging over the domain N as\n",
      "8n: .n 2 Evens/ \n",
      "IMPLIES\n",
      "  .9p 9q: p 2 Primes \n",
      "AND\n",
      " q 2 Primes \n",
      "AND\n",
      " n D p C q/:\n",
      "1.3.8\n",
      "\t\n",
      "Negating Quantifiers\n",
      "There is a simple relationship between the two kinds of quantifiers. The following two sentences mean the same thing:\n",
      "It is not the case that everyone likes to snowboard.\n",
      "There exists someone who does not like to snowboard.\n",
      "In terms of logic notation, this follows from a general property of predicate formu-las:\n",
      "NOT \n",
      ".8x: P .x//\n",
      "\t\n",
      "is equivalent to\n",
      "\t\n",
      "9x: \n",
      "NOT\n",
      ".P .x//:\n",
      "Similarly, these sentences mean the same thing:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 19  #25\n",
      "\n",
      "There does not exist anyone who likes skiing over magma.\n",
      "Everyone dislikes skiing over magma.\n",
      "We can express the equivalence in logic notation this way:\n",
      "The general principle is that moving a not across a quantifier changes the kind of quantifier.\n",
      "\n",
      "1.4\tValidity\n",
      "A propositional formula is called valid when it evaluates to T no matter what truth values are assigned to the individual propositional variables. For example, the propositional version of the Distributive Law is that \n",
      "P\n",
      " \n",
      "AND\n",
      " \n",
      ".Q\n",
      " \n",
      "OR\n",
      " \n",
      "R/\n",
      " is equiv-alent to \n",
      ".P\n",
      " \n",
      "AND\n",
      " \n",
      "Q/\n",
      " \n",
      "OR\n",
      " \n",
      ".P\n",
      " \n",
      "AND\n",
      " \n",
      "R/\n",
      ". This is the same as saying that\n",
      "is valid. This can be verified by checking the truth table for \n",
      "P\n",
      " \n",
      "AND\n",
      " \n",
      ".Q\n",
      " \n",
      "OR\n",
      " \n",
      "R/\n",
      " and \n",
      ".P \n",
      "AND\n",
      " Q/ \n",
      "OR\n",
      " .P \n",
      "AND\n",
      " R/\n",
      ":\n",
      "The same idea extends to predicate formulas, but to be valid, a formula now must evaluate to true no matter what values its variables may take over any unspecified domain, and no matter what interpretation a predicate variable may be given. For example, we already observed that the rule for negating a quantifier is captured by the valid assertion (\n",
      ").\n",
      "Another useful example of a valid assertion is\n",
      "Heres an explanation why this is valid:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 20  #26\n",
      "\n",
      "20\n",
      "\t\n",
      "Chapter 1\n",
      "\t\n",
      "Propositions\n",
      "Let D be the domain for the variables and P\n",
      "0\n",
      " be some binary predi-cate\n",
      "on D. We need to show that if\n",
      "holds under this interpretation, then so does\n",
      "So suppose (\n",
      ") is true. Then by definition of 9, this means that some element d\n",
      "0\n",
      " 2 D has the property that\n",
      "8y 2 D: P\n",
      "0\n",
      ".d\n",
      "0\n",
      "; y/:\n",
      "By definition of 8, this means that\n",
      "P\n",
      "0\n",
      ".d\n",
      "0\n",
      "; d /\n",
      "is true for all d 2 D. So given any d 2 D, there is an element in D, namely, d\n",
      "0\n",
      ", such that P\n",
      "0\n",
      ".d\n",
      "0\n",
      "; d / is true. But thats exactly what (\n",
      ") means, so weve proved that (\n",
      ") holds under this interpretation, as required.\n",
      "We hope this is helpful as an explanation, although purists would not really want to call it a proof. The problem is that with something as basic as (\n",
      "), its hard to see what more elementary axioms are ok to use in proving it. What the explanation above did was translate the logical formula (\n",
      ") into English and then appeal to the meaning, in English, of for all and there exists as justification.\n",
      "In contrast to (\n",
      "), the formula\n",
      "is not valid. We can prove this by describing an interpretation where the hypoth-esis, 8y9x: P .x; y/, is true but the conclusion, 9x8y: P .x; y/, is not true. For example, let the domain be the integers and P .x; y/ mean x > y. Then the hypoth-esis would be true because, given a value, n, for y we could, for example, choose the value of x to be n C 1. But under this interpretation the conclusion asserts that there is an integer that is bigger than all integers, which is certainly false. An interpretation like this which falsifies an assertion is called a counter model to the assertion.\n",
      "\n",
      "That is, a predicate that depends on two variables.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 21  #27\n",
      "\n",
      "\n",
      "1.5\tSatisfiability\n",
      "A proposition is satisfiable if some setting of the variables makes the proposition true. For example, P \n",
      "AND\n",
      " Q is satisfiable because the expression is true if P is true or Q is false. On the other hand, P \n",
      "AND\n",
      " P is not satisfiable because the expression as a whole is false for both settings of P . But determining whether or not a more complicated proposition is satisfiable is not so easy. How about this one?\n",
      "\n",
      ".P \n",
      "OR\n",
      " Q \n",
      "OR\n",
      " R/ \n",
      "AND\n",
      " .P \n",
      "OR\n",
      " Q/ \n",
      "AND\n",
      " .P \n",
      "OR\n",
      " R/ \n",
      "AND\n",
      " .R \n",
      "OR\n",
      " Q/\n",
      "The general problem of deciding whether a proposition is satisfiable is called SAT. One approach to SAT is to construct a truth table and check whether or not a T ever appears. But this approach is not very efficient; a proposition with n variables has a truth table with 2\n",
      "n\n",
      " lines, so the effort required to decide about a proposition grows exponentially with the number of variables. For a proposition with just 30 variables, thats already over a billion lines to check!\n",
      "Is there a more efficient solution to SAT? In particular, is there some, presum-ably very ingenious, procedure that determines in a number of steps that grows polynomiallylike n\n",
      "2\n",
      " or n\n",
      "14\n",
      "instead of exponentially, whether any given propo-sition is satisfiable or not? No one knows. And an awful lot hangs on the answer. An efficient solution to SAT would immediately imply efficient solutions to many, many other important problems involving packing, scheduling, routing, and cir-cuit verification, among other things. This would be wonderful, but there would also be worldwide chaos. Decrypting coded messages would also become an easy task (for most codes). Online financial transactions would be insecure and secret communications could be read by everyone.\n",
      "Recently there has been exciting progress on sat-solvers for practical applica-tions like digital circuit verification. These programs find satisfying assignments with amazing efficiency even for formulas with millions of variables. Unfortu-nately, its hard to predict which kind of formulas are amenable to sat-solver meth-ods, and for formulas that are NOT satisfiable, sat-solvers generally take exponen-tial time to verify that.\n",
      "So no one has a good idea how to solve SAT in polynomial time, or how to prove that it cant be doneresearchers are completely stuck. The problem of determining whether or not SAT has a polynomial time solution is known as the P vs. NP problem. It is the outstanding unanswered question in theoretical computer science. It is also one of the seven \n",
      ": the Clay Institute will award you $1,000,000 if you solve the P vs. NP problem.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 22  #28\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 23  #29\n",
      "\n",
      "Patterns of Proof\n",
      "\n",
      "2.1\n",
      "\t\n",
      "The Axiomatic Method\n",
      "The standard procedure for establishing truth in mathematics was invented by Eu-clid, a mathematician working in Alexandria, Egypt around 300 BC. His idea was to begin with five assumptions about geometry, which seemed undeniable based on direct experience. For example, one of the assumptions was There is a straight line segment between every pair of points. Propositions like these that are simply accepted as true are called axioms.\n",
      "Starting from these axioms, Euclid established the truth of many additional propo-sitions by providing proofs. A proof is a sequence of logical deductions from axioms and previously-proved statements that concludes with the proposition in question. You probably wrote many proofs in high school geometry class, and youll see a lot more in this course.\n",
      "There are several common terms for a proposition that has been proved. The different terms hint at the role of the proposition within a larger body of work.\n",
      "Important propositions are called theorems.\n",
      "A lemma is a preliminary proposition useful for proving later propositions. A corollary is a proposition that follows in just a few logical steps from a\n",
      "lemma or a theorem.\n",
      "The definitions are not precise. In fact, sometimes a good lemma turns out to be far more important than the theorem it was originally used to prove.\n",
      "Euclids axiom-and-proof approach, now called the axiomatic method, is the foundation for mathematics today. In fact, just a handful of axioms, collectively called Zermelo-Frankel Set Theory with Choice (ZFC), together with a few logical deduction rules, appear to be sufficient to derive essentially all of mathematics.\n",
      "2.1.1\tOur Axioms\n",
      "The ZFC axioms are important in studying and justifying the foundations of math-ematics, but for practical purposes, they are much too primitive. Proving theorems in ZFC is a little like writing programs in byte code instead of a full-fledged pro-gramming languageby one reckoning, a formal proof in ZFC that 2 C 2 D 4 requires more than 20,000 steps! So instead of starting with ZFC, were going to\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 24  #30\n",
      "\n",
      "24\n",
      "\t\n",
      "Chapter 2\n",
      "\t\n",
      "Patterns of Proof\n",
      "take a huge set of axioms as our foundation: well accept all familiar facts from high school math!\n",
      "This will give us a quick launch, but you may find this imprecise specification of the axioms troubling at times. For example, in the midst of a proof, you may find yourself wondering, Must I prove this little fact or can I take it as an axiom? Feel free to ask for guidance, but really there is no absolute answer. Just be up front about what youre assuming, and dont try to evade homework and exam problems by declaring everything an axiom!\n",
      "2.1.2\n",
      "\t\n",
      "Logical Deductions\n",
      "Logical deductions or inference rules are used to prove new propositions using previously proved ones.\n",
      "A fundamental inference rule is modus ponens. This rule says that a proof of P together with a proof that P \n",
      "IMPLIES\n",
      " Q is a proof of Q.\n",
      "Inference rules are sometimes written in a funny notation. For example, modus ponens is written:\n",
      "Rule 2.1.1.\n",
      "P;\tP \n",
      "IMPLIES\n",
      " Q\n",
      "\n",
      "Q\n",
      "When the statements above the line, called the antecedents, are proved, then we can consider the statement below the line, called the conclusion or consequent, to also be proved.\n",
      "A key requirement of an inference rule is that it must be sound: any assignment of truth values that makes all the antecedents true must also make the consequent true. So if we start off with true axioms and apply sound inference rules, everything we prove will also be true.\n",
      "You can see why modus ponens is a sound inference rule by checking the truth table of P \n",
      "IMPLIES\n",
      " Q. There is only one case where P and P \n",
      "IMPLIES\n",
      " Q are both true, and in that case Q is also true.\n",
      "\n",
      "QP!Q\n",
      "There are many other natural, sound inference rules, for example:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 25  #31\n",
      "\n",
      "Rule 2.1.2.\n",
      "P \n",
      "IMPLIES\n",
      " Q;\tQ \n",
      "IMPLIES\n",
      " R\n",
      "\n",
      "IMPLIES \n",
      "R\n",
      "Rule 2.1.3.\n",
      "P \n",
      "IMPLIES\n",
      " Q;\n",
      "\t\n",
      "NOT\n",
      ".Q/\n",
      "\n",
      "NOT\n",
      ".P /\n",
      "Rule 2.1.4.\n",
      "NOT\n",
      ".P /\n",
      " IMPLIES NOT\n",
      ".Q/\n",
      "\n",
      "Q \n",
      "IMPLIES\n",
      " P\n",
      "On the other hand,\n",
      "Non-Rule.\n",
      "NOT\n",
      ".P /\n",
      " IMPLIES NOT\n",
      ".Q/\n",
      "\n",
      "IMPLIES \n",
      "Q\n",
      "is not sound: if P is assigned T and Q is assigned F, then the antecedent is true and the consequent is not.\n",
      "Note that a propositional inference rule is sound precisely when the conjunction (AND) of all its antecedents implies its consequent.\n",
      "As with axioms, we will not be too formal about the set of legal inference rules. Each step in a proof should be clear and logical; in particular, you should state what previously proved facts are used to derive each new conclusion.\n",
      "2.1.3\n",
      "\t\n",
      "Proof Templates\n",
      "In principle, a proof can be any sequence of logical deductions from axioms and previously proved statements that concludes with the proposition in question. This freedom in constructing a proof can seem overwhelming at first. How do you even start a proof?\n",
      "Heres the good news: many proofs follow one of a handful of standard tem-plates. Each proof has it own details, of course, but these templates at least provide you with an outline to fill in. In the remainder of this chapter, well go through several of these standard patterns, pointing out the basic idea and common pitfalls and giving some examples. Many of these templates fit together; one may give you a top-level outline while others help you at the next level of detail. And well show you other, more sophisticated proof techniques in Chapter \n",
      ".\n",
      "The recipes that follow are very specific at times, telling you exactly which words to write down on your piece of paper. Youre certainly free to say things your own way instead; were just giving you something you could say so that youre never at a complete loss.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 26  #32\n",
      "\n",
      "26\n",
      "\t\n",
      "Chapter 2\n",
      "\t\n",
      "Patterns of Proof\n",
      "\n",
      "2.2\n",
      "\t\n",
      "Proof by Cases\n",
      "Breaking a complicated proof into cases and proving each case separately is a use-ful and common proof strategy. In fact, we have already implicitly used this strategy when we used truth tables to show that certain propositions were true or valid. For example, in section \n",
      ", we showed that an implication P \n",
      "IMPLIES\n",
      " Q is equiv-alent to its contrapositive \n",
      "NOT\n",
      ".Q/ \n",
      "IMPLIES NOT\n",
      ".P / by considering all 4 possible assignments of T or F to P and Q. In each of the four cases, we showed that\n",
      "IMPLIES \n",
      "Q\n",
      " \n",
      "is true if and only if\n",
      " NOT\n",
      ".Q/\n",
      " IMPLIES NOT\n",
      ".P /\n",
      " \n",
      "is true. For exam-ple, if P D T and Q D F, then both P \n",
      "IMPLIES\n",
      " Q and \n",
      "NOT\n",
      ".Q/ \n",
      "IMPLIES NOT\n",
      ".P / are false, thereby establishing that .P \n",
      "IMPLIES\n",
      " Q/\n",
      "IFF\n",
      ".\n",
      "NOT\n",
      ".Q/ \n",
      "IMPLIES NOT\n",
      ".P // is true for this case. If a proposition is true in every possible case, then it is true.\n",
      "Proof by cases works in much more general environments than propositions in-volving Boolean variables. In what follows, we will use this approach to prove a simple fact about acquaintances. As background, we will assume that for any pair of people, either they have met or not. If every pair of people in a group has met, well call the group a club. If every pair of people in a group has not met, well call it a group of strangers.\n",
      "Theorem. Every collection of 6 people includes a club of 3 people or a group of 3 strangers.\n",
      "Proof. The proof is by case analysis\n",
      ". Let x denote one of the six people. There are two cases:\n",
      "Among the other 5 people besides x, at least 3 have met x.\n",
      "Among the other 5 people, at least 3 have not met x.\n",
      "Now we have to be sure that at least one of these two cases must hold,\n",
      "but thats easy: weve split the 5 people into two groups, those who have shaken hands with x and those who have not, so one of the groups must have at least half the people.\n",
      "Case 1: Suppose that at least 3 people have met x.\n",
      "This case splits into two subcases:\n",
      "\n",
      "Describing your approach at the outset helps orient the reader. Try to remember to always do\n",
      "this.\n",
      "2\n",
      "Part of a case analysis argument is showing that youve covered all the cases. Often this is obvious, because the two cases are of the form P  and not P . However, the situation above is not stated quite so simply.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 27  #33\n",
      "\n",
      "Case 1.1: Among the people who have met x, none have met each other. Then the people who have met x are a group of at least 3 strangers. So the Theorem holds in this subcase.\n",
      "Case 1.2: Among the people who have met x, some pair have met each other. Then that pair, together with x, form a club of 3 people. So the Theorem holds in this subcase.\n",
      "This implies that the Theorem holds in Case 1.\n",
      "Case 2: Suppose that at least 3 people have not met x.\n",
      "This case also splits into two subcases:\n",
      "Case 2.1: Among the people who have not met x, every pair has met each other. Then the people who have not met x are a club of at least 3 people. So the Theorem holds in this subcase.\n",
      "Case 2.2: Among the people who have not met x, some pair have not met each other. Then that pair, together with x, form a group of at least 3 strangers. So the Theorem holds in this subcase.\n",
      "This implies that the Theorem also holds in Case 2, and therefore holds in all cases.\n",
      "\n",
      "2.3\n",
      "\t\n",
      "Proving an Implication\n",
      "Propositions of the form If P , then Q are called implications. This implication is often rephrased as P \n",
      "IMPLIES\n",
      " Q or P ! Q.\n",
      "Here are some examples of implications:\n",
      "(Quadratic Formula) If ax\n",
      "2\n",
      " C bx C c D 0 and a  0, then\n",
      "(Goldbachs Conjecture) If n is an even integer greater than 2, then n is a sum of two primes.\n",
      "If 0\n",
      "\t\n",
      "x\n",
      "\t\n",
      "2, then x  \n",
      "3\n",
      " C 4x C 1 > 0.\n",
      "There are a couple of standard methods for proving an implication.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 28  #34\n",
      "\n",
      "28\n",
      "\t\n",
      "Chapter 2\n",
      "\t\n",
      "Patterns of Proof\n",
      "2.3.1\n",
      "\t\n",
      "Method #1: Assume P is true\n",
      "When proving P \n",
      "IMPLIES\n",
      " Q, there are two cases to consider: P is true and P is false. The case when P is false is easy since, by definition, F \n",
      "IMPLIES\n",
      " Q is true no matter what Q is. This case is so easy that we usually just forget about it and start right off by assuming that P is true when proving an implication, since this is the only case that is interesting. Hence, in order to prove that P \n",
      "IMPLIES\n",
      " Q:\n",
      "Write, Assume P .\n",
      "Show that Q logically follows.\n",
      "For example, we will use this method to prove\n",
      "Theorem 2.3.1. If 0\n",
      "\t\n",
      "x\n",
      "\t\n",
      "2, then x  \n",
      "3\n",
      " C 4x C 1 > 0.\n",
      "Before we write a proof of this theorem, we have to do some scratchwork to figure out why it is true.\n",
      "The inequality certainly holds for x D 0; then the left side is equal to 1 and\n",
      "1 > 0. As x grows, the 4x term (which is positive) initially seems to have greater\n",
      "So far, so good. But we still have to replace all those seems like phrases with solid, logical arguments. We can get a better handle on the critical x \n",
      "3\n",
      " C 4x part by factoring it, which is not too hard:\n",
      "x  \n",
      "3\n",
      " C 4x D x.2\tx/.2 C x/\n",
      "Aha! For x between 0 and 2, all of the terms on the right side are nonnegative. And a product of nonnegative terms is also nonnegative. Lets organize this blizzard of observations into a clean proof.\n",
      "Proof. Assume 0 x 2. Then x, 2 x, and 2Cx are all nonnegative. Therefore, the product of these terms is also nonnegative. Adding 1 to this product gives a positive number, so:\n",
      "x.2\tx/.2 C x/ C 1 > 0\n",
      "Multiplying out on the left side proves that\n",
      "3\n",
      " C 4x C 1 > 0\n",
      "as claimed.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 29  #35\n",
      "\n",
      "There are a couple points here that apply to all proofs:\n",
      "Youll often need to do some scratchwork while youre trying to figure out the logical steps of a proof. Your scratchwork can be as disorganized as you likefull of dead-ends, strange diagrams, obscene words, whatever. But keep your scratchwork separate from your final proof, which should be clear and concise.\n",
      "Proofs typically begin with the word Proof and end with some sort of doohickey like or or q.e.d. The only purpose for these conventions is to clarify where proofs begin and end.\n",
      "Potential Pitfall\n",
      "For the purpose of proving an implication P \n",
      "IMPLIES\n",
      " Q, its OK, and typical, to begin by assuming P . But when the proof is over, its no longer OK to assume that\n",
      "holds! For example, Theorem \n",
      "has the form if P , then Q with P being\n",
      "0 x 2 and Q being x \n",
      "3\n",
      " C 4x C 1 > 0, and its proof began by assuming that 0 x 2. But of course this assumption does not always hold. Indeed, if you were going to prove another result using the variable x, it could be disastrous to have a step where you assume that 0 x 2 just because you assumed it as part of the proof of Theorem \n",
      ".\n",
      "2.3.2\n",
      "\t\n",
      "Method #2: Prove the Contrapositive\n",
      "We have already seen that an implication P \n",
      "IMPLIES\n",
      " Q is logically equivalent to its contrapositive\n",
      "NOT\n",
      ".Q/\n",
      " IMPLIES NOT\n",
      ".P /:\n",
      "Proving one is as good as proving the other, and proving the contrapositive is some-times easier than proving the original statement. Hence, you can proceed as fol-lows:\n",
      "Write, We prove the contrapositive: and then state the contrapositive.\n",
      "Proceed as in Method #1.\n",
      "For example, we can use this approach to prove\n",
      "p\n",
      "\n",
      "Theorem 2.3.2. If r is irrational, then\n",
      "\t\n",
      "r is also irrational.\n",
      "Recall that rational numbers are equal to a ratio of integers and irrational num-p\n",
      "\n",
      "bers are not. So we must show that if r is not a ratio of integers, then r is also not a ratio of integers. Thats pretty convoluted! We can eliminate both nots and make the proof straightforward by considering the contrapositive instead.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 30  #36\n",
      "\n",
      "\n",
      "2.4\tProving an If and Only If\n",
      "Many mathematical theorems assert that two statements are logically equivalent; that is, one holds if and only if the other does. Here is an example that has been known for several thousand years:\n",
      "Two triangles have the same side lengths if and only if two side lengths and the angle between those sides are the same in each triangle.\n",
      "The phrase if and only if comes up so often that it is often abbreviated iff.\n",
      "2.4.1\n",
      "\t\n",
      "Method #1: Prove Each Statement Implies the Other\n",
      "The statement P \n",
      "IFF\n",
      " Q is equivalent to the two statements P \n",
      "IMPLIES\n",
      " Q and Q \n",
      "IMPLIES\n",
      " P . So you can prove an iff by proving two implications:\n",
      "Write, We prove P implies Q and vice-versa.\n",
      "Write, First, we show P implies Q. Do this by one of the methods in Section \n",
      ".\n",
      "Write, Now, we show Q implies P . Again, do this by one of the methods in Section \n",
      ".\n",
      "2.4.2\n",
      "\t\n",
      "Method #2: Construct a Chain of \n",
      "IFF\n",
      "s\n",
      "In order to prove that P is true iff Q is true:\n",
      "Write, We construct a chain of if-and-only-if implications.\n",
      "Prove P is equivalent to a second statement which is equivalent to a third statement and so forth until you reach Q.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 31  #37\n",
      "\n",
      "This method sometimes requires more ingenuity than the first, but the result can be a short, elegant proof, as we see in the following example.\n",
      "Theorem 2.4.1. The standard deviation of a sequence of values x\n",
      "1\n",
      "; : : : ; x\n",
      "n\n",
      " is zero iff all the values are equal to the mean.\n",
      "Definition. The standard deviation of a sequence of values x\n",
      "1\n",
      "; x\n",
      "2\n",
      "; : : : ; x\n",
      "n\n",
      " is de-fined to be:\n",
      "\n",
      "s\n",
      "As an example, Theorem \n",
      "says that the standard deviation of test scores is zero if and only if everyone scored exactly the class average. (We will talk a lot more about means and standard deviations in Part IV of the book.)\n",
      "Proof. We construct a chain of iff implications, starting with the statement that the standard deviation (\n",
      ") is zero:\n",
      "s\n",
      "\n",
      "Since zero is the only number whose square root is zero, equation (\n",
      ") holds iff\n",
      "Squares of real numbers are always nonnegative, and so every term on the left hand side of equation (\n",
      ") is nonnegative. This means that (\n",
      ") holds iff\n",
      "Every term on the left hand side of (\n",
      ") is zero.\t\n",
      "(2.4)\n",
      "But a term .x\n",
      "i\n",
      "\t\n",
      "/\n",
      "2\n",
      " is zero iff x\n",
      "i\n",
      " D\n",
      "\t\n",
      ", so (\n",
      ") is true iff\n",
      "Every x\n",
      "i\n",
      " equals the mean.\n",
      "mcs-ftl  2010/9/8  0:40  page 32  #38\n",
      "\n",
      "32\n",
      "\t\n",
      "Chapter 2\n",
      "\t\n",
      "Patterns of Proof\n",
      "\n",
      "2.5\n",
      "\t\n",
      "Proof by Contradiction\n",
      "In a proof by contradiction or indirect proof, you show that if a proposition were false, then some false fact would be true. Since a false fact cant be true, the propo-sition had better not be false. That is, the proposition really must be true.\n",
      "Proof by contradiction is always a viable approach. However, as the name sug-gests, indirect proofs can be a little convoluted. So direct proofs are generally preferable as a matter of clarity.\n",
      "Method: In order to prove a proposition P by contradiction:\n",
      "Write, We use proof by contradiction.\n",
      "Write, Suppose P is false.\n",
      "Deduce something known to be false (a logical contradiction).\n",
      "Write, This is a contradiction. Therefore, P must be true.\n",
      "p\n",
      "\n",
      "As an example, we will use proof by contradiction to prove that 2 is irrational. Recall that a number is rational if it is equal to a ratio of integers. For example, 3:5 D 7=2 and 0:1111 D 1=9 are rational numbers.\n",
      "integers. Furthermore, lets take n and d so that n=d is in lowest terms (that is, so that there is no number greater than 1 that divides both n and d ).\n",
      "Squaring both sides gives 2 D n\n",
      "2\n",
      "=d \n",
      "2\n",
      " and so 2d \n",
      "2\n",
      " D n\n",
      "2\n",
      ". This implies that n is a multiple of 2. Therefore n\n",
      "2\n",
      " must be a multiple of 4. But since 2d \n",
      "2\n",
      " D n\n",
      "2\n",
      ", we know 2d \n",
      "2\n",
      " is a multiple of 4 and so d \n",
      "2\n",
      " is a multiple of 2. This implies that d is a multiple of 2.\n",
      "So the numerator and denominator have 2 as a common factor, which contradicts\n",
      "p\n",
      "\n",
      "the fact that n=d is in lowest terms. So\n",
      "\t\n",
      "2 must be irrational.\n",
      "Potential Pitfall\n",
      "A proof of a proposition P by contradiction is really the same as proving the impli-cation T \n",
      "IMPLIES\n",
      " P by contrapositive. Indeed, the contrapositive of T \n",
      "IMPLIES\n",
      " P is \n",
      "NOT\n",
      ".P / \n",
      "IMPLIES\n",
      " F. As we saw in Section \n",
      ", such a proof would be begin by assuming \n",
      "NOT\n",
      ".P / in an effort to derive a falsehood, just as you do in a proof by contradiction.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 33  #39\n",
      "\n",
      "No matter how you think about it, it is important to remember that when you start by assuming \n",
      "NOT\n",
      ".P /, you will derive conclusions along the way that are not necessarily true. (Indeed, the whole point of the method is to derive a falsehood.) This means that you cannot rely on intermediate results after a proof by contradic-tion is completed (for example, that n is even after the proof of Theorem \n",
      "). There was not much risk of that happening in the proof of Theorem \n",
      ", but when you are doing more complicated proofs that build up from several lemmas, some of which utilize a proof by contradiction, it will be important to keep track of which propositions only follow from a (false) assumption in a proof by contradiction.\n",
      "\n",
      "2.6\n",
      "\t\n",
      "Proofs about Sets\n",
      "Sets are simple, flexible, and everywhere. You will find some set mentioned in nearly every section of this text. In fact, we have already talked about a lot of sets: the set of integers, the set of real numbers, and the set of positive even numbers, to name a few.\n",
      "In this section, well see how to prove basic facts about sets. Well start with some definitions just to make sure that you know the terminology and that you are comfortable working with sets.\n",
      "2.6.1\n",
      "\t\n",
      "Definitions\n",
      "Informally, a set is a bunch of objects, which are called the elements of the set. The elements of a set can be just about anything: numbers, points in space, or even other sets. The conventional way to write down a set is to list the elements inside curly-braces. For example, here are some sets:\n",
      "D fAlex; Tippy; Shells; Shadowg dead pets\n",
      "B\n",
      "\t\n",
      "D fred; blue; yellowg\n",
      "\t\n",
      "primary colors\n",
      "C\n",
      "\t\n",
      "D ffa; bg; fa; cg; fb; cgg\n",
      "\t\n",
      "a set of sets\n",
      "This works fine for small finite sets. Other sets might be defined by indicating how to generate a list of them:\n",
      "D D f1; 2; 4; 8; 16; : : : g\n",
      "\t\n",
      "the powers of 2\n",
      "The order of elements is not significant, so fx; y g and fy; xg are the same set written two different ways. Also, any object is, or is not, an element of a given\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 34  #40\n",
      "\n",
      "34\n",
      "\t\n",
      "Chapter 2\n",
      "\t\n",
      "Patterns of Proof\n",
      "setthere is no notion of an element appearing more than once in a set.\n",
      "So writ-ing fx; xg is just indicating the same thing twice, namely, that x is in the set. In particular, fx; xg D fxg.\n",
      "The expression e 2 S asserts that e is an element of set S. For example, 32 2 D and blue 2 B, but Tailspin 62Ayet.\n",
      "Some Popular Sets\n",
      "Mathematicians have devised special symbols to represent some common sets.\n",
      "A superscript \n",
      "C\n",
      " restricts a set to its positive elements; for example, R\n",
      "C\n",
      " denotes the set of positive real numbers. Similarly, R denotes the set of negative reals.\n",
      "Comparing and Combining Sets\n",
      "The expression S T indicates that set S is a subset of set T , which means that every element of S is also an element of T (it could be that S D T ). For example, N Z and Q R (every rational number is a real number), but C 6 Z (not every complex number is an integer).\n",
      "As a memory trick, notice that the points to the smaller set, just like a sign points to the smaller number. Actually, this connection goes a little further: there is a symbol analogous to <. Thus, S T means that S is a subset of T , but the two are not equal. So A A, but A 6 A, for every set A.\n",
      "There are several ways to combine sets. Lets define a couple of sets for use in examples:\n",
      "X WWD f1; 2; 3g\n",
      "Y WWD f2; 3; 4g\n",
      "The union of sets X and Y (denoted X [ Y ) contains all elements appearing\n",
      "in X or Y or both. Thus, X [ Y D f1; 2; 3; 4g.\n",
      "\n",
      "Its not hard to develop a notion of multisets in which elements can occur more than once, but multisets are not ordinary sets.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 35  #41\n",
      "\n",
      "The intersection of X and Y (denoted X \\ Y ) consists of all elements that appear in both X and Y . So X \\ Y D f2; 3g.\n",
      "The set difference of X and Y (denoted X Y ) consists of all elements that are in X, but not in Y . Therefore, X Y D f1g and Y X D f4g.\n",
      "The Complement of a Set\n",
      "Sometimes we are focused on a particular domain, D. Then for any subset, A, of D, we define A to be the set of all elements of D not in A. That is, A WWD D A. The set A is called the complement of A.\n",
      "\n",
      "For example, when the domain were working with is the real numbers, the com-plement of the positive real numbers is the set of negative real numbers together with zero. That is,\n",
      "R\n",
      "C\n",
      " D R [ f0g:\n",
      "\n",
      "It can be helpful to rephrase properties of sets using complements. For example, two sets, A and B, are said to be disjoint iff they have no elements in common, that is, A \\ B D ;. This is the same as saying that A is a subset of the complement of B, that is, A B.\n",
      "\n",
      "Cardinality\n",
      "The cardinality of a set A is the number of elements in A and is denoted by jAj. For example,\n",
      "j;j D 0;\n",
      "jf1; 2; 4gj D 3, and\n",
      "jNj is infinite.\n",
      "The Power Set\n",
      "The set of all the subsets of a set, A, is called the power set, P.A/, of A.  So\n",
      "2 P.A/ iff B A. For example, the elements of P.f1; 2g/ are ;; f1g; f2g and f1; 2g.\n",
      "More generally, if A has n elements, then there are 2\n",
      "n\n",
      " sets in P.A/. In other words, if A is finite, then jP.A/j D 2\n",
      "jAj\n",
      ". For this reason, some authors use the notation 2\n",
      "A\n",
      " instead of P.A/ to denote the power set of A.\n",
      "Sequences\n",
      "Sets provide one way to group a collection of objects. Another way is in a se-quence, which is a list of objects called terms or components. Short sequences\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 36  #42\n",
      "\n",
      "36\n",
      "\t\n",
      "Chapter 2\n",
      "\t\n",
      "Patterns of Proof\n",
      "are commonly described by listing the elements between parentheses; for example, .a; b; c/ is a sequence with three terms.\n",
      "While both sets and sequences perform a gathering role, there are several differ-ences.\n",
      "The elements of a set are required to be distinct, but terms in a sequence can be the same. Thus, .a; b; a/ is a valid sequence of length three, but fa; b; ag is a set with two elementsnot three.\n",
      "The terms in a sequence have a specified order, but the elements of a set do not. For example, .a; b; c/ and .a; c; b/ are different sequences, but fa; b; cg and fa; c; bg are the same set.\n",
      "Texts differ on notation for the empty sequence; we use for the empty sequence and ; for the empty set.\n",
      "Cross Products\n",
      "The product operation is one link between sets and sequences. A product of sets, S\n",
      "1\n",
      " S\n",
      "2\n",
      " S\n",
      "n\n",
      ", is a new set consisting of all sequences where the first component is drawn from S\n",
      "1\n",
      ", the second from S\n",
      "2\n",
      ", and so forth. For example, N fa; bg is the set of all pairs whose first element is a nonnegative integer and whose second element is an a or a b:\n",
      "fa; bg D f.0; a/; .0; b/; .1; a/; .1; b/; .2; a/; .2; b/; : : : g\n",
      "A product of n copies of a set S is denoted S\n",
      "n\n",
      ". For example, f0; 1g\n",
      "3\n",
      " is the set of all 3-bit sequences:\n",
      "f0; 1g\n",
      "3\n",
      " D f.0; 0; 0/; .0; 0; 1/; .0; 1; 0/; .0; 1; 1/; .1; 0; 0/; .1; 0; 1/; .1; 1; 0/; .1; 1; 1/g\n",
      "2.6.2\n",
      "\t\n",
      "Set Builder Notation\n",
      "An important use of predicates is in set builder notation. Well often want to talk about sets that cannot be described very well by listing the elements explicitly or by taking unions, intersections, etc., of easily-described sets. Set builder notation often comes to the rescue. The idea is to define a set using a predicate; in particular, the set consists of all values that make the predicate true. Here are some examples of set builder notation:\n",
      "A WWD fn 2 N j n is a prime and n D 4k C 1 for some integer kg B WWD fx 2 R j x\n",
      "3\n",
      " 3x C 1 > 0g\n",
      "WWD fa C bi 2 C j a\n",
      "2\n",
      " C 2b\n",
      "2\n",
      "   1g\n",
      "The set A consists of all nonnegative integers n for which the predicate\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 37  #43\n",
      "\n",
      "\n",
      "n\n",
      " is a prime and \n",
      "n\n",
      " D \n",
      "4k\n",
      " C \n",
      "1\n",
      " for some integer \n",
      "k\n",
      " is true. Thus, the smallest elements of \n",
      "A\n",
      " are:\n",
      "5; 13; 17; 29; 37; 41; 53; 57; 61; 73; : : : :\n",
      "Trying to indicate the set \n",
      "A\n",
      " by listing these first few elements wouldnt work very well; even after ten terms, the pattern is not obvious! Similarly, the set \n",
      "B\n",
      " consists of all real numbers \n",
      "x\n",
      " for which the predicate\n",
      "x\n",
      "3\n",
      "\t3x \n",
      "C\n",
      " 1 > 0\n",
      "is true. In this case, an explicit description of the set \n",
      "B\n",
      " in terms of intervals would require solving a cubic equation. Finally, set \n",
      "C\n",
      " consists of all complex numbers \n",
      "a \n",
      "C\n",
      " bi \n",
      "such that:\n",
      "a\n",
      "2\n",
      " \n",
      "C\n",
      " 2b\n",
      "2\n",
      "\t\n",
      "1\n",
      "This is an oval-shaped region around the origin in the complex plane.\n",
      "2.6.3\n",
      "\t\n",
      "Proving Set Equalities\n",
      "Two sets are defined to be equal if they contain the same elements. That is, \n",
      "X\n",
      " D \n",
      "Y\n",
      " means that \n",
      "z\n",
      " 2 \n",
      "X\n",
      " if and only if \n",
      "z\n",
      " 2 \n",
      "Y\n",
      " , for all elements, \n",
      "z\n",
      ". (This is actually the first of the ZFC axioms.) So set equalities can often be formulated and proved as iff theorems. For example:\n",
      "Theorem 2.6.1 (Distributive Law for Sets). Let \n",
      "A\n",
      ", \n",
      "B\n",
      ", and \n",
      "C\n",
      " be sets. Then:\n",
      "Proof. The equality (\n",
      ") is equivalent to the assertion that\n",
      "for all \n",
      "z\n",
      ". This assertion looks very similar to the Distributive Law for \n",
      "AND\n",
      " and \n",
      "OR \n",
      "that we proved in Section\n",
      " \n",
      "(equation\n",
      " \n",
      "). Namely, if\n",
      " \n",
      "P\n",
      " \n",
      ",\n",
      " \n",
      "Q\n",
      ", and\n",
      " \n",
      "R\n",
      " \n",
      "are\n",
      " \n",
      "propositions, then\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 38  #44\n",
      "\n",
      "38\n",
      "\t\n",
      "Chapter 2\n",
      "\t\n",
      "Patterns of Proof\n",
      "Many other set equalities can be derived from other valid propositions and proved in an analogous manner. In particular, propositions such as P , Q and R are re-placed with sets such as A, B, and C , \n",
      "AND\n",
      " (^) is replaced with intersection (\\), \n",
      "OR \n",
      "(_) is replaced with union ([),\n",
      " NOT \n",
      "is replaced with complement (for example,\n",
      "\n",
      "would become A), and \n",
      "IFF\n",
      " becomes set equality (D). Of course, you should always check that any alleged set equality derived in this manner is indeed true.\n",
      "2.6.4\n",
      "\t\n",
      "Russells Paradox and the Logic of Sets\n",
      "Reasoning naively about sets can sometimes be tricky. In fact, one of the earliest at-tempts to come up with precise axioms for sets by a late nineteenth century logician named Gotlob Frege was shot down by a three line argument known as Russells Paradox:\n",
      "This was an astonishing blow to efforts to provide an axiomatic founda-tion for mathematics.\n",
      "\n",
      "Russells Paradox\n",
      "Let S be a variable ranging over all sets, and define\n",
      "WWD fS j S 62Sg:\n",
      "So by definition, for any set S,\n",
      "S 2 W iff S 62S:\n",
      "In particular, we can let S be W , and obtain the contradictory result that\n",
      "W 2 W iff W 62W:\n",
      "\n",
      "A way out of the paradox was clear to Russell and others at the time: its unjus-tified to assume that W is a set. So the step in the proof where we let S be W has no justification, because S ranges over sets, and W may not be a set. In fact, the paradox implies that W had better not be a set!\n",
      "But denying that W is a set means we must reject the very natural axiom that every mathematically well-defined collection of elements is actually a set. So the problem faced by Frege, Russell and their colleagues was how to specify which\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bertrand Russell was a mathematician/logician at Cambridge University at the turn of the Twen-tieth Century. He reported that when he felt too old to do mathematics, he began to study and write about philosophy, and when he was no longer smart enough to do philosophy, he began writing about politics. He was jailed as a conscientious objector during World War I. For his extensive philosophical and political writing, he won a Nobel Prize for Literature.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 39  #45\n",
      "\n",
      "well-defined collections are sets. Russell and his fellow Cambridge University col-league Whitehead immediately went to work on this problem. They spent a dozen years developing a huge new axiom system in an even huger monograph called Principia Mathematica.\n",
      "Over time, more efficient axiom systems were developed and today, it is gen-erally agreed that, using some simple logical deduction rules, essentially all of mathematics can be derived from the Axioms of Zermelo-Frankel Set Theory with Choice (ZFC). We are not going to be working with these axioms in this course, but just in case you are interested, we have included them as a sidebar below.\n",
      "The ZFC axioms avoid Russells Paradox because they imply that no set is ever a member of itself. Unfortunately, this does not necessarily mean that there are not other paradoxes lurking around out there, just waiting to be uncovered by future mathematicians.\n",
      "ZFC Axioms\n",
      "\n",
      "Extensionality. Two sets are equal if they have the same members. In formal log-ical notation, this would be stated as:\n",
      ".\n",
      "8\n",
      "z: .z \n",
      "2\n",
      " x \n",
      "IFF\n",
      " z \n",
      "2\n",
      " y// \n",
      "IMPLIES\n",
      " x \n",
      "D\n",
      " y:\n",
      "Pairing. For any two sets \n",
      "x\n",
      " and \n",
      "y\n",
      ", there is a set, f\n",
      "x; y\n",
      "g, with \n",
      "x\n",
      " and \n",
      "y\n",
      " as its only elements:\n",
      "8\n",
      "x; y:\n",
      " 9\n",
      "u:\n",
      " 8\n",
      "z: z\n",
      " 2 \n",
      "u\n",
      " \n",
      "IFF\n",
      " \n",
      ".z\n",
      " D \n",
      "x\n",
      " \n",
      "OR\n",
      " \n",
      "z\n",
      " D \n",
      "y/\n",
      "Union. The union, \n",
      "u\n",
      ", of a collection, \n",
      "z\n",
      ", of sets is also a set:\n",
      "8\n",
      "z:\n",
      " 9\n",
      "u\n",
      "8\n",
      "x: .\n",
      "9\n",
      "y: x\n",
      " 2 \n",
      "y\n",
      " \n",
      "AND\n",
      " \n",
      "y\n",
      " 2 \n",
      "z/\n",
      " \n",
      "IFF\n",
      " \n",
      "x\n",
      " 2 \n",
      "u:\n",
      "Infinity. There is an infinite set. Specifically, there is a nonempty set, \n",
      "x\n",
      ", such that for any set \n",
      "y\n",
      " 2 \n",
      "x\n",
      ", the set f\n",
      "y\n",
      "g is also a member of \n",
      "x\n",
      ".\n",
      "Subset. Given any set, \n",
      "x\n",
      ", and any proposition \n",
      "P .y/\n",
      ", there is a set containing pre-cisely those elements \n",
      "y\n",
      " 2 \n",
      "x\n",
      " for which \n",
      "P .y/\n",
      " holds.\n",
      "Power Set. All the subsets of a set form another set:\n",
      "8\n",
      "x:\n",
      " 9\n",
      "p:\n",
      " 8\n",
      "u: u\n",
      "\t\n",
      "x \n",
      "IFF\n",
      " u \n",
      "2\n",
      " p:\n",
      "Replacement. Suppose a formula,\n",
      " \n",
      ", of set theory defines the graph of a function, that is,\n",
      "8\n",
      "x; y; z:  .x; y/\n",
      " \n",
      "AND\n",
      "   \n",
      ".x; z/\n",
      " \n",
      "IMPLIES\n",
      " \n",
      "y\n",
      " D \n",
      "z:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 40  #46\n",
      "\n",
      "40\n",
      "\t\n",
      "Chapter 2\n",
      "\t\n",
      "Patterns of Proof\n",
      "\n",
      "Then the image of any set, \n",
      "s\n",
      ", under that function is also a set, \n",
      "t\n",
      ". Namely,\n",
      "8\n",
      "s\n",
      " 9\n",
      "t\n",
      " 8\n",
      "y:\n",
      " 9\n",
      "x:  .x; y/\n",
      " \n",
      "IFF\n",
      " \n",
      "y\n",
      " 2 \n",
      "t :\n",
      "Foundation. There cannot be an infinite sequence\n",
      "2 \n",
      "x\n",
      "n\n",
      " 2\t2 \n",
      "x\n",
      "1\n",
      " 2 \n",
      "x\n",
      "0\n",
      "of sets each of which is a member of the previous one. This is equivalent to saying every nonempty set has a member-minimal element. Namely, define\n",
      "member-minimal\n",
      ".m; x/\n",
      " WWD \n",
      "m\n",
      " 2 \n",
      "x\n",
      " \n",
      "AND\n",
      " 8\n",
      "y\n",
      " 2 \n",
      "x: y\n",
      "\t\n",
      "m :\n",
      "Then the Foundation axiom is\n",
      "8\n",
      "x: x\n",
      "  ; \n",
      "IMPLIES\n",
      "  9\n",
      "m:\n",
      " member-minimal\n",
      ".m; x/:\n",
      "Choice. Given a set, \n",
      "s\n",
      ", whose members are nonempty sets no two of which have any element in common, then there is a set, \n",
      "c\n",
      ", consisting of exactly one element from each set in \n",
      "s\n",
      ".\n",
      "\n",
      "2.7\n",
      "\t\n",
      "Good Proofs in Practice\n",
      "One purpose of a proof is to establish the truth of an assertion with absolute cer-tainty. Mechanically checkable proofs of enormous length or complexity can ac-complish this. But humanly intelligible proofs are the only ones that help someone understand the subject. Mathematicians generally agree that important mathemati-cal results cant be fully understood until their proofs are understood. That is why proofs are an important part of the curriculum.\n",
      "To be understandable and helpful, more is required of a proof than just logical correctness: a good proof must also be clear. Correctness and clarity usually go together; a well-written proof is more likely to be a correct proof, since mistakes are harder to hide.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 41  #47\n",
      "\n",
      "In practice, the notion of proof is a moving target. Proofs in a professional research journal are generally unintelligible to all but a few experts who know all the terminology and prior results used in the proof. Conversely, proofs in the first weeks of an introductory course like Mathematics for Computer Science would be regarded as tediously long-winded by a professional mathematician. In fact, what we accept as a good proof later in the term will be different than what we consider to be a good proof in the first couple of weeks of this course. But even so, we can offer some general tips on writing good proofs:\n",
      "State your game plan. A good proof begins by explaining the general line of rea-soning. For example, We use case analysis or We argue by contradiction.\n",
      "Keep a linear flow. Sometimes proofs are written like mathematical mosaics, with juicy tidbits of independent reasoning sprinkled throughout. This is not good. The steps of an argument should follow one another in an intelligible order.\n",
      "A proof is an essay, not a calculation. Many students initially write proofs the way they compute integrals. The result is a long sequence of expressions without explanation, making it very hard to follow. This is bad. A good proof usually looks like an essay with some equations thrown in. Use complete sentences.\n",
      "Avoid excessive symbolism. Your reader is probably good at understanding words, but much less skilled at reading arcane mathematical symbols. So use words where you reasonably can.\n",
      "Revise and simplify. Your readers will be grateful.\n",
      "Introduce notation thoughtfully. Sometimes an argument can be greatly simpli-fied by introducing a variable, devising a special notation, or defining a new term. But do this sparingly since youre requiring the reader to remember all that new stuff. And remember to actually define the meanings of new variables, terms, or notations; dont just start using them!\n",
      "Structure long proofs. Long programs are usually broken into a hierarchy of smaller procedures. Long proofs are much the same. Facts needed in your proof that are easily stated, but not readily proved are best pulled out and proved in pre-liminary lemmas. Also, if you are repeating essentially the same argument over and over, try to capture that argument in a general lemma, which you can cite repeatedly instead.\n",
      "Be wary of the obvious. When familiar or truly obvious facts are needed in a proof, its OK to label them as such and to not prove them. But remember\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 42  #48\n",
      "\n",
      "42\n",
      "\t\n",
      "Chapter 2\n",
      "\t\n",
      "Patterns of Proof\n",
      "that whats obvious to you, may not beand typically is notobvious to your reader.\n",
      "Most especially, dont use phrases like clearly or obviously in an attempt to bully the reader into accepting something youre having trouble proving. Also, go on the alert whenever you see one of these phrases in someone elses proof.\n",
      "Finish. At some point in a proof, youll have established all the essential facts you need. Resist the temptation to quit and leave the reader to draw the obvious conclusion. Instead, tie everything together yourself and explain why the original claim follows.\n",
      "The analogy between good proofs and good programs extends beyond structure. The same rigorous thinking needed for proofs is essential in the design of criti-cal computer systems. When algorithms and protocols only mostly work due to reliance on hand-waving arguments, the results can range from problematic to catastrophic. An early example was the Therac 25, a machine that provided radia-tion therapy to cancer victims, but occasionally killed them with massive overdoses due to a software race condition. A more recent (August 2004) example involved a single faulty command to a computer system used by United and American Airlines that grounded the entire fleet of both companiesand all their passengers!\n",
      "It is a certainty that well all one day be at the mercy of critical computer systems designed by you and your classmates. So we really hope that youll develop the ability to formulate rock-solid logical arguments that a system actually does what you think it does!\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 43  #49\n",
      "\n",
      "Induction\n",
      "Now that you understand the basics of how to prove that a proposition is true, it is time to equip you with the most powerful methods we have for establishing truth: the Well Ordering Principle, the Induction Rule, and Strong Induction. These methods are especially useful when you need to prove that a predicate is true for all natural numbers.\n",
      "Although the three methods look and feel different, it turns out that they are equivalent in the sense that a proof using any one of the methods can be automat-ically reformatted so that it becomes a proof using any of the other methods. The choice of which method to use is up to you and typically depends on whichever seems to be the easiest or most natural for the problem at hand.\n",
      "\n",
      "3.1\n",
      "\t\n",
      "The Well Ordering Principle\n",
      "\n",
      "Every nonempty set of nonnegative integers has a smallest element.\n",
      "\n",
      "This statement is known as The Well Ordering Principle. Do you believe it? Seems sort of obvious, right? But notice how tight it is: it requires a nonempty setits false for the empty set which has no smallest element because it has no elements at all! And it requires a set of nonnegative integersits false for the set of negative integers and also false for some sets of nonnegative rationalsfor example, the set of positive rationals. So, the Well Ordering Principle captures something special about the nonnegative integers.\n",
      "3.1.1\n",
      "\t\n",
      "Well Ordering Proofs\n",
      "While the Well Ordering Principle may seem obvious, its hard to see offhand why it is useful. But in fact, it provides one of the most important proof rules in discrete mathematics.\n",
      "In fact, looking back, we took the Well Ordering Principle for granted in proving p\n",
      "\n",
      "that 2 is irrational. That proof assumed that for any positive integers m and n, the fraction m=n can be written in lowest terms, that is, in the form m\n",
      "0\n",
      "=n\n",
      "0\n",
      " where m\n",
      "0\n",
      " and n\n",
      "0\n",
      " are positive integers with no common factors. How do we know this is always possible?\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 44  #50\n",
      "\n",
      "so any way of expressing the left hand fraction in lowest terms would also work for m\n",
      "0\n",
      "=n\n",
      "0\n",
      ", which implies\n",
      "m\n",
      "0\n",
      "=p\n",
      "the fraction \n",
      "n\n",
      "0\n",
      "=p\n",
      " cannot be in written in lowest terms either.\n",
      "\n",
      "So by definition of C , the numerator, m\n",
      "0\n",
      "=p, is in C . But m\n",
      "0\n",
      "=p < m\n",
      "0\n",
      ", which contradicts the fact that m\n",
      "0\n",
      " is the smallest element of C .\n",
      "Since the assumption that C is nonempty leads to a contradiction, it follows that C must be empty. That is, that there are no numerators of fractions that cant be written in lowest terms, and hence there are no such fractions at all.\n",
      "Weve been using the Well Ordering Principle on the sly from early on!\n",
      "3.1.2\n",
      "\t\n",
      "Template for Well Ordering Proofs\n",
      "More generally, to prove that P .n/ is true for all n 2 N using the Well Ordering Principle, you can take the following steps:\n",
      "Define the set, C , of counterexamples to P being true. Namely, define\n",
      " C WWD fn 2 N j P .n/ is falseg:\n",
      "Use a proof by contradiction and assume that C is nonempty.\n",
      "By the Well Ordering Principle, there will be a smallest element, n, in C .\n",
      "Reach a contradiction (somehow)often by showing how to use n to find another member of C that is smaller than n. (This is the open-ended part of the proof task.)\n",
      "Conclude that C must be empty, that is, no counterexamples exist. QED\n",
      "\n",
      "This means that you are about to see an informal proof by contradiction.\n",
      "As we learned in Section \n",
      ", the notation f n j P .n/ is false g means the set of all elements n, for which P .n/ is false.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 45  #51\n",
      "\n",
      "3.1.3\n",
      "\t\n",
      "Examples\n",
      "Lets use this this template to prove\n",
      "for all nonnegative integers, n.\n",
      "First, we better address of a couple of ambiguous special cases before they trip us up:\n",
      "If n D 1, then there is only one term in the summation, and so 1 C 2 C 3 C\n",
      "C n is just the term 1. Dont be misled by the appearance of 2 and 3 and the suggestion that 1 and n are distinct terms!\n",
      "If n 0, then there are no terms at all in the summation. By convention, the sum in this case is 0.\n",
      "So while the dots notation is convenient, you have to watch out for these special cases where the notation is misleading! (In fact, whenever you see the dots, you should be on the lookout to be sure you understand the pattern, watching out for the beginning and the end.)\n",
      "We could have eliminated the need for guessing by rewriting the left side of (\n",
      ")\n",
      "with summation notation:\n",
      "n\n",
      "X\n",
      "\t\n",
      "X\n",
      "i\n",
      "\t\n",
      "or\n",
      "\t\n",
      "i:\n",
      "iD1\n",
      "\t\n",
      "1 i  n\n",
      "Both of these expressions denote the sum of all values taken by the expression to the right of the sigma as the variable, i, ranges from 1 to n. Both expressions make it clear what (\n",
      ") means when n D 1. The second expression makes it clear that when n D 0, there are no terms in the sum, though you still have to know the convention that a sum of no numbers equals 0 (the product of no numbers is 1, by the way).\n",
      "OK, back to the proof:\n",
      "Proof. By contradiction and use of the Well Ordering Principle. Assume that the theorem is false. Then, some nonnegative integers serve as counterexamples to it. Lets collect them in a set:\n",
      "WWD fn 2 N j 1 C 2 C 3 C C n  \n",
      "n.n\n",
      " \n",
      "C\n",
      " \n",
      "1/\n",
      "g: 2\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 46  #52\n",
      "\n",
      "Here is another result that can be proved using Well Ordering. It will be useful in Chapter \n",
      "when we study number theory and cryptography.\n",
      "Theorem 3.1.2. Every natural number can be factored as a product of primes.\n",
      "Proof. By contradiction and Well Ordering. Assume that the theorem is false and let C be the set of all integers greater than one that cannot be factored as a product of primes. We assume that C is not empty and derive a contradiction.\n",
      "If C is not empty, there is a least element, n 2 C , by Well Ordering. The n cant be prime, because a prime by itself is considered a (length one) product of primes and no such products are in C .\n",
      "So n must be a product of two integers a and b where 1 < a; b < n. Since a and b are smaller than the smallest element in C , we know that a; b C . In other words, a can be written as a product of primes p\n",
      "1\n",
      "p\n",
      "2\n",
      " p\n",
      "k\n",
      " and b as a product of primes q\n",
      "1\n",
      " q\n",
      "l\n",
      " . Therefore, n D p\n",
      "1\n",
      " p\n",
      "k\n",
      "q\n",
      "1\n",
      " q\n",
      "l\n",
      " can be written as a product of primes, contradicting the claim that n 2 C . Our assumption that C is not empty\n",
      "must therefore be false.\n",
      "\n",
      "3.2\tOrdinary Induction\n",
      "Induction is by far the most powerful and commonly-used proof technique in dis-crete mathematics and computer science. In fact, the use of induction is a defining\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 47  #53\n",
      "\n",
      "characteristic of discreteas opposed to continuousmathematics. To understand how it works, suppose there is a professor who brings to class a bottomless bag of assorted miniature candy bars. She offers to share the candy in the following way. First, she lines the students up in order. Next she states two rules:\n",
      "The student at the beginning of the line gets a candy bar.\n",
      "If a student gets a candy bar, then the following student in line also gets a candy bar.\n",
      "Lets number the students by their order in line, starting the count with 0, as usual in computer science. Now we can understand the second rule as a short description of a whole sequence of statements:\n",
      "If student 0 gets a candy bar, then student 1 also gets one. If student 1 gets a candy bar, then student 2 also gets one. If student 2 gets a candy bar, then student 3 also gets one.\n",
      ":\n",
      ":\n",
      ":\n",
      "Of course this sequence has a more concise mathematical description:\n",
      "If student n gets a candy bar, then student n C 1 gets a candy bar, for all nonnegative integers n.\n",
      "So suppose you are student 17. By these rules, are you entitled to a miniature candy bar? Well, student 0 gets a candy bar by the first rule. Therefore, by the second rule, student 1 also gets one, which means student 2 gets one, which means student 3 gets one as well, and so on. By 17 applications of the professors second rule, you get your candy bar! Of course the rules actually guarantee a candy bar to every student, no matter how far back in line they may be.\n",
      "3.2.1\tA Rule for Ordinary Induction\n",
      "The reasoning that led us to conclude that every student gets a candy bar is essen-tially all there is to induction.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 48  #54\n",
      "\n",
      "48\n",
      "\t\n",
      "Chapter 3\n",
      "\t\n",
      "Induction\n",
      "\n",
      "The Principle of Induction.\n",
      "Let P .n/ be a predicate. If\n",
      "P .0/ is true, and\n",
      "P .n/ \n",
      "IMPLIES\n",
      " P .n C 1/ for all nonnegative integers, n, then\n",
      "P .m/ is true for all nonnegative integers, m.\n",
      "\n",
      "Since were going to consider several useful variants of induction in later sec-tions, well refer to the induction method described above as ordinary induction when we need to distinguish it. Formulated as a proof rule, this would be\n",
      "Rule. Induction Rule\n",
      "P .0/;\n",
      "\t\n",
      "8n 2 N: P .n/ \n",
      "IMPLIES\n",
      " P .n C 1/\n",
      "\n",
      "8m 2 N: P .m/\n",
      "This general induction rule works for the same intuitive reason that all the stu-dents get candy bars, and we hope the explanation using candy bars makes it clear why the soundness of the ordinary induction can be taken for granted. In fact, the rule is so obvious that its hard to see what more basic principle could be used to justify it.\n",
      "Whats not so obvious is how much mileage we get by using it.\n",
      "3.2.2\n",
      "\t\n",
      "A Familiar Example\n",
      "Ordinary induction often works directly in proving that some statement about non-negative integers holds for all of them. For example, here is the formula for the sum of the nonnegative integers that we already proved (equation (\n",
      ")) using the Well Ordering Principle:\n",
      "Theorem 3.2.1. For all n 2 N,\n",
      "1 C 2 C 3 C\n",
      "\t\n",
      "C n D \n",
      "n.n\n",
      " \n",
      "C\n",
      " \n",
      "1/\n",
      "\t\n",
      "(3.2)\n",
      "\n",
      "2\n",
      "This time, lets use the Induction Principle to prove Theorem \n",
      ".\n",
      "Suppose that we define predicate P .n/ to be the equation (\n",
      "). Recast in terms of this predicate, the theorem claims that P .n/ is true for all n 2 N. This is great, because the induction principle lets us reach precisely that conclusion, provided we establish two simpler facts:\n",
      "\n",
      "But see section \n",
      ".\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 49  #55\n",
      "\n",
      "P .0/ is true.\n",
      "For all n 2 N, P .n/ \n",
      "IMPLIES\n",
      " P .n C 1/.\n",
      "So now our job is reduced to proving these two statements. The first is true because P .0/ asserts that a sum of zero terms is equal to 0.0 C 1/=2 D 0, which is true by definition. The second statement is more complicated. But remember the basic plan for proving the validity of any implication from Section \n",
      ": assume the statement on the left and then prove the statement on the right. In this case, we assume P .n/ in order to prove P .n C 1/, which is the equation\n",
      "These two equations are quite similar; in fact, adding .n C 1/ to both sides of equation (\n",
      ") and simplifying the right side gives the equation (\n",
      "):\n",
      "n.n \n",
      "C\n",
      " 1/\n",
      "1 C 2 C 3 C\n",
      "\t\n",
      "C n C .n C 1/ D\n",
      "\t\n",
      "C .n C 1/\n",
      "\n",
      "D\n",
      " .n C 2/.n C 1/\n",
      "\n",
      "2\n",
      "Thus, if P .n/ is true, then so is P .n C 1/. This argument is valid for every non-negative integer n, so this establishes the second fact required by the induction principle. Therefore, the induction principle says that the predicate P .m/ is true for all nonnegative integers, m, so the theorem is proved.\n",
      "3.2.3\n",
      "\t\n",
      "A Template for Induction Proofs\n",
      "The proof of Theorem \n",
      "was relatively simple, but even the most complicated induction proof follows exactly the same template. There are five components:\n",
      "State that the proof uses induction. This immediately conveys the overall structure of the proof, which helps the reader understand your argument.\n",
      "Define an appropriate predicate P .n/. The eventual conclusion of the in-duction argument will be that P .n/ is true for all nonnegative n. Thus, you should define the predicate P .n/ so that your theorem is equivalent to (or follows from) this conclusion. Often the predicate can be lifted straight from the proposition that you are trying to prove, as in the example above. The predicate P .n/ is called the induction hypothesis. Sometimes the induction hypothesis will involve several variables, in which case you should indicate which variable serves as n.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 50  #56\n",
      "\n",
      "50\n",
      "\t\n",
      "Chapter 3\n",
      "\t\n",
      "Induction\n",
      "Prove that P .0/ is true. This is usually easy, as in the example above. This part of the proof is called the base case or basis step.\n",
      "Prove that P .n/ implies P .n C 1/ for every nonnegative integer n. This is called the inductive step. The basic plan is always the same: assume that P .n/ is true and then use this assumption to prove that P .nC1/ is true. These two statements should be fairly similar, but bridging the gap may require some ingenuity. Whatever argument you give must be valid for every non-negative integer n, since the goal is to prove the implications P .0/ ! P .1/, P .1/ ! P .2/, P .2/ ! P .3/, etc. all at once.\n",
      "Invoke induction. Given these facts, the induction principle allows you to conclude that P .n/ is true for all nonnegative n. This is the logical capstone to the whole argument, but it is so standard that its usual not to mention it explicitly.\n",
      "Always be sure to explicitly label the base case and the inductive step. It will make your proofs clearer, and it will decrease the chance that you forget a key step (such as checking the base case).\n",
      "3.2.4\tA Clean Writeup\n",
      "The proof of Theorem \n",
      "given above is perfectly valid; however, it contains a lot of extraneous explanation that you wont usually see in induction proofs. The writeup below is closer to what you might see in print and should be prepared to produce yourself.\n",
      "Proof of Theorem \n",
      ". We use induction. The induction hypothesis, P .n/, will be equation (\n",
      ").\n",
      "Base case: P .0/ is true, because both sides of equation (\n",
      ") equal zero when\n",
      "n D 0.\n",
      "Inductive step: Assume that P .n/ is true, where n is any nonnegative integer.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 51  #57\n",
      "\n",
      "\n",
      "2\n",
      "n\n",
      "2\n",
      "n\n",
      "Figure 3.1\n",
      "\t\n",
      "A 2\n",
      "n\n",
      "\t\n",
      "2\n",
      "n\n",
      " courtyard for n D 3.\n",
      "Induction was helpful for proving the correctness of this summation formula, but not helpful for discovering it in the first place. Tricks and methods for finding such formulas will be covered in Part III of the text.\n",
      "3.2.5\n",
      "\t\n",
      "A More Challenging Example\n",
      "During the development of MITs famous Stata Center, as costs rose further and further beyond budget, there were some radical fundraising ideas. One rumored plan was to install a big courtyard with dimensions 2\n",
      "n\n",
      " 2\n",
      "n\n",
      " (as shown in Figure \n",
      " for the case where n D 3) and to have one of the central squares\n",
      "be occupied by a statue of a wealthy potential donor (who we will refer to as Bill, for the purposes of preserving anonymity). A complication was that the buildings unconventional architect, Frank Gehry, was alleged to require that only special L-shaped tiles (show in Figure \n",
      ") be used for the courtyard. It was quickly determined that a courtyard meeting these constraints exists, at least for n D 2. (See Figure \n",
      ".) But what about for larger values of n? Is there a way to tile a 2\n",
      "n\n",
      " 2\n",
      "n\n",
      " courtyard with L-shaped tiles around a statue in the center? Lets try to prove that this is so.\n",
      "Theorem 3.2.2. For all n 0 there exists a tiling of a 2\n",
      "n\n",
      " 2\n",
      "n\n",
      " courtyard with Bill in a central square.\n",
      "Proof. (doomed attempt) The proof is by induction. Let P .n/ be the proposition that there exists a tiling of a 2\n",
      "n\n",
      " 2\n",
      "n\n",
      " courtyard with Bill in the center.\n",
      "\n",
      "In the special case n D 0, the whole courtyard consists of a single central square; otherwise, there are four central squares.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 52  #58\n",
      "\n",
      "52\n",
      "\t\n",
      "Chapter 3\n",
      "\t\n",
      "Induction\n",
      "\n",
      "Figure 3.2\n",
      "\t\n",
      "The special L-shaped tile.\n",
      "\n",
      "B\n",
      "Figure 3.3\n",
      "\t\n",
      "A tiling using L-shaped tiles for n D 2 with Bill in a center square.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 53  #59\n",
      "\n",
      "Base case: P .0/ is true because Bill fills the whole courtyard.\n",
      "Inductive step: Assume that there is a tiling of a 2\n",
      "n\n",
      " 2\n",
      "n\n",
      " courtyard with Bill in the center for some n 0. We must prove that there is a way to tile a 2\n",
      "nC1\n",
      " 2\n",
      "nC1\n",
      "courtyard with Bill in the center . . . .\n",
      "Now were in trouble! The ability to tile a smaller courtyard with Bill in the center isnt much help in tiling a larger courtyard with Bill in the center. We havent figured out how to bridge the gap between P .n/ and P .n C 1/.\n",
      "So if were going to prove Theorem \n",
      "by induction, were going to need some other induction hypothesis than simply the statement about n that were trying to prove.\n",
      "When this happens, your first fallback should be to look for a stronger induction hypothesis; that is, one which implies your previous hypothesis. For example, we could make P .n/ the proposition that for every location of Bill in a 2\n",
      "n\n",
      " 2\n",
      "n\n",
      " courtyard, there exists a tiling of the remainder.\n",
      "This advice may sound bizarre: If you cant prove something, try to prove some-thing grander! But for induction arguments, this makes sense. In the inductive step, where you have to prove P .n/ \n",
      "IMPLIES\n",
      " P .n C 1/, youre in better shape because you can assume P .n/, which is now a more powerful statement. Lets see how this plays out in the case of courtyard tiling.\n",
      "Proof (successful attempt). The proof is by induction. Let P .n/ be the proposition that for every location of Bill in a 2\n",
      "n\n",
      " 2\n",
      "n\n",
      " courtyard, there exists a tiling of the remainder.\n",
      "Base case: P .0/ is true because Bill fills the whole courtyard.\n",
      "Inductive step: Assume that P .n/ is true for some n 0; that is, for every location of Bill in a 2\n",
      "n\n",
      " 2\n",
      "n\n",
      " courtyard, there exists a tiling of the remainder. Divide the 2\n",
      "nC1\n",
      " 2\n",
      "nC1\n",
      " courtyard into four quadrants, each 2\n",
      "n\n",
      " 2\n",
      "n\n",
      ". One quadrant contains Bill (B in the diagram below). Place a temporary Bill (X in the diagram) in each of the three central squares lying outside this quadrant as shown in Figure \n",
      ".\n",
      "Now we can tile each of the four quadrants by the induction assumption. Replac-ing the three temporary Bills with a single L-shaped tile completes the job. This proves that P .n/ implies P .n C 1/ for all n 0. Thus P .m/ is true for all n 2 N, and the theorem follows as a special case where we put Bill in a central square.\n",
      "This proof has two nice properties. First, not only does the argument guarantee that a tiling exists, but also it gives an algorithm for finding such a tiling. Second, we have a stronger result: if Bill wanted a statue on the edge of the courtyard, away from the pigeons, we could accommodate him!\n",
      "Strengthening the induction hypothesis is often a good move when an induction proof wont go through. But keep in mind that the stronger assertion must actually\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 54  #60\n",
      "\n",
      "54\n",
      "\t\n",
      "Chapter 3\n",
      "\t\n",
      "Induction\n",
      "\n",
      "B\n",
      "2\n",
      "n\n",
      "X\n",
      "X\tX\n",
      "2\n",
      "n\n",
      "2\n",
      "n\n",
      "\t\n",
      "2\n",
      "n\n",
      "Figure 3.4\n",
      "\t\n",
      "Using a stronger inductive hypothesis to prove Theorem \n",
      ".\n",
      "be true; otherwise, there isnt much hope of constructing a valid proof! Sometimes finding just the right induction hypothesis requires trial, error, and insight. For example, mathematicians spent almost twenty years trying to prove or disprove the conjecture that Every planar graph is 5-choosable\n",
      ". Then, in 1994, Carsten Thomassen gave an induction proof simple enough to explain on a napkin. The key turned out to be finding an extremely clever induction hypothesis; with that in hand, completing the argument was easy!\n",
      "3.2.6\tA Faulty Induction Proof\n",
      "If we have done a good job in writing this text, right about now you should be thinking, Hey, this induction stuff isnt so hard after alljust show P .0/ is true and that P .n/ implies P .n C 1/ for any number n. And, you would be right, although sometimes when you start doing induction proofs on your own, you can run into trouble. For example, we will now attempt to ruin your day by using induction to prove that all horses are the same color. And just when you thought it was safe to skip class and work on your robot program instead. Bummer!\n",
      "False Theorem. All horses are the same color.\n",
      "Notice that no n is mentioned in this assertion, so were going to have to re-formulate it in a way that makes an n explicit. In particular, well (falsely) prove that\n",
      "\n",
      "5-choosability is a slight generalization of 5-colorability. Although every planar graph is 4-colorable and therefore 5-colorable, not every planar graph is 4-choosable. If this all sounds like nonsense, dont panic. Well discuss graphs, planarity, and coloring in Part II of the text.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 55  #61\n",
      "\n",
      "False Theorem 3.2.3. In every set of n 1 horses, all the horses are the same color.\n",
      "This a statement about all integers n 1 rather 0, so its natural to use a slight variation on induction: prove P .1/ in the base case and then prove that P .n/ implies P .nC1/ for all n 1 in the inductive step. This is a perfectly valid variant of induction and is not the problem with the proof below.\n",
      "Bogus proof. The proof is by induction on n. The induction hypothesis, P .n/, will be\n",
      "Base case: (n D 1). P .1/ is true, because in a set of horses of size 1, theres only one horse, and this horse is definitely the same color as itself.\n",
      "Inductive step: Assume that P .n/ is true for some n 1. That is, assume that in every set of n horses, all are the same color. Now consider a set of n C 1 horses:\n",
      "h\n",
      "1\n",
      "; h\n",
      "2\n",
      "; : : : ; h\n",
      "n\n",
      "; h\n",
      "nC1\n",
      "By our assumption, the first n horses are the same color:\n",
      "h\n",
      "1\n",
      "; h\n",
      "2\n",
      "; : : : ; h\n",
      "n\n",
      "; h\n",
      "nC1\n",
      "Also by our assumption, the last n horses are the same color:\n",
      "h\n",
      "1\n",
      "; h\n",
      "2\n",
      "; : : : ; h\n",
      "n\n",
      "; h\n",
      "nC1\n",
      "So h\n",
      "1\n",
      " is the same color as the remaining horses besides h\n",
      "nC1\n",
      "that is, h\n",
      "2\n",
      ", . . . , h\n",
      "n\n",
      ")and likewise h\n",
      "nC1\n",
      " is the same color as the remaining horses besides h\n",
      "1\n",
      "h\n",
      "2\n",
      ",\n",
      ". . . , h\n",
      "n\n",
      ". Since h\n",
      "1\n",
      " and h\n",
      "nC1\n",
      " are the same color as h\n",
      "2\n",
      ", . . . , h\n",
      "n\n",
      ", horses h\n",
      "1\n",
      ", h\n",
      "2\n",
      ", . . . , h\n",
      "nC1\n",
      " must all be the same color, and so P .n C 1/ is true. Thus, P .n/ implies P .n C 1/.\n",
      "By the principle of induction, P .n/ is true for all n\n",
      "\t\n",
      "1.\n",
      "Weve proved something false! Is math broken? Should we all become poets? No, this proof has a mistake.\n",
      "The first error in this argument is in the sentence that begins So h\n",
      "1\n",
      " is the same color as the remaining horses besides h\n",
      "nC1\n",
      "h\n",
      "2\n",
      ", . . . , h\n",
      "n\n",
      "). . . \n",
      "The : : :  notation in the expression h\n",
      "1\n",
      ", h\n",
      "2\n",
      ", . . . , h\n",
      "n\n",
      ", h\n",
      "nC1\n",
      " creates the im-pression that there are some remaining horses (namely h\n",
      "2\n",
      ", . . . , h\n",
      "n\n",
      ") besides h\n",
      "1\n",
      " and h\n",
      "nC1\n",
      ". However, this is not true when n D 1. In that case, h\n",
      "1\n",
      ", h\n",
      "2\n",
      ", . . . , h\n",
      "n\n",
      ", h\n",
      "nC1\n",
      " =\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 56  #62\n",
      "\n",
      "56\n",
      "\t\n",
      "Chapter 3\n",
      "\t\n",
      "Induction\n",
      "h\n",
      "1\n",
      ", h\n",
      "2\n",
      " and there are no remaining horses besides h\n",
      "1\n",
      " and h\n",
      "nC1\n",
      ". So h\n",
      "1\n",
      " and h\n",
      "2\n",
      " need not be the same color!\n",
      "This mistake knocks a critical link out of our induction argument. We proved P .1/ and we correctly proved P .2/ ! P .3/, P .3/ ! P .4/, etc. But we failed to prove P .1/ ! P .2/, and so everything falls apart: we can not conclude that P .2/, P .3/, etc., are true. And, of course, these propositions are all false; there are sets of n non-uniformly-colored horses for all n 2.\n",
      "Students sometimes claim that the mistake in the proof is because P .n/ is false for n 2, and the proof assumes something false, namely, P .n/, in order to prove P .n C 1/. You should think about how to explain to such a student why this claim would get no credit on a Math for Computer Science exam.\n",
      "3.2.7\n",
      "\t\n",
      "Induction versus Well Ordering\n",
      "The Induction Rule looks nothing like the Well Ordering Principle, but these two proof methods are closely related. In fact, as the examples above suggest, we can take any Well Ordering proof and reformat it into an Induction proof. Conversely, its equally easy to take any Induction proof and reformat it into a Well Ordering proof.\n",
      "So whats the difference? Well, sometimes induction proofs are clearer because they resemble recursive procedures that reduce handling an input of size n C 1 to handling one of size n. On the other hand, Well Ordering proofs sometimes seem more natural, and also come out slightly shorter. The choice of method is really a matter of style and is up to you.\n",
      "\n",
      "3.3\tInvariants\n",
      "One of the most important uses of induction in computer science involves proving that a program or process preserves one or more desirable properties as it proceeds. A property that is preserved through a series of operations or steps is known as an invariant. Examples of desirable invariants include properties such as a variable never exceeding a certain value, the altitude of a plane never dropping below 1,000 feet without the wingflaps and landing gear being deployed, and the temperature of a nuclear reactor never exceeding the threshold for a meltdown.\n",
      "We typically use induction to prove that a proposition is an invariant. In particu-lar, we show that the proposition is true at the beginning (this is the base case) and that if it is true after t steps have been taken, it will also be true after step t C1 (this is the inductive step). We can then use the induction principle to conclude that the\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 57  #63\n",
      "\n",
      "proposition is indeed an invariant, namely, that it will always hold.\n",
      "3.3.1\n",
      "\t\n",
      "A Simple Example: The Diagonally-Moving Robot\n",
      "Invariants are useful in systems that have a start state (or starting configuration) and a well-defined series of steps during which the system can change state.\n",
      "For example, suppose that you have a robot that can walk across diagonals on an infinite 2-dimensional grid. The robot starts at position .0; 0/ and at each step it moves up or down by 1 unit vertically and left or right by 1 unit horizontally. To be clear, the robot must move by exactly 1 unit in each dimension during each step, since it can only traverse diagonals.\n",
      "In this example, the state of the robot at any time can be specified by a coordinate pair .x; y/ that denotes the robots position. The start state is .0; 0/ since it is given that the robot starts at that position. After the first step, the robot could be in states\n",
      ".1; 1/, .1; 1/, .1; 1/, or .1; 1/. After two steps, there are 9 possible states for the robot, including .0; 0/.\n",
      "Can the robot ever reach position .1; 0/?\n",
      "After playing around with the robot for a bit, it will become apparent that the robot will never be able to reach position .1; 0/. This is because the robot can only reach positions .x; y/ for which x C y is even. This crucial observation quickly leads to the formulation of a predicate\n",
      "P .t/ WW if the robot is in state .x; y/ after t steps, then x C y is even\n",
      "which we can prove to be an invariant by induction.\n",
      "Theorem 3.3.1. The sum of robots coordinates is always even.\n",
      "Proof. We will prove that P is an invariant by induction.\n",
      "P .0/ is true since the robot starts at .0; 0/ and 0 C 0 is even.\n",
      "Assume that P .t/ is true for the inductive step. Let .x; y/ be the position of the robot after t steps. Since P .t/ is assumed to be true, we know that x C y is even. There are four cases to consider for step t C 1, depending on which direction the robot moves.\n",
      "Case 1 The robot moves to .x C 1; y C 1/. Then the sum of the coordinates is x C y C 2, which is even, and so P .t C 1/ is true.\n",
      "Case 2 The robot moves to .x C1; y\n",
      " \n",
      "1/. The the sum of the coordinates is x Cy, which is even, and so P .t C 1/ is true.\n",
      "\n",
      "Such systems are known as state machines and we will study them in greater detail in Chapter \n",
      ".\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 58  #64\n",
      "\n",
      "Since this was the first time we proved that a predicate was an invariant, we were careful to go through all four cases in gory detail. As you become more experienced with such proofs, you will likely become more brief as well. Indeed, if we were going through the proof again at a later point in the text, we might simply note that the sum of the coordinates after step t C1 can be only x Cy, x Cy C2 or x Cy 2 and therefore that the sum is even.\n",
      "3.3.2\tThe Invariant Method\n",
      "In summary, if you would like to prove that some property \n",
      "NICE\n",
      " holds for every step of a process, then it is often helpful to use the following method:\n",
      "Define P .t/ to be the predicate that \n",
      "NICE\n",
      " holds immediately after step t. Show that P .0/ is true, namely that \n",
      "NICE\n",
      " holds for the start state.\n",
      "Show that\n",
      "8t 2 N: P .t/ \n",
      "IMPLIES\n",
      " P .t C 1/;\n",
      "namely, that for any t 0, if \n",
      "NICE\n",
      " holds immediately after step t, it must also hold after the following step.\n",
      "3.3.3\n",
      "\t\n",
      "A More Challenging Example: The 15-Puzzle\n",
      "In the late 19th century, Noyes Chapman, a postmaster in Canastota, New York, invented the 15-puzzle\n",
      ", which consisted of a 4 4 grid containing 15 numbered blocks in which the 14-block and the 15-block were out of order. The objective was to move the blocks one at a time into an adjacent hole in the grid so as to eventually\n",
      "\n",
      "Actually, there is a dispute about who really invented the 15-puzzle. Sam Lloyd, a well-known puzzle designer, claimed to be the inventor, but this claim has since been discounted.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 59  #65\n",
      "\n",
      "\n",
      "Figure 3.5 The 15-puzzle in its starting configuration (a) and after the 12-block is moved into the hole below (b).\n",
      "\n",
      "9\n",
      "\t\n",
      "10\t11\n",
      "\t\n",
      "12\n",
      "13\t14\n",
      "\t\n",
      "15\n",
      "Figure 3.6 The desired final configuration for the 15-puzzle. Can it be achieved by only moving one block at a time into an adjacent hole?\n",
      "get all 15 blocks into their natural order. A picture of the 15-puzzle is shown in Figure \n",
      "along with the configuration after the 12-block is moved into the hole below. The desired final configuration is shown in Figure \n",
      ".\n",
      "The 15-puzzle became very popular in North America and Europe and is still sold in game and puzzle shops today. Prizes were offered for its solution, but it is doubtful that they were ever awarded, since it is impossible to get from the configuration in Figure \n",
      "(a) to the configuration in Figure \n",
      "by only moving one block at a time into an adjacent hole. The proof of this fact is a little tricky so we have left it for you to figure out on your own! Instead, we will prove that the analogous task for the much easier 8-puzzle cannot be performed. Both proofs, of course, make use of the Invariant Method.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 60  #66\n",
      "\n",
      "60\n",
      "\t\n",
      "Chapter 3\n",
      "\t\n",
      "Induction\n",
      "\n",
      "Figure 3.7 The 8-Puzzle in its initial configuration (a) and after one (b) and two (c) possible moves.\n",
      "3.3.4\n",
      "\t\n",
      "The 8-Puzzle\n",
      "In the 8-Puzzle, there are 8 lettered tiles (AH) and a blank square arranged in a 3 3 grid. Any lettered tile adjacent to the blank square can be slid into the blank. For example, a sequence of two moves is illustrated in Figure \n",
      ".\n",
      "In the initial configuration shown in Figure \n",
      "(a), the G and H tiles are out of order. We can find a way of swapping G and H so that they are in the right order, but then other letters may be out of order. Can you find a sequence of moves that puts these two letters in correct order, but returns every other tile to its original position? Some experimentation suggests that the answer is probably no, and we will prove that is so by finding an invariant, namely, a property of the puzzle that is always maintained, no matter how you move the tiles around. If we can then show that putting all the tiles in the correct order would violate the invariant, then we can conclude that the puzzle cannot be solved.\n",
      "Theorem 3.3.3. No sequence of legal moves transforms the configuration in Fig-ure \n",
      "(a) into the configuration in Figure \n",
      ".\n",
      "Well build up a sequence of observations, stated as lemmas. Once we achieve a critical mass, well assemble these observations into a complete proof of Theo-rem \n",
      ".\n",
      "Define a row move as a move in which a tile slides horizontally and a column move as one in which the tile slides vertically. Assume that tiles are read top-to-bottom and left-to-right like English text, that is, the natural order, defined as follows: So when we say that two tiles are out of order, we mean that the larger letter precedes the smaller letter in this natural order.\n",
      "Our difficulty is that one pair of tiles (the G and H) is out of order initially. An immediate observation is that row moves alone are of little value in addressing this\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 61  #67\n",
      "\n",
      "\n",
      "A\n",
      "\t\n",
      "B\n",
      "\t\n",
      "C\n",
      "D\n",
      "\t\n",
      "E\n",
      "\t\n",
      "F\n",
      "H\n",
      "Figure 3.8\n",
      "\t\n",
      "The desired final configuration of the 8-puzzle.\n",
      "\n",
      "problem:\n",
      "Lemma 3.3.4. A row move does not change the order of the tiles.\n",
      "Proof. A row move moves a tile from cell i to cell i C 1 or vice versa. This tile does not change its order with respect to any other tile. Since no other tile moves,\n",
      "there is no change in the order of any of the other pairs of tiles.\n",
      "Lets turn to column moves. This is the more interesting case, since here the order can change. For example, the column move in Figure \n",
      "changes the relative order of the pairs .G; H / and .G; E/.\n",
      "Lemma 3.3.5. A column move changes the relative order of exactly two pairs of tiles.\n",
      "Proof. Sliding a tile down moves it after the next two tiles in the order. Sliding a tile up moves it before the previous two tiles in the order. Either way, the relative order changes between the moved tile and each of the two tiles it crosses. The\n",
      "relative order between any other pair of tiles does not change.\n",
      "These observations suggest that there are limitations on how tiles can be swapped. Some such limitation may lead to the invariant we need. In order to reason about swaps more precisely, lets define a term referring to a pair of items that are out of order:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 62  #68\n",
      "\n",
      "62\n",
      "\t\n",
      "Chapter 3\n",
      "\t\n",
      "Induction\n",
      "\n",
      "Figure 3.9 An example of a column move in which the G-tile is moved into the adjacent hole above. In this case, G changes order with E and H .\n",
      "Definition 3.3.6. A pair of letters L\n",
      "1\n",
      " and L\n",
      "2\n",
      " is an inversion if L\n",
      "1\n",
      " precedes L\n",
      "2\n",
      " in the alphabet, but L\n",
      "1\n",
      " appears after L\n",
      "2\n",
      " in the puzzle order.\n",
      "For example, in the puzzle below, there are three inversions: .D; F /, .E; F /, .E; G/.\n",
      "\n",
      "A\n",
      "\t\n",
      "B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\n",
      "C\n",
      "F\n",
      "\t\n",
      "D\n",
      "\t\n",
      "G\n",
      "E\n",
      "\t\n",
      "H\n",
      "There is exactly one inversion .G; H / in the start state:\n",
      "\n",
      "A\n",
      "\t\n",
      "B\n",
      "\t\n",
      "C\n",
      "D\n",
      "\t\n",
      "E\n",
      "\t\n",
      "F\n",
      "H\tG\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 63  #69\n",
      "\n",
      "There are no inversions in the end state:\n",
      "\n",
      "A\n",
      "\t\n",
      "B\n",
      "\t\n",
      "C\n",
      "D\n",
      "\t\n",
      "E\n",
      "\t\n",
      "F\n",
      "H\n",
      "Lets work out the effects of row and column moves in terms of inversions.\n",
      "Lemma 3.3.7. During a move, the number of inversions can only increase by 2, decrease by 2, or remain the same.\n",
      "Proof. By Lemma \n",
      ", a row move does not change the order of the tiles, and so a row move does not change the number of inversions.\n",
      "By Lemma \n",
      ", a column move changes the relative order of exactly 2 pairs of tiles. There are three cases: If both pairs were originally in order, then the number of inversions after the move goes up by 2. If both pairs were originally inverted, then the number of inversions after the move goes down by 2. If one pair was originally inverted and the other was originally in order, then the number of inversions stays the same (since changing the former pair makes the number of inversions smaller by 1, and changing the latter pair makes the number of inversions\n",
      "larger by 1).\n",
      "We are almost there. If the number of inversions only changes by 2, then what about the parity of the number of inversions? (The parity of a number refers to whether the number is even or odd. For example, 7 and 5 have odd parity, and 18 and 0 have even parity.)\n",
      "Since adding or subtracting 2 from a number does not change its parity, we have the following corollary to Lemma \n",
      ":\n",
      "Corollary 3.3.8. Neither a row move nor a column move ever changes the parity of the number of inversions.\n",
      "Now we can bundle up all these observations and state an invariant, that is, a property of the puzzle that never changes, no matter how you slide the tiles around.\n",
      "Lemma 3.3.9. In every configuration reachable from the configuration shown in Figure \n",
      "(a), the parity of the number of inversions is odd.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 64  #70\n",
      "\n",
      "\n",
      "Proof. In the target configuration on the right, the total number of inversions is zero, which is even. Therefore, by Lemma \n",
      ", the target configuration is un-\n",
      "reachable.\n",
      "\n",
      "3.4\n",
      "\t\n",
      "Strong Induction\n",
      "Strong induction is a variation of ordinary induction that is useful when the pred-icate P .n C 1/ naturally depends on P .a/ for values of a < n. As with ordinary induction, strong induction is useful to prove that a predicate P .n/ is true for all n 2 N.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 65  #71\n",
      "\n",
      "3.4.1\n",
      "\t\n",
      "A Rule for Strong Induction\n",
      "\n",
      "Principle of Strong Induction. Let P .n/ be a predicate. If\n",
      "P .0/ is true, and\n",
      "for all n 2 N, P .0/, P .1/, . . . , P .n/ together imply P .n C 1/, then P .n/ is true for all n 2 N.\n",
      "\n",
      "The only change from the ordinary induction principle is that strong induction allows you to assume more stuff in the inductive step of your proof! In an ordinary induction argument, you assume that P .n/ is true and try to prove that P .n C 1/ is also true. In a strong induction argument, you may assume that P .0/, P .1/, . . . , and P .n/ are all true when you go to prove P .n C1/. These extra assumptions can only make your job easier. Hence the name: strong induction.\n",
      "Formulated as a proof rule, strong induction is\n",
      "Rule. Strong Induction Rule\n",
      "\n",
      "The template for strong induction proofs is identical to the template given in\n",
      "Section \n",
      "for ordinary induction except for two things:\n",
      "you should state that your proof is by strong induction, and\n",
      "you can assume that P .0/, P .1/, . . . , P .n/ are all true instead of only P .n/ during the inductive step.\n",
      "3.4.2\n",
      "\t\n",
      "Some Examples\n",
      "Products of Primes\n",
      "As a first example, well use strong induction to re-prove Theorem \n",
      "which we previously proved using Well Ordering.\n",
      "Lemma 3.4.1. Every integer greater than 1 is a product of primes.\n",
      "Proof. We will prove Lemma \n",
      "by strong induction, letting the induction hy-pothesis, P .n/, be\n",
      "n is a product of primes:\n",
      "So Lemma \n",
      "will follow if we prove that P .n/ holds for all n\t\n",
      "2.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 66  #72\n",
      "\n",
      "66\n",
      "\t\n",
      "Chapter 3\n",
      "\t\n",
      "Induction\n",
      "Base Case: (n D 2) P .2/ is true because 2 is prime, and so it is a length one product of primes by convention.\n",
      "Inductive step: Suppose that n 2 and that i is a product of primes for every integer i where 2 i < n C 1. We must show that P .n C 1/ holds, namely, that n C 1 is also a product of primes. We argue by cases:\n",
      "If n C 1 is itself prime, then it is a length one product of primes by convention, and so P .n C 1/ holds in this case.\n",
      "Otherwise, n C 1 is not prime, which by definition means n C 1 D km for some integers k; m such that 2 k; m < n C 1. Now by the strong induction hypothesis, we know that k is a product of primes. Likewise, m is a product of primes. It follows immediately that km D n is also a product of primes. Therefore, P .n C 1/ holds in this case as well.\n",
      "So P .n C 1/ holds in any case, which completes the proof by strong induction that P .n/ holds for all n 2.\n",
      "Making Change\n",
      "The country Inductia, whose unit of currency is the Strong, has coins worth 3Sg (3 Strongs) and 5Sg. Although the Inductians have some trouble making small change like 4Sg or 7Sg, it turns out that they can collect coins to make change for any number that is at least 8 Strongs.\n",
      "Strong induction makes this easy to prove for n C 1 11, because then .n C 1/ 3 8, so by strong induction the Inductians can make change for exactly\n",
      ".n C1/ 3 Strongs, and then they can add a 3Sg coin to get .n C1/Sg. So the only thing to do is check that they can make change for all the amounts from 8 to 10Sg, which is not too hard to do.\n",
      "Heres a detailed writeup using the official format:\n",
      "Proof. We prove by strong induction that the Inductians can make change for any amount of at least 8Sg. The induction hypothesis, P .n/ will be:\n",
      "There is a collection of coins whose value is n C 8 Strongs.\n",
      "Base case: P .0/ is true because a 3Sg coin together with a 5Sg coin makes 8Sg.\n",
      "Inductive step: We assume P .m/ holds for all m n, and prove that P .n C 1/ holds. We argue by cases:\n",
      "Case (n C 1 = 1): We have to make .n C 1/ C 8 D 9Sg. We can do this using three 3Sg coins.\n",
      "Case (n C 1 = 2): We have to make .n C 1/ C 8 D 10Sg. Use two 5Sg coins.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 67  #73\n",
      "\n",
      "Figure 3.10 An example of the stacking game with n D 10 boxes. On each line, the underlined stack is divided in the next step.\n",
      "Case (n C 1 3): Then 0 n 2 n, so by the strong induction hypothesis, the Inductians can make change for n 2 Strong. Now by adding a 3Sg coin, they can make change for .n C 1/Sg.\n",
      "Since n 0, we know that n C 1 1 and thus that the three cases cover every possibility. Since P .n C 1/ is true in every case, we can conclude by strong induction that for all n 0, the Inductians can make change for n C8 Strong. That is, they can make change for any number of eight or more Strong.\n",
      "The Stacking Game\n",
      "Here is another exciting game thats surely about to sweep the nation!\n",
      "You begin with a stack of n boxes. Then you make a sequence of moves. In each move, you divide one stack of boxes into two nonempty stacks. The game ends when you have n stacks, each containing a single box. You earn points for each move; in particular, if you divide one stack of height a C b into two stacks with heights a and b, then you score ab points for that move. Your overall score is the sum of the points that you earn for each move. What strategy should you use to maximize your total score?\n",
      "As an example, suppose that we begin with a stack of n D 10 boxes. Then the game might proceed as shown in Figure \n",
      ". Can you find a better strategy?\n",
      "Lets use strong induction to analyze the unstacking game. Well prove that your score is determined entirely by the number of boxesyour strategy is irrelevant!\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 68  #74\n",
      "\n",
      "68\n",
      "\t\n",
      "Chapter 3\n",
      "\t\n",
      "Induction\n",
      "Theorem 3.4.2. Every way of unstacking n blocks gives a score of n.n 1/=2 points.\n",
      "There are a couple technical points to notice in the proof:\n",
      "The template for a strong induction proof mirrors the template for ordinary induction.\n",
      "As with ordinary induction, we have some freedom to adjust indices. In this case, we prove P .1/ in the base case and prove that P .1/; : : : ; P .n/ imply P .n C 1/ for all n 1 in the inductive step.\n",
      "Proof. The proof is by strong induction. Let P .n/ be the proposition that every way of unstacking n blocks gives a score of n.n 1/=2.\n",
      "Base case: If n D 1, then there is only one block. No moves are possible, and so the total score for the game is 1.1 1/=2 D 0. Therefore, P .1/ is true.\n",
      "Inductive step: Now we must show that P .1/, . . . , P .n/ imply P .n C 1/ for all n 1. So assume that P .1/, . . . , P .n/ are all true and that we have a stack of n C 1 blocks. The first move must split this stack into substacks with positive sizes a and b where a C b D n C 1 and 0 < a; b n. Now the total score for the game is the sum of points for this first move plus points obtained by unstacking the two\n",
      "3.4.3\n",
      "\t\n",
      "Strong Induction versus Induction\n",
      "Is strong induction really stronger than ordinary induction? It certainly looks that way. After all, you can assume a lot more when proving the induction step. But actually, any proof using strong induction can be reformatted into a proof using ordinary inductionyou just need to use a stronger induction hypothesis.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 69  #75\n",
      "\n",
      "Which method should you use? Whichever you find easier. But whichever method you choose, be sure to state the method up front so that the reader can understand and more easily verify your proof.\n",
      "\n",
      "3.5\tStructural Induction\n",
      "Up to now, we have focussed on induction over the natural numbers. But the idea of induction is far more generalit can be applied to a much richer class of sets. In particular, it is especially useful in connection with sets or data types that are defined recursively.\n",
      "3.5.1\n",
      "\t\n",
      "Recursive Data Types\n",
      "Recursive data types play a central role in programming. They are specified by recursive definitions that say how to build something from its parts. Recursive definitions have two parts:\n",
      "Base case(s) that dont depend on anything else.\n",
      "Constructor case(s) that depend on previous cases.\n",
      "Lets see how this works in a couple of examples: Strings of brackets and expres-sion evaluation.\n",
      "Example 1: Strings of Brackets\n",
      "Let brkts be the set of all sequences (or strings) of square brackets. For example, the following two strings are in brkts:\n",
      "Definition 3.5.1. The set brkts of strings of brackets can be defined recursively as follows:\n",
      "Base case: The empty string,  , is in brkts.\n",
      "Constructor case: If s 2 brkts, then s\n",
      "]\n",
      " and s\n",
      "[\n",
      " are in brkts.\n",
      "Here, were writing s\n",
      "]\n",
      " to indicate the string that is the sequence of brackets (if any) in the string s, followed by a right bracket; similarly for s\n",
      "[\n",
      " .\n",
      "A string s 2 brkts is called a matched string if its brackets can be matched up in the usual way. For example, the left hand string in \n",
      "is not matched because its second right bracket does not have a matching left bracket. The string on the right is matched. The set of matched strings can be defined recursively as follows.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 70  #76\n",
      "\n",
      "70\n",
      "\t\n",
      "Chapter 3\n",
      "\t\n",
      "Induction\n",
      "Definition 3.5.2. Recursively define the set, RecMatch, of strings as follows:\n",
      "Base case:  2 RecMatch.\n",
      "Constructor case: If s; t 2 RecMatch, then\n",
      "[ \n",
      "s\n",
      " ] \n",
      "t\n",
      " \n",
      "2\n",
      " \n",
      "RecMatch:\n",
      "Here were writing \n",
      "[\n",
      " s \n",
      "]\n",
      " t to indicate the string that starts with a left bracket, followed by the sequence of brackets (if any) in the string s, followed by a right bracket, and ending with the sequence of brackets in the string t.\n",
      "Using this definition, we can see that\n",
      "\t\n",
      "2 RecMatch by the Base case, so\n",
      "]  \n",
      "D\n",
      " [ ] \n",
      "2\n",
      " \n",
      "RecMatch\n",
      "by the Constructor case. So now,\n",
      "are also strings in RecMatch by repeated applications of the Constructor case.\n",
      "In general, RecMatch will contain precisely the strings with matching brack-ets. This is because the constructor case is, in effect, identifying the bracket that matches the leftmost bracket in any string. Since that matching bracket is unique, this method of constructing RecMatch gives a unique way of constructing any string with matched brackets. This will turn out to be important later when we talk about ambiguity.\n",
      "Strings with matched brackets arise in the area of expression parsing. A brief history of the advances in this field is provided in the box on the next page.\n",
      "Example 2: Arithmetic Expressions\n",
      "Expression evaluation is a key feature of programming languages, and recognition of expressions as a recursive data type is a key to understanding how they can be processed.\n",
      "To illustrate this approach well work with a toy example: arithmetic expressions like 3x\n",
      "2\n",
      " C 2x C 1 involving only one variable, x. Well refer to the data type of such expressions as Aexp. Here is its definition:\n",
      "Definition 3.5.3. The set Aexp is defined recursively as follows:\n",
      "Base cases:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 71  #77\n",
      "\n",
      "\n",
      "Expression Parsing\n",
      "During the early development of computer science in the 1950s and 60s, creation of effective programming language compilers was a central concern. A key aspect in processing a program for compilation was expression parsing. The problem was to take in an expression like\n",
      "x \n",
      "C\n",
      " y\tz\n",
      "2\n",
      "\ty \n",
      "C\n",
      " 7\n",
      "and put in the brackets that determined how it should be evaluatedshould it be\n",
      "x \n",
      "C\n",
      " y\tz\n",
      "2\n",
      "\ty \n",
      "C\n",
      " 7; \n",
      "or\n",
      ";\n",
      "x \n",
      "C\n",
      " y\tz\n",
      "2\n",
      "\ty \n",
      "C\n",
      " 7 ; \n",
      "or\n",
      ";\n",
      "x \n",
      "C\n",
      " y\tz\n",
      "2\n",
      "\t\n",
      "y \n",
      "C\n",
      " 7 ;\n",
      "or . . . ?\n",
      "The Turing award (the Nobel Prize of computer science) was ultimately be-stowed on Robert Floyd, for, among other things, being discoverer of a simple program that would insert the brackets properly.\n",
      "In the 70s and 80s, this parsing technology was packaged into high-level compiler-compilers that automatically generated parsers from expression gram-mars. This automation of parsing was so effective that the subject stopped de-manding attention and largely disappeared from the computer science curriculum by the 1990s.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 72  #78\n",
      "\n",
      "72\n",
      "\t\n",
      "Chapter 3\n",
      "\t\n",
      "Induction\n",
      "The variable, x, is in Aexp.\n",
      "The arabic numeral, k, for any nonnegative integer, k, is in Aexp. Constructor cases: If e; f 2 Aexp, then\n",
      "3. .e C f / 2 Aexp. The expression .e C f / is called a sum. The Aexps e and f are called the components of the sum; theyre also called the summands.\n",
      "4. .e\n",
      " \n",
      "f / 2 Aexp. The expression .e f / is called a product. The Aexps e and f are called the components of the product; theyre also called the multiplier and multiplicand.\n",
      "5. .e/\n",
      "\t\n",
      "2 Aexp. The expression .e/  is called a negative.\n",
      "Notice that Aexps are fully parenthesized, and exponents arent allowed. So the Aexp version of the polynomial expression 3x\n",
      "2\n",
      " C2x C1 would officially be written as\n",
      "These parentheses and s clutter up examples, so well often use simpler expres-sions like 3x\n",
      "2\n",
      " C 2x C 1 instead of (\n",
      "). But its important to recognize that 3x\n",
      "2\n",
      " C 2x C 1 is not an Aexp; its an abbreviation for an Aexp.\n",
      "3.5.2\n",
      "\t\n",
      "Structural Induction on Recursive Data Types\n",
      "Structural induction is a method for proving that some property, P , holds for all the elements of a recursively-defined data type. The proof consists of two steps:\n",
      "Prove P for the base cases of the definition.\n",
      "Prove P for the constructor cases of the definition, assuming that it is true for the component data items.\n",
      "A very simple application of structural induction proves that (recursively-defined) matched strings always have an equal number of left and right brackets. To do this, define a predicate, P , on strings s 2 brkts:\n",
      "P .s/ WWD s has an equal number of left and right brackets:\n",
      "Theorem 3.5.4. P .s/ holds for all s 2 RecMatch.\n",
      "Proof. By structural induction on the definition that s 2 RecMatch, using P .s/ as the induction hypothesis.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 73  #79\n",
      "\n",
      "Base case: P . / holds because the empty string has zero left and zero right brackets.\n",
      "Constructor case: For r D \n",
      "[\n",
      " s \n",
      "]\n",
      " t, we must show that P .r/ holds, given that P .s/ and P .t/ holds. So let n\n",
      "s\n",
      ", n\n",
      "t\n",
      " be, respectively, the number of left brackets in s and t. So the number of left brackets in r is 1 C n\n",
      "s\n",
      " C n\n",
      "t\n",
      " .\n",
      "Now from the respective hypotheses P .s/ and P .t/, we know that the number of right brackets in s is n\n",
      "s\n",
      ", and likewise, the number of right brackets in t is n\n",
      "t\n",
      " . So the number of right brackets in r is 1 C n\n",
      "s\n",
      " C n\n",
      "t\n",
      " , which is the same as the number of left brackets. This proves P .r/. We conclude by structural induction that P .s/\n",
      "holds for all s 2 RecMatch.\n",
      "3.5.3\n",
      "\t\n",
      "Functions on Recursively-defined Data Types\n",
      "A Quick Review of Functions\n",
      "A function assigns an element of one set, called the domain, to elements of another set, called the codomain. The notation\n",
      "WA!B\n",
      "indicates that f is a function with domain, A, and codomain, B. The familiar notation f .a/ D b indicates that f assigns the element b 2 B to a. Here b would be called the value of f at argument a.\n",
      "Functions are often defined by formulas as in:\n",
      "1\n",
      "f .x/ WWD\n",
      "\n",
      "1\n",
      "\t\n",
      "x\n",
      "2\n",
      "where x is a real-valued variable, or\n",
      "f\n",
      "2\n",
      ".y; z/ WWD y10yz\n",
      "where y and z range over binary strings, or\n",
      "f\n",
      "3\n",
      ".x; n/ WWD the pair .n; x/ where n ranges over the nonnegative integers.\n",
      "A function with a finite domain could be specified by a table that shows the value of the function at each element of the domain. For example, a function f\n",
      "4\n",
      ".P; Q/ where P and Q are propositional variables is specified by:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 74  #80\n",
      "\n",
      "74\n",
      "\t\n",
      "Chapter 3\n",
      "\t\n",
      "Induction\n",
      "Notice that \n",
      "f\n",
      "4\n",
      " could also have been described by a formula:\n",
      "f\n",
      "4\n",
      ".P; Q/ \n",
      "WWD\n",
      " P \n",
      "IMPLIES\n",
      " Q :\n",
      "A function might also be defined by a procedure for computing its value at any element of its domain, or by some other kind of specification. For example, define \n",
      "f\n",
      "5\n",
      ".y/ \n",
      "to be the length of a left to right search of the bits in the binary string\n",
      " y \n",
      "until\n",
      " \n",
      "a 1 appears, so\n",
      "f\n",
      "5\n",
      ".0010/ \n",
      "D\n",
      " 3;\n",
      "f\n",
      "5\n",
      ".100/ \n",
      "D\n",
      " 1;\n",
      "f\n",
      "5\n",
      ".0000/ \n",
      "is undefined\n",
      ":\n",
      "Notice that \n",
      "f\n",
      "5\n",
      " does not assign a value to a string of just 0s. This illustrates an important fact about functions: they need not assign a value to every element in the domain. In fact this came up in our first example \n",
      "f\n",
      "1\n",
      ".x/\n",
      " D \n",
      "1=x\n",
      "2\n",
      ", which does not assign a value to \n",
      "0\n",
      ". So in general, functions may be partial functions, meaning that there may be domain elements for which the function is not defined. If a function is defined on every element of its domain, it is called a total function.\n",
      "Its often useful to find the set of values a function takes when applied to the elements in a set of arguments. So if \n",
      "f\n",
      " W \n",
      "A\n",
      " ! \n",
      "B\n",
      ", and \n",
      "S\n",
      " is a subset of \n",
      "A\n",
      ", we define \n",
      "f .S/ \n",
      "to be the set of all the values that\n",
      " f \n",
      "takes when it is applied to elements of\n",
      " S\n",
      ".\n",
      " \n",
      "That is,\n",
      "f .S/ \n",
      "WWD f\n",
      "b \n",
      "2\n",
      " B \n",
      "j\n",
      " f .s/ \n",
      "D\n",
      " b \n",
      "for some\n",
      " s \n",
      "2\n",
      " S\n",
      "g\n",
      ":\n",
      "For example, if we let \n",
      "r; s\n",
      " denote the interval from \n",
      "r\n",
      " to \n",
      "s\n",
      " on the real line, then \n",
      "f\n",
      "1\n",
      ". 1; 2 / \n",
      "D\n",
      " 1=4; 1 \n",
      ".\n",
      "For another example, lets take the search for a 1 function, \n",
      "f\n",
      "5\n",
      ". If we let \n",
      "X\n",
      " be the set of binary words which start with an even number of 0s followed by a 1, then \n",
      "f\n",
      "5\n",
      ".X/\n",
      " would be the odd nonnegative integers.\n",
      "Applying \n",
      "f\n",
      " to a set, \n",
      "S\n",
      ", of arguments is referred to as applying \n",
      "f\n",
      " pointwise to \n",
      "S\n",
      ", and the set\n",
      " f .S/ \n",
      "is referred to as the\n",
      " \n",
      "image\n",
      " \n",
      "of\n",
      " S \n",
      "under\n",
      " f \n",
      ".\n",
      "The\n",
      " \n",
      "set of values\n",
      " \n",
      "that arise from applying \n",
      "f\n",
      " to all possible arguments is called the range of \n",
      "f\n",
      " . That is,\n",
      "range\n",
      ".f /\n",
      " WWD \n",
      "f .\n",
      "domain\n",
      ".f //:\n",
      "\n",
      "There is a picky distinction between the function f which applies to elements of A and the function which applies f pointwise to subsets of A, because the domain of f is A, while the domain of pointwise-f is P.A/. It is usually clear from context whether f or pointwise-f is meant, so there is no harm in overloading the symbol f in this way.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 75  #81\n",
      "\n",
      "Recursively-Defined Functions\n",
      "Functions on recursively-defined data types can be defined recursively using the same cases as the data type definition. Namely, to define a function, f , on a recur-sive data type, define the value of f for the base cases of the data type definition, and then define the value of f in each constructor case in terms of the values of f on the component data items.\n",
      "For example, consider the function\n",
      "eval W Aexp\n",
      "\t\n",
      "Z ! Z;\n",
      "which evaluates any expression in Aexp using the value n for x. It is useful to express this function with a recursive definition as follows:\n",
      "Definition 3.5.5. The evaluation function, eval W Aexp Z ! Z, is defined recur-sively on expressions, e 2 Aexp, as follows. Let n be any integer.\n",
      "Base cases:\n",
      "Case[e is x]\n",
      "eval.x; n/ WWD n:\n",
      "(The value of the variable, x, is given to be n.)\n",
      "2. Case[e is k]\n",
      "eval.k; n/ WWD k:\n",
      "(The value of the numeral k is the integer k, no matter what value x has.)\n",
      "Constructor cases:\n",
      "Case[e is .e\n",
      "1\n",
      " C e\n",
      "2\n",
      "/]\n",
      "eval..e\n",
      "1\n",
      " C e\n",
      "2\n",
      "/; n/ WWD eval.e\n",
      "1\n",
      "; n/ C eval.e\n",
      "2\n",
      "; n/:\n",
      "4. Case[e is .e\n",
      "1\n",
      "\t\n",
      "e\n",
      "2\n",
      "/]\n",
      "eval..e\n",
      "1\n",
      "\t\n",
      "e\n",
      "2\n",
      "/; n/ WWD eval.e\n",
      "1\n",
      "; n/ eval.e\n",
      "2\n",
      "; n/:\n",
      "5. Case[e is .e \n",
      "1\n",
      "/]\n",
      "eval..e \n",
      "1\n",
      "/; n/ WWD\n",
      "\t\n",
      "eval.e\n",
      "1\n",
      "; n/:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 76  #82\n",
      "\n",
      "76\n",
      "\t\n",
      "Chapter 3\n",
      "\t\n",
      "Induction\n",
      "For example, heres how the recursive definition of eval would arrive at the value of 3 C x\n",
      "2\n",
      " when x is 2:\n",
      "A Second Example\n",
      "We next consider the function on matched strings that specifies the depth of the matched brackets in any string. This function can be specified recursively as fol-lows:\n",
      "Definition 3.5.6. The depth d.s/ of a string s 2 RecMatch is defined recursively by the rules:\n",
      "d. / WWD 0:\n",
      "d.\n",
      "[\n",
      " s \n",
      "]\n",
      " t/ WWD maxfd.s/ C 1; d.t/g\n",
      "Ambiguity\n",
      "When a recursive definition of a data type allows the same element to be constructed in more than one way, the definition is said to be ambiguous. A function defined recursively from an ambiguous definition of a data type will not be well-defined unless the values specified for the different ways of constructing the element agree.\n",
      "We were careful to choose an unambiguous definition of RecMatch to ensure that functions defined recursively on the definition would always be well-defined. As an example of the trouble an ambiguous definition can cause, lets consider another definition of the matched strings.\n",
      "Definition 3.5.7. Define the set, M\n",
      "\t\n",
      "brkts recursively as follows:\n",
      "Base case:  2 M ,\n",
      "Constructor cases: if s; t 2 M , then the strings \n",
      "[\n",
      " s \n",
      "]\n",
      " and st are also in M .\n",
      "By using structural induction, it is possible to prove that M D RecMatch. In-deed, the definition of M might even seem like a more natural way to define the set\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 77  #83\n",
      "\n",
      "of matched strings than the definition of RecMatch. But the definition of M is am-biguous, while the (perhaps less natural) definition of RecMatch is unambiguous. Does this ambiguity matter? Yes, it can. For example, suppose we defined\n",
      "f . / WWD 1;\n",
      "f . \n",
      "[\n",
      " s \n",
      "]\n",
      " / WWD 1 C f .s/;\n",
      "f .st/ WWD .f .s/ C 1/ .f .t/ C 1/\n",
      "\t\n",
      "for st \n",
      "\t\n",
      ":\n",
      "Let a be the string \n",
      "[ [ ] ]\n",
      " 2 M built by two successive applications of the first M constructor starting with . Next let\n",
      "b WWD aa\n",
      "[[]][[]]\n",
      "and\n",
      "c WWD bb\n",
      "[[]][[]][[]][[]]\n",
      "each be built by successive applications of the second M constructor starting with a.\n",
      "Alternatively, we can build ba from the second constructor with s D b and\n",
      "D a, and then get to c using the second constructor with s D ba and t D a.\n",
      "By applying these rules to the first way of constructing c, f .a/ D 2,  f .b/ D\n",
      ".2 C 1/.2 C 1/ D 9, and f .c/ D f .bb/ D .9 C 1/.9 C 1/ D 100. Using the second way of constructing c, we find that f .ba/ D .9 C 1/.2 C 1/ D 27 and f .c/ D f .ba a/ D .27 C 1/.2 C 1/ D 84. The outcome is that f .c/ is defined to be both 100 and 84, which shows that the rules defining f are inconsistent.\n",
      "Note that structural induction remains a sound proof method even for ambiguous recursive definitions, which is why it is easy to prove that M D RecMatch.\n",
      "3.5.4 Recursive Functions on NStructural Induction versus Ordinary Induction\n",
      "The nonnegative integers can be understood as a recursive data type.\n",
      "Definition 3.5.8. The set, N, is a data type defined recursivly as:\n",
      "Base Case: 0 2 N.\n",
      "Constructor Case: If n 2 N, then the successor, n C 1, of n is in N.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 78  #84\n",
      "\n",
      "78\n",
      "\t\n",
      "Chapter 3\n",
      "\t\n",
      "Induction\n",
      "This means that ordinary induction is a special case of structural induction on the recursive Definition \n",
      ". Conversely, most proofs based on structural induction that you will encounter in computer science can also be reformatted into proofs that use only ordinary induction. The decision as to which technique to use is up to you, but it will often be the case that structural induction provides the easiest approach when you are dealing with recursive data structures or functions.\n",
      "Definition \n",
      "also justifies the familiar recursive definitions of functions on the nonnegative integers. Here are some examples.\n",
      "The Factorial Function\n",
      "The factorial function is often written \n",
      "n\n",
      " . You will be seeing it a lot in Parts III and IV of this text. For now, well use the notation fac\n",
      ".n/\n",
      " and define it recursively as follows:\n",
      "Base Case: fac\n",
      ".0/\n",
      " WWD \n",
      "1\n",
      ".\n",
      "Constructor Case: fac\n",
      ".n\n",
      " C \n",
      "1/\n",
      " WWD \n",
      ".n\n",
      " C \n",
      "1/\n",
      " fac\n",
      ".n/\n",
      " for \n",
      "n  0\n",
      ".\n",
      "The Fibonacci numbers.\n",
      "Fibonacci numbers arose out of an effort 800 years ago to model population growth. We will study them at some length in Part III. The \n",
      "n\n",
      "th Fibonacci number, fib\n",
      ".n/\n",
      ", can be defined recursively by:\n",
      "Base Cases: fib\n",
      ".0/\n",
      " WWD \n",
      "0\n",
      " and fib\n",
      ".1/\n",
      " WWD \n",
      "1\n",
      "Constructor Case: fib\n",
      ".n/\n",
      " WWD fib\n",
      ".n\n",
      "\t\n",
      "1/ \n",
      "C\n",
      " \n",
      "fib\n",
      ".n\t2/ \n",
      "for\n",
      " n\n",
      "\t\n",
      "2\n",
      ".\n",
      "Here the recursive step starts at \n",
      "n\n",
      " D \n",
      "2\n",
      " with base cases for \n",
      "n\n",
      " D \n",
      "0\n",
      " and \n",
      "n\n",
      " D \n",
      "1\n",
      ". This is needed since the recursion relies on two previous values.\n",
      "What is fib\n",
      ".4/\n",
      "? Well, fib\n",
      ".2/\n",
      " D fib\n",
      ".1/\n",
      " Cfib\n",
      ".0/\n",
      " D \n",
      "1\n",
      ", fib\n",
      ".3/\n",
      " D fib\n",
      ".2/\n",
      " Cfib\n",
      ".1/\n",
      " D \n",
      "2\n",
      ", so fib\n",
      ".4/\n",
      " D \n",
      "3\n",
      ". The sequence starts out \n",
      "0; 1; 1; 2; 3; 5; 8; 13; 21; : : :\n",
      " .\n",
      "Sum-notation\n",
      "P\n",
      "n\n",
      "Let \n",
      "S.n/\n",
      " abbreviate the expression  \n",
      "iD1\n",
      " \n",
      "f .i/\n",
      ". We can recursively define \n",
      "S.n/\n",
      " with the rules\n",
      "Base Case: \n",
      "S.0/\n",
      " WWD \n",
      "0\n",
      ".\n",
      "Constructor Case: \n",
      "S.n\n",
      " C \n",
      "1/\n",
      " WWD \n",
      "f .n\n",
      " C \n",
      "1/\n",
      " C \n",
      "S.n/\n",
      " for \n",
      "n  0\n",
      ".\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 79  #85\n",
      "\n",
      "Ill-formed Function Definitions\n",
      "There are some blunders to watch out for when defining functions recursively. Be-low are some function specifications that resemble good definitions of functions on the nonnegative integers, but they arent.\n",
      "Definition 3.5.9.\n",
      "This definition has no base case. If some function, f\n",
      "1\n",
      ", satisfied (\n",
      "), so would a function obtained by adding a constant to the value of f\n",
      "1\n",
      ". So equation (\n",
      ") does not uniquely define an f\n",
      "1\n",
      ".\n",
      "Definition 3.5.10.\n",
      "This definition has a base case, but still doesnt uniquely determine f\n",
      "2\n",
      ". Any function that is 0 at 0 and constant everywhere else would satisfy the specification, so (\n",
      ") also does not uniquely define anything.\n",
      "In a typical programming language, evaluation of f\n",
      "2\n",
      ".1/ would begin with a re-cursive call of f\n",
      "2\n",
      ".2/, which would lead to a recursive call of f\n",
      "2\n",
      ".3/, . . . with recur-sive calls continuing without end. This operational approach interprets (\n",
      ") as defining a partial function, f\n",
      "2\n",
      ", that is undefined everywhere but 0.\n",
      "Definition 3.5.11.\n",
      "This definition is inconsistent: it requires f\n",
      "3\n",
      ".6/ D 0 and f\n",
      "3\n",
      ".6/ D 1, so (\n",
      ") doesnt define anything.\n",
      "A Mysterious Function\n",
      "Mathematicians have been wondering about the following function specification for many years:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 80  #86\n",
      "\n",
      "80\n",
      "\t\n",
      "Chapter 3\n",
      "\t\n",
      "Induction\n",
      "For example, f\n",
      "4\n",
      ".3/ D 1 because\n",
      "f\n",
      "4\n",
      ".3/ WWDf\n",
      "4\n",
      ".10/ WWDf\n",
      "4\n",
      ".5/ WWDf\n",
      "4\n",
      ".16/ WWDf\n",
      "4\n",
      ".8/ WWDf\n",
      "4\n",
      ".4/ WWDf\n",
      "4\n",
      ".2/ WWDf\n",
      "4\n",
      ".1/ WWD1:\n",
      "The constant function equal to 1 will satisfy (\n",
      "), but its not known if another function does too. The problem is that the third case specifies f\n",
      "4\n",
      ".n/ in terms of f\n",
      "4\n",
      " at arguments larger than n, and so cannot be justified by induction on N. Its known that any f\n",
      "4\n",
      " satisfying (\n",
      ") equals 1 for all n up to over a billion.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 81  #87\n",
      "\n",
      "Number Theory\n",
      "Number theory is the study of the integers. Why anyone would want to study the integers is not immediately obvious. First of all, whats to know? Theres 0, theres 1, 2, 3, and so on, and, oh yeah, -1, -2, . . . . Which one dont you understand? Sec-ond, what practical value is there in it? The mathematician G. H. Hardy expressed pleasure in its impracticality when he wrote:\n",
      "[Number theorists] may be justified in rejoicing that there is one sci-ence, at any rate, and that their own, whose very remoteness from or-dinary human activities should keep it gentle and clean.\n",
      "Hardy was specially concerned that number theory not be used in warfare; he was a pacifist. You may applaud his sentiments, but he got it wrong: Number Theory underlies modern cryptography, which is what makes secure online communication possible. Secure communication is of course crucial in warwhich may leave poor Hardy spinning in his grave. Its also central to online commerce. Every time you buy a book from Amazon, check your grades on WebSIS, or use a PayPal account, you are relying on number theoretic algorithms.\n",
      "Number theory also provides an excellent environment for us to practice and apply the proof techniques that we developed in Chapters \n",
      "and \n",
      ".\n",
      "Since well be focusing on properties of the integers, well adopt the default convention in this chapter that variables range over the set of integers, Z.\n",
      "\n",
      "4.1\tDivisibility\n",
      "The nature of number theory emerges as soon as we consider the divides relation\n",
      "a divides b\n",
      "\t\n",
      "iff\n",
      "\t\n",
      "ak D b for some k:\n",
      "The notation, a j b, is an abbreviation for a divides b. If a j b, then we also say that b is a multiple of a. A consequence of this definition is that every number divides zero.\n",
      "This seems simple enough, but lets play with this definition. The Pythagoreans, an ancient sect of mathematical mystics, said that a number is perfect if it equals the sum of its positive integral divisors, excluding itself. For example, 6 D 1 C 2 C 3 and 28 D 1 C 2 C 4 C 7 C 14 are perfect numbers. On the other hand, 10 is not perfect because 1C2C5 D 8, and 12 is not perfect because 1C2C3C4C6 D 16.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 82  #88\n",
      "\n",
      "82\n",
      "\t\n",
      "Chapter 4\n",
      "\t\n",
      "Number Theory\n",
      "Euclid characterized all the even perfect numbers around 300 BC. But is there an odd perfect number? More than two thousand years later, we still dont know! All numbers up to about 10\n",
      "300\n",
      " have been ruled out, but no one has proved that there isnt an odd perfect number waiting just over the horizon.\n",
      "So a half-page into number theory, weve strayed past the outer limits of human knowledge! This is pretty typical; number theory is full of questions that are easy to pose, but incredibly difficult to answer.\n",
      "For example, several such problems are shown in the box on the following page. Interestingly, well see that computer scientists have found ways to turn some of these difficulties to their advantage.\n",
      "4.1.1\n",
      "\t\n",
      "Facts about Divisibility\n",
      "The lemma below states some basic facts about divisibility that are not difficult to prove:\n",
      "Lemma 4.1.1. The following statements about divisibility hold.\n",
      "If a j b, then a j bc for all c.\n",
      "If a j b and b j c, then a j c.\n",
      "If a j b and a j c, then a j sb C tc for all s and t.\n",
      "For all c  0, a j b if and only if ca j cb.\n",
      "Proof. Well prove only part 2.; the other proofs are similar.\n",
      "Proof of 2: Assume a j b and b j c. Since a j b, there exists an integer k\n",
      "1\n",
      " such that ak\n",
      "1\n",
      " D b. Since b j c, there exists an integer k\n",
      "2\n",
      " such that bk\n",
      "2\n",
      " D c. Substituting ak\n",
      "1\n",
      " for b in the second equation gives .ak\n",
      "1\n",
      "/k\n",
      "2\n",
      " D c. So a.k\n",
      "1\n",
      "k\n",
      "2\n",
      "/ D c,\n",
      "which implies that a j c.\n",
      "4.1.2\n",
      "\t\n",
      "When Divisibility Goes Bad\n",
      "As you learned in elementary school, if one number does not evenly divide another, you get a quotient and a remainder left over. More precisely:\n",
      "Theorem 4.1.2 (Division Theorem). \n",
      "Let n and d be integers such that d > 0. Then there exists a unique pair of integers q and r, such that\n",
      "\n",
      "Dont Panicwere going to stick to some relatively benign parts of number theory. These super-hard unsolved problems rarely get put on problem sets.\n",
      "3\n",
      "This theorem is often called the Division Algorithm, even though it is not what we would call an algorithm. We will take this familiar result for granted without proof.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 83  #89\n",
      "\n",
      "\n",
      "Famous Conjectures in Number Theory\n",
      "Fermats Last Theorem There are no positive integers x, y, and z such that\n",
      "x\n",
      "n\n",
      " C y\n",
      "n\n",
      " D z\n",
      "n\n",
      "for some integer n > 2. In a book he was reading around 1630, Fermat claimed to have a proof but not enough space in the margin to write it down. Wiles finally gave a proof of the theorem in 1994, after seven years of working in secrecy and isolation in his attic. His proof did not fit in any margin.\n",
      "Goldbach Conjecture Every even integer greater than two is equal to the sum of two primes\n",
      "2\n",
      ". For example, 4 D 2 C 2, 6 D 3 C 3, 8 D 3 C 5, etc. The conjecture holds for all numbers up to 10\n",
      "16\n",
      ". In 1939 Schnirelman proved that every even number can be written as the sum of not more than 300,000 primes, which was a start. Today, we know that every even number is the sum of at most 6 primes.\n",
      "Twin Prime Conjecture There are infinitely many primes p such that p C 2 is also a prime. In 1966 Chen showed that there are infinitely many primes p such that p C 2 is the product of at most two primes. So the conjecture is known to be almost true!\n",
      "Primality Testing There is an efficient way to determine whether a number is\n",
      "prime. A naive search for factors of an integer n takes a number of steps p\n",
      "\n",
      "proportional to n, which is exponential in the size of n in decimal or bi-nary notation. All known procedures for prime checking blew up like this on various inputs. Finally in 2002, an amazingly simple, new method was discovered by Agrawal, Kayal, and Saxena, which showed that prime test-ing only required a polynomial number of steps. Their paper began with a quote from Gauss emphasizing the importance and antiquity of the prob-lem even in his timetwo centuries ago. So prime testing is definitely not in the category of infeasible problems requiring an exponentially growing number of steps in bad cases.\n",
      "Factoring Given the product of two large primes n D pq, there is no efficient way to recover the primes p and q. The best known algorithm is the num-ber field sieve, which runs in time proportional to:\n",
      "e\n",
      "1:9.ln n/\n",
      "1=3\n",
      ".ln ln n/\n",
      "2=3\n",
      "This is infeasible when n has 300 digits or more.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 84  #90\n",
      "\n",
      "84\n",
      "\t\n",
      "Chapter 4\n",
      "\t\n",
      "Number Theory\n",
      "The number q is called the quotient and the number r is called the remainder of n divided by d . We use the notation qcnt.n; d / for the quotient and rem.n; d / for the remainder.\n",
      "For example, qcnt.2716; 10/ D 271 and rem.2716; 10/ D 6, since 2716 D 271 10 C 6. Similarly, rem.11; 7/ D 3, since 11 D .2/ 7 C 3. There is a remainder operator built into many programming languages. For example, the expression 32 % 5 evaluates to 2 in Java, C, and C++. However, all these languages treat negative numbers strangely.\n",
      "4.1.3\n",
      "\t\n",
      "Die Hard\n",
      "\n",
      "Simon: On the fountain, there should be 2 jugs, do you see them? A 5-gallon and a 3-gallon. Fill one of the jugs with exactly 4 gallons of water and place it on the scale and the timer will stop. You must be precise; one ounce more or less will result in detonation. If youre still alive in 5 minutes, well speak.\n",
      "Bruce: Wait, wait a second. I dont get it. Do you get it?\n",
      "Samuel: No.\n",
      "Bruce: Get the jugs. Obviously, we cant fill the 3-gallon jug with 4 gallons of water.\n",
      "Samuel: Obviously.\n",
      "Bruce: All right. I know, here we go. We fill the 3-gallon jug exactly to the top, right?\n",
      "Samuel: Uh-huh.\n",
      "Bruce: Okay, now we pour this 3 gallons into the 5-gallon jug, giving us exactly 3 gallons in the 5-gallon jug, right?\n",
      "Samuel: Right, then what?\n",
      "Bruce: All right. We take the 3-gallon jug and fill it a third of the way. . .\n",
      "Samuel: No! He said, Be precise. Exactly 4 gallons.\n",
      "Bruce: Sh. Every cop within 50 miles is running his a off and Im out here playing kids games in the park.\n",
      "Samuel: Hey, you want to focus on the problem at hand?\n",
      "\n",
      "The preceding script is from the movie Die Hard 3: With a Vengeance. In the movie, Samuel L. Jackson and Bruce Willis have to disarm a bomb planted by the diabolical Simon Gruber. Fortunately, they find a solution in the nick of time. (No doubt reading the script helped.) On the surface, Die Hard 3 is just a B-grade action movie; however, we think the inner message of the film is that everyone should learn at least a little number theory.\n",
      "Unfortunately, Hollywood never lets go of a gimmick. Although there were no water jug tests in Die Hard 4: Live Free or Die Hard, rumor has it that the jugs will\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 85  #91\n",
      "\n",
      "return in future sequels:\n",
      "Die Hard 5: Die Hardest Bruce goes on vacation andshockinglyhappens into a terrorist plot. To save the day, he must make 3 gallons using 21- and 26-gallon jugs.\n",
      "Die Hard 6: Die of Old Age Bruce must save his assisted living facility from a criminal mastermind by forming 2 gallons with 899- and 1147-gallon jugs.\n",
      "Die Hard 7: Die Once and For All Bruce has to make 4 gallons using 3- and 6-gallon jugs.\n",
      "It would be nice if we could solve all these silly water jug questions at once. In particular, how can one form g gallons using jugs with capacities a and b?\n",
      "Thats where number theory comes in handy.\n",
      "Finding an Invariant Property\n",
      "Suppose that we have water jugs with capacities a and b with b a. The state of the system is described below with a pair of numbers .x; y/, where x is the amount of water in the jug with capacity a and y is the amount in the jug with capacity b. Lets carry out sample operations and see what happens, assuming the b-jug is big enough:\n",
      "What leaps out is that at every step, the amount of water in each jug is of the form\n",
      "for some integers s and t. An expression of the form (\n",
      ") is called an integer linear combination of a and b, but in this chapter well just call it a linear combination, since were only talking integers. So were suggesting:\n",
      "Lemma 4.1.3. Suppose that we have water jugs with capacities a and b. Then the amount of water in each jug is always a linear combination of a and b.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 86  #92\n",
      "\n",
      "86\n",
      "\t\n",
      "Chapter 4\n",
      "\t\n",
      "Number Theory\n",
      "Lemma \n",
      "is easy to prove by induction on the number of pourings.\n",
      "Proof. The induction hypothesis, P .n/, is the proposition that after n steps, the amount of water in each jug is a linear combination of a and b.\n",
      "Base case: (n D 0). P .0/ is true, because both jugs are initially empty, and 0 a C 0 b D 0.\n",
      "Inductive step. We assume by induction hypothesis that after n steps the amount of water in each jug is a linear combination of a and b. There are two cases:\n",
      "If we fill a jug from the fountain or empty a jug into the fountain, then that jug is empty or full. The amount in the other jug remains a linear combination of a and b. So P .n C 1/ holds.\n",
      "Otherwise, we pour water from one jug to another until one is empty or the other is full. By our assumption, the amount in each jug is a linear combina-tion of a and b before we begin pouring:\n",
      "j\n",
      "1\n",
      " D s\n",
      "1\n",
      "  a C t\n",
      "1\n",
      "  b\n",
      "j\n",
      "2\n",
      " D s\n",
      "2\n",
      "  a C t\n",
      "2\n",
      "  b\n",
      "After pouring, one jug is either empty (contains 0 gallons) or full (contains a\n",
      "So we have established that the jug problem has an invariant property, namely that the amount of water in every jug is always a linear combination of the capacities of the jugs. This lemma has an important corollary:\n",
      "Corollary 4.1.4. Bruce dies.\n",
      "Proof. In Die Hard 7, Bruce has water jugs with capacities 3 and 6 and must form 4 gallons of water. However, the amount in each jug is always of the form 3s C 6t by Lemma \n",
      ". This is always a multiple of 3 by part \n",
      "of Lemma \n",
      ", so he\n",
      "cannot measure out 4 gallons.\n",
      "But Lemma \n",
      "isnt very satisfying. Weve just managed to recast a pretty understandable question about water jugs into a complicated question about linear combinations. This might not seem like a lot of progress. Fortunately, linear com-binations are closely related to something more familiar, namely greatest common divisors, and these will help us solve the water jug problem.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 87  #93\n",
      "\n",
      "\n",
      "4.2\n",
      "\t\n",
      "The Greatest Common Divisor\n",
      "The greatest common divisor of a and b is exactly what youd guess: the largest number that is a divisor of both a and b. It is denoted by gcd.a; b/. For example, gcd.18; 24/ D 6. The greatest common divisor turns out to be a very valuable piece of information about the relationship between a and b and for reasoning about integers in general. So well be making lots of arguments about greatest common divisors in what follows.\n",
      "4.2.1\n",
      "\t\n",
      "Linear Combinations and the GCD\n",
      "The theorem below relates the greatest common divisor to linear combinations. This theorem is very useful; take the time to understand it and then remember it!\n",
      "Theorem 4.2.1. The greatest common divisor of a and b is equal to the smallest positive linear combination of a and b.\n",
      "For example, the greatest common divisor of 52 and 44 is 4. And, sure enough, 4 is a linear combination of 52 and 44:\n",
      "6 52C.7/\t44D4\n",
      "Furthermore, no linear combination of 52 and 44 is equal to a smaller positive integer.\n",
      "Proof of Theorem \n",
      ". By the Well Ordering Principle, there is a smallest positive linear combination of a and b; call it m. Well prove that m D gcd.a; b/ by showing both gcd.a; b/ m and m gcd.a; b/.\n",
      "First, we show that gcd.a; b/ m. Now any common divisor of a and bthat is, any c such that c j a and c j bwill divide both sa and tb, and therefore also sa C tb for any s and t. The gcd.a; b/ is by definition a common divisor of a and\n",
      "for every s and t. In particular, gcd.a; b/ j m, which implies that gcd.a; b/\n",
      " \n",
      "m. Now, we show that m gcd.a; b/. We do this by showing that m j a. A\n",
      "symmetric argument shows that m j b, which means that m is a common divisor of a and b. Thus, m must be less than or equal to the greatest common divisor of a and b.\n",
      "All that remains is to show that m j a. By the Division Algorithm, there exists a quotient q and remainder r such that:\n",
      "a D q m C r\n",
      "\t\n",
      "(where 0\n",
      "\t\n",
      "r < m)\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 88  #94\n",
      "\n",
      "88\n",
      "\t\n",
      "Chapter 4\n",
      "\t\n",
      "Number Theory\n",
      "Recall that m D sa C tb for some integers s and t. Substituting in for m gives:\n",
      "a D q .sa C tb/ C r;\n",
      "\t\n",
      "so\n",
      "r D .1\tqs/a C .qt/b:\n",
      "Weve just expressed r as a linear combination of a and b. However, m is the smallest positive linear combination and 0 r < m. The only possibility is that\n",
      "the remainder r is not positive; that is, r D 0. This implies m j a.\n",
      "Corollary 4.2.2. An integer is linear combination of a and b iff it is a multiple of gcd.a; b/.\n",
      "Proof. By (\n",
      "), every linear combination of a and b is a multiple of gcd.a; b/. Conversely, since gcd.a; b/ is a linear combination of a and b, every multiple of\n",
      "gcd.a; b/ is as well.\n",
      "Now we can restate the water jugs lemma in terms of the greatest common divi-sor:\n",
      "Corollary 4.2.3. Suppose that we have water jugs with capacities a and b. Then the amount of water in each jug is always a multiple of gcd.a; b/.\n",
      "For example, there is no way to form 4 gallons using 3- and 6-gallon jugs, be-cause 4 is not a multiple of gcd.3; 6/ D 3.\n",
      "4.2.2\n",
      "\t\n",
      "Properties of the Greatest Common Divisor\n",
      "Well often make use of some basic gcd facts:\n",
      "Lemma 4.2.4. The following statements about the greatest common divisor hold:\n",
      "Every common divisor of a and b divides gcd.a; b/.\n",
      "gcd.ka; kb/ D k gcd.a; b/ for all k > 0.\n",
      "If gcd.a; b/ D 1 and gcd.a; c/ D 1, then gcd.a; bc/ D 1.\n",
      "If a j bc and gcd.a; b/ D 1, then a j c.\n",
      "gcd.a; b/ D gcd.b; rem.a; b//.\n",
      "Heres the trick to proving these statements: translate the gcd world to the linear combination world using Theorem \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", argue about linear combinations, and then translate back using Theorem \n",
      "again.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 89  #95\n",
      "\n",
      "Proof. We prove only parts \n",
      ". and \n",
      ".\n",
      "Proof of \n",
      ". The assumptions together with Theorem \n",
      "imply that there exist integers s, t, u, and v such that:\n",
      "sa C tb D 1\n",
      "ua C vc D 1\n",
      "Multiplying these two equations gives:\n",
      ".sa C tb/.ua C vc/ D 1\n",
      "The left side can be rewritten as a .asu C btu C csv/ C bc.tv/. This is a linear combination of a and bc that is equal to 1, so gcd.a; bc/ D 1 by Theorem \n",
      ".\n",
      "Proof of \n",
      ". Theorem \n",
      "says that gcd.ac; bc/ is equal to a linear combination of ac and bc. Now a j ac trivially and a j bc by assumption. Therefore, a divides every linear combination of ac and bc. In particular, a divides gcd.ac; bc/ D c gcd.a; b/ D c 1 D c. The first equality uses part \n",
      ". of this lemma, and the\n",
      "second uses the assumption that gcd.a; b/ D 1.\n",
      "4.2.3\tEuclids Algorithm\n",
      "Part (5) of Lemma \n",
      "is useful for quickly computing the greatest common divi-sor of two numbers. For example, we could compute the greatest common divisor of 1147 and 899 by repeatedly applying part (5):\n",
      "gcd.1147; 899/ D gcd 899; rem.1147; 899/\n",
      "\n",
      " \n",
      "D248\n",
      "D gcd 248; rem.899; 248/\n",
      "\n",
      " \n",
      "D155\n",
      "D gcd 155; rem.248; 155/\n",
      "\n",
      " \n",
      "D93\n",
      "D gcd 93; rem.155; 93/\n",
      "\n",
      "D62\n",
      "D gcd 62; rem.93; 62/\n",
      "\n",
      "D31\n",
      "D gcd 31; rem.62; 31/\n",
      "\n",
      "D0\n",
      "gcd.31; 0/\n",
      "31\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 90  #96\n",
      "\n",
      "90\n",
      "\t\n",
      "Chapter 4\n",
      "\t\n",
      "Number Theory\n",
      "The last equation might look wrong, but 31 is a divisor of both 31 and 0 since every integer divides 0.\n",
      "This process is called Euclids algorithm and it was discovered by the Greeks over 3000 years ago. You can prove that the algorithm always eventually terminates by using induction and the fact that the numbers in each step keep getting smaller until the remainder is 0, whereupon you have computed the GCD. In fact, the numbers are getting smaller quickly (by at least a factor of 2 every two steps) and so Eulers Algorithm is quite fast. The fact that Euclids Algorithm actually produces the GCD (and not something different) can also be proved by an inductive invariant argument.\n",
      "The calculation that gcd.1147; 899/ D 31 together with Corollary \n",
      "implies that there is no way to measure out 2 gallons of water using jugs with capacities 1147 and 899, since we can only obtain multiples of 31 gallons with these jugs. This is good newsBruce wont even survive Die Hard 6!\n",
      "But what about Die Hard 5? Is it possible for Bruce to make 3 gallons using 21-and 26-gallon jugs? Using Euclids algorithm:\n",
      "gcd.26; 21/ D gcd.21; 5/ D gcd.5; 1/ D 1:\n",
      "Since 3 is a multiple of 1, so we cant rule out the possibility that 3 gallons can be formed. On the other hand, we dont know if it can be done either. To resolve the matter, we will need more number theory.\n",
      "4.2.4\n",
      "\t\n",
      "One Solution for All Water Jug Problems\n",
      "Corollary \n",
      "says that 3 can be written as a linear combination of 21 and 26, since 3 is a multiple of gcd.21; 26/ D 1. In other words, there exist integers s and\n",
      "such that:\n",
      "3 D s 21 C t  26\n",
      "We dont know what the coefficients s and t are, but we do know that they exist. Now the coefficient s could be either positive or negative. However, we can\n",
      "readily transform this linear combination into an equivalent linear combination\n",
      "where the coefficient s\n",
      "0\n",
      " is positive. The trick is to notice that if we increase s by 26 in the original equation and decrease t by 21, then the value of the expression s 21 C t 26 is unchanged overall. Thus, by repeatedly increasing the value of s (by 26 at a time) and decreasing the value of t (by 21 at a time), we get a linear combination s\n",
      "0\n",
      " 21 C t\n",
      "0\n",
      " 26 D 3 where the coefficient s\n",
      "0\n",
      " is positive. Notice that then t\n",
      "0\n",
      " must be negative; otherwise, this expression would be much greater than 3.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 91  #97\n",
      "\n",
      "Now we can form 3 gallons using jugs with capacities 21 and 26: We simply repeat the following steps s\n",
      "0\n",
      " times:\n",
      "Fill the 21-gallon jug.\n",
      "Pour all the water in the 21-gallon jug into the 26-gallon jug. If at any time the 26-gallon jug becomes full, empty it out, and continue pouring the 21-gallon jug into the 26-gallon jug.\n",
      "At the end of this process, we must have have emptied the 26-gallon jug exactly jt\n",
      "0\n",
      "j times. Heres why: weve taken s\n",
      "0\n",
      " 21 gallons of water from the fountain, and weve poured out some multiple of 26 gallons. If we emptied fewer than jt \n",
      "0\n",
      " j times, then by (\n",
      "), the big jug would be left with at least 3 C 26 gallons, which is more than it can hold; if we emptied it more times, the big jug would be left containing at most 3 26 gallons, which is nonsense. But once we have emptied the 26-gallon jug exactly jt\n",
      "0\n",
      "j times, equation (\n",
      ") implies that there are exactly 3 gallons left.\n",
      "Remarkably, we dont even need to know the coefficients s\n",
      "0\n",
      " and t\n",
      "0\n",
      " in order to use this strategy! Instead of repeating the outer loop s\n",
      "0\n",
      " times, we could just repeat until we obtain 3 gallons, since that must happen eventually. Of course, we have to keep track of the amounts in the two jugs so we know when were done. Heres the\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 92  #98\n",
      "\n",
      "92\n",
      "\t\n",
      "Chapter 4\n",
      "\t\n",
      "Number Theory\n",
      "The same approach works regardless of the jug capacities and even regardless the amount were trying to produce! Simply repeat these two steps until the desired amount of water is obtained:\n",
      "Fill the smaller jug.\n",
      "Pour all the water in the smaller jug into the larger jug. If at any time the larger jug becomes full, empty it out, and continue pouring the smaller jug into the larger jug.\n",
      "By the same reasoning as before, this method eventually generates every multiple of the greatest common divisor of the jug capacitiesall the quantities we can possibly produce. No ingenuity is needed at all!\n",
      "4.2.5\n",
      "\t\n",
      "The Pulverizer\n",
      "We have shown that no matter which pair of numbers a and b we are given, there is always a pair of integer coefficients s and t such that\n",
      "gcd.a; b/ D sa C tb:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 93  #99\n",
      "\n",
      "Unfortunately, the proof was nonconstructive: it didnt suggest a way for finding such s and t. That job is tackled by a mathematical tool that dates to sixth-century India, where it was called kuttak, which means The Pulverizer. Today, the Pul-verizer is more commonly known as the extended Euclidean GCD algorithm, because it is so close to Euclids Algorithm.\n",
      "Euclids Algorithm for finding the GCD of two numbers relies on repeated ap-plication of the equation:\n",
      "gcd.a; b/ D gcd.b; rem.a; b; //:\n",
      "For example, we can compute the GCD of 259 and 70 as follows:\n",
      "gcd.259; 70/ D gcd.70; 49/\n",
      "D gcd.49; 21/\n",
      "D gcd.21; 7/\n",
      "D gcd.7; 0/\n",
      "D 7:\n",
      "\n",
      "\n",
      "since rem.259; 70/ D 49 since rem.70; 49/ D 21 since rem.49; 21/ D 7 since rem.21; 7/ D 0\n",
      "The Pulverizer goes through the same steps, but requires some extra bookkeeping along the way: as we compute gcd.a; b/, we keep track of how to write each of the remainders (49, 21, and 7, in the example) as a linear combination of a and b (this is worthwhile, because our objective is to write the last nonzero remainder, which is the GCD, as such a linear combination). For our example, here is this extra bookkeeping:\n",
      "We began by initializing two variables, x D a and y D b. In the first two columns above, we carried out Euclids algorithm. At each step, we computed rem.x; y/, which can be written in the form x q y. (Remember that the Division Algorithm says x D q y C r, where r is the remainder. We get r D x q y by rearranging terms.) Then we replaced x and y in this equation with equivalent linear combina-tions of a and b, which we already had computed. After simplifying, we were left\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 94  #100\n",
      "\n",
      "94\n",
      "\t\n",
      "Chapter 4\n",
      "\t\n",
      "Number Theory\n",
      "with a linear combination of a and b that was equal to the remainder as desired.\n",
      "The final solution is boxed.\n",
      "You can prove that the Pulverizer always works and that it terminates by using induction. Indeed, you can pulverize very large numbers very quickly by using this algorithm. As we will soon see, its speed makes the Pulverizer a very useful tool in the field of cryptography.\n",
      "\n",
      "4.3\n",
      "\t\n",
      "The Fundamental Theorem of Arithmetic\n",
      "We now have almost enough tools to prove something that you probably already know.\n",
      "Theorem 4.3.1 (Fundamental Theorem of Arithmetic). Every positive integer n can be written in a unique way as a product of primes:\n",
      "n D p\n",
      "1\n",
      "  p\n",
      "2\n",
      "\tp\n",
      "j\n",
      "\t\n",
      ".p\n",
      "1\n",
      "\tp\n",
      "2\n",
      "\t\n",
      "p\n",
      "j\n",
      " /\n",
      "Notice that the theorem would be false if 1 were considered a prime; for example,\n",
      "15 could be written as 3 5 or 1 3 5 or 1\n",
      "2\n",
      " 3 5. Also, were relying on a standard convention: the product of an empty set of numbers is defined to be 1, much as the sum of an empty set of numbers is defined to be 0. Without this convention, the theorem would be false for n D 1.\n",
      "There is a certain wonder in the Fundamental Theorem, even if youve known it since you were in a crib. Primes show up erratically in the sequence of integers. In fact, their distribution seems almost random:\n",
      "2; 3; 5; 7; 11; 13; 17; 19; 23; 29; 31; 37; 41; 43; : : :\n",
      "Basic questions about this sequence have stumped humanity for centuries. And yet we know that every natural number can be built up from primes in exactly one way. These quirky numbers are the building blocks for the integers.\n",
      "The Fundamental Theorem is not hard to prove, but well need a couple of pre-liminary facts.\n",
      "Lemma 4.3.2. If p is a prime and p j ab, then p j a or p j b.\n",
      "Proof. The greatest common divisor of a and p must be either 1 or p, since these are the only positive divisors of p. If gcd.a; p/ D p, then the claim holds, be-cause a is a multiple of p. Otherwise, gcd.a; p/ D 1 and so p j b by part (\n",
      ") of\n",
      "Lemma \n",
      ".\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 95  #101\n",
      "\n",
      "\n",
      "The Prime Number Theorem\n",
      "Let\n",
      "\t\n",
      ".x/ denote the number of primes less than or equal to x.  For example,\n",
      ".10/ D 4 because 2, 3, 5, and 7 are the primes less than or equal to 10. Primes are very irregularly distributed, so the growth of is similarly erratic. However, the Prime Number Theorem gives an approximate answer:\n",
      ".x/\n",
      "lim\n",
      "\t\n",
      "D 1\n",
      "\n",
      "Thus, primes gradually taper off. As a rule of thumb, about 1 integer out of every ln x in the vicinity of x is a prime.\n",
      "The Prime Number Theorem was conjectured by Legendre in 1798 and proved a century later by de la Vallee Poussin and Hadamard in 1896. However, after his death, a notebook of Gauss was found to contain the same conjecture, which he apparently made in 1791 at age 15. (You sort of have to feel sorry for all the oth-erwise great mathematicians who had the misfortune of being contemporaries of Gauss.)\n",
      "In late 2004 a billboard appeared in various locations around the country:\n",
      " \n",
      "first 10-digit prime found\n",
      "in consecutive digits of e\n",
      "\n",
      "\n",
      ". com\n",
      "Substituting the correct number for the expression in curly-braces produced the URL for a Google employment page. The idea was that Google was interested in hiring the sort of people that could and would solve such a problem.\n",
      "How hard is this problem? Would you have to look through thousands or millions or billions of digits of e to find a 10-digit prime? The rule of thumb derived from the Prime Number Theorem says that among 10-digit numbers, about 1 in\n",
      "ln 10\n",
      "10\n",
      "\t\n",
      "23\n",
      "is prime. This suggests that the problem isnt really so hard! Sure enough, the first 10-digit prime in consecutive digits of e appears quite early:\n",
      "D2:718281828459045235360287471352662497757247093699959574966 96762772407663035354759457138217852516642\n",
      "7427466391\n",
      "9320030\n",
      "599218174135966290435729003342952605956307381323286279434 : : :\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 96  #102\n",
      "\n",
      "96\n",
      "\t\n",
      "Chapter 4\n",
      "\t\n",
      "Number Theory\n",
      "A routine induction argument extends this statement to:\n",
      "Lemma 4.3.3. Let p be a prime. If p j a\n",
      "1\n",
      "a\n",
      "2\n",
      "\t\n",
      "a\n",
      "n\n",
      ", then p divides some a\n",
      "i\n",
      " .\n",
      "Now were ready to prove the Fundamental Theorem of Arithmetic.\n",
      "Proof. Theorem \n",
      "showed, using the Well Ordering Principle, that every posi-tive integer can be expressed as a product of primes. So we just have to prove this expression is unique. We will use Well Ordering to prove this too.\n",
      "The proof is by contradiction: assume, contrary to the claim, that there exist positive integers that can be written as products of primes in more than one way. By the Well Ordering Principle, there is a smallest integer with this property. Call this integer n, and let\n",
      "D p\n",
      "1\n",
      " p\n",
      "2\n",
      " p\n",
      "j\n",
      " D q\n",
      "1\n",
      " q\n",
      "2\n",
      " q\n",
      "k\n",
      "be two of the (possibly many) ways to write n as a product of primes. Then p\n",
      "1\n",
      " j n and so p\n",
      "1\n",
      " j q\n",
      "1\n",
      "q\n",
      "2\n",
      " q\n",
      "k\n",
      ". Lemma \n",
      "implies that p\n",
      "1\n",
      " divides one of the primes q\n",
      "i\n",
      " . But since q\n",
      "i\n",
      " is a prime, it must be that p\n",
      "1\n",
      " D q\n",
      "i\n",
      " . Deleting p\n",
      "1\n",
      " from the first product and q\n",
      "i\n",
      " from the second, we find that n=p\n",
      "1\n",
      " is a positive integer smaller than n that can also be written as a product of primes in two distinct ways. But this contradicts\n",
      "the definition of n as the smallest such positive integer.\n",
      "\n",
      "4.4\tAlan Turing\n",
      "The man pictured in Figure \n",
      "is Alan Turing, the most important figure in the history of computer science. For decades, his fascinating life story was shrouded by government secrecy, societal taboo, and even his own deceptions.\n",
      "At age 24, Turing wrote a paper entitled On Computable Numbers, with an Ap-plication to the Entscheidungsproblem. The crux of the paper was an elegant way to model a computer in mathematical terms. This was a breakthrough, because it allowed the tools of mathematics to be brought to bear on questions of computation. For example, with his model in hand, Turing immediately proved that there exist problems that no computer can solveno matter how ingenious the programmer. Turings paper is all the more remarkable because he wrote it in 1936, a full decade before any electronic computer actually existed.\n",
      "The word Entscheidungsproblem in the title refers to one of the 28 mathemat-ical problems posed by David Hilbert in 1900 as challenges to mathematicians of\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 97  #103\n",
      "\n",
      "4.4. Alan Turing\n",
      "Photograph of Alan Turing removed due to copyright restrictions. Please see: \n",
      "the 20th century. Turing knocked that one off in the same paper. And perhaps youve heard of the Church-Turing thesis? Same paper. So Turing was obviously a brilliant guy who generated lots of amazing ideas. But this lecture is about one of Turings less-amazing ideas. It involved codes. It involved number theory. And it was sort of stupid.\n",
      "Lets look back to the fall of 1937. Nazi Germany was rearming under Adolf Hitler, world-shattering war looked imminent, andlike usAlan Turing was pon-dering the usefulness of number theory. He foresaw that preserving military secrets would be vital in the coming conflict and proposed a way to encrypt communica-tions using number theory. This is an idea that has ricocheted up to our own time. Today, number theory is the basis for numerous public-key cryptosystems, digital signature schemes, cryptographic hash functions, and electronic payment systems. Furthermore, military funding agencies are among the biggest investors in crypto-graphic research. Sorry Hardy!\n",
      "Soon after devising his code, Turing disappeared from public view, and half a century would pass before the world learned the full story of where hed gone and what he did there. Well come back to Turings life in a little while; for now, lets investigate the code Turing left behind. The details are uncertain, since he never formally published the idea, so well consider a couple of possibilities.\n",
      "\n",
      "17\n",
      "mcs-ftl  2010/9/8  0:40  page 98  #104\n",
      "\n",
      "98\n",
      "\t\n",
      "Chapter 4\n",
      "\t\n",
      "Number Theory\n",
      "4.4.1\n",
      "\t\n",
      "Turings Code (Version 1.0)\n",
      "The first challenge is to translate a text message into an integer so we can perform mathematical operations on it. This step is not intended to make a message harder to read, so the details are not too important. Here is one approach: replace each letter of the message with two digits (A D 01, B D 02, C D 03, etc.) and string all the digits together to form one huge number. For example, the message victory could be translated this way:\n",
      "v\ti\n",
      "\t\n",
      "c\n",
      "\t\n",
      "t\n",
      "\t\n",
      "o\n",
      "\t\n",
      "r\ty\n",
      "22  09  03  20  15  18  25\n",
      "Turings code requires the message to be a prime number, so we may need to pad the result with a few more digits to make a prime. In this case, appending the digits 13 gives the number 2209032015182513, which is prime.\n",
      "Here is how the encryption process works. In the description below, m is the unencoded message (which we want to keep secret), m is the encrypted message (which the Nazis may intercept), and k is the key.\n",
      "Beforehand The sender and receiver agree on a secret key, which is a large prime\n",
      ".\n",
      "Encryption The sender encrypts the message m by computing:\n",
      "m  D m k\n",
      "Decryption The receiver decrypts m  by computing:\n",
      "m\n",
      "\t\n",
      "D \n",
      "m k \n",
      "D\n",
      " \n",
      "m\n",
      "\n",
      "k\n",
      "\t\n",
      "k\n",
      "For example, suppose that the secret key is the prime number k D 22801763489 and the message m is victory. Then the encrypted message is:\n",
      "m  D m k\n",
      "2209032015182513 22801763489\n",
      "50369825549820718594667857\n",
      "There are a couple of questions that one might naturally ask about Turings code.\n",
      "How can the sender and receiver ensure that m and k are prime numbers, as required?\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 99  #105\n",
      "\n",
      "The general problem of determining whether a large number is prime or com-posite has been studied for centuries, and reasonably good primality tests were known even in Turings time. In 2002, Manindra Agrawal, Neeraj Kayal, and Nitin Saxena announced a primality test that is guaranteed to work on a number n in about .log n/\n",
      "12\n",
      " steps, that is, a number of steps bounded by a twelfth degree polynomial in the length (in bits) of the in-put, n. This definitively places primality testing way below the problems of exponential difficulty. Amazingly, the description of their breakthrough algorithm was only thirteen lines long!\n",
      "Of course, a twelfth degree polynomial grows pretty fast, so the Agrawal, et al. procedure is of no practical use. Still, good ideas have a way of breeding more good ideas, so theres certainly hope that further improvements will lead to a procedure that is useful in practice. But the truth is, theres no practical need to improve it, since very efficient probabilistic procedures for prime-testing have been known since the early 1970s. These procedures have some probability of giving a wrong answer, but their probability of being wrong is so tiny that relying on their answers is the best bet youll ever make.\n",
      "Is Turings code secure?\n",
      "The Nazis see only the encrypted message m D m k, so recovering the original message m requires factoring m . Despite immense efforts, no re-ally efficient factoring algorithm has ever been found. It appears to be a fundamentally difficult problem, though a breakthrough someday is not im-possible. In effect, Turings code puts to practical use his discovery that there are limits to the power of computation. Thus, provided m and k are sufficiently large, the Nazis seem to be out of luck!\n",
      "This all sounds promising, but there is a major flaw in Turings code.\n",
      "4.4.2\n",
      "\t\n",
      "Breaking Turings Code\n",
      "Lets consider what happens when the sender transmits a second message using Turings code and the same key. This gives the Nazis two encrypted messages to look at:\n",
      "m\n",
      "1\n",
      " D m\n",
      "1\n",
      "  k\n",
      "\t\n",
      "and\n",
      "\t\n",
      "m\n",
      "2\n",
      " D m\n",
      "2\n",
      "  k\n",
      "The greatest common divisor of the two encrypted messages, m\n",
      "1\n",
      " and m\n",
      "2\n",
      ", is the secret key k. And, as weve seen, the GCD of two numbers can be computed very efficiently. So after the second message is sent, the Nazis can recover the secret key and read every message!\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 100  #106\n",
      "\n",
      "100\n",
      "\t\n",
      "Chapter 4\n",
      "\t\n",
      "Number Theory\n",
      "It is difficult to believe a mathematician as brilliant as Turing could overlook such a glaring problem. One possible explanation is that he had a slightly different system in mind, one based on modular arithmetic.\n",
      "\n",
      "4.5\tModular Arithmetic\n",
      "On page 1 of his masterpiece on number theory, Disquisitiones Arithmeticae, Gauss introduced the notion of congruence. Now, Gauss is another guy who managed to cough up a half-decent idea every now and then, so lets take a look at this one.\n",
      "There is a close connection between congruences and remainders:\n",
      "Lemma 4.5.1 (Congruences and Remainders).\n",
      "a\tb\t.mod n/\n",
      "\t\n",
      "iff\n",
      "\t\n",
      "rem.a; n/ D rem.b; n/:\n",
      "Proof. By the Division Theorem, there exist unique pairs of integers q\n",
      "1\n",
      "; r\n",
      "1\n",
      " and q\n",
      "2\n",
      "; r\n",
      "2\n",
      " such that:\n",
      "a D q\n",
      "1\n",
      "n C r\n",
      "1\n",
      "\t\n",
      "where 0\n",
      "\t\n",
      "r\n",
      "1\n",
      " < n;\n",
      "b D q\n",
      "2\n",
      "n C r\n",
      "2\n",
      "\t\n",
      "where 0\n",
      "\t\n",
      "r\n",
      "2\n",
      " < n:\n",
      "Subtracting the second equation from the first gives:\n",
      "a\tb D .q\n",
      "1\n",
      "\tq\n",
      "2\n",
      "/n C .r\n",
      "1\n",
      "\tr\n",
      "2\n",
      "/\n",
      "\t\n",
      "where n < r \n",
      "1\n",
      "\t\n",
      "r\n",
      "2\n",
      " < n:\n",
      "Now a b .mod n/ if and only if n divides the left side. This is true if and only if n divides the right side, which holds if and only if r\n",
      "1\n",
      " r\n",
      "2\n",
      " is a multiple of n. Given the bounds on r\n",
      "1\n",
      " r\n",
      "2\n",
      ", this happens precisely when r\n",
      "1\n",
      " D r\n",
      "2\n",
      ", that is, when\n",
      "rem.a; n/ D rem.b; n/.\n",
      "So we can also see that\n",
      "29\t15\t.mod 7/\n",
      "\t\n",
      "because rem.29; 7/ D 1 D rem.15; 7/:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 101  #107\n",
      "\n",
      "This formulation explains why the congruence relation has properties like an equal-ity relation. Notice that even though (mod 7) appears over on the right side, the symbol, it isnt any more strongly associated with the 15 than with the 29. It would really be clearer to write 29 \n",
      "mod\n",
      " \n",
      "7\n",
      " 15 for example, but the notation with the modulus at the end is firmly entrenched and well stick to it.\n",
      "Well make frequent use of the following immediate Corollary of Lemma \n",
      ":\n",
      "Corollary 4.5.2.\n",
      "a\n",
      "\t\n",
      "rem.a; n/\n",
      "\t\n",
      ".mod n/\n",
      "Still another way to think about congruence modulo n is that it defines a partition of the integers into n sets so that congruent numbers are all in the same set. For example, suppose that were working modulo 3. Then we can partition the integers into 3 sets as follows:\n",
      "according to whether their remainders on division by 3 are 0, 1, or 2. The upshot is that when arithmetic is done modulo n there are really only n different kinds of numbers to worry about, because there are only n possible remainders. In this sense, modular arithmetic is a simplification of ordinary arithmetic and thus is a good reasoning tool.\n",
      "There are many useful facts about congruences, some of which are listed in the lemma below. The overall theme is that congruences work a lot like equations, though there are a couple of exceptions.\n",
      "Lemma 4.5.3 (Facts About Congruences). The following hold for n\n",
      "\t\n",
      "1:\n",
      "a   a .mod n/\n",
      "a   b .mod n/ implies b   a .mod n/\n",
      "a   b .mod n/ and b   c .mod n/ implies a   c .mod n/\n",
      "a   b .mod n/ implies a C c   b C c .mod n/\n",
      "a   b .mod n/ implies ac   bc .mod n/\n",
      "a   b .mod n/ and c   d .mod n/ imply a C c   b C d .mod n/\n",
      "a   b .mod n/ and c   d .mod n/ imply ac   bd .mod n/\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 102  #108\n",
      "\n",
      "102\n",
      "\t\n",
      "Chapter 4\n",
      "\t\n",
      "Number Theory\n",
      "Proof. Parts 13. follow immediately from Lemma \n",
      ". diately from the definition that a b .mod n/ iff n j .a follows because if n j .a b/ then it divides .a b/c D ac assume\n",
      "\n",
      "\n",
      "Part 4. follows imme-b/. Likewise, part 5. bc. To prove part 6.,\n",
      "Then\n",
      "a C c\n",
      "\t\n",
      "b C c\n",
      "c C b\n",
      "\t\n",
      "d C b\n",
      "b C c\n",
      "\t\n",
      "b C d\n",
      "a C c\n",
      "\t\n",
      "b C d\n",
      "\n",
      "\n",
      "Part 7 has a similar proof.\n",
      "4.5.1\n",
      "\t\n",
      "Turings Code (Version 2.0)\n",
      "In 1940, France had fallen before Hitlers army, and Britain stood alone against the Nazis in western Europe. British resistance depended on a steady flow of sup-plies brought across the north Atlantic from the United States by convoys of ships. These convoys were engaged in a cat-and-mouse game with German U-boats submarineswhich prowled the Atlantic, trying to sink supply ships and starve Britain into submission. The outcome of this struggle pivoted on a balance of in-formation: could the Germans locate convoys better than the Allies could locate U-boats or vice versa?\n",
      "Germany lost.\n",
      "But a critical reason behind Germanys loss was made public only in 1974: Ger-manys naval code, Enigma, had been broken by the \n",
      "(see \n",
      ")\n",
      " \n",
      "and the\n",
      " \n",
      "secret had been turned over to the British a few weeks before the Nazi invasion of Poland in 1939. Throughout much of the war, the Allies were able to route con-voys around German submarines by listening in to German communications. The British government didnt explain how Enigma was broken until 1996. When it was finally released (by the US), the story revealed that Alan Turing had joined the secret British codebreaking effort at Bletchley Park in 1939, where he became the lead developer of methods for rapid, bulk decryption of German Enigma messages. Turings Enigma deciphering was an invaluable contribution to the Allied victory over Hitler.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 103  #109\n",
      "\n",
      "Governments are always tight-lipped about cryptography, but the half-century of official silence about Turings role in breaking Enigma and saving Britain may be related to some disturbing events after the war. More on that later. Lets get back to number theory and consider an alternative interpretation of Turings code. Perhaps we had the basic idea right (multiply the message by the key), but erred in using conventional arithmetic instead of modular arithmetic. Maybe this is what Turing meant:\n",
      "Beforehand The sender and receiver agree on a large prime p, which may be made public. (This will be the modulus for all our arithmetic.) They also agree on\n",
      "a secret key k 2 f1; 2; : : : ; p\n",
      "\t\n",
      "1g.\n",
      "Encryption The message m can be any integer in the set f0; 1; 2; : : : ; p\n",
      "\t\n",
      "1g; in\n",
      "particular, the message is no longer required to be a prime. The sender en-\n",
      "crypts the message m to produce m\n",
      "\t\n",
      "by computing:\n",
      "m  D rem.mk; p/\n",
      "\t\n",
      "(4.7)\n",
      "Decryption (Uh-oh.)\n",
      "The decryption step is a problem. We might hope to decrypt in the same way as before: by dividing the encrypted message m by the key k. The difficulty is that m is the remainder when mk is divided by p. So dividing m by k might not even give us an integer!\n",
      "This decoding difficulty can be overcome with a better understanding of arith-metic modulo a prime.\n",
      "\n",
      "4.6\n",
      "\t\n",
      "Arithmetic with a Prime Modulus\n",
      "4.6.1\n",
      "\t\n",
      "Multiplicative Inverses\n",
      "The multiplicative inverse of a number x is another number x\n",
      "1\n",
      "\t\n",
      "such that:\n",
      "x x\n",
      "1\n",
      "\t\n",
      "D 1\n",
      "Generally, multiplicative inverses exist over the real numbers. For example, the multiplicative inverse of 3 is 1=3 since:\n",
      "3 \n",
      "1\n",
      "3\n",
      "D1\n",
      "\n",
      "The sole exception is that 0 does not have an inverse.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 104  #110\n",
      "\n",
      "104\n",
      "\t\n",
      "Chapter 4\n",
      "\t\n",
      "Number Theory\n",
      "On the other hand, inverses generally do not exist over the integers. For example, 7 can not be multiplied by another integer to give 1.\n",
      "Surprisingly, multiplicative inverses do exist when were working modulo a prime number. For example, if were working modulo 5, then 3 is a multiplicative inverse of 7, since:\n",
      "7 3\t1\n",
      "\t\n",
      ".mod 5/\n",
      "(All numbers congruent to 3 modulo 5 are also multiplicative inverses of 7; for example, 7 8 1 .mod 5/ as well.) The only exception is that numbers congruent to 0 modulo 5 (that is, the multiples of 5) do not have inverses, much as 0 does not have an inverse over the real numbers. Lets prove this.\n",
      "Lemma 4.6.1. If p is prime and k is not a multiple of p, then k has a multiplicative inverse modulo p.\n",
      "Proof. Since p is prime, it has only two divisors: 1 and p. And since k is not a mul-tiple of p, we must have gcd.p; k/ D 1. Therefore, there is a linear combination of p and k equal to 1:\n",
      "sp C tk D 1\n",
      "Rearranging terms gives:\n",
      "sp D 1\ttk\n",
      "This implies that p j .1\n",
      "\t\n",
      "tk/ by the definition of divisibility, and therefore tk\n",
      "\t\n",
      "1\n",
      ".mod p/ by the definition of congruence.  Thus, t is a multiplicative inverse of\n",
      "k.\n",
      "Multiplicative inverses are the key to decryption in Turings code. Specifically, we can recover the original message by multiplying the encoded message by the inverse of the key:\n",
      "m\tk\n",
      "1\n",
      "\t\n",
      "D rem.mk; p/ k\n",
      "1\n",
      "\t\n",
      "(the def. (\n",
      ") of m )\n",
      ".mk/k\n",
      "1\n",
      "\t.mod p/\n",
      "\t\n",
      "(by Cor. \n",
      ")\n",
      "m\t.mod p/:\n",
      "This shows that m k\n",
      "1\n",
      " is congruent to the original message m. Since m was in the range 0; 1; : : : ; p 1, we can recover it exactly by taking a remainder:\n",
      "m D rem.m k\n",
      "1\n",
      "  ; p/:\n",
      "So all we need to decrypt the message is to find a value of k\n",
      "1\n",
      " . From the proof of Lemma \n",
      ", we know that t is such a value, where sp Ctk D 1. Finding t is easy using the Pulverizer.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 105  #111\n",
      "\n",
      "4.6.2\n",
      "\t\n",
      "Cancellation\n",
      "Another sense in which real numbers are nice is that one can cancel multiplicative terms. In other words, if we know that m\n",
      "1\n",
      "k D m\n",
      "2\n",
      "k, then we can cancel the ks and conclude that m\n",
      "1\n",
      " D m\n",
      "2\n",
      ", provided k  0. In general, cancellation is not valid in modular arithmetic. For example,\n",
      "2 3\t4 3\n",
      "\t\n",
      ".mod 6/;\n",
      "but canceling the 3s leads to the false conclusion that \n",
      "2 4 .mod\n",
      " \n",
      "6/\n",
      ". The fact that multiplicative terms can not be canceled is the most significant sense in which congruences differ from ordinary equations. However, this difference goes away if were working modulo a prime; then cancellation is valid.\n",
      "Lemma 4.6.2. Suppose p is a prime and k is not a multiple of p. Then\n",
      "ak\tbk\t.mod p/\n",
      "\t\n",
      "IMPLIES\n",
      "\t\n",
      "a\tb\t.mod p/:\n",
      "Proof. Multiply both sides of the congruence by k\n",
      "1\n",
      "  .\n",
      "We can use this lemma to get a bit more insight into how Turings code works. In particular, the encryption operation in Turings code permutes the set of possible messages. This is stated more precisely in the following corollary.\n",
      "Corollary 4.6.3. Suppose p is a prime and k is not a multiple of p. Then the sequence:\n",
      "rem..1 k/; p/;\trem..2 k/; p/;\n",
      "\t\n",
      ": : : ;\n",
      "\t\n",
      "rem...p\n",
      "\t\n",
      "1/ k/ ; p/\n",
      "is a permutation\n",
      "of the sequence:\n",
      "1;\t2;\t: : : ;\t.p\t1/:\n",
      "Proof. The sequence of remainders contains p\n",
      "\t\n",
      "1 numbers.  Since i\tk is not\n",
      "divisible by p for i D 1; : : : p\n",
      "\t\n",
      "1, all these remainders are in the range 1 to p\n",
      "\t\n",
      "1\n",
      "by the definition of remainder. Furthermore, the remainders are all different: no two numbers in the range 1 to p 1 are congruent modulo p, and by Lemma \n",
      ", i k j k .mod p/ if and only if i j .mod p/. Thus, the sequence of\n",
      "remainders must contain all of the numbers from 1 to p\n",
      "\t\n",
      "1 in some order.\n",
      "\n",
      "4\n",
      "A permutation of a sequence of elements is a reordering of the elements.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 106  #112\n",
      "\n",
      "106\n",
      "\t\n",
      "Chapter 4\n",
      "\t\n",
      "Number Theory\n",
      "For example, suppose \n",
      "p\n",
      " D \n",
      "5\n",
      " and \n",
      "k\n",
      " D \n",
      "3\n",
      ". Then the sequence:\n",
      "is a permutation of 1, 2, 3, 4. As long as the Nazis dont know the secret key \n",
      "k\n",
      ", they dont know how the set of possible messages are permuted by the process of encryption and thus they cant read encoded messages.\n",
      "4.6.3\n",
      "\t\n",
      "Fermats Little Theorem\n",
      "An alternative approach to finding the inverse of the secret key \n",
      "k\n",
      " in Turings code (about equally efficient and probably more memorable) is to rely on Fermats Little Theorem, which is much easier than his famous Last Theorem.\n",
      "Theorem 4.6.4 (Fermats Little Theorem). Suppose \n",
      "p\n",
      " is a prime and \n",
      "k\n",
      " is not a multiple of \n",
      "p\n",
      ". Then:\n",
      "k\n",
      "p1\n",
      "\t\n",
      "1\t.\n",
      "mod\n",
      " p/\n",
      "Proof. We reason as follows:\n",
      ".p\t1/ \n",
      "WWD\n",
      " 1 2\t.p\n",
      "\t\n",
      "1/\n",
      "D rem\n",
      ".k; p/\n",
      " rem\n",
      ".2k; p/\n",
      "\t\n",
      "rem\n",
      "..p\n",
      "\t\n",
      "1/k; p/\n",
      "\t\n",
      "(by Cor \n",
      ")\n",
      "k 2k\t.p\t1/k\t.\n",
      "mod\n",
      " p/\n",
      "\t\n",
      "(by Cor \n",
      ")\n",
      ".p\t1/\tk\n",
      "p1\n",
      "\t.\n",
      "mod\n",
      " p/\n",
      "\t\n",
      "(rearranging terms)\n",
      "Now \n",
      ".p\n",
      "\t\n",
      "1/ \n",
      "is not a multiple of\n",
      " p \n",
      "because the prime factorizations of\n",
      " 1; 2; : : : \n",
      ",\n",
      ".p\t1/ \n",
      "contain only primes smaller than\n",
      " p\n",
      ". So by Lemma\n",
      " \n",
      ",\n",
      " \n",
      "we can cancel\n",
      ".p\t1/ \n",
      "from the first and last expressions, which proves the claim.\n",
      "Here is how we can find inverses using Fermats Theorem. Suppose \n",
      "p\n",
      " is a prime and \n",
      "k\n",
      " is not a multiple of \n",
      "p\n",
      ". Then, by Fermats Theorem, we know that:\n",
      "k\n",
      "p2\n",
      "\tk\t1\t.\n",
      "mod\n",
      " p/\n",
      "Therefore, \n",
      "k\n",
      "p2\n",
      " must be a multiplicative inverse of \n",
      "k\n",
      ". For example, suppose that we want the multiplicative inverse of 6 modulo 17. Then we need to compute rem\n",
      ".6\n",
      "15\n",
      "; 17/\n",
      ", which we can do by successive squaring. All the congruences below\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 107  #113\n",
      "\n",
      "hold modulo 17.\n",
      "6\n",
      "2\n",
      "\t36\n",
      "\t\n",
      "2\n",
      "6\n",
      "4\n",
      "\t.6\n",
      "2\n",
      "/\n",
      "2\n",
      "\t2\n",
      "2\n",
      "\t\n",
      "4\n",
      "6\n",
      "8\n",
      "\t.6\n",
      "4\n",
      "/\n",
      "2\n",
      "\t4\n",
      "2\n",
      "\t\n",
      "16\n",
      "6\n",
      "15\n",
      "\t6\n",
      "8\n",
      "6\n",
      "4\n",
      "6\n",
      "2\n",
      "6\t16426\n",
      "\t\n",
      "3\n",
      "Therefore, rem.6\n",
      "15\n",
      "; 17/ D 3. Sure enough, 3 is the multiplicative inverse of 6 modulo 17, since:\n",
      "3 6\t1\n",
      "\t\n",
      ".mod 17/\n",
      "In general, if we were working modulo a prime p, finding a multiplicative in-verse by trying every value between 1 and p 1 would require about p operations. However, the approach above requires only about 2 log p operations, which is far better when p is large.\n",
      "4.6.4\n",
      "\t\n",
      "Breaking Turings CodeAgain\n",
      "The Germans didnt bother to encrypt their weather reports with the highly-secure Enigma system. After all, so what if the Allies learned that there was rain off the south coast of Iceland? But, amazingly, this practice provided the British with a critical edge in the Atlantic naval battle during 1941.\n",
      "The problem was that some of those weather reports had originally been trans-mitted using Enigma from U-boats out in the Atlantic. Thus, the British obtained both unencrypted reports and the same reports encrypted with Enigma. By com-paring the two, the British were able to determine which key the Germans were using that day and could read all other Enigma-encoded traffic. Today, this would be called a known-plaintext attack.\n",
      "Lets see how a known-plaintext attack would work against Turings code. Sup-pose that the Nazis know both m and m where:\n",
      "m\n",
      "\t\n",
      "mk\t.mod p/\n",
      "Now they can compute:\n",
      "m\n",
      "p2\n",
      "\tm  D m\n",
      "p2\n",
      "\t\n",
      "rem.mk; p/\n",
      "\t\n",
      "(def. (\n",
      ") of m )\n",
      "m\n",
      "p2\n",
      "\tmk\t.mod p/\n",
      "\t\n",
      "(by Cor \n",
      ")\n",
      "m\n",
      "p1\n",
      "\tk\t.mod p/\n",
      "k\t.mod p/\n",
      "\t\n",
      "(Fermats Theorem)\n",
      "Now the Nazis have the secret key k and can decrypt any message!\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 108  #114\n",
      "\n",
      "108\n",
      "\t\n",
      "Chapter 4\n",
      "\t\n",
      "Number Theory\n",
      "This is a huge vulnerability, so Turings code has no practical value. Fortunately, Turing got better at cryptography after devising this code; his subsequent decipher-ing of Enigma messages surely saved thousands of lives, if not the whole of Britain.\n",
      "4.6.5\n",
      "\t\n",
      "Turing Postscript\n",
      "A few years after the war, Turings home was robbed. Detectives soon determined that a former homosexual lover of Turings had conspired in the robbery. So they arrested himthat is, they arrested Alan Turingbecause homosexuality was a British crime punishable by up to two years in prison at that time. Turing was sentenced to a hormonal treatment for his homosexuality: he was given estrogen injections. He began to develop breasts.\n",
      "Three years later, Alan Turing, the founder of computer science, was dead. His mother explained what happened in a biography of her own son. Despite her re-peated warnings, Turing carried out chemistry experiments in his own home. Ap-parently, her worst fear was realized: by working with potassium cyanide while eating an apple, he poisoned himself.\n",
      "However, Turing remained a puzzle to the very end. His mother was a devoutly religious woman who considered suicide a sin. And, other biographers have pointed out, Turing had previously discussed committing suicide by eating a poisoned ap-ple. Evidently, Alan Turing, who founded computer science and saved his country, took his own life in the end, and in just such a way that his mother could believe it was an accident.\n",
      "Turings last project before he disappeared from public view in 1939 involved the construction of an elaborate mechanical device to test a mathematical conjecture called the Riemann Hypothesis. This conjecture first appeared in a sketchy paper by Bernhard Riemann in 1859 and is now one of the most famous unsolved problem in mathematics.\n",
      "\n",
      "4.7\tArithmetic with an Arbitrary Modulus\n",
      "Turings code did not work as he hoped. However, his essential ideausing num-ber theory as the basis for cryptographysucceeded spectacularly in the decades after his death.\n",
      "In 1977, Ronald Rivest, Adi Shamir, and Leonard Adleman at MIT proposed a highly secure cryptosystem (called RSA) based on number theory. Despite decades of attack, no significant weakness has been found. Moreover, RSA has a major advantage over traditional codes: the sender and receiver of an encrypted mes-\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 109  #115\n",
      "\n",
      "\n",
      "The Riemann Hypothesis\n",
      "The formula for the sum of an infinite geometric series says:\n",
      "1 C x C x\n",
      "2\n",
      " C x\n",
      "3\n",
      " C\n",
      "\t\n",
      "D \n",
      "1\n",
      " \n",
      "1\n",
      " \n",
      "x\n",
      "\n",
      "Substituting x D \n",
      "2\n",
      "1\n",
      "s\n",
      " , x D \n",
      "3\n",
      "1\n",
      "s\n",
      " , x D \n",
      "5\n",
      "1\n",
      "s\n",
      " , and so on for each prime number gives a sequence of equations:\n",
      "\n",
      "etc.\n",
      "Multiplying together all the left sides and all the right sides gives:\n",
      "The sum on the left is obtained by multiplying out all the infinite series and ap-plying the Fundamental Theorem of Arithmetic. For example, the term 1=300\n",
      "s\n",
      " in the sum is obtained by multiplying 1=2\n",
      "2s\n",
      " from the first equation by 1=3\n",
      "s\n",
      " in the second and 1=5\n",
      "2s\n",
      " in the third. Riemann noted that every prime appears in the expression on the right. So he proposed to learn about the primes by studying the equivalent, but simpler expression on the left. In particular, he regarded s as a complex number and the left side as a function, .s/. Riemann found that the distribution of primes is related to values of s for which .s/ D 0, which led to his famous conjecture:\n",
      "Definition 4.6.5. The Riemann Hypothesis: Every nontrivial zero of the zeta func-tion .s/ lies on the line s D 1=2 C ci in the complex plane.\n",
      "A proof would immediately imply, among other things, a strong form of the Prime Number Theorem.\n",
      "Researchers continue to work intensely to settle this conjecture, as they have for over a century. It is another of the \n",
      "whose solver will earn $1,000,000 from the Clay Institute.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 110  #116\n",
      "\n",
      "110\n",
      "\t\n",
      "Chapter 4\n",
      "\t\n",
      "Number Theory\n",
      "sage need not meet beforehand to agree on a secret key. Rather, the receiver has both a secret key, which she guards closely, and a public key, which she distributes as widely as possible. The sender then encrypts his message using her widely-distributed public key. Then she decrypts the received message using her closely-held private key. The use of such a public key cryptography system allows you and Amazon, for example, to engage in a secure transaction without meeting up beforehand in a dark alley to exchange a key.\n",
      "Interestingly, RSA does not operate modulo a prime, as Turings scheme may have, but rather modulo the product of two large primes. Thus, well need to know a bit about how arithmetic works modulo a composite number in order to understand RSA. Arithmetic modulo an arbitrary positive integer is really only a little more painful than working modulo a primethough you may think this is like the doctor saying, This is only going to hurt a little, before he jams a big needle in your arm.\n",
      "4.7.1\tRelative Primality\n",
      "First, we need a new definition. Integers a and b are relatively prime iff gcd.a; b/ D 1. For example, 8 and 15 are relatively prime, since gcd.8; 15/ D 1. Note that, except for multiples of p, every integer is relatively prime to a prime number p.\n",
      "Next well need to generalize what we know about arithmetic modulo a prime to work modulo an arbitrary positive integer n. The basic theme is that arithmetic modulo n may be complicated, but the integers relatively prime to n remain fairly well-behaved. For example, the proof of Lemma \n",
      "of an inverse for k modulo p extends to an inverse for k relatively prime to n:\n",
      "Lemma 4.7.1. Let n be a positive integer. If k is relatively prime to n, then there exists an integer k\n",
      "1\n",
      " such that:\n",
      "k k\n",
      "1\n",
      "\t\n",
      "1\t.mod n/\n",
      "As a consequence of this lemma, we can cancel a multiplicative term from both sides of a congruence if that term is relatively prime to the modulus:\n",
      "Corollary 4.7.2. Suppose n is a positive integer and k is relatively prime to n. If\n",
      "ak\tbk\t.mod n/\n",
      "then\n",
      "a\tb\t.mod n/\n",
      "This holds because we can multiply both sides of the first congruence by k\n",
      "1\n",
      " and simplify to obtain the second.\n",
      "The following lemma is the natural generalization of Corollary \n",
      ".\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 111  #117\n",
      "\n",
      "Lemma 4.7.3. Suppose \n",
      "n\n",
      " is a positive integer and \n",
      "k\n",
      " is relatively prime to \n",
      "n\n",
      ". Let \n",
      "k\n",
      "1\n",
      "; : : : ; k\n",
      "r\n",
      " \n",
      "denote all the integers relatively prime to\n",
      " n \n",
      "in the range\n",
      " 1 \n",
      "to\n",
      " n 1\n",
      ". Then\n",
      " \n",
      "the sequence:\n",
      "rem\n",
      ".k\n",
      "1\n",
      "  \n",
      "k; n/;\n",
      "\trem\n",
      ".k\n",
      "2\n",
      "  \n",
      "k; n/;\n",
      "\trem\n",
      ".k\n",
      "3\n",
      "  \n",
      "k; n/;\n",
      "\t\n",
      ": : :\t; \n",
      "rem\n",
      ".k\n",
      "r\n",
      "  k; n/\n",
      "is a permutation of the sequence:\n",
      "k\n",
      "1\n",
      ";\tk\n",
      "2\n",
      ";\t: : :\n",
      "\t\n",
      "; k\n",
      "r\n",
      " :\n",
      "Proof. We will show that the remainders in the first sequence are all distinct and are equal to some member of the sequence of \n",
      "k\n",
      "j\n",
      " s. Since the two sequences have the same length, the first must be a permutation of the second.\n",
      "First, we show that the remainders in the first sequence are all distinct. Suppose that rem\n",
      ".k\n",
      "i\n",
      " \n",
      "k; n/\n",
      " D rem\n",
      ".k\n",
      "j\n",
      " \n",
      "k; n/\n",
      ". This is equivalent to \n",
      "k\n",
      "i\n",
      " \n",
      "k k\n",
      "j\n",
      " \n",
      "k .\n",
      "mod \n",
      "n/\n",
      ", which implies \n",
      "k\n",
      "i\n",
      " \n",
      "k\n",
      "j\n",
      " \n",
      ".\n",
      "mod \n",
      "n/\n",
      " by Corollary \n",
      ". This, in turn, means that \n",
      "k\n",
      "i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " D \n",
      "k\n",
      "j\n",
      " since both are between 1 and \n",
      "n 1\n",
      ". Thus, none of the remainder terms in the first sequence is equal to any other remainder term.\n",
      "Next, we show that each remainder in the first sequence equals one of the \n",
      "k\n",
      "i\n",
      " . By assumption, gcd\n",
      ".k\n",
      "i\n",
      " \n",
      "; n/\n",
      " D \n",
      "1\n",
      " and gcd\n",
      ".k; n/\n",
      " D \n",
      "1\n",
      ", which means that\n",
      "gcd\n",
      ".n;\n",
      " rem\n",
      ".k\n",
      "i\n",
      " \n",
      "k; n//\n",
      " D gcd\n",
      ".k\n",
      "i\n",
      " \n",
      "k; n/\n",
      "\t\n",
      "(by part (\n",
      ") of Lemma \n",
      ")\n",
      "D \n",
      "1\n",
      "\t\n",
      "(by part (\n",
      ") of Lemma \n",
      ")\n",
      ":\n",
      "Since rem\n",
      ".k\n",
      "i\n",
      " \n",
      "k; n/\n",
      " is in the range from 0 to \n",
      "n\n",
      "\t\n",
      "1 \n",
      "by the definition of remainder,\n",
      "and since it is relatively prime to \n",
      "n\n",
      ", it must (by definition of the \n",
      "k\n",
      "j\n",
      " s) be equal to\n",
      "some \n",
      "k\n",
      "j\n",
      " .\n",
      "4.7.2\n",
      "\t\n",
      "Eulers Theorem\n",
      "RSA relies heavily on a generalization of Fermats Theorem known as Eulers The-orem. For both theorems, the exponent of \n",
      "k\n",
      " needed to produce an inverse of \n",
      "k\n",
      " mod-ulo \n",
      "n\n",
      " depends on the number of integers in the set f\n",
      "1; 2; : : : ; n\n",
      "g (denoted \n",
      "1; n\n",
      " ) that are relatively prime to \n",
      "n\n",
      ". This value is known as Eulers function (a.k.a. Eulers totient function) and it is denoted as \n",
      ".n/\n",
      ". For example, \n",
      ".7/\n",
      " D \n",
      "6\n",
      " since 1, 2, 3, 4, 5, and 6 are all relatively prime to 7. Similarly, \n",
      ".12/\n",
      " D \n",
      "4\n",
      " since 1, 5, 7, and 11 are the only numbers in \n",
      "1; 12\n",
      " that are relatively prime to 12.\n",
      "If \n",
      "n\n",
      " is prime, then \n",
      ".n/\n",
      " D \n",
      "n 1\n",
      " since every number less than a prime number is relatively prime to that prime. When \n",
      "n\n",
      " is composite, however, the function gets a little complicated. The following theorem characterizes the function for\n",
      "\n",
      "5\n",
      "Recall that gcd.n; n/ D n and so n is never relatively prime to itself.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 112  #118\n",
      "\n",
      "112\n",
      "\t\n",
      "Chapter 4\n",
      "\t\n",
      "Number Theory\n",
      "composite \n",
      "n\n",
      ". We wont prove the theorem in its full generality, although we will give a proof for the special case when \n",
      "n\n",
      " is the product of two primes since that is the case that matters for RSA.\n",
      "Theorem 4.7.4. For any number \n",
      "n\n",
      ", if \n",
      "p\n",
      "1\n",
      ", \n",
      "p\n",
      "2\n",
      ", . . . , \n",
      "p\n",
      "j\n",
      " are the (distinct) prime factors of \n",
      "n\n",
      ", then\n",
      "For example,\n",
      ".300/ \n",
      "D\n",
      "  .2\n",
      "2\n",
      "  3 5\n",
      "2\n",
      "/\n",
      "300\n",
      "1 2 4 2 3 5\n",
      "\n",
      "80:\n",
      "Corollary 4.7.5. Let \n",
      "n\n",
      " D \n",
      "pq\n",
      " where \n",
      "p\n",
      " and \n",
      "q\n",
      " are different primes. Then \n",
      ".n/\n",
      " D \n",
      ".p 1/.q 1/\n",
      ".\n",
      "Corollary \n",
      "follows easily from Theorem \n",
      ", but since Corollary \n",
      "is important to RSA and we have not provided a proof of Theorem \n",
      ", we will give a direct proof of Corollary \n",
      "in what follows.\n",
      "Proof of Corollary \n",
      ". Since \n",
      "p\n",
      " and \n",
      "q\n",
      " are prime, any number that is not relatively prime to \n",
      "n\n",
      " D \n",
      "pq\n",
      " must be a multiple of \n",
      "p\n",
      " or a multiple of \n",
      "q\n",
      ". Among the numbers 1, 2, . . . , \n",
      "pq\n",
      ", there are precisely \n",
      "q\n",
      " multiples of \n",
      "p\n",
      " and \n",
      "p\n",
      " multiples of \n",
      "q\n",
      ". Since \n",
      "p\n",
      " and \n",
      "q\n",
      " are relatively prime, the only number in \n",
      "1; pq\n",
      " that is a multiple of both \n",
      "p\n",
      " and \n",
      "q\n",
      " is \n",
      "pq\n",
      ". Hence, there are \n",
      "p\n",
      " C \n",
      "q 1\n",
      " numbers in \n",
      "1; pq\n",
      " that are not relatively prime to \n",
      "n\n",
      ". This means that\n",
      ".n/ \n",
      "D\n",
      " pq\tp\n",
      "\t\n",
      "q \n",
      "C\n",
      " 1\n",
      "D \n",
      ".p\n",
      "\t\n",
      "1/.q\t1/;\n",
      "as claimed.\n",
      "We can now prove Eulers Theorem:\n",
      "\n",
      "This proof provides a brief preview of the kinds of counting arguments that we will explore more fully in Part III.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 113  #119\n",
      "\n",
      "Theorem 4.7.6 (Eulers Theorem). Suppose n is a positive integer and k is rela-tively prime to n. Then\n",
      "k \n",
      ".n/\n",
      "\t1\t.mod n/\n",
      "Proof. Let k\n",
      "1\n",
      "; : : : ; k\n",
      "r\n",
      " denote all integers relatively prime to n such that 0 k\n",
      "i\n",
      " < n. Then r D .n/, by the definition of the function . The remainder of the proof mirrors the proof of Fermats Theorem. In particular,\n",
      "Part (\n",
      ") of Lemma \n",
      ". implies that k\n",
      "1\n",
      " k\n",
      "2\n",
      " k\n",
      "r\n",
      " is relatively prime to n. So by Corollary \n",
      ", we can cancel this product from the first and last expressions. This\n",
      "proves the claim.\n",
      "We can find multiplicative inverses using Eulers theorem as we did with Fer-mats theorem: if k is relatively prime to n, then k \n",
      ".n/1\n",
      " is a multiplicative inverse of k modulo n. However, this approach requires computing .n/. Computing\n",
      ".n/ is easy (using Theorem \n",
      ") if we know the prime factorization of n. Un-fortunately, finding the factors of n can be hard to do when n is large and so the Pulverizer is often the best approach to computing inverses modulo n.\n",
      "\n",
      "4.8\n",
      "\t\n",
      "The RSA Algorithm\n",
      "Finally, we are ready to see how the RSA public key encryption scheme works. The details are in the box on the next page.\n",
      "It is not immediately clear from the description of the RSA cryptosystem that the decoding of the encrypted message is, in fact, the original unencrypted mes-sage. In order to check that this is the case, we need to show that the decryption rem..m\n",
      "0\n",
      "/\n",
      "d\n",
      " ; n/ is indeed equal to the senders message m. Since m\n",
      "0\n",
      " D rem.m\n",
      "e\n",
      "; n/, m\n",
      "0\n",
      " is congruent to m\n",
      "e\n",
      " modulo n by Corollary \n",
      ". That is,\n",
      "m\n",
      "0\n",
      "\tm\n",
      "e\n",
      "\t.mod n/:\n",
      "By raising both sides to the power d , we obtain the congruence\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 114  #120\n",
      "\n",
      "114\n",
      "\t\n",
      "Chapter 4\n",
      "\t\n",
      "Number Theory\n",
      "\n",
      "The RSA Cryptosystem\n",
      "Beforehand The receiver creates a public key and a secret key as follows.\n",
      "Generate two distinct primes, p and q. Since they can be used to generate the secret key, they must be kept hidden.\n",
      "Let n D pq.\n",
      "The secret key is the pair .d; n/. This should be kept hidden!\n",
      "Encoding Given a message m, the sender first checks that gcd.m; n/ D 1.\n",
      "The\n",
      "sender then encrypts message m to produce m\n",
      "0\n",
      " using the public key:\n",
      "m\n",
      "0\n",
      " D rem.m\n",
      "e\n",
      "; n/:\n",
      "Decoding The receiver decrypts message m\n",
      "0\n",
      " back to message m using the secret key:\n",
      "m D rem..m\n",
      "0\n",
      "/\n",
      "d\n",
      " ; n/:\n",
      "\n",
      "It would be very bad if gcd.m; n/ equals p or q since then it would be easy for someone to use the encoded message to compute the secret key If gcd.m; n/ D n, then the encoded message would be 0, which is fairly useless. For very large values of n, it is extremely unlikely that gcd.m; n/  1. If this does happen, you should get a new set of keys or, at the very least, add some bits to m so that the resulting message is relatively prime to n.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 115  #121\n",
      "\n",
      "The encryption exponent e and the decryption exponent d are chosen such that\n",
      "Hence, the decryption process indeed reproduces the original message m.\n",
      "Is it hard for someone without the secret key to decrypt the message? No one knows for sure but it is generally believed that if n is a very large number (say, with a thousand digits), then it is difficult to reverse engineer d from e and n. Of course, it is easy to compute d if you know p and q (by using the Pulverizer) but it is not known how to quickly factor n into p and q when n is very large. Maybe with a little more studying of number theory, you will be the first to figure out how to do it. Although, we should warn you that Gauss worked on it for years without a lot to show for his efforts. And if you do figure it out, you might wind up meeting some serious-looking fellows in black suits. . . .\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 116  #122\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 117  #123\n",
      "\n",
      "II\n",
      "\t\n",
      "Structures\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 118  #124\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 119  #125\n",
      "\n",
      "Introduction\n",
      "Structure is fundamental in computer science. Whether you are writing code, solv-ing an optimization problem, or designing a network, you will be dealing with structure. The better you can understand the structure, the better your results will be. And if you can reason about structure, then you will be in a good position to convince others (and yourself) that your results are worthy.\n",
      "The most important structure in computer science is a graph, also known as a net-work). Graphs provide an excellent mechanism for modeling associations between pairs of objects; for example, two exams that cannot be given at the same time, two people that like each other, or two subroutines that can be run independently. In Chapter \n",
      ", we study graphs that represent symmetric relationships, like those just mentioned. In Chapter \n",
      ", we consider graphs where the relationship is one-way; that is, a situation where you can go from x to y but not necessarily vice-versa.\n",
      "In Chapter \n",
      ", we consider the more general notion of a relation and we examine important classes of relations such as partially ordered sets. Partially ordered sets arise frequently in scheduling problems.\n",
      "We conclude in Chapter \n",
      "with a discussion of state machines. State machines can be used to model a variety of processes and are a fundamental tool in proving that an algorithm terminates and that it produces the correct output.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 120  #126\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 121  #127\n",
      "\n",
      "Graph Theory\n",
      "Informally, a graph is a bunch of dots and lines where the lines connect some pairs of dots. An example is shown in Figure \n",
      ". The dots are called nodes (or vertices) and the lines are called edges.\n",
      "b\n",
      "\t\n",
      "h\n",
      "\n",
      "a\n",
      "\n",
      "    f\n",
      "\n",
      "d\n",
      "g\n",
      "\t\n",
      "i\n",
      "e\n",
      "Figure 5.1\n",
      "\t\n",
      "An example of a graph with 9 nodes and 8 edges.\n",
      "Graphs are ubiquitous in computer science because they provide a handy way to represent a relationship between pairs of objects. The objects represent items of interest such as programs, people, cities, or web pages, and we place an edge between a pair of nodes if they are related in a certain way. For example, an edge between a pair of people might indicate that they like (or, in alternate scenarios, that they dont like) each other. An edge between a pair of courses might indicate that one needs to be taken before the other.\n",
      "In this chapter, we will focus our attention on simple graphs where the relation-ship denoted by an edge is symmetric. Afterward, in Chapter \n",
      ", we consider the situation where the edge denotes a one-way relationship, for example, where one web page points to the other.\n",
      "\n",
      "5.1\n",
      "\t\n",
      "Definitions\n",
      "5.1.1\n",
      "\t\n",
      "Simple Graphs\n",
      "Definition 5.1.1. A simple graph G consists of a nonempty set V , called the ver-tices (aka nodes\n",
      ") of G, and a set E of two-element subsets of V . The members of E are called the edges of G, and we write G D .V; E/.\n",
      "\n",
      "1\n",
      "Two Stanford students analyzed such a graph to become multibillionaires. So, pay attention to graph theory, and who knows what might happen!\n",
      "2\n",
      "We will use the terms vertex and node interchangeably.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 122  #128\n",
      "\n",
      "122\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "The vertices correspond to the dots in Figure \n",
      ", and the edges correspond to the lines. The graph in Figure \n",
      "is expressed mathematically as G D .V; E/, where:\n",
      "V D fa; b; c; d; e; f; g; h; ig\n",
      "E D f fa; bg; fa; cg; fb; d g; fc; d g; fc; eg; fe; f g; fe; gg; fh; ig g:\n",
      "Note that fa; b g and fb; ag are different descriptions of the same edge, since sets are unordered. In this case, the graph G D .V; E/ has 9 nodes and 8 edges.\n",
      "Definition 5.1.2. Two vertices in a simple graph are said to be adjacent if they are joined by an edge, and an edge is said to be incident to the vertices it joins. The number of edges incident to a vertex v is called the degree of the vertex and is denoted by deg.v/; equivalently, the degree of a vertex is equals the number of vertices adjacent to it.\n",
      "For example, in the simple graph shown in Figure \n",
      ", vertex a is adjacent to b and b is adjacent to d , and the edge fa; cg is incident to vertices a and c. Vertex h has degree 1, d has degree 2, and deg.e/ D 3. It is possible for a vertex to have degree 0, in which case it is not adjacent to any other vertices. A simple graph does not need to have any edges at all in which case, the degree of every vertex is zero and jEj D 0\n",
      "but it does need to have at least one vertex, that is, jV j 1.\n",
      "Note that simple graphs do not have any self-loops (that is, an edge of the form fa; a g) since an edge is defined to be a set of two vertices. In addition, there is at most one edge between any pair of vertices in a simple graph. In other words, a simple graph does not contain multiedges or multiple edges. That is because E is a set. Lastly, and most importantly, simple graphs do not contain directed edges (that is, edges of the form .a; b/ instead of fa; bg).\n",
      "Theres no harm in relaxing these conditions, and some authors do, but we dont need self-loops, multiple edges between the same two vertices, or graphs with no vertices, and its simpler not to have them around. We will consider graphs with di-rected edges (called directed graphs or digraphs) at length in Chapter \n",
      ". Since well only be considering simple graphs in this chapter, well just call them graphs from now on.\n",
      "5.1.2\n",
      "\t\n",
      "Some Common Graphs\n",
      "Some graphs come up so frequently that they have names. The complete graph on n vertices, denoted K\n",
      "n\n",
      ", has an edge between every two vertices, for a total of\n",
      "1/=2 edges. For example, K\n",
      "5\n",
      " is shown in Figure \n",
      ".\n",
      "The empty graph has no edges at all. For example, the empty graph with 5 nodes is shown in Figure \n",
      ".\n",
      "\n",
      "3\n",
      "The cardinality, jEj, of the set E is the number of elements in E.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 123  #129\n",
      "\n",
      "\n",
      "Figure 5.2\n",
      "\t\n",
      "The complete graph on 5 nodes, K\n",
      "5\n",
      ".\n",
      "\n",
      "Figure 5.3\n",
      "\t\n",
      "The empty graph with 5 nodes.\n",
      "The n-node graph containing n 1 edges in sequence is known as the line graph L\n",
      "n\n",
      ". More formally, L\n",
      "n\n",
      " D .V; E/ where\n",
      "V D fv\n",
      "1\n",
      "; v\n",
      "2\n",
      "; : : : ; v\n",
      "n\n",
      "g\n",
      "and\n",
      "E D f fv\n",
      "1\n",
      "; v\n",
      "2\n",
      "g; fv\n",
      "2\n",
      "; v\n",
      "3\n",
      "g; : : : ; fv\n",
      "n1\n",
      " ; v\n",
      "n\n",
      "g g For example, L\n",
      "5\n",
      " is displayed in Figure \n",
      ".\n",
      "If we add the edge fv\n",
      "n\n",
      "; v\n",
      "1\n",
      "g to the line graph L\n",
      "n\n",
      ", we get the graph C\n",
      "n\n",
      " consisting of a simple cycle. For example, C\n",
      "5\n",
      " is illustrated in Figure \n",
      ".\n",
      "\n",
      "Figure 5.4\n",
      "\t\n",
      "The 5-node line graph L\n",
      "5\n",
      ".\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 124  #130\n",
      "\n",
      "124\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "\n",
      "Figure 5.5\n",
      "\t\n",
      "The 5-node cycle graph C\n",
      "5\n",
      ".\n",
      "a\n",
      "\t\n",
      "b\n",
      "\t\n",
      "1\n",
      "\t\n",
      "2\n",
      "\n",
      "Figure 5.6\n",
      "\t\n",
      "Two graphs that are isomorphic to C\n",
      "4\n",
      ".\n",
      "5.1.3\n",
      "\t\n",
      "Isomorphism\n",
      "Two graphs that look the same might actually be different in a formal sense. For example, the two graphs in Figure \n",
      "are both simple cycles with 4 vertices, but one graph has vertex set fa; b; c; d g while the other has vertex set f1; 2; 3; 4g. Strictly speaking, these graphs are different mathematical objects, but this is a frustrating distinction since the graphs look the same!\n",
      "Fortunately, we can neatly capture the idea of looks the same through the no-tion of graph isomorphism.\n",
      "Definition 5.1.3. If G\n",
      "1\n",
      " D .V\n",
      "1\n",
      "; E\n",
      "1\n",
      "/ and G\n",
      "2\n",
      " D .V\n",
      "2\n",
      "; E\n",
      "2\n",
      "/ are two graphs, then we say that G\n",
      "1\n",
      " is isomorphic to G\n",
      "2\n",
      " iff there exists a bijection\n",
      "f W V\n",
      "1\n",
      " ! V\n",
      "2\n",
      " such that for every pair of vertices u; v 2 V\n",
      "1\n",
      ":\n",
      "fu; vg 2 E\n",
      "1\n",
      "  iff  ff .u/; f .v/g 2 E\n",
      "2\n",
      ":\n",
      "The function f is called an isomorphism between G\n",
      "1\n",
      " and G\n",
      "2\n",
      ".\n",
      "In other words, two graphs are isomorphic if they are the same up to a relabeling of their vertices. For example, here is an isomorphism between vertices in the two\n",
      "4\n",
      "A bijection f W V\n",
      "1\n",
      " ! V\n",
      "2\n",
      " is a function that associates every node in V\n",
      "1\n",
      " with a unique node in V\n",
      "2\n",
      " and vice-versa. We will study bijections more deeply in Part \n",
      ".\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 125  #131\n",
      "\n",
      "\n",
      "Figure 5.7\n",
      "\t\n",
      "Two ways of drawing C\n",
      "5\n",
      ".\n",
      "graphs shown in Figure \n",
      ":\n",
      "a corresponds to 1\n",
      "\t\n",
      "b corresponds to 2\n",
      "d corresponds to 4\n",
      "\t\n",
      "c corresponds to 3:\n",
      "You can check that there is an edge between two vertices in the graph on the left if and only if there is an edge between the two corresponding vertices in the graph on the right.\n",
      "Two isomorphic graphs may be drawn very differently. For example, we have shown two different ways of drawing C\n",
      "5\n",
      " in Figure \n",
      ".\n",
      "Isomorphism preserves the connection properties of a graph, abstracting out what the vertices are called, what they are made out of, or where they appear in a drawing of the graph. More precisely, a property of a graph is said to be preserved under isomorphism if whenever G has that property, every graph isomorphic to G also has that property. For example, isomorphic graphs must have the same number of vertices. Whats more, if f is a graph isomorphism that maps a vertex, v, of one graph to the vertex, f .v/, of an isomorphic graph, then by definition of isomor-phism, every vertex adjacent to v in the first graph will be mapped by f to a vertex adjacent to f .v/ in the isomorphic graph. This means that v and f .v/ will have the same degree. So if one graph has a vertex of degree 4 and another does not, then they cant be isomorphic. In fact, they cant be isomorphic if the number of degree 4 vertices in each of the graphs is not the same.\n",
      "Looking for preserved properties can make it easy to determine that two graphs are not isomorphic, or to actually find an isomorphism between them if there is one. In practice, its frequently easy to decide whether two graphs are isomorphic. However, no one has yet found a general procedure for determining whether two graphs are isomorphic that is guaranteed to run in polynomial time\n",
      "in jV j.\n",
      "Having such a procedure would be useful. For example, it would make it easy to search for a particular molecule in a database given the molecular bonds. On\n",
      "\n",
      "I.e., in an amount of time that is upper-bounded by jV j\n",
      "c\n",
      " where c is a fixed number independent of jV j.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 126  #132\n",
      "\n",
      "126\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "the other hand, knowing there is no such efficient procedure would also be valu-able: secure protocols for encryption and remote authentication can be built on the hypothesis that graph isomorphism is computationally exhausting.\n",
      "5.1.4\n",
      "\t\n",
      "Subgraphs\n",
      "Definition 5.1.4. A graph G\n",
      "1\n",
      " D .V\n",
      "1\n",
      "; E\n",
      "1\n",
      "/ is said to be a subgraph of a graph G\n",
      "2\n",
      " D .V\n",
      "2\n",
      "; E\n",
      "2\n",
      "/ if V\n",
      "1\n",
      " V\n",
      "2\n",
      " and E\n",
      "1\n",
      " E\n",
      "2\n",
      ".\n",
      "For example, the empty graph on n nodes is a subgraph of L\n",
      "n\n",
      ", L\n",
      "n\n",
      " is a subgraph of C\n",
      "n\n",
      ", and C\n",
      "n\n",
      " is a subgraph of K\n",
      "n\n",
      ". Also, the graph G D .V; E/ where\n",
      "V D fg; h; ig\n",
      "\t\n",
      "and\n",
      "\t\n",
      "E D f fh; ig g\n",
      "is a subgraph of the graph in Figure \n",
      ". On the other hand, any graph containing an edge fg; hg would not be a subgraph of the graph in Figure \n",
      "because the graph in Figure \n",
      "does not contain this edge.\n",
      "Note that since a subgraph is itself a graph, the endpoints of any edge in a sub-graph must also be in the subgraph. In other words if G\n",
      "0\n",
      " D .V \n",
      "0\n",
      "; E\n",
      "0\n",
      "/ is a subgraph of some graph G, and fv\n",
      "i\n",
      " ; v\n",
      "j\n",
      " g 2 E\n",
      "0\n",
      ", then it must be the case that v\n",
      "i\n",
      " 2 V \n",
      "0\n",
      " and v\n",
      "j\n",
      " 2 V \n",
      "0\n",
      ".\n",
      "5.1.5\n",
      "\t\n",
      "Weighted Graphs\n",
      "Sometimes, we will use edges to denote a connection between a pair of nodes where the connection has a capacity or weight. For example, we might be interested in the capacity of an Internet fiber between a pair of computers, the resistance of a wire between a pair of terminals, the tension of a spring connecting a pair of devices in a dynamical system, the tension of a bond between a pair of atoms in a molecule, or the distance of a highway between a pair of cities.\n",
      "In such cases, it is useful to represent the system with an edge-weighted graph (aka a weighted graph). A weighted graph is the same as a simple graph except that we associate a real number (that is, the weight) with each edge in the graph. Mathematically speaking, a weighted graph consists of a graph G D .V; E/ and a weight function w W E ! R. For example, Figure \n",
      "shows a weighted graph where the weight of edge fa; bg is 5.\n",
      "5.1.6\n",
      "\t\n",
      "Adjacency Matrices\n",
      "There are many ways to represent a graph. We have already seen two ways: you can draw it, as in Figure \n",
      "for example, or you can represent it with sets as in G D .V; E/. Another common representation is with an adjacency matrix.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 127  #133\n",
      "\n",
      "b\n",
      "\n",
      "6\n",
      "a \n",
      "\n",
      " c\n",
      "\n",
      "3\n",
      "d\n",
      "Figure 5.8\n",
      "\t\n",
      "A 4-node weighted graph where the edge fa; bg has weight 5.\n",
      "Figure 5.9 Examples of adjacency matrices. (a) shows the adjacency matrix for the graph in Figure \n",
      "(a) and (b) shows the adjacency matrix for the weighted graph in Figure \n",
      ". In each case, we set v\n",
      "1\n",
      " D a, v\n",
      "2\n",
      " D b, v\n",
      "3\n",
      " D c, and v\n",
      "4\n",
      " D d to construct the matrix.\n",
      "Definition 5.1.5. Given an n-node graph G D .V; E/ where V D fv\n",
      "1\n",
      "; v\n",
      "2\n",
      "; : : : ; v\n",
      "n\n",
      "g, the adjacency matrix for G is the n n matrix A\n",
      "G\n",
      " D fa\n",
      "ij\n",
      " g where\n",
      "If G is a weighted graph with edge weights given by w W E ! R, then the adja-cency matrix for G is A\n",
      "G\n",
      " D fa\n",
      "ij\n",
      " g where\n",
      "For example, Figure \n",
      "displays the adjacency matrices for the graphs shown in Figures \n",
      "(a) and \n",
      "where v\n",
      "1\n",
      " D a, v\n",
      "2\n",
      " D b, v\n",
      "3\n",
      " D c, and v\n",
      "4\n",
      " D d .\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 128  #134\n",
      "\n",
      "128\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "\n",
      "5.2\n",
      "\t\n",
      "Matching Problems\n",
      "We begin our study of graph theory by considering the scenario where the nodes in a graph represent people and the edges represent a relationship between pairs of people such as likes, marries, and so on. Now, you may be wondering what marriage has to do with computer science, and with good reason. It turns out that the techniques we will develop apply to much more general scenarios where instead of matching men to women, we need to match packets to paths in a network, applicants to jobs, or Internet traffic to web servers. And, as we will describe later, these techniques are widely used in practice.\n",
      "In our first example, we will show how graph theory can be used to debunk an urban legend about sexual practices in America. Yes, you read correctly. So, fasten your seat beltwho knew that math might actually be interesting!\n",
      "5.2.1\n",
      "\t\n",
      "Sex in America\n",
      "On average, who has more opposite-gender partners: men or women?\n",
      "Sexual demographics have been the subject of many studies. In one of the largest, researchers from the University of Chicago interviewed a random sample of 2500 Americans over several years to try to get an answer to this question. Their study, published in 1994, and entitled The Social Organization of Sexuality found that, on average, men have 74% more opposite-gender partners than women.\n",
      "Other studies have found that the disparity is even larger. In particular, ABC News claimed that the average man has 20 partners over his lifetime, and the aver-age woman has 6, for a percentage disparity of 233%. The ABC News study, aired on Primetime Live in 2004, purported to be one of the most scientific ever done, with only a 2.5% margin of error. It was called American Sex Survey: A peek between the sheets. The promotion for the study is even better:\n",
      "A ground breaking ABC News Primetime Live survey finds a range of eye-popping sexual activities, fantasies and attitudes in this country, confirming some conventional wisdom, exploding some mythsand venturing where few scientific surveys have gone before.\n",
      "Probably that last part about going where few scientific surveys have gone before is pretty accurate!\n",
      "Yet again, in August, 2007, the N.Y. Times reported on a study by the National Center for Health Statistics of the U.S. Government showing that men had seven partners while women had four.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 129  #135\n",
      "\n",
      "Anyway, whose numbers do you think are more accurate, the University of Chicago, ABC News, or the National Center for Health Statistics?dont answer; this is a setup question like When did you stop beating your wife? Using a little graph theory, we will now explain why none of these findings can be anywhere near the truth.\n",
      "Lets model the question of heterosexual partners in graph theoretic terms. To do this, well let G be the graph whose vertices, V , are all the people in America. Then we split V into two separate subsets: M , which contains all the males, and F , which contains all the females.\n",
      "Well put an edge between a male and a female iff they have been sexual partners. A possible subgraph of this graph is illustrated in Figure \n",
      "with males on the left and females on the right.\n",
      "M\n",
      "\t\n",
      "W\n",
      "\n",
      "Figure 5.10\n",
      "\t\n",
      "A possible subgraph of the sex partners graph.\n",
      "Actually, G is a pretty hard graph to figure out, let alone draw. The graph is enormous: the US population is about 300 million, so jV j 300M . In the United States, approximately 50.8% of the populatin is female and 49.2% is male, and so jM j 147:6M , and jF j 152:4M . And we dont even have trustworthy estimates of how many edges there are, let alone exactly which couples are adja-cent. But it turns out that we dont need to know any of this to debunk the sex surveyswe just need to figure out the relationship between the average number of partners per male and partners per female. To do this, we note that every edge is incident to exactly one M vertex and one F vertex (remember, were only con-sidering male-female relationships); so the sum of the degrees of the M vertices equals the number of edges, and the sum of the degrees of the F vertices equals the\n",
      "\n",
      "For simplicity, well ignore the possibility of someone being both, or neither, a man and a woman.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 130  #136\n",
      "\n",
      "130\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "number of edges. So these sums are equal:\n",
      "X\n",
      "\t\n",
      "X\n",
      "deg.x/ D\n",
      "\t\n",
      "deg.y/:\n",
      "x2M\n",
      "\t\n",
      "y2F\n",
      "If we divide both sides of this equation by the product of the sizes of the two sets, jM j jF j, we obtain\n",
      "Notice that\n",
      "P\n",
      "x2M\n",
      " deg.x/\n",
      "\n",
      "jM j\n",
      "is simply the average degree of a node in M . This is the average number of opposite-gender partners for a male in America. Similarly,\n",
      "P\n",
      "x2F\n",
      " deg.x/\n",
      "\n",
      "jF j\n",
      "is the average degree of a node in F , which is the average number of opposite-gender partners for a female in America. Hence, Equation \n",
      "implies that on average, an American male has jF j=jM j times as many opposite-gender partners as the average American female.\n",
      "From the Census Bureau reports, we know that there are slightly more females than males in America; in particular jF j=jM j is about 1.035. So we know that on average, males have 3.5% more opposite-gender partners than females. Of course, this statistic really says nothing about any sexs promiscuity or selectivity. Remark-ably, promiscuity is completely irrelevant in this analysis. That is because the ratio of the average number of partners is completely determined by the relative number of males and females. Collectively, males and females have the same number of opposite gender partners, since it takes one of each set for every partnership, but there are fewer males, so they have a higher ratio. This means that the University of Chicago, ABC, and the Federal Government studies are way off. After a huge effort, they gave a totally wrong answer.\n",
      "Theres no definite explanation for why such surveys are consistently wrong. One hypothesis is that males exaggerate their number of partnersor maybe fe-males downplay theirsbut these explanations are speculative. Interestingly, the principal author of the National Center for Health Statistics study reported that she knew the results had to be wrong, but that was the data collected, and her job was to report it.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 131  #137\n",
      "\n",
      "The same underlying issue has led to serious misinterpretations of other survey data. For example, a few years ago, the Boston Globe ran a story on a survey of the study habits of students on Boston area campuses. Their survey showed that on average, minority students tended to study with non-minority students more than the other way around. They went on at great length to explain why this remarkable phenomenon might be true. But its not remarkable at allusing our graph theory formulation, we can see that all it says is that there are fewer minority students than non-minority students, which is, of course what minority means.\n",
      "The Handshaking Lemma\n",
      "The previous argument hinged on the connection between a sum of degrees and the number edges. There is a simple connection between these quantities in any graph:\n",
      "Lemma 5.2.1 (The Handshaking Lemma). The sum of the degrees of the vertices in a graph equals twice the number of edges.\n",
      "Proof. Every edge contributes two to the sum of the degrees, one for each of its\n",
      "endpoints.\n",
      "Lemma \n",
      "is called the Handshake Lemma because if we total up the number of people each person at a party shakes hands with, the total will be twice the number of handshakes that occurred.\n",
      "5.2.2\n",
      "\t\n",
      "Bipartite Matchings\n",
      "There were two kinds of vertices in the Sex in America graphmales and fe-males, and edges only went between the two kinds. Graphs like this come up so frequently that they have earned a special namethey are called bipartite graphs.\n",
      "Definition 5.2.2. A bipartite graph is a graph together with a partition of its vertices into two sets, L and R, such that every edge is incident to a vertex in L and to a vertex in R.\n",
      "The bipartite matching problem is related to the sex-in-America problem that we just studied; only now the goal is to get everyone happily married. As you might imagine, this is not possible for a variety of reasons, not the least of which is the fact that there are more women in America than men. So, it is simply not possible to marry every woman to a man so that every man is married only once.\n",
      "But what about getting a mate for every man so that every woman is married only once? Is it possible to do this so that each man is paired with a woman that he likes? The answer, of course, depends on the bipartite graph that represents who\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 132  #138\n",
      "\n",
      "132\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "\n",
      "Alice\n",
      "\n",
      "Chuck\n",
      "Tom\n",
      "\n",
      "\n",
      "\n",
      "Martha\n",
      "\n",
      "Sara\n",
      "Michael \n",
      "\n",
      "\n",
      "Jane\n",
      "John \n",
      "\n",
      "\n",
      "Mergatroid\n",
      "Figure 5.11 A graph where an edge between a man and woman denotes that the man likes the woman.\n",
      "likes who, but the good news is that it is possible to find natural properties of the who-likes-who graph that completely determine the answer to this question.\n",
      "In general, suppose that we have a set of men and an equal-sized or larger set of women, and there is a graph with an edge between a man and a woman if the man likes the woman. Note that in this scenario, the likes relationship need not be symmetric, since for the time being, we will only worry about finding a mate for each man that he likes.\n",
      "(Later, we will consider the likes relationship from the female perspective as well.) For example, we might obtain the graph in Figure \n",
      ".\n",
      "In this problem, a matching will mean a way of assigning every man to a woman so that different men are assigned to different women, and a man is always assigned to a woman that he likes. For example, one possible matching for the men is shown in Figure \n",
      ".\n",
      "The Matching Condition\n",
      "A famous result known as Halls Matching Theorem gives necessary and sufficient conditions for the existence of a matching in a bipartite graph. It turns out to be a remarkably useful mathematical tool.\n",
      "Well state and prove Halls Theorem using man-likes-woman terminology. De-fine the set of women liked by a given set of men to consist of all women liked by at least one of those men. For example, the set of women liked by Tom and John in\n",
      "\n",
      "7\n",
      "By the way, we do not mean to imply that marriage should or should not be of a heterosexual nature. Nor do we mean to imply that men should get their choice instead of women. Its just that with bipartite graphs, the edges only connected male nodes to female nodes and there are fewer men in America. So please dont take offense.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 133  #139\n",
      "\n",
      "\n",
      "Alice\n",
      "\n",
      "Chuck\n",
      "\n",
      "Martha\n",
      "Tom \n",
      "\n",
      "\n",
      "Sara\n",
      "Michael \n",
      "\n",
      "\n",
      "Jane\n",
      "John \n",
      "\n",
      "\n",
      "Mergatroid\n",
      "Figure 5.12 One possible matching for the men is shown with bold edges. For example, John is matched with Jane.\n",
      "Figure \n",
      "consists of Martha, Sarah, and Mergatroid. For us to have any chance at all of matching up the men, the following matching condition must hold:\n",
      "Every subset of men likes at least as large a set of women.\n",
      "For example, we can not find a matching if some set of 4 men like only 3 women. Halls Theorem says that this necessary condition is actually sufficient; if the match-ing condition holds, then a matching exists.\n",
      "Theorem 5.2.3. A matching for a set of men M with a set of women W can be found if and only if the matching condition holds.\n",
      "Proof. First, lets suppose that a matching exists and show that the matching condi-tion holds. Consider an arbitrary subset of men. Each man likes at least the woman he is matched with. Therefore, every subset of men likes at least as large a set of women. Thus, the matching condition holds.\n",
      "Next, lets suppose that the matching condition holds and show that a matching exists. We use strong induction on jM j, the number of men, on the predicate:\n",
      "P .m/ WWD for any set of m men M , if the matching condition holds\n",
      "for M , then there is a matching for M .\n",
      "Base Case (jM j D 1): If jM j D 1, then the matching condition implies that the lone man likes at least one woman, and so a matching exists.\n",
      "Inductive Step: We need to show that P .m/ \n",
      "IMPLIES\n",
      " P .m C 1/. Suppose that jM j D m C 1 2.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 134  #140\n",
      "\n",
      "134\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "Case 1: Every proper subset\n",
      "of men likes a strictly larger set of women. In this case, we have some latitude: we pair an arbitrary man with a woman he likes and send them both away. The matching condition still holds for the remaining men and women since we have removed only one woman, so we can match the rest of the men by induction.\n",
      "Case 2: Some proper subset of men X\n",
      "\t\n",
      "M likes an equal-size set of women\n",
      "W . We match the men in X with the women in Y by induction and send them all away. We can also match the rest of the men by induction if we show that the matching condition holds for the remaining men and women. To check the matching condition for the remaining people, consider\n",
      "an arbitrary subset of the remaining men X\n",
      "0\n",
      " .M X/, and let Y \n",
      "0\n",
      " be the set of remaining women that they like. We must show that jX\n",
      "0\n",
      "j jY \n",
      "0\n",
      "j. Originally, the combined set of men X [ X\n",
      "0\n",
      " liked the set of women Y [ Y \n",
      "0\n",
      ". So, by the matching condition, we know:\n",
      "jX [ X\n",
      "0\n",
      "j\tjY [ Y \n",
      "0\n",
      "j\n",
      "We sent away jX j men from the set on the left (leaving X\n",
      "0\n",
      ") and sent away an equal number of women from the set on the right (leaving Y \n",
      "0\n",
      "). Therefore, it must be that jX\n",
      "0\n",
      "j jY \n",
      "0\n",
      "j as claimed.\n",
      "So in both cases, there is a matching for the men, which completes the proof of\n",
      "the Inductive step. The theorem follows by induction.\n",
      "The proof of Theorem \n",
      "gives an algorithm for finding a matching in a bipar-tite graph, albeit not a very efficient one. However, efficient algorithms for finding a matching in a bipartite graph do exist. Thus, if a problem can be reduced to finding a matching, the problem can be solved from a computational perspective.\n",
      "A Formal Statement\n",
      "Lets restate Theorem \n",
      "in abstract terms so that youll not always be con-demned to saying, Now this group of men likes at least as many women. . . \n",
      "Definition 5.2.4. A matching in a graph, G, is a set of edges such that no two edges in the set share a vertex. A matching is said to cover a set, L, of vertices iff each vertex in L has an edge of the matching incident to it. A matching is said to be perfect if every node in the graph is incident to an edge in the matching. In any graph, the set N.S/, of neighbors of some set, S, of vertices is the set of all vertices adjacent to some vertex in S. That is,\n",
      "N.S/ WWD f r j fs; rg is an edge for some s 2 S g:\n",
      "\n",
      "8\n",
      "Recall that a subset A of B is proper if A  B.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 135  #141\n",
      "\n",
      "is called a bottleneck if\n",
      "jSj > jN.S/j:\n",
      "Theorem 5.2.5 (Halls Theorem). Let G be a bipartite graph with vertex partition L; R. There is matching in G that covers L iff no subset of L is a bottleneck.\n",
      "An Easy Matching Condition\n",
      "The bipartite matching condition requires that every subset of men has a certain property. In general, verifying that every subset has some property, even if its easy to check any particular subset for the property, quickly becomes overwhelming because the number of subsets of even relatively small sets is enormousover a billion subsets for a set of size 30. However, there is a simple property of vertex degrees in a bipartite graph that guarantees the existence of a matching. Namely, call a bipartite graph degree-constrained if vertex degrees on the left are at least as large as those on the right. More precisely,\n",
      "Definition 5.2.6. A bipartite graph G with vertex partition L, R where jLj jRj is degree-constrained if deg.l/ deg.r/ for every l 2 L and r 2 R.\n",
      "For example, the graph in Figure \n",
      "is degree constrained since every node on the left is adjacent to at least two nodes on the right while every node on the right is incident to at most two nodes on the left.\n",
      "Theorem 5.2.7. Let G be a bipartite graph with vertex partition L, R where jLj jRj. If G is degree-constrained, then there is a matching that covers L.\n",
      "Proof. The proof is by contradiction. Suppose that G is degree constrained but that there is no matching that covers L. By Theorem \n",
      ", this means that there must be a bottleneck S L.\n",
      "Let d be a value such that deg.l/ x deg.r/ for every l 2 L and r 2 R. Since every edge incident to a node in S is incident to a node in N.S/, we know that\n",
      "jN.S/jx\tjSjx\n",
      "and thus that\n",
      "jN.S/j\tjSj:\n",
      "This means that S is not a bottleneck, which is a contradiction. Hence G has a\n",
      "matching that covers L.\n",
      "Regular graphs provide a large class of graphs that often arise in practice that are degree constrained. Hence, we can use Theorem \n",
      "to prove that every regular bipartite graph has a perfect matching. This turns out to be a surprisingly useful result in computer science\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 136  #142\n",
      "\n",
      "136\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "Definition 5.2.8. A graph is said to be regular if every node has the same degree.\n",
      "Theorem 5.2.9. Every regular bipartite graph has a perfect matching.\n",
      "Proof. Let G be a regular bipartite graph with vertex partition L, R where jLj jRj. Since regular graphs are degree-constrained, we know by Theorem \n",
      "that there must be a matching in G that covers L. Since G is regular, we also know that jLj D jRj and thus the matching must also cover R. This means that every node in G is incident to an edge in the matching and thus G has a perfect matching.\n",
      "5.2.3\n",
      "\t\n",
      "The Stable Marriage Problem\n",
      "We next consider a version of the bipartite matching problem where there are an equal number of men and women, and where each person has preferences about who they would like to marry. In fact, we assume that each man has a complete list of all the women ranked according to his preferences, with no ties. Likewise, each woman has a ranked list of all of the men.\n",
      "The preferences dont have to be symmetric. That is, Jennifer might like Brad best, but Brad doesnt necessarily like Jennifer best. The goal is to marry everyone: every man must marry exactly one woman and vice-versano polygamy. More-over, we would like to find a matching between men and women that is stable in the sense that there is no pair of people that prefer each other to their spouses.\n",
      "For example, suppose every man likes Angelina best, and every woman likes Brad best, but Brad and Angelina are married to other people, say Jennifer and Billy Bob. Now Brad and Angelina prefer each other to their spouses, which puts their marriages at risk: pretty soon, theyre likely to start spending late nights together working on problem sets!\n",
      "This unfortunate situation is illustrated in Figure \n",
      ", where the digits 1 and 2 near a man shows which of the two women he ranks first second, respectively, and similarly for the women.\n",
      "More generally, in any matching, a man and woman who are not married to each other and who like each other better than their spouses, is called a rogue couple. In the situation shown in Figure \n",
      ", Brad and Angelina would be a rogue couple.\n",
      "Having a rogue couple is not a good thing, since it threatens the stability of the marriages. On the other hand, if there are no rogue couples, then for any man and woman who are not married to each other, at least one likes their spouse better than the other, and so they wont be tempted to start an affair.\n",
      "Definition 5.2.10. A stable matching is a matching with no rogue couples.\n",
      "The question is, given everybodys preferences, how do you find a stable set of marriages? In the example consisting solely of the four people in Figure \n",
      ", we\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 137  #143\n",
      "\n",
      "5.2. Matching Problems\n",
      "\t\n",
      "137\n",
      "Brad \n",
      "\n",
      " 2\n",
      "\t\n",
      "1 \n",
      "\n",
      " Jennifer\n",
      "\n",
      "2\n",
      "1\n",
      "Billy Bob \n",
      "\n",
      " 1\n",
      "\t\n",
      "2 \n",
      "\n",
      " Angelina\n",
      "Figure 5.13 Preferences for four people. Both men like Angelina best and both women like Brad best.\n",
      "could let Brad and Angelina both have their first choices by marrying each other. Now neither Brad nor Angelina prefers anybody else to their spouse, so neither will be in a rogue couple. This leaves Jen not-so-happily married to Billy Bob, but neither Jen nor Billy Bob can entice somebody else to marry them, and so there is a stable matching.\n",
      "Surprisingly, there is always a stable matching among a group of men and women. The surprise springs in part from considering the apparently similar buddy match-ing problem. That is, if people can be paired off as buddies, regardless of gender, then a stable matching may not be possible. For example, Figure \n",
      "shows a situ-ation with a love triangle and a fourth person who is everyones last choice. In this figure Mergatroids preferences arent shown because they dont even matter. Lets see why there is no stable matching.\n",
      "\n",
      "Mergatroid\n",
      "Figure 5.14\n",
      "\t\n",
      "Some preferences with no stable buddy matching.\n",
      "Lemma 5.2.11. There is no stable buddy matching among the four people in Fig-ure \n",
      ".\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 138  #144\n",
      "\n",
      "So getting a stable buddy matching may not only be hard, it may be impossible. But when mens are only allowed to marry women, and vice versa, then it turns out that a stable matching can always be found.\n",
      "The Mating Ritual\n",
      "The procedure for finding a stable matching involves a Mating Ritual that takes place over several days. The following events happen each day:\n",
      "Morning: Each woman stands on her balcony. Each man stands under the bal-cony of his favorite among the women on his list, and he serenades her. If a man has no women left on his list, he stays home and does his math homework.\n",
      "Afternoon: Each woman who has one or more suitors serenading her, says to her favorite among them, We might get engaged. Come back tomorrow. To the other suitors, she says, No. I will never marry you! Take a hike!\n",
      "Evening: Any man who is told by a woman to take a hike, crosses that woman off his list.\n",
      "Termination condition: When a day arrives in which every woman has at most one suitor, the ritual ends with each woman marrying her suitor, if she has one.\n",
      "There are a number of facts about this Mating Ritual that we would like to prove:\n",
      "The Ritual eventually reaches the termination condition.\n",
      "Everybody ends up married.\n",
      "The resulting marriages are stable.\n",
      "There is a Marriage Day\n",
      "Its easy to see why the Mating Ritual has a terminal day when people finally get married. Every day on which the ritual hasnt terminated, at least one man crosses a woman off his list. (If the ritual hasnt terminated, there must be some woman serenaded by at least two men, and at least one of them will have to cross her off his\n",
      "\n",
      "Once again, we disclaim any political statement hereits just the way that the math works out.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 139  #145\n",
      "\n",
      "list). If we start with n men and n women, then each of the n mens lists initially has n women on it, for a total of n\n",
      "2\n",
      " list entries. Since no women ever gets added to a list, the total number of entries on the lists decreases every day that the Ritual continues, and so the Ritual can continue for at most n\n",
      "2\n",
      " days.\n",
      "They All Live Happily Every After. . .\n",
      "We still have to prove that the Mating Ritual leaves everyone in a stable marriage. To do this, we note one very useful fact about the Ritual: if a woman has a favorite suitor on some morning of the Ritual, then that favorite suitor will still be serenad-ing her the next morningbecause his list wont have changed. So she is sure to have todays favorite man among her suitors tomorrow. That means she will be able to choose a favorite suitor tomorrow who is at least as desirable to her as todays favorite. So day by day, her favorite suitor can stay the same or get better, never worse. This sounds like an invariant, and it is.\n",
      "Definition 5.2.12. Let P be the predicate: For every woman, w, and every man, m, if w is crossed off ms list, then w has a suitor whom she prefers over m.\n",
      "Lemma 5.2.13. P is an invariant for The Mating Ritual.\n",
      "Proof. By induction on the number of days.\n",
      "Base Case: In the beginning (that is, at the end of day 0), every woman is on every listno one has been crossed off and so P is vacuously true.\n",
      "Inductive Step: Assume P is true at the end of day d and let w be a woman that has been crossed off a man ms list by the end of day d C 1.\n",
      "Case 1: w was crossed off ms list on day d C 1. Then, w must have a suitor she prefers on day d C 1.\n",
      "Case 2: w was crossed off ms list prior to day d C1. Since P is true at the end of day d , this means that w has a suitor she prefers to m on day d . She therefore has the same suitor or someone she prefers better at the end of day d C 1.\n",
      "In both cases, P is true at the end of day d C 1 and so P must be an invariant.\n",
      "With Lemma \n",
      "in hand, we can now prove:\n",
      "Theorem 5.2.14. Everyone is married by the Mating Ritual.\n",
      "Proof. By contradiction. Assume that it is the last day of the Mating Ritual and someone does not get married. Since there are an equal number of men and women,\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 140  #146\n",
      "\n",
      "140\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "and since bigamy is not allowed, this means that at least one man (call him Bob) and at least one woman do not get married.\n",
      "Since Bob is not married, he cant be serenading anybody and so his list must be empty. This means that Bob has crossed every woman off his list and so, by invariant P , every woman has a suitor whom she prefers to Bob. Since it is the last day and every woman still has a suitor, this means that every woman gets married. This is a contradiction since we already argued that at least one woman is not married. Hence our assumption must be false and so everyone must be married.\n",
      "Theorem 5.2.15. The Mating Ritual produces a stable matching.\n",
      "Proof. Let Brad and Jen be any man and woman, respectively, that are not married to each other on the last day of the Mating Ritual. We will prove that Brad and Jen are not a rogue couple, and thus that all marriages on the last day are stable. There are two cases to consider.\n",
      "Case 1: Jen is not on Brads list by the end. Then by invariant P , we know that Jen has a suitor (and hence a husband) that she prefers to Brad. So shes not going to run off with BradBrad and Jen cannot be a rogue couple.\n",
      "Case 2: Jen is on Brads list. But since Brad is not married to Jen, he must be choosing to serenade his wife instead of Jen, so he must prefer his wife. So hes not going to run off with Jenonce again, Brad and Jenn are not a rogue\n",
      "couple.\n",
      ". . . Especially the Men\n",
      "Who is favored by the Mating Ritual, the men or the women? The women seem to have all the power: they stand on their balconies choosing the finest among their suitors and spurning the rest. Whats more, we know their suitors can only change for the better as the Ritual progresses. Similarly, a man keeps serenading the woman he most prefers among those on his list until he must cross her off, at which point he serenades the next most preferred woman on his list. So from the mans perspective, the woman he is serenading can only change for the worse. Sounds like a good deal for the women.\n",
      "But its not! The fact is that from the beginning, the men are serenading their first choice woman, and the desirability of the woman being serenaded decreases only enough to ensure overall stability. The Mating Ritual actually does as well as possible for all the men and does the worst possible job for the women.\n",
      "To explain all this we need some definitions. Lets begin by observing that while The Mating Ritual produces one stable matching, there may be other stable match-ings among the same set of men and women. For example, reversing the roles of men and women will often yield a different stable matching among them.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 141  #147\n",
      "\n",
      "But some spouses might be out of the question in all possible stable matchings. For example, given the preferences shown in Figure \n",
      ", Brad is just not in the realm of possibility for Jennifer, since if you ever pair them, Brad and Angelina will form a rogue couple.\n",
      "Definition 5.2.16. Given a set of preference lists for all men and women, one per-son is in another persons realm of possible spouses if there is a stable matching in which the two people are married. A persons optimal spouse is their most pre-ferred person within their realm of possibility. A persons pessimal spouse is their least preferred person in their realm of possibility.\n",
      "Everybody has an optimal and a pessimal spouse, since we know there is at least one stable matching, namely, the one produced by the Mating Ritual. Now here is the shocking truth about the Mating Ritual:\n",
      "Theorem 5.2.17. The Mating Ritual marries every man to his optimal spouse.\n",
      "Proof. By contradiction. Assume for the purpose of contradiction that some man does not get his optimal spouse. Then there must have been a day when he crossed off his optimal spouseotherwise he would still be serenading (and would ulti-mately marry) her or some even more desirable woman.\n",
      "By the Well Ordering Principle, there must be a first day when a man (call him Keith) crosses off his optimal spouse (call her Nicole). According to the rules of the Ritual, Keith crosses off Nicole because Nicole has a preferred suitor (call him Tom), so\n",
      "Nicole prefers Tom to Keith.\n",
      "\t\n",
      "( )\n",
      "Since this is the first day an optimal woman gets crossed off, we know that Tom had not previously crossed off his optimal spouse, and so\n",
      "Tom ranks Nicole at least as high as his optimal spouse.\n",
      "\t\n",
      "(\t)\n",
      "By the definition of an optimal spouse, there must be some stable set of marriages in which Keith gets his optimal spouse, Nicole. But then the preferences given in ( ) and ( ) imply that Nicole and Tom are a rogue couple within this supposedly\n",
      "stable set of marriages (think about it). This is a contradiction.\n",
      "Theorem 5.2.18. The Mating Ritual marries every woman to her pessimal spouse.\n",
      "Proof. By contradiction. Assume that the theorem is not true. Hence there must be a stable set of marriages M where some woman (call her Nicole) is married to a man (call him Tom) that she likes less than her spouse in The Mating Ritual (call him Keith). This means that\n",
      "Nicole prefers Keith to Tom.\n",
      "\t\n",
      "(+)\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 142  #148\n",
      "\n",
      "142\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "By Theorem \n",
      "and the fact that Nicole and Keith are married in the Mating Ritual, we know that\n",
      "Keith prefers Nicole to his spouse in M.\n",
      "\t\n",
      "(++)\n",
      "This means that Keith and Nicole form a rogue couple in M, which contradicts the\n",
      "stability of M.\n",
      "Applications\n",
      "The Mating Ritual was first announced in a paper by D. Gale and L.S. Shapley in 1962, but ten years before the Gale-Shapley paper was published, and unknown by them, a similar algorithm was being used to assign residents to hospitals by the National Resident Matching Program (NRMP)\n",
      ". The NRMP has, since the turn of the twentieth century, assigned each years pool of medical school graduates to hospital residencies (formerly called internships) with hospitals and graduates playing the roles of men and women. (In this case, there may be multiple women married to one man, a scenario we consider in the problem section at the end of the chapter.). Before the Ritual-like algorithm was adopted, there were chronic disrup-tions and awkward countermeasures taken to preserve assignments of graduates to residencies. The Ritual resolved these problems so successfully, that it was used essentially without change at least through 1989.\n",
      "The Internet infrastructure company, Akamai, also uses a variation of the Mating Ritual to assign web traffic to its servers. In the early days, Akamai used other com-binatorial optimization algorithms that got to be too slow as the number of servers (over 65,000 in 2010) and requests (over 800 billion per day) increased. Akamai switched to a Ritual-like approach since it is fast and can be run in a distributed manner. In this case, web requests correspond to women and web servers corre-spond to men. The web requests have preferences based on latency and packet loss, and the web servers have preferences based on cost of bandwidth and collocation.\n",
      "Not surprisingly, the Mating Ritual is also used by at least one large online dating agency. Even here, there is no serenading going oneverything is handled by computer.\n",
      "\n",
      "Of course, there is no serenading going on in the hospitalsthe preferences are submitted to a program and the whole process is carried out by a computer.\n",
      "Much more about the Stable Marriage Problem can be found in the very readable mathematical monograph by Dan Gusfield and Robert W. Irving, \n",
      " \n",
      ",\n",
      " \n",
      "MIT Press, Cambridge, Massachusetts, 1989, 240 pp.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 143  #149\n",
      "\n",
      "6:170\n",
      "\n",
      "6:002\n",
      "\t\n",
      "6:003\n",
      "6:041           \n",
      "\n",
      " 6:042\n",
      "Figure 5.15 A scheduling graph for five exams. Exams connected by an edge cannot be given at the same time.\n",
      "\n",
      "5.3\tColoring\n",
      "In Section \n",
      ", we used edges to indicate an affinity between a pair of nodes. We now consider situations where it is useful to use edges to represent a conflict be-tween a pair of nodes. For example, consider the following exam scheduling prob-lem.\n",
      "5.3.1\n",
      "\t\n",
      "An Exam Scheduling Problem\n",
      "Each term, the MIT Schedules Office must assign a time slot for each final exam. This is not easy, because some students are taking several classes with finals, and (even at MIT) a student can take only one test during a particular time slot. The Schedules Office wants to avoid all conflicts. Of course, you can make such a schedule by having every exam in a different slot, but then you would need hun-dreds of slots for the hundreds of courses, and the exam period would run all year! So, the Schedules Office would also like to keep exam period short.\n",
      "The Schedules Offices problem is easy to describe as a graph. There will be a vertex for each course with a final exam, and two vertices will be adjacent exactly when some student is taking both courses. For example, suppose we need to sched-ule exams for 6.041, 6.042, 6.002, 6.003 and 6.170. The scheduling graph might appear as in Figure \n",
      ".\n",
      "6.002 and 6.042 cannot have an exam at the same time since there are students in both courses, so there is an edge between their nodes. On the other hand, 6.042 and 6.170 can have an exam at the same time if theyre taught at the same time (which they sometimes are), since no student can be enrolled in both (that is, no student should be enrolled in both when they have a timing conflict).\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 144  #150\n",
      "\n",
      "144\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "blue\n",
      "\n",
      "red\n",
      "\t\n",
      "green\n",
      "green \n",
      "\n",
      " blue\n",
      "Figure 5.16\n",
      "\t\n",
      "A 3-coloring of the exam graph from Figure \n",
      ".\n",
      "We next identify each time slot with a color. For example, Monday morning is red, Monday afternoon is blue, Tuesday morning is green, etc. Assigning an exam to a time slot is then equivalent to coloring the corresponding vertex. The main constraint is that adjacent vertices must get different colorsotherwise, some student has two exams at the same time. Furthermore, in order to keep the exam period short, we should try to color all the vertices using as few different colors as possible. As shown in Figure \n",
      ", three colors suffice for our example.\n",
      "The coloring in Figure \n",
      "corresponds to giving one final on Monday morning (red), two Monday afternoon (blue), and two Tuesday morning (green). Can we use fewer than three colors? No! We cant use only two colors since there is a triangle in the graph, and three vertices in a triangle must all have different colors.\n",
      "This is an example of a graph coloring problem: given a graph G, assign colors to each node such that adjacent nodes have different colors. A color assignment with this property is called a valid coloring of the grapha coloring, for short. A graph G is k-colorable if it has a coloring that uses at most k colors.\n",
      "Definition 5.3.1. The minimum value of k for which a graph G has a valid k-coloring is called its chromatic number, .G/.\n",
      "In general, trying to figure out if you can color a graph with a fixed number of colors can take a long time. Its a classic example of a problem for which no fast algorithms are known. It is easy to check if a coloring works, but it seems really hard to find it. (If you figure out how, then you can get a $1 million Clay prize.)\n",
      "5.3.2\n",
      "\t\n",
      "Degree-Bounded Coloring\n",
      "There are some simple graph properties that give useful upper bounds on the chro-matic number. For example, if the graph is bipartite, then we can color it with 2 colors (one color for the nodes in the left set and a second color for the nodes\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 145  #151\n",
      "\n",
      "in the right set). In fact, if the graph has any edges at all, then being bipartite is equivalent to being 2-colorable.\n",
      "Alternatively, if the graph is planar, then the famous 4-Color Theorem says that the graph is 4-colorable. This is a hard result to prove, but we will come close in Section \n",
      "where we define planar graphs and prove that they are 5-colorable.\n",
      "The chromatic number of a graph can also be shown to be small if the vertex degrees of the graph are small. In particular, if we have an upper bound on the degrees of all the vertices in a graph, then we can easily find a coloring with only one more color than the degree bound.\n",
      "Theorem 5.3.2. A graph with maximum degree at most k is .k C 1/-colorable.\n",
      "The natural way to try to prove this theorem is to use induction on k. Unfor-tunately, this approach leads to disaster. It is not that it is impossible, just that it is extremely painful and would ruin your week if you tried it on an exam. When you encounter such a disaster when using induction on graphs, it is usually best to change what you are inducting on. In graphs, typical good choices for the induction parameter are n, the number of nodes, or e, the number of edges.\n",
      "Proof of Theorem \n",
      ". We use induction on the number of vertices in the graph, which we denote by n. Let P .n/ be the proposition that an n-vertex graph with maximum degree at most k is .k C 1/-colorable.\n",
      "Base case (n D 1): A 1-vertex graph has maximum degree 0 and is 1-colorable, so P .1/ is true.\n",
      "Inductive step: Now assume that P .n/ is true, and let G be an .nC1/-vertex graph with maximum degree at most k. Remove a vertex v (and all edges incident to it), leaving an n-vertex subgraph, H . The maximum degree of H is at most k, and so\n",
      "is .k C 1/-colorable by our assumption P .n/. Now add back vertex v. We can assign v a color (from the set of k C 1 colors) that is different from all its adjacent vertices, since there are at most k vertices adjacent to v and so at least one of the k C 1 colors is still available. Therefore, G is .k C 1/-colorable. This completes\n",
      "the inductive step, and the theorem follows by induction.\n",
      "Sometimes k C 1 colors is the best you can do. For example, in the complete graph, K\n",
      "n\n",
      ", every one of its n vertices is adjacent to all the others, so all n must be assigned different colors. Of course n colors is also enough, so .K\n",
      "n\n",
      "/ D n. In this case, every node has degree k D n 1 and so this is an example where Theo-rem \n",
      "gives the best possible bound. By a similar argument, we can show that Theorem \n",
      "gives the best possible bound for any graph with degree bounded by\n",
      "that has K\n",
      "kC1\n",
      " as a subgraph.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 146  #152\n",
      "\n",
      "146\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "\n",
      "Figure 5.17\n",
      "\t\n",
      "A 7-node star graph.\n",
      "But sometimes k C 1 colors is far from the best that you can do. For example, the n-node star graph shown in Figure \n",
      "has maximum degree n 1 but can be colored using just 2 colors.\n",
      "5.3.3\n",
      "\t\n",
      "Why coloring?\n",
      "One reason coloring problems frequently arise in practice is because scheduling conflicts are so common. For example, at Akamai, a new version of software is deployed over each of 75,000 servers every few days. The updates cannot be done at the same time since the servers need to be taken down in order to deploy the software. Also, the servers cannot be handled one at a time, since it would take forever to update them all (each one takes about an hour). Moreover, certain pairs of servers cannot be taken down at the same time since they have common critical functions. This problem was eventually solved by making a 75,000-node conflict graph and coloring it with 8 colorsso only 8 waves of install are needed!\n",
      "Another example comes from the need to assign frequencies to radio stations. If two stations have an overlap in their broadcast area, they cant be given the same frequency. Frequencies are precious and expensive, so you want to minimize the number handed out. This amounts to finding the minimum coloring for a graph whose vertices are the stations and whose edges connect stations with overlapping areas.\n",
      "Coloring also comes up in allocating registers for program variables. While a variable is in use, its value needs to be saved in a register. Registers can be reused for different variables but two variables need different registers if they are refer-enced during overlapping intervals of program execution. So register allocation is the coloring problem for a graph whose vertices are the variables; vertices are ad-jacent if their intervals overlap, and the colors are registers. Once again, the goal is to minimize the number of colors needed to color the graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finally, theres the famous map coloring problem stated in Proposition \n",
      ". The question is how many colors are needed to color a map so that adjacent ter-\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 147  #153\n",
      "\n",
      "ritories get different colors? This is the same as the number of colors needed to color a graph that can be drawn in the plane without edges crossing. A proof that four colors are enough for planar graphs was acclaimed when it was discovered about thirty years ago. Implicit in that proof was a 4-coloring procedure that takes time proportional to the number of vertices in the graph (countries in the map). Surprisingly, its another of those million dollar prize questions to find an efficient procedure to tell if a planar graph really needs four colors or if three will actually do the job. (Its always easy to tell if an arbitrary graph is 2-colorable.) In Sec-tion \n",
      ", well develop enough planar graph theory to present an easy proof that all planar graphs are 5-colorable.\n",
      "\n",
      "5.4\tGetting from A to B in a Graph\n",
      "5.4.1\n",
      "\t\n",
      "Paths and Walks\n",
      "Definition 5.4.1. A walk\n",
      "in a graph, G, is a sequence of vertices\n",
      "v\n",
      "0\n",
      "; v\n",
      "1\n",
      "; : : : ; v\n",
      "k\n",
      "and edges\n",
      "fv\n",
      "0\n",
      "; v\n",
      "1\n",
      "g; fv\n",
      "1\n",
      "; v\n",
      "2\n",
      "g; : : : ; fv\n",
      "k1\n",
      "  ; v\n",
      "k\n",
      "g\n",
      "such that fv\n",
      "i\n",
      " ; v\n",
      "iC1\n",
      "g is an edge of G for all i where 0 i < k . The walk is said to start at v\n",
      "0\n",
      " and to end at v\n",
      "k\n",
      ", and the length of the walk is defined to be k. An edge, fu; vg, is traversed n times by the walk if there are n different values of i such that fv\n",
      "i\n",
      " ; v\n",
      "iC1\n",
      "g D fu; vg. A path is a walk where all the v\n",
      "i\n",
      " s are different, that is, i  j implies v\n",
      "i\n",
      "  v\n",
      "j\n",
      " . For simplicity, we will refer to paths and walks by the sequence of vertices.\n",
      "For example, the graph in Figure \n",
      "has a length 6 path a, b, c, d , e, f , g. This is the longest path in the graph. Of course, the graph has walks with arbitrarily large lengths; for example, a, b, a, b, a, b, . . . .\n",
      "The length of a walk or path is the total number of times it traverses edges, which is one less than its length as a sequence of vertices. For example, the length 6 path a, b, c, d , e, f , g contains a sequence of 7 vertices.\n",
      "\n",
      "12\n",
      "Some texts use the word path for our definition of walk and the term simple path for our definition of path.\n",
      "This works fine for simple graphs since the edges in a walk are completely determined by the sequence of vertices and there is no ambiguity. For graphs with multiple edges, we would need to specify the edges as well as the nodes.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 148  #154\n",
      "\n",
      "148\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "b\n",
      "\t\n",
      "d\n",
      "\t\n",
      "e\n",
      "\n",
      "c\n",
      "a\n",
      "\t\n",
      "g\n",
      "\t\n",
      "h\n",
      "f\n",
      "Figure 5.18\n",
      "\t\n",
      "A graph containing a path a, b, c, d , e, f , g of length 6.\n",
      "5.4.2\n",
      "\t\n",
      "Finding a Path\n",
      "Where theres a walk, theres a path. This is sort of obvious, but its easy enough to prove rigorously using the Well Ordering Principle.\n",
      "Lemma 5.4.2. If there is a walk from a vertex u to a vertex v in a graph, then there is a path from u to v.\n",
      "Proof. Since there is a walk from u to v, there must, by the Well-ordering Principle, be a minimum length walk from u to v. If the minimum length is zero or one, this minimum length walk is itself a path from u to v. Otherwise, there is a minimum length walk\n",
      "v\n",
      "0\n",
      "; v\n",
      "1\n",
      "; : : : ; v\n",
      "k\n",
      "from u D v\n",
      "0\n",
      " to v D v\n",
      "k\n",
      " where k 2. We claim this walk must be a path. To prove the claim, suppose to the contrary that the walk is not a path; that is, some vertex on the walk occurs twice. This means that there are integers i; j such that 0 i < j k with v\n",
      "i\n",
      " D v\n",
      "j\n",
      " . Then deleting the subsequence\n",
      "v\n",
      "iC1\n",
      "; : : : ; v\n",
      "j\n",
      "yields a strictly shorter walk\n",
      "v\n",
      "0\n",
      "; v\n",
      "1\n",
      "; : : : ; v\n",
      "i\n",
      " ; v\n",
      "j\n",
      " \n",
      "C1\n",
      "; v\n",
      "j\n",
      " \n",
      "C2\n",
      "; : : : ; v\n",
      "k\n",
      "from u to v, contradicting the minimality of the given walk.\n",
      "Actually, we proved something stronger:\n",
      "Corollary 5.4.3. For any walk of length k in a graph, there is a path of length at most k with the same endpoints. Moreover, the shortest walk between a pair of vertices is, in fact, a path.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 149  #155\n",
      "\n",
      "v\n",
      "1\n",
      "\n",
      "v\n",
      "2\n",
      "\n",
      "v\n",
      "4\n",
      "\n",
      "v\n",
      "3\n",
      "Figure 5.19 A graph for which there are 5 walks of length 3 from v\n",
      "1\n",
      " to v\n",
      "4\n",
      ". The walks are .v\n",
      "1\n",
      "; v\n",
      "2\n",
      "; v\n",
      "1\n",
      "; v\n",
      "4\n",
      "/, .v\n",
      "1\n",
      "; v\n",
      "3\n",
      "; v\n",
      "1\n",
      "; v\n",
      "4\n",
      "/, .v\n",
      "1\n",
      "; v\n",
      "4\n",
      "; v\n",
      "1\n",
      "; v\n",
      "4\n",
      "/, .v\n",
      "1\n",
      "; v\n",
      "2\n",
      "; v\n",
      "3\n",
      "; v\n",
      "4\n",
      "/, and .v\n",
      "1\n",
      "; v\n",
      "4\n",
      "; v\n",
      "3\n",
      "; v\n",
      "4\n",
      "/.\n",
      "5.4.3\n",
      "\t\n",
      "Numbers of Walks\n",
      "Given a pair of nodes that are connected by a walk of length k in a graph, there are often many walks that can be used to get from one node to the other. For example, there are 5 walks of length 3 that start at v\n",
      "1\n",
      " and end at v\n",
      "4\n",
      " in the graph shown in Figure \n",
      ".\n",
      "There is a surprising relationship between the number of walks of length k be-tween a pair of nodes in a graph G and the kth power of the adjacency matrix A\n",
      "G\n",
      " for G. The relationship is captured in the following theorem.\n",
      "Theorem 5.4.4. Let G D .V; E/ be an n-node graph with V D fv\n",
      "1\n",
      "; v\n",
      "2\n",
      "; : : : ; v\n",
      "n\n",
      "g and let A\n",
      "G\n",
      " D fa\n",
      "ij\n",
      " g denote the adjacency matrix for G. Let a\n",
      "ij\n",
      ".k/\n",
      " denote the .i; j /-entry of the kth power of A\n",
      "G\n",
      ". Then the number of walks of length k between v\n",
      "i\n",
      " and v\n",
      "j\n",
      " is a\n",
      "ij\n",
      ".k/\n",
      ".\n",
      "In other words, we can determine the number of walks of length k between any pair of nodes simply by computing the kth power of the adjacency matrix! Thats pretty amazing.\n",
      "For example, the first three powers of the adjacency matrix for the graph in Fig-\n",
      "Sure enough, the .1; 4/ coordinate of A\n",
      "3\n",
      " is a\n",
      "14\n",
      ".3/\n",
      " D 5, which is the number of length 3 walks from v\n",
      "1\n",
      " to v\n",
      "4\n",
      ". And a\n",
      "24\n",
      ".3/\n",
      " D 2, which is the number of length 3 walks from v\n",
      "2\n",
      " to v\n",
      "4\n",
      ". By proving the theorem, well discover why it is true and thereby uncover the relationship between matrix multiplication and numbers of walks.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 150  #156\n",
      "\n",
      "150\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "Proof of Theorem \n",
      ". The proof is by induction on \n",
      "k\n",
      ". We will let \n",
      "P .k/\n",
      " be the predicate that the theorem is true for \n",
      "k\n",
      ". Let \n",
      "P\n",
      "ij\n",
      ".k/\n",
      " denote the number of walks of length \n",
      "k\n",
      " between \n",
      "v\n",
      "i\n",
      " and \n",
      "v\n",
      "j\n",
      " . Then \n",
      "P .k/\n",
      " is the predicate\n",
      "Base Case (\n",
      "k\n",
      " D \n",
      "1\n",
      "): There are two cases to consider:\n",
      "Case 1: f\n",
      "v\n",
      "i\n",
      " \n",
      "; v\n",
      "j\n",
      " g 2 \n",
      "E\n",
      ". Then \n",
      "P\n",
      "ij\n",
      ".1/\n",
      " D \n",
      "1\n",
      " since there is precisely one walk of length 1 between \n",
      "v\n",
      "i\n",
      " and \n",
      "v\n",
      "j\n",
      " . Moreover, f\n",
      "v\n",
      "i\n",
      " \n",
      "; v\n",
      "j\n",
      " g 2 \n",
      "E\n",
      " means that \n",
      "a\n",
      "ij\n",
      ".1/\n",
      " D \n",
      "a\n",
      "ij\n",
      " D \n",
      "1\n",
      ". So, \n",
      "P\n",
      "ij\n",
      ".1/\n",
      " \n",
      "D\n",
      " a\n",
      "ij\n",
      ".1/\n",
      " \n",
      "in this case.\n",
      "Case 2: f\n",
      "v\n",
      "i\n",
      " \n",
      "; v\n",
      "j\n",
      " g\n",
      " \n",
      "E\n",
      ". Then\n",
      " P\n",
      "ij\n",
      ".1/\n",
      " \n",
      "D\n",
      " 0 \n",
      "since there cannot be any walks of length 1\n",
      " \n",
      "between \n",
      "v\n",
      "i\n",
      " and \n",
      "v\n",
      "j\n",
      " . Moreover, f\n",
      "v\n",
      "i\n",
      " \n",
      "; v\n",
      "j\n",
      " g \n",
      "E\n",
      " means that \n",
      "a\n",
      "ij\n",
      " D \n",
      "0\n",
      ". So, \n",
      "P\n",
      "ij\n",
      ".1/\n",
      " D \n",
      "a\n",
      "ij\n",
      ".1/\n",
      " \n",
      "in this case as well.\n",
      "Hence, \n",
      "P .1/\n",
      " must be true.\n",
      "Inductive Step: Assume \n",
      "P .k/\n",
      " is true. In other words, assume that equation \n",
      " holds.\n",
      "We can group (and thus count the number of) walks of length \n",
      "k\n",
      " C\n",
      "1\n",
      " from \n",
      "v\n",
      "i\n",
      " to \n",
      "v\n",
      "j\n",
      " according to the first edge in the walk (call it f\n",
      "v\n",
      "i\n",
      " \n",
      "; v\n",
      "t\n",
      " g). This means that\n",
      "if f\n",
      "v\n",
      "i\n",
      " \n",
      "; v\n",
      "t\n",
      " g 2 \n",
      "E\n",
      " and \n",
      "a\n",
      "it\n",
      " D \n",
      "0\n",
      " otherwise, we can rewrite Equation \n",
      "as follows:\n",
      "n\n",
      ".kC1/\n",
      "\t\n",
      "X\n",
      "\t\n",
      ".k/\n",
      "P\n",
      "ij\n",
      "\t\n",
      "D\n",
      "\t\n",
      "a\n",
      "it\n",
      " P\n",
      "tj\n",
      "  :\n",
      "By the inductive hypothesis, \n",
      "P\n",
      "tj\n",
      ".k/\n",
      " D \n",
      "a\n",
      "tj\n",
      ".k/\n",
      " and thus\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 151  #157\n",
      "\n",
      "5.4.4\n",
      "\t\n",
      "Shortest Paths\n",
      "Although the connection between the power of the adjacency matrix and the num-ber of walks is cool (at least if you are a mathematician), the problem of counting walks does not come up very often in practice. Much more important is the problem of finding the shortest path between a pair of nodes in a graph.\n",
      "There is good news and bad news to report on this front. The good news is that it is not very hard to find a shortest path. The bad news is that you cant win one of those million dollar prizes for doing it.\n",
      "In fact, there are several good algorithms known for finding a Shortest Path be-tween a pair of nodes. The simplest to explain (but not the fastest) is to compute the powers of the adjacency matrix one by one until the value of a\n",
      "ij\n",
      ".k/\n",
      " exceeds 0. Thats\n",
      "because Theorem \n",
      "and Corollary \n",
      "imply that the length of the shortest path between v\n",
      "i\n",
      " and v\n",
      "j\n",
      " will be the smallest value of k for which a\n",
      "ij\n",
      ".k/\n",
      " > 0.\n",
      "Paths in Weighted Graphs\n",
      "The problem of computing shortest paths in a weighted graph frequently arises in practice. For example, when you drive home for vacation, you usually would like to take the shortest route.\n",
      "Definition 5.4.5. Given a weighted graph, the length of a path in the graph is the sum of the weights of the edges in the path.\n",
      "Finding shortest paths in weighted graphs is not a lot harder than finding shortest paths in unweighted graphs. We wont show you how to do it here, but you will study algorithms for finding shortest paths if you take an algorithms course. Not surprisingly, the proof of correctness will use induction.\n",
      "\n",
      "5.5\n",
      "\t\n",
      "Connectivity\n",
      "Definition 5.5.1. Two vertices in a graph are said to be connected if there is a path that begins at one and ends at the other. By convention, every vertex is considered to be connected to itself by a path of length zero.\n",
      "Definition 5.5.2. A graph is said to be connected when every pair of vertices are connected.\n",
      "5.5.1\n",
      "\t\n",
      "Connected Components\n",
      "Being connected is usually a good property for a graph to have. For example, it could mean that it is possible to get from any node to any other node, or that it is\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 152  #158\n",
      "\n",
      "152\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "possible to communicate between any pair of nodes, depending on the application. But not all graphs are connected. For example, the graph where nodes represent cities and edges represent highways might be connected for North American cities, but would surely not be connected if you also included cities in Australia.  The same is true for communication networks like the Internetin order to be protected from viruses that spread on the Internet, some government networks are completely\n",
      "isolated from the Internet.\n",
      "\n",
      "Figure 5.20\n",
      "\t\n",
      "One graph with 3 connected components.\n",
      "For example, the diagram in Figure \n",
      "looks like a picture of three graphs, but is intended to be a picture of one graph. This graph consists of three pieces (subgraphs). Each piece by itself is connected, but there are no paths between ver-tices in different pieces. These connected pieces of a graph are called its connected components.\n",
      "Definition 5.5.3. A connected component is a subgraph of a graph consisting of some vertex and every node and edge that is connected to that vertex.\n",
      "So a graph is connected iff it has exactly one connected component. At the other extreme, the empty graph on n vertices has n connected components.\n",
      "5.5.2\n",
      "\t\n",
      "k-Connected Graphs\n",
      "If we think of a graph as modeling cables in a telephone network, or oil pipelines, or electrical power lines, then we not only want connectivity, but we want connectivity that survives component failure. A graph is called k-edge connected if it takes at least k edge-failures to disconnect it. More precisely:\n",
      "Definition 5.5.4. Two vertices in a graph are k-edge connected if they remain con-nected in every subgraph obtained by deleting k 1 edges. A graph with at least two vertices is k-edge connected\n",
      "if every two of its vertices are k-edge connected.\n",
      "\n",
      "The corresponding definition of connectedness based on deleting vertices rather than edges is common in Graph Theory texts and is usually simply called k-connected rather than k-vertex connected.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 153  #159\n",
      "\n",
      "So 1-edge connected is the same as connected for both vertices and graphs. An-other way to say that a graph is k-edge connected is that every subgraph obtained from it by deleting at most k 1 edges is connected. For example, in the graph in Figure \n",
      ", vertices c and e are 3-edge connected, b and e are 2-edge connected, g and e are 1-edge connected, and no vertices are 4-edge connected. The graph as a whole is only 1-edge connected. The complete graph, K\n",
      "n\n",
      ", is .n 1/-edge connected.\n",
      "If two vertices are connected by k edge-disjoint paths (that is, no two paths traverse the same edge), then they are obviously k-edge connected. A fundamental fact, whose ingenious proof we omit, is Mengers theorem which confirms that the converse is also true: if two vertices are k-edge connected, then there are k edge-disjoint paths connecting them. It even takes some ingenuity to prove this for the case k D 2.\n",
      "5.5.3\n",
      "\t\n",
      "The Minimum Number of Edges in a Connected Graph\n",
      "The following theorem says that a graph with few edges must have many connected components.\n",
      "Theorem 5.5.5. Every graph with v vertices and e edges has at least v e con-nected components.\n",
      "Of course for Theorem \n",
      "to be of any use, there must be fewer edges than vertices.\n",
      "Proof. We use induction on the number of edges, e. Let P .e/ be the proposition that\n",
      "for every v, every graph with v vertices and e edges has at least v e connected components.\n",
      "Base case:(e D 0). In a graph with 0 edges and v vertices, each vertex is itself a connected component, and so there are exactly v D v 0 connected components. So P .e/ holds.\n",
      "Inductive step: Now we assume that the induction hypothesis holds for every e-edge graph in order to prove that it holds for every .eC1/-edge graph, where e 0. Consider a graph, G, with e C 1 edges and v vertices. We want to prove that G has at least v .e C 1/ connected components. To do this, remove an arbitrary edge fa; bg and call the resulting graph G\n",
      "0\n",
      ". By the induction assumption, G\n",
      "0\n",
      " has at least\n",
      "e connected components. Now add back the edge fa; bg to obtain the original graph G. If a and b were in the same connected component of G\n",
      "0\n",
      ", then G has the\n",
      "same connected components as G\n",
      "0\n",
      ", so G has at least v\n",
      "\t\n",
      "e > v  .eC1/ components.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 154  #160\n",
      "\n",
      "154\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "\n",
      "Figure 5.21\n",
      "\t\n",
      "A counterexample graph to the False Claim.\n",
      "Otherwise, if a and b were in different connected components of G\n",
      "0\n",
      ", then these two components are merged into one component in G, but all other components remain unchanged, reducing the number of components by 1. Therefore, G has at least\n",
      ".v e/ 1 D v .e C1/ connected components. So in either case, P .e C1/ holds. This completes the Inductive step. The theorem now follows by induction.\n",
      "Corollary 5.5.6. Every connected graph with v vertices has at least v\n",
      "\t\n",
      "1 edges.\n",
      "A couple of points about the proof of Theorem \n",
      "are worth noticing. First, we used induction on the number of edges in the graph. This is very common in proofs involving graphs, as is induction on the number of vertices. When youre presented with a graph problem, these two approaches should be among the first you consider.\n",
      "The second point is more subtle. Notice that in the inductive step, we took an arbitrary .nC1/-edge graph, threw out an edge so that we could apply the induction assumption, and then put the edge back. Youll see this shrink-down, grow-back process very often in the inductive steps of proofs related to graphs. This might seem like needless effort; why not start with an n-edge graph and add one more to get an .n C 1/-edge graph? That would work fine in this case, but opens the door to a nasty logical error called buildup error.\n",
      "5.5.4\tBuild-Up Error\n",
      "False Claim. If every vertex in a graph has degree at least 1, then the graph is connected.\n",
      "There are many counterexamples; for example, see Figure \n",
      ".\n",
      "False proof. We use induction. Let P .n/ be the proposition that if every vertex in an n-vertex graph has degree at least 1, then the graph is connected.\n",
      "Base case: There is only one graph with a single vertex and has degree 0. There-fore, P .1/ is vacuously true, since the if-part is false.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 155  #161\n",
      "\n",
      "\n",
      "\n",
      "z\n",
      "\n",
      "n\n",
      "-node\n",
      "x\n",
      "\n",
      "                     connected\n",
      "graph\n",
      "y\n",
      "Figure 5.22\n",
      "\t\n",
      "Adding a vertex x with degree at least 1 to a connected n-node graph.\n",
      "Inductive step: We must show that P .n/ implies P .n C 1/ for all n 1. Consider an n-vertex graph in which every vertex has degree at least 1. By the assump-tion P .n/, this graph is connected; that is, there is a path between every pair of vertices. Now we add one more vertex x to obtain an .n C 1/-vertex graph as shown in Figure \n",
      ".\n",
      "All that remains is to check that there is a path from x to every other vertex z. Since x has degree at least one, there is an edge from x to some other vertex; call it y. Thus, we can obtain a path from x to z by adjoining the edge fx; yg to the path from y to z. This proves P .n C 1/.\n",
      "By the principle of induction, P .n/ is true for all n\n",
      "\t\n",
      "1, which proves the\n",
      "theorem\n",
      "Uh-oh. . . this proof looks fine! Where is the bug? It turns out that the faulty as-sumption underlying this argument is that every .nC1/-vertex graph with minimum degree 1 can be obtained from an n-vertex graph with minimum degree 1 by adding 1 more vertex. Instead of starting by considering an arbitrary .n C 1/-node graph, this proof only considered .n C 1/-node graphs that you can make by starting with an n-node graph with minimum degree 1.\n",
      "The counterexample in Figure \n",
      "shows that this assumption is false; there is no way to build the 4-vertex graph in Figure \n",
      "from a 3-vertex graph with minimum degree 1. Thus the first error in the proof is the statement This proves P .n C 1/.\n",
      "This kind of flaw is known as build-up error. Usually, build-up error arises from a faulty assumption that every size n C 1 graph with some property can be built up from a size n graph with the same property. (This assumption is cor-rect for some properties, but incorrect for otherssuch as the one in the argument above.)\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 156  #162\n",
      "\n",
      "156\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "One way to avoid an accidental build-up error is to use a shrink down, grow back process in the inductive step; that is, start with a size n C 1 graph, remove a vertex (or edge), apply the inductive hypothesis P .n/ to the smaller graph, and then add back the vertex (or edge) and argue that P .n C 1/ holds. Lets see what would have happened if wed tried to prove the claim above by this method:\n",
      "Revised inductive step: We must show that P .n/ implies P .n C 1/ for all n 1. Consider an .n C 1/-vertex graph G in which every vertex has degree at least 1. Remove an arbitrary vertex v, leaving an n-vertex graph G\n",
      "0\n",
      " in which every vertex has degree. . . uh oh!\n",
      "The reduced graph G\n",
      "0\n",
      " might contain a vertex of degree 0, making the inductive hypothesis P .n/ inapplicable! We are stuckand properly so, since the claim is false!\n",
      "Always use shrink-down, grow-back arguments and youll never fall into this trap.\n",
      "\n",
      "5.6\n",
      "\t\n",
      "Around and Around We Go\n",
      "5.6.1\n",
      "\t\n",
      "Cycles and Closed Walks\n",
      "Definition 5.6.1. A closed walk\n",
      "in a graph G is a sequence of vertices v\n",
      "0\n",
      "; v\n",
      "1\n",
      "; : : : ; v\n",
      "k\n",
      "and edges\n",
      "fv\n",
      "0\n",
      "; v\n",
      "1\n",
      "g; fv\n",
      "1\n",
      "; v\n",
      "2\n",
      "g; : : : ; fv\n",
      "k1\n",
      "  ; v\n",
      "k\n",
      "g\n",
      "where v\n",
      "0\n",
      " is the same node as v\n",
      "k\n",
      " and fv\n",
      "i\n",
      " ; v\n",
      "iC1\n",
      "g is an edge of G for all i where 0 i < k. The length of the closed walk is k. A closed walk is said to be a cycle if k 3 and v\n",
      "0\n",
      ", v\n",
      "1\n",
      ", . . . , v\n",
      "k1\n",
      " are all different.\n",
      "For example, b, c, d , e, c, b is a closed walk of length 5 in the graph shown in Figure \n",
      ". It is not a cycle since it contains node c twice. On the other hand, c, d , e, c is a cycle of length 3 in this graph since every node appears just once.\n",
      "There are many ways to represent the same closed walk or cycle. For example, b, c, d , e, c, b is the same as c, d , e, c, b, c (just starting at node c instead of node b) and the same as b, c, e, d , c, b (just reversing the direction).\n",
      "\n",
      "15\n",
      "Some texts use the word cycle for our definition of closed walk and simple cycle for our definition of cycle.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 157  #163\n",
      "\n",
      "Cycles are similar to paths, except that the last node is the first node and the notion of first and last does not matter. Indeed, there are many possible vertex orders that can be used to describe cycles and closed walks, whereas walks and paths have a prescribed beginning, end, and ordering.\n",
      "5.6.2\n",
      "\t\n",
      "Odd Cycles and 2-Colorability\n",
      "We have already seen that determining the chromatic number of a graph is a chal-lenging problem. There is a special case where this problem is very easy; namely, the case where every cycle in the graph has even length. In this case, the graph is 2-colorable! Of course, this is optimal if the graph has any edges at all. More generally, we will prove\n",
      "Theorem 5.6.2. The following properties of a graph are equivalent (that is, if the graph has any one of the properties, then it has all of the properties):\n",
      "The graph is bipartite.\n",
      "The graph is 2-colorable.\n",
      "The graph does not contain any cycles with odd length.\n",
      "The graph does not contain any closed walks with odd length.\n",
      "Proof. We will show that property \n",
      "IMPLIES\n",
      " property \n",
      ", property \n",
      "IMPLIES\n",
      " prop-erty \n",
      ", property \n",
      "IMPLIES\n",
      " property \n",
      ", and property \n",
      "IMPLIES\n",
      " property \n",
      ". This will show that all four properties are equivalent by repeated application of Rule \n",
      "in Section \n",
      ".\n",
      "IMPLIES\n",
      " \n",
      "Assume\n",
      " \n",
      "that\n",
      " \n",
      "G\n",
      " \n",
      "D\n",
      " \n",
      ".V; E/\n",
      " \n",
      "is a bipartite graph. Then\n",
      " \n",
      "V\n",
      " \n",
      "can be parti-tioned into two sets L and R so that no edge connects a pair of nodes in L nor a pair of nodes in R. Hence, we can use one color for all the nodes in L and a second color for all the nodes in R. Hence .G/ D 2.\n",
      "IMPLIES\n",
      " \n",
      "Let\n",
      " \n",
      "G\n",
      " \n",
      "D\n",
      " \n",
      ".V; E/\n",
      " \n",
      "be a 2-colorable graph and\n",
      "C WWD v\n",
      "0\n",
      "; v\n",
      "1\n",
      "; : : : ; v\n",
      "k\n",
      "be any cycle in G. Consider any 2-coloring for the nodes of G. Since fv\n",
      "i\n",
      " ; v\n",
      "iC1\n",
      "g 2 E, v\n",
      "i\n",
      " and v\n",
      "iC1\n",
      " must be differently colored for 0 i < k. Hence v\n",
      "0\n",
      ", v\n",
      "2\n",
      ", v\n",
      "4\n",
      ", . . . , have one color and v\n",
      "1\n",
      ", v\n",
      "3\n",
      ", v\n",
      "5\n",
      ", . . . , have the other color. Since C is a cycle, v\n",
      "k\n",
      " is the same node as v\n",
      "0\n",
      ", which means they must have the same color, and so k must be an even number. This means that\n",
      "has even length.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 158  #164\n",
      "\n",
      "158\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "IMPLIES\n",
      " \n",
      "The\n",
      " \n",
      "proof is by contradiction. Assume for the purposes of contradic-tion that G is a graph that does not contain any cycles with odd length (that is, G satisfies Property \n",
      ") but that G does contain a closed walk with odd length (that is, G does not satisfy Property \n",
      ").\n",
      "Let\n",
      "w WWD v\n",
      "0\n",
      "; v\n",
      "1\n",
      "; v\n",
      "2\n",
      "; : : : ; v\n",
      "k\n",
      "be the shortest closed walk with odd length in G. Since G has no odd-length cycles, w cannot be a cycle. Hence v\n",
      "i\n",
      " D v\n",
      "j\n",
      " for some 0 i < j < k. This means that w is the union of two closed walks:\n",
      "v\n",
      "0\n",
      "; v\n",
      "1\n",
      "; : : : ; v\n",
      "i\n",
      " ; v\n",
      "j\n",
      " \n",
      "C1\n",
      "; v\n",
      "j\n",
      " \n",
      "C2\n",
      "; : : : ; v\n",
      "k\n",
      "and\n",
      "v\n",
      "i\n",
      " ; v\n",
      "iC1\n",
      "; : : : ; v\n",
      "j\n",
      " :\n",
      "Since w has odd length, one of these two closed walks must also have odd length and be shorter than w. This contradicts the minimality of w. Hence \n",
      "IMPLIES \n",
      ".\n",
      "IMPLIES\n",
      " \n",
      "Once\n",
      " \n",
      "again, the proof is by contradiction. Assume for the purposes\n",
      " \n",
      "of contradictin that G is a graph without any closed walks with odd length (that is, G satisfies Property \n",
      ") but that G is not bipartite (that is, G does not satisfy Property \n",
      ").\n",
      "Since G is not bipartite, it must contain a connected component G\n",
      "0\n",
      " D .V \n",
      "0\n",
      "; E\n",
      "0\n",
      "/ that is not bipartite. Let v be some node in V \n",
      "0\n",
      ". For every node u 2 V \n",
      "0\n",
      ", define\n",
      "dist.u/ WWD the length of the shortest path from u to v in G\n",
      "0\n",
      ".\n",
      "If u D v, the distance is zero.\n",
      "Partition V \n",
      "0\n",
      " into sets L and R so that\n",
      "L D f u j dist.u/ is even g;\n",
      "D f u j dist.u/ is odd g:\n",
      "Since G\n",
      "0\n",
      " is not bipartite, there must be a pair of adjacent nodes u\n",
      "1\n",
      " and u\n",
      "2\n",
      " that are both in L or both in R. Let e denote the edge incident to u\n",
      "1\n",
      " and u\n",
      "2\n",
      ".\n",
      "Let P\n",
      "i\n",
      " denote a shortest path in G\n",
      "0\n",
      " from u\n",
      "i\n",
      " to v for i D 1; 2. Because u\n",
      "1\n",
      " and u\n",
      "2\n",
      " are both in L or both in R, it must be the case that P\n",
      "1\n",
      " and P\n",
      "2\n",
      " both have even length or they both have odd length. In either case, the union of P\n",
      "1\n",
      ", P\n",
      "2\n",
      ", and e forms a closed walk with odd length, which is a contradiction.\n",
      "Hence \n",
      "IMPLIES\n",
      " \n",
      ".\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 159  #165\n",
      "\n",
      "\n",
      "Figure 5.23 A possible floor plan for a museum. Can you find a walk that tra-verses every edge exactly once?\n",
      "Theorem \n",
      "turns out to be useful since bipartite graphs come up fairly often in practice. Well see examples when we talk about planar graphs in Section \n",
      " and when we talk about packet routing in communication networks in Chapter \n",
      ".\n",
      "5.6.3\n",
      "\t\n",
      "Euler Tours\n",
      "Can you walk every hallway in the Museum of Fine Arts exactly once? If we represent hallways and intersections with edges and vertices, then this reduces to a question about graphs. For example, could you visit every hallway exactly once in a museum with the floor plan in Figure \n",
      "?\n",
      "The entire field of graph theory began when Euler asked whether the seven bridges of Konigsberg could all be traversed exactly onceessentially the same question we asked about the Museum of Fine Arts. In his honor, an Euler walk is a defined to be a walk that traverses every edge in a graph exactly once. Similarly, an Euler tour is an Euler walk that starts and finishes at the same vertex. Graphs with Euler tours and Euler walks both have simple characterizations.\n",
      "Theorem 5.6.3. A connected graph has an Euler tour if and only if every vertex has even degree.\n",
      "Proof. We first show that if a graph has an Euler tour, then every vertex has even degree. Assume that a graph G D .V; E/ has an Euler tour v\n",
      "0\n",
      ", v\n",
      "1\n",
      ", . . . , v\n",
      "k\n",
      " where v\n",
      "k\n",
      " D v\n",
      "0\n",
      ". Since every edge is traversed once in the tour, k D jEj and the degree of a node u in G is the number of times that node appears in the sequence v\n",
      "0\n",
      ", v\n",
      "1\n",
      ", . . . , v\n",
      "k1\n",
      " times two. We multiply by two since if u D v\n",
      "i\n",
      " for some i where 0 < i < k, then both fv\n",
      "i1\n",
      " ; v\n",
      "i\n",
      " g and fv\n",
      "i\n",
      " ; v\n",
      "iC1\n",
      "g are edges incident to u in G. If u D v\n",
      "0\n",
      " D v\n",
      "k\n",
      ",\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 160  #166\n",
      "\n",
      "160\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "then both fv\n",
      "k1\n",
      " ; v\n",
      "k\n",
      "g and fv\n",
      "0\n",
      "; v\n",
      "1\n",
      "g are edges incident to u in G. Hence, the degree of every node is even.\n",
      "We next show that if the degree of every node is even in a graph G D .V; E/, then there is an Euler tour. Let\n",
      "W WWD v\n",
      "0\n",
      "; v\n",
      "1\n",
      "; : : : ; v\n",
      "k\n",
      "be the longest walk in G that traverses no edge more than once\n",
      ". W must traverse every edge incident to v\n",
      "k\n",
      "; otherwise the walk could be extended and W would not be the longest walk that traverses all edges at most once. Moreover, it must be that v\n",
      "k\n",
      " D v\n",
      "0\n",
      " and that W is a closed walk, since otherwise v\n",
      "k\n",
      " would have odd degree in W (and hence in G), which is not possible by assumption.\n",
      "We conclude the argument with a proof by contradiction. Suppose that W is not an Euler tour. Because G is a connected graph, we can find an edge not in W but incident to some vertex in W . Call this edge fu; v\n",
      "i\n",
      " g. But then we can construct a walk W \n",
      "0\n",
      " that is longer than W but that still uses no edge more than once:\n",
      "W \n",
      "0\n",
      " WWD u; v\n",
      "i\n",
      " ; v\n",
      "iC1\n",
      "; : : : ; v\n",
      "k\n",
      "; v\n",
      "1\n",
      "; v\n",
      "2\n",
      "; : : : ; v\n",
      "i\n",
      " :\n",
      "This contradicts the definition of W , so W must be an Euler tour after all.\n",
      "It is not difficult to extend Theorem \n",
      "to prove that a connected graph G has an Euler walk if and only if precisely 0 or 2 nodes in G have odd degree. Hence, we can conclude that the graph shown in Figure \n",
      "has an Euler walk but not an Euler tour since the graph has precisely two nodes with odd degree.\n",
      "Although the proof of Theorem \n",
      "does not explicitly define a method for finding an Euler tour when one exists, it is not hard to modify the proof to produce such a method. The idea is to grow a tour by continually splicing in closed walks until all the edges are consumed.\n",
      "5.6.4\n",
      "\t\n",
      "Hamiltonian Cycles\n",
      "Hamiltonian cycles are the unruly cousins of Euler tours.\n",
      "Definition 5.6.4. A Hamiltonian cycle in a graph G is a cycle that visits every node in G exactly once. Similarly, a Hamiltonian path is a path in G that visits every node exactly once.\n",
      "\n",
      "Did you notice that we are using a variation of the Well Ordering Principle here when we im-plicitly assume that a longest walk exists? This is ok since the length of a walk where no edge is used more than once is at most jEj.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 161  #167\n",
      "\n",
      "3\n",
      "\n",
      "5\n",
      "\t\n",
      "2\n",
      "v\n",
      "6\n",
      "\n",
      "     6     \n",
      "\n",
      "v\n",
      "5\n",
      "Figure 5.24 A weighted graph. Can you find a cycle with weight 15 that visits every node exactly once?\n",
      "Although Hamiltonian cycles sound similar to Euler toursone visits every node once while the other visits every edge oncefinding a Hamiltonian cycle can be a lot harder than finding an Euler tour. The same is true for Hamiltonian paths. This is because no one has discovered a simple characterization of all graphs with a Hamiltonian cycle. In fact, determining whether a graph has a Hamiltonian cycle is the same category of problem as the SAT problem of Section \n",
      "and the coloring problem in Section \n",
      "; you get a million dollars for finding an efficient way to determine when a graph has a Hamiltonian cycleor proving that no procedure works efficiently on all graphs.\n",
      "5.6.5\n",
      "\t\n",
      "The Traveling Salesperson Problem\n",
      "As if the problem of finding a Hamiltonian cycle is not hard enough, when the graph is weighted, we often want to find a Hamiltonian cycle that has least pos-sible weight. This is a very famous optimization problem known as the Traveling Salesperson Problem.\n",
      "Definition 5.6.5. Given a weighted graph G, the weight of a cycle in G is defined as the sum of the weights of the edges in the cycle.\n",
      "For example, consider the graph shown in Figure \n",
      "and suppose that you would like to visit every node once and finish at the node where you started. Can you find way to do this by traversing a cycle with weight 15?\n",
      "Needless to say, if you can figure out a fast procedure that finds the optimal cycle for the traveling salesperson, let us know so that we can win a million dollars.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 162  #168\n",
      "\n",
      "162\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "a\n",
      "\t\n",
      "e\n",
      "\t\n",
      "h\n",
      "\n",
      "f\n",
      "\n",
      "Figure 5.25\n",
      "\t\n",
      "A 9-node tree.\n",
      "\n",
      "Figure 5.26 A 6-node forest consisting of 2 component trees. Note that this 6-node graph is not itself a tree since it is not connected.\n",
      "\n",
      "5.7\n",
      "\t\n",
      "Trees\n",
      "As we have just seen, finding good cycles in a graph can be trickier than you might first think. But what if a graph has no cycles at all? Sounds pretty dull. But graphs without cycles (called acyclic graphs) are probably the most important graphs of all when it comes to computer science.\n",
      "5.7.1\n",
      "\t\n",
      "Definitions\n",
      "Definition 5.7.1. A connected acyclic graph is called a tree.\n",
      "For example, Figure \n",
      "shows an example of a 9-node tree.\n",
      "The graph shown in Figure \n",
      "is not a tree since it is not connected, but it is a forest. Thats because, of course, it consists of a collection of trees.\n",
      "Definition 5.7.2. If every connected component of a graph G is a tree, then G is a forest.\n",
      "One of the first things you will notice about trees is that they tend to have a lot of nodes with degree one. Such nodes are called leaves.\n",
      "Definition 5.7.3. A leaf is a node with degree 1 in a tree (or forest).\n",
      "For example, the tree in Figure \n",
      "has 5 leaves and the forest in Figure \n",
      " has 4 leaves.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 163  #169\n",
      "\n",
      "e\n",
      "\n",
      "g\n",
      "b\n",
      "\t\n",
      "c\tf\n",
      "\t\n",
      "h\n",
      "\t\n",
      "i\n",
      "a\n",
      "Figure 5.27 The tree from Figure \n",
      "redrawn in a leveled fashion, with node E as the root.\n",
      "Trees are a fundamental data structure in computer science. For example, in-formation is often stored in tree-like data structures and the execution of many recursive programs can be modeled as the traversal of a tree. In such cases, it is often useful to draw the tree in a leveled fashion where the node in the top level is identified as the root, and where every edge joins a parent to a child. For example, we have redrawn the tree from Figure \n",
      "in this fashion in Figure \n",
      ". In this example, node d is a child of node e and a parent of nodes b and c.\n",
      "In the special case of ordered binary trees, every node is the parent of at most 2 children and the children are labeled as being a left-child or a right-child.\n",
      "5.7.2\n",
      "\t\n",
      "Properties\n",
      "Trees have many unique properties. We have listed some of them in the following theorem.\n",
      "Theorem 5.7.4. Every tree has the following properties:\n",
      "Any connected subgraph is a tree.\n",
      "There is a unique simple path between every pair of vertices.\n",
      "Adding an edge between nonadjacent nodes in a tree creates a graph with a cycle.\n",
      "Removing any edge disconnects the graph.\n",
      "If the tree has at least two vertices, then it has at least two leaves.\n",
      "The number of vertices in a tree is one larger than the number of edges.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 164  #170\n",
      "\n",
      "164\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "\n",
      "u\n",
      "\t\n",
      "x\n",
      "\n",
      " y\n",
      "\t\n",
      "v\n",
      "Figure 5.28 If there are two paths between u and v, the graph must contain a cycle.\n",
      "Proof.\n",
      "\t\n",
      "1. A cycle in a subgraph is also a cycle in the whole graph, so any sub-graph of an acyclic graph must also be acyclic. If the subgraph is also con-nected, then by definition, it is a tree.\n",
      "Since a tree is connected, there is at least one path between every pair of ver-tices. Suppose for the purposes of contradiction, that there are two different paths between some pair of vertices u and v. Beginning at u, let x be the first vertex where the paths diverge, and let y be the next vertex they share. (For example, see Figure \n",
      ".) Then there are two paths from x to y with no common edges, which defines a cycle. This is a contradiction, since trees are acyclic. Therefore, there is exactly one path between every pair of vertices.\n",
      "An additional edge fu; vg together with the unique path between u and v forms a cycle.\n",
      "Suppose that we remove edge fu; vg. Since the tree contained a unique path between u and v, that path must have been fu; vg. Therefore, when that edge is removed, no path remains, and so the graph is not connected.\n",
      "Let v\n",
      "1\n",
      "; : : : ; v\n",
      "m\n",
      " be the sequence of vertices on a longest path in the tree. Then m 2, since a tree with two vertices must contain at least one edge. There cannot be an edge fv\n",
      "1\n",
      "; v\n",
      "i\n",
      " g for 2 < i m; otherwise, vertices v\n",
      "1\n",
      "; : : : ; v\n",
      "i\n",
      " would from a cycle. Furthermore, there cannot be an edge fu; v\n",
      "1\n",
      "g where u is not on the path; otherwise, we could make the path longer. Therefore, the only edge incident to v\n",
      "1\n",
      " is fv\n",
      "1\n",
      "; v\n",
      "2\n",
      "g, which means that v\n",
      "1\n",
      " is a leaf. By a symmetric argument, v\n",
      "m\n",
      " is a second leaf.\n",
      "6.\tWe use induction on the proposition P .n/ WWD there are n 1 edges in any n-vertex tree.\n",
      "Base Case (n D 1): P .1/ is true since a tree with 1 node has 0 edges and\n",
      "1D0.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 165  #171\n",
      "\n",
      "\n",
      "Figure 5.29\n",
      "\t\n",
      "A graph where the edges of a spanning tree have been thickened.\n",
      "Inductive step: Now suppose that P .n/ is true and consider an .n C 1/-vertex tree, T . Let v be a leaf of the tree. You can verify that deleting a vertex of degree 1 (and its incident edge) from any connected graph leaves a connected subgraph. So by part \n",
      "of Theorem \n",
      ", deleting v and its incident edge gives a smaller tree, and this smaller tree has n 1 edges by induction. If we re-attach the vertex v and its incident edge, then we find that\n",
      "has n D .n C 1/  1 edges. Hence, P .n C 1/ is true, and the induction\n",
      "proof is complete.\n",
      "Various subsets of properties in Theorem \n",
      "provide alternative characteriza-tions of trees, though we wont prove this. For example, a connected graph with a number of vertices one larger than the number of edges is necessarily a tree. Also, a graph with unique paths between every pair of vertices is necessarily a tree.\n",
      "5.7.3\n",
      "\t\n",
      "Spanning Trees\n",
      "Trees are everywhere. In fact, every connected graph contains a subgraph that is a tree with the same vertices as the graph. This is a called a spanning tree for the graph. For example, Figure \n",
      "is a connected graph with a spanning tree highlighted.\n",
      "Theorem 5.7.5. Every connected graph contains a spanning tree.\n",
      "Proof. By contradiction. Assume there is some connected graph G that has no spanning tree and let T be a connected subgraph of G, with the same vertices as G, and with the smallest number of edges possible for such a subgraph. By the assumption, T is not a spanning tree and so it contains some cycle:\n",
      "fv\n",
      "0\n",
      "; v\n",
      "1\n",
      "g; fv\n",
      "1\n",
      "; v\n",
      "2\n",
      "g; : : : ; fv\n",
      "k\n",
      "; v\n",
      "0\n",
      "g\n",
      "Suppose that we remove the last edge, fv\n",
      "k\n",
      "; v\n",
      "0\n",
      "g. If a pair of vertices x and y was joined by a path not containing fv\n",
      "k\n",
      "; v\n",
      "0\n",
      "g, then they remain joined by that path. On the other hand, if x and y were joined by a path containing fv\n",
      "k\n",
      "; v\n",
      "0\n",
      "g, then they\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 166  #172\n",
      "\n",
      "166\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "\n",
      "Figure 5.30\n",
      "\t\n",
      "A spanning tree (a) with weight 19 for a graph (b).\n",
      "remain joined by a walk containing the remainder of the cycle. By Lemma \n",
      ", they must also then be joined by a path. So all the vertices of G are still connected after we remove an edge from T . This is a contradiction, since T was defined to be a minimum size connected subgraph with all the vertices of G. So the theorem\n",
      "must be true.\n",
      "5.7.4\n",
      "\t\n",
      "Minimum Weight Spanning Trees\n",
      "Spanning trees are interesting because they connect all the nodes of a graph using the smallest possible number of edges. For example the spanning tree for the 6-node graph shown in Figure \n",
      "has 5 edges.\n",
      "Spanning trees are very useful in practice, but in the real world, not all span-ning trees are equally desirable. Thats because, in practice, there are often costs associated with the edges of the graph.\n",
      "For example, suppose the nodes of a graph represent buildings or towns and edges represent connections between buildings or towns. The cost to actually make a connection may vary a lot from one pair of buildings or towns to another. The cost might depend on distance or topography. For example, the cost to connect LA to NY might be much higher than that to connect NY to Boston. Or the cost of a pipe through Manhattan might be more than the cost of a pipe through a cornfield.\n",
      "In any case, we typically represent the cost to connect pairs of nodes with a weighted edge, where the weight of the edge is its cost. The weight of a spanning tree is then just the sum of the weights of the edges in the tree. For example, the weight of the spanning tree shown in Figure \n",
      "is 19.\n",
      "The goal, of course, is to find the spanning tree with minimum weight, called the min-weight spanning tree (MST for short).\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 167  #173\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "2\n",
      "1\n",
      "\t\n",
      "1\n",
      "\n",
      "\n",
      "3\n",
      "7\n",
      "Figure 5.31\n",
      "\t\n",
      "An MST with weight 17 for the graph in Figure \n",
      "(b).\n",
      "Definition 5.7.6. The min-weight spanning tree (MST) of an edge-weighted graph G is the spanning tree of G with the smallest possible sum of edge weights.\n",
      "Is the spanning tree shown in Figure \n",
      "(a) an MST of the weighted graph shown in Figure \n",
      "(b)? Actually, it is not, since the tree shown in Figure \n",
      "is also a spanning tree of the graph shown in Figure \n",
      "(b), and this spanning tree has weight 17.\n",
      "What about the tree shown in Figure \n",
      "? Is it an MST? It seems to be, but how do we prove it? In general, how do we find an MST? We could, of course, enumerate all trees, but this could take forever for very large graphs.\n",
      "Here are two possible algorithms:\n",
      "Algorithm 1. Grow a tree one edge at a time by adding the minimum weight edge possible to the tree, making sure that you have a tree at each step.\n",
      "Algorithm 2. Grow a subgraph one edge at a time by adding the minimum-weight edge possible to the subgraph, making sure that you have an acyclic subgraph at each step.\n",
      "For example, in the weighted graph we have been considering, we might run Algorithm \n",
      "as follows. We would start by choosing one of the weight 1 edges, since this is the smallest weight in the graph. Suppose we chose the weight 1 edge on the bottom of the triangle of weight 1 edges in our graph. This edge is incident to two weight 1 edges, a weight 4 edge, a weight 7 edge, and a weight 3 edge. We would then choose the incident edge of minimum weight. In this case, one of the two weight 1 edges. At this point, we cannot choose the third weight 1 edge since this would form a cycle, but we can continue by choosing a weight 2 edge. We might end up with the spanning tree shown in Figure \n",
      ", which has weight 17, the smallest weve seen so far.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 168  #174\n",
      "\n",
      "168\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "1\n",
      "\n",
      "2\n",
      "\t\n",
      "3\n",
      "2\n",
      "1\n",
      "1\n",
      "7\n",
      "Figure 5.32\n",
      "\t\n",
      "A spanning tree found by Algorithm \n",
      ".\n",
      "Now suppose we instead ran Algorithm \n",
      "on our graph. We might again choose the weight 1 edge on the bottom of the triangle of weight 1 edges in our graph. Now, instead of choosing one of the weight 1 edges it touches, we might choose the weight 1 edge on the top of the graph. Note that this edge still has minimum weight, and does not cause us to form a cycle, so Algorithm \n",
      "can choose it. We would then choose one of the remaining weight 1 edges. Note that neither causes us to form a cycle. Continuing the algorithm, we may end up with the same spanning tree in Figure \n",
      ", though this need not always be the case.\n",
      "It turns out that both algorithms work, but they might end up with different MSTs. The MST is not necessarily uniqueindeed, if all edges of an n-node graph have the same weight ( D 1), then all spanning trees have weight n 1.\n",
      "These are examples of greedy approaches to optimization. Sometimes it works and sometimes it doesnt. The good news is that it works to find the MST. In fact, both variations work. Its a little easier to prove it for Algorithm \n",
      ", so well do that one here.\n",
      "Theorem 5.7.7. For any connected, weighted graph G, Algorithm \n",
      "produces an MST for G.\n",
      "Proof. The proof is a bit tricky. We need to show the algorithm terminates, that is, that if we have selected fewer than n 1 edges, then we can always find an edge to add that does not create a cycle. We also need to show the algorithm creates a tree of minimum weight.\n",
      "The key to doing all of this is to show that the algorithm never gets stuck or goes in a bad direction by adding an edge that will keep us from ultimately producing an MST. The natural way to prove this is to show that the set of edges selected at any point is contained in some MSTthat is, we can always get to where we need to be. Well state this as a lemma.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 169  #175\n",
      "\n",
      "Lemma 5.7.8. For any m 0, let S consist of the first m edges selected by Algo-rithm \n",
      ". Then there exists some MST T D .V; E/ for G such that S E, that is, the set of edges that we are growing is always contained in some MST.\n",
      "Well prove this momentarily, but first lets see why it helps to prove the theorem. Assume the lemma is true. Then how do we know Algorithm \n",
      "can always find an edge to add without creating a cycle? Well, as long as there are fewer than n 1 edges picked, there exists some edge in E S and so there is an edge that we can add to S without forming a cycle. Next, how do we know that we get an MST at the end? Well, once m D n 1, we know that S is an MST.\n",
      "Ok, so the theorem is an easy corollary of the lemma. To prove the lemma, well use induction on the number of edges chosen by the algorithm so far. This is very typical in proving that an algorithm preserves some kind of invariant condition induct on the number of steps taken, that is, the number of edges added.\n",
      "Our inductive hypothesis P .m/ is the following: for any G and any set S of m edges initially selected by Algorithm \n",
      ", there exists an MST T D .V; E/ of G such that S E.\n",
      "For the base case, we need to show P .0/. In this case, S D ;, so S E trivially holds for any MST T D .V; E/.\n",
      "For the inductive step, we assume P .m/ holds and show that it implies P .mC1/. Let e denote the .mC1/st edge selected by Algorithm \n",
      ", and let S denote the first m edges selected by Algorithm \n",
      ". Let T D .V ; E / be the MST such that S E , which exists by the inductive hypothesis. There are now two cases:\n",
      "Case 1: e 2 E , in which case S [ feg\n",
      "\t\n",
      "E , and thus P .m C 1/ holds.\n",
      "Case 2: e\n",
      " \n",
      "E , as illustrated in Figure \n",
      ". Now we need to find a different MST that contains S and e.\n",
      "What happens when we add e to T ? Since T is a tree, we get a cycle. (Here we used part 3 of Theorem \n",
      ".) Moreover, the cycle cannot only contains edges in S, since e was chosen so that together with the edges in S, it does not form a cycle. This implies that feg [ T contains a cycle that contains an edge e\n",
      "0\n",
      " of E S. For example, such an e\n",
      "0\n",
      " is shown in Figure \n",
      ".\n",
      "Note that the weight of e is at most that of e\n",
      "0\n",
      ". This is because Algorithm \n",
      "picks the minimum weight edge that does not make a cycle with S. Since e\n",
      "0\n",
      " 2 T , e\n",
      "0\n",
      " cannot make a cycle with S and if the weight of e were greater than the weight of e\n",
      "0\n",
      ", Algorithm \n",
      "would not have selected e ahead of e\n",
      "0\n",
      ".\n",
      "Okay, were almost done. Now well make an MST that contains S [ feg. Let T D .V; E / where E D .E fe \n",
      "0\n",
      "g/ [ feg, that is, we swap e and e\n",
      "0\n",
      " in T .\n",
      "Claim 5.7.9. T\n",
      "\t\n",
      "is an MST.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 170  #176\n",
      "\n",
      "170\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "e\n",
      "\n",
      "e\n",
      "0\n",
      "Figure 5.33 The graph formed by adding e to T . Edges of S are denoted with solid lines and edges of E S are denoted with dashed lines.\n",
      "Proof of claim. We first show that T is a spanning tree. T is acyclic because it was produced by removing an edge from the only cycle in T [ feg. T is connected since the edge we deleted from T [ feg was on a cycle. Since T contains all the nodes of G, it must be a spanning tree for G.\n",
      "Now lets look at the weight of T . Well, since the weight of e was at most that of e\n",
      "0\n",
      ", the weight of T is at most that of T , and thus T is an MST for G.\n",
      "Since S [ feg\n",
      "\t\n",
      "E\n",
      "\t\n",
      ", P .m C 1/ holds. Thus, Algorithm \n",
      "must eventually\n",
      "produce an MST. This will happens when it adds n\n",
      "\t\n",
      "1 edges to the subgraph it\n",
      "builds.\n",
      "So now we know for sure that the MST for our example graph has weight 17 since it was produced by Algorithm \n",
      ". And we have a fast algorithm for finding a minimum-weight spanning tree for any graph.\n",
      "\n",
      "5.8\n",
      "\t\n",
      "Planar Graphs\n",
      "5.8.1\n",
      "\t\n",
      "Drawing Graphs in the Plane\n",
      "Suppose there are three dog houses and three human houses, as shown in Fig-ure \n",
      ". Can you find a route from each dog house to each human house such that no route crosses any other route?\n",
      "A quadrapus is a little-known animal similar to an octopus, but with four arms.\n",
      "Suppose there are five quadrapi resting on the sea floor, as shown in Figure \n",
      ".\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 171  #177\n",
      "\n",
      "\n",
      "Figure 5.34 Three dog houses and and three human houses. Is there a route from each dog house to each human house so that no pair of routes cross each other?\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 172  #178\n",
      "\n",
      "172\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "\n",
      "Figure 5.35\n",
      "\t\n",
      "Five quadrapi (4-armed creatures).\n",
      "Can each quadrapus simultaneously shake hands with every other in such a way that no arms cross?\n",
      "Definition 5.8.1. A drawing of a graph in the plane consists of an assignment of vertices to distinct points in the plane and an assignment of edges to smooth, non-self-intersecting curves in the plane (whose endpoints are the nodes incident to the edge). The drawing is planar (that is, it is a planar drawing) if none of the curves crossthat is, if the only points that appear on more than one curve are the vertex points. A planar graph is a graph that has a planar drawing.\n",
      "Thus, these two puzzles are asking whether the graphs in Figure \n",
      "are planar; that is, whether they can be redrawn so that no edges cross. The first graph is called the complete bipartite graph, K\n",
      "3;3\n",
      ", and the second is K\n",
      "5\n",
      ".\n",
      "In each case, the answer is, Nobut almost! In fact, if you remove an edge from either of them, then the resulting graphs can be redrawn in the plane so that no edges cross. For example, we have illustrated the planar drawings for each resulting graph in Figure \n",
      ".\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 173  #179\n",
      "\n",
      "\n",
      "(a)\n",
      "\t\n",
      "(b)\n",
      "Figure 5.36 K\n",
      "3;3\n",
      " (a) and K\n",
      "5\n",
      " (b). Can you redraw these graphs so that no pairs of edges cross?\n",
      "\n",
      "(a)\n",
      "\t\n",
      "(b)\n",
      "Figure 5.37\n",
      "\t\n",
      "Planar drawings of K\n",
      "3;3\n",
      " fu; v\n",
      "\t\n",
      "g (a) and K\n",
      "5\n",
      " fu; v  g (b).\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 174  #180\n",
      "\n",
      "174\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "Planar drawings have applications in circuit layout and are helpful in displaying graphical data such as program flow charts, organizational charts, and scheduling conflicts. For these applications, the goal is to draw the graph in the plane with as few edge crossings as possible. (See the box on the following page for one such example.)\n",
      "5.8.2\n",
      "\t\n",
      "A Recursive Definition for Planar Graphs\n",
      "Definition \n",
      "is perfectly precise but has the challenge that it requires us to work with concepts such as a smooth curve when trying to prove results about planar graphs. The trouble is that we have not really laid the groundwork from geometry and topology to be able to reason carefully about such concepts. For example, we havent really defined what it means for a curve to be smoothwe just drew a simple picture (for example, Figure \n",
      ") and hoped you would get the idea.\n",
      "Relying on pictures to convey new concepts is generally not a good idea and can sometimes lead to disaster (or, at least, false proofs). Indeed, it is because of this issue that there have been so many false proofs relating to planar graphs over time.\n",
      "Such proofs usually rely way too heavily on pictures and have way too many statements like,\n",
      "As you can see from Figure ABC, it must be that property XYZ holds for all planar graphs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The good news is that there is another way to define planar graphs that uses only discrete mathematics. In particular, we can define the class of planar graphs as a recursive data type. In order to understand how it works, we first need to understand the concept of a face in a planar drawing.\n",
      "Faces\n",
      "In a planar drawing of a graph. the curves corresponding to the edges divide up the plane into connected regions. These regions are called the continuous faces\n",
      " of the drawing. For example, the drawing in Figure \n",
      "has four continuous faces. Face IV, which extends off to infinity in all directions, is called the outside face.\n",
      "Notice that the vertices along the boundary of each of the faces in Figure \n",
      " form a cycle. For example, labeling the vertices as in Figure \n",
      ", the cycles for the face boundaries are\n",
      "abca\n",
      "\t\n",
      "abda\n",
      "\t\n",
      "bcdb\n",
      "\t\n",
      "acda:\n",
      "\t\n",
      "(5.4)\n",
      "\n",
      "The false proof of the 4-Color Theorem for planar graphs is not the only example.\n",
      "Most texts drop the word continuous from the definition of a face. We need it to differentiate the connected region in the plane from the closed walk in the graph that bounds the region, which we will call a discrete face.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 175  #181\n",
      "\n",
      "\n",
      "When wires are arranged on a surface, like a circuit board or microchip, crossings require troublesome three-dimensional structures. When Steve Wozniak designed the disk drive for the early Apple II computer, he struggled mightily to achieve a nearly planar design:\n",
      "For two weeks, he worked late each night to make a satisfactory de-sign. When he was finished, he found that if he moved a connector he could cut down on feedthroughs, making the board more reliable. To make that move, however, he had to start over in his design. This time it only took twenty hours. He then saw another feedthrough that could be eliminated, and again started over on his design. The final design was generally recognized by computer engineers as bril-liant and was by engineering aesthetics beautiful. Woz later said, Its something you can only do if youre the engineer and the PC board layout person yourself. That was an artistic layout. The board has virtually no feedthroughs. \n",
      "17\n",
      "\n",
      "III\n",
      "II\n",
      "\t\n",
      "I\n",
      "IV\n",
      "Figure 5.38\n",
      "\t\n",
      "A planar drawing with four faces.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 176  #182\n",
      "\n",
      "176\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "\n",
      "b\n",
      "III\n",
      "a \n",
      "\n",
      "     II\n",
      "\t\n",
      "I    \n",
      "\n",
      "c\n",
      "IV\n",
      "d\n",
      "Figure 5.39\n",
      "\t\n",
      "The drawing with labeled vertices.\n",
      "f\n",
      "b\n",
      "\n",
      "g\n",
      "d\n",
      "Figure 5.40\n",
      "\t\n",
      "A planar drawing with a bridge, namely the edge fc; eg.\n",
      "These four cycles correspond nicely to the four continuous faces in Figure \n",
      ". So nicely, in fact, that we can identify each of the faces in Figure \n",
      "by its cycle. For example, the cycle abca identifies face III. Hence, we say that the cycles in Equation \n",
      "are the discrete faces of the graph in Figure \n",
      ". We use the term discrete since cycles in a graph are a discrete data type (as opposed to a region in the plane, which is a continuous data type).\n",
      "Unfortunately, continuous faces in planar drawings are not always bounded by cycles in the graphthings can get a little more complicated. For example, con-sider the planar drawing in Figure \n",
      ". This graph has what we will call a bridge (namely, the edge fc; eg) and the outer face is\n",
      "abcefgecda:\n",
      "This is not a cycle, since it has to traverse the bridge fc; eg twice, but it is a closed walk.\n",
      "As another example, consider the planar drawing in Figure \n",
      ". This graph has what we will call a dongle (namely, the nodes v, x, y, and w, and the edges incident\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 177  #183\n",
      "\n",
      "\n",
      "u\n",
      "Figure 5.41 A planar drawing with a dongle, namely the subgraph with nodes v, w, x, y.\n",
      "to them) and the inner face is\n",
      "rstvxyxvwvtur:\n",
      "This is not a cycle because it has to traverse every edge of the dongle twiceonce coming and once going, but once again, it is a closed walk.\n",
      "It turns out that bridges and dongles are the only complications, at least for con-nected graphs. In particular, every continuous face in a planar drawing corresponds to a closed walk in the graph. We refer to such closed walks as the discrete faces of the drawing.\n",
      "A Recursive Definition for Planar Embeddings\n",
      "The association between the continuous faces of a planar drawing and closed walks will allow us to characterize a planar drawing in terms of the closed walks that bound the continuous faces. In particular, it leads us to the discrete data type of pla-nar embeddings that we can use in place of continuous planar drawings. Namely, well define a planar embedding recursively to be the set of boundary-tracing closed walks that we could get by drawing one edge after another.\n",
      "Definition 5.8.2. A planar embedding of a connected graph consists of a nonempty set of closed walks of the graph called the discrete faces of the embedding. Planar embeddings are defined recursively as follows:\n",
      "Base case: If G is a graph consisting of a single vertex v, then a planar embedding of G has one discrete face, namely the length zero closed walk v.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 178  #184\n",
      "\n",
      "178\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "w\n",
      "\n",
      "a\n",
      "\n",
      "x\n",
      "z\n",
      "\n",
      "y\n",
      "\t\n",
      "b\n",
      "Figure 5.42\n",
      "\t\n",
      "The split a face case.\n",
      "Constructor Case (split a face): Suppose G is a connected graph with a planar embedding, and suppose a and b are distinct, nonadjacent vertices of G that appear on some discrete face of the planar embedding. That is, is a closed walk of the form\n",
      "a : : : b : : : a:\n",
      "Then the graph obtained by adding the edge fa; bg to the edges of G has a planar embedding with the same discrete faces as G, except that face is replaced by the two discrete faces\n",
      "a : : : ba\n",
      "\t\n",
      "and\n",
      "\t\n",
      "ab : : : a;\n",
      "as illustrated in Figure \n",
      ".\n",
      "Constructor Case (add a bridge): Suppose G and H are connected graphs with planar embeddings and disjoint sets of vertices. Let a be a vertex on a discrete face,\n",
      ", in the embedding of G. That is,  is of the form\n",
      "a : : : a:\n",
      "Similarly, let b be a vertex on a discrete face, , in the embedding of H . So is of the form\n",
      "b\n",
      "\t\n",
      "b:\n",
      "Then the graph obtained by connecting G and H with a new edge, fa; bg, has a planar embedding whose discrete faces are the union of the discrete faces of G and\n",
      "\n",
      "There is a special case of this rule. If G is a line graph beginning with a and ending with b,\n",
      "then the cycles into which splits are actually the same. Thats because adding edge fa; bg creates a simple cycle graph, C\n",
      "n\n",
      ", that divides the plane into an inner and an outer region with the same border. In order to maintain the correspondence between continuous faces and discrete faces, we have to allow two copies of this same cycle to count as discrete faces.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 179  #185\n",
      "\n",
      "t\n",
      "z\n",
      "\n",
      "\n",
      "u\n",
      "b y\n",
      "w\n",
      "v\n",
      "x\n",
      "Figure 5.43\n",
      "\t\n",
      "The add a bridge case.\n",
      "H , except that faces\n",
      "\t\n",
      "and\n",
      "\t\n",
      "are replaced by one new face\n",
      "a : : : ab\n",
      "\t\n",
      "ba:\n",
      "This is illustrated in Figure \n",
      ", where the faces of G and H are:\n",
      "G W faxyza; axya; ayzag\n",
      "\t\n",
      "H W fbtuvwb; btvwb; tuvtg;\n",
      "and after adding the bridge fa; bg, there is a single connected graph with faces\n",
      "faxyz\n",
      "ab\n",
      "tuvw\n",
      "ba\n",
      "; axya; ayza; btvwb; tuvtg:\n",
      "Does It Work?\n",
      "Yes! In general, a graph is planar if and only if each of its connected components has a planar embedding as defined in Definition \n",
      ". Unfortunately, proving this fact requires a bunch of mathematics that we dont cover in this textstuff like geometry and topology. Of course, that is why we went to the trouble of including Definition \n",
      "we dont want to deal with that stuff in this text and now that we have a recursive definition for planar graphs, we wont need to. Thats the good news.\n",
      "The bad news is that Definition \n",
      "looks a lot more complicated than the intuitively simple notion of a drawing where edges dont cross. It seems like it would be easier to stick to the simple notion and give proofs using pictures. Perhaps so, but your proofs are more likely to be complete and correct if you work from the discrete Definition \n",
      "instead of the continuous Definition \n",
      ".\n",
      "Where Did the Outer Face Go?\n",
      "Every planar drawing has an immediately-recognizable outer faceits the one that goes to infinity in all directions. But where is the outer face in a planar embedding?\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 180  #186\n",
      "\n",
      "180\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "r\n",
      "\t\n",
      "r\n",
      "\n",
      "t\n",
      "\t\n",
      "t\n",
      "Figure 5.44\n",
      "\t\n",
      "Two illustrations of the same embedding.\n",
      "There isnt one! Thats because there really isnt any need to distinguish one. In fact, a planar embedding could be drawn with any given face on the outside. An intuitive explanation of this is to think of drawing the embedding on a sphere instead of the plane. Then any face can be made the outside face by puncturing that face of the sphere, stretching the puncture hole to a circle around the rest of the faces, and flattening the circular drawing onto the plane.\n",
      "So pictures that show different outside boundaries may actually be illustra-tions of the same planar embedding. For example, the two embeddings shown in Figure \n",
      "are really the same.\n",
      "This is what justifies the add a bridge case in Definition \n",
      ": whatever face is chosen in the embeddings of each of the disjoint planar graphs, we can draw a bridge between them without needing to cross any other edges in the drawing, because we can assume the bridge connects two outer faces.\n",
      "5.8.3\n",
      "\t\n",
      "Eulers Formula\n",
      "The value of the recursive definition is that it provides a powerful technique for proving properties of planar graphs, namely, structural induction. For example, we will now use Definition \n",
      "and structural induction to establish one of the most basic properties of a connected planar graph; namely, the number of vertices and edges completely determines the number of faces in every possible planar embed-ding of the graph.\n",
      "Theorem 5.8.3 (Eulers Formula). If a connected graph has a planar embedding, then\n",
      "v\te C f D 2\n",
      "where v is the number of vertices, e is the number of edges, and f is the number of faces.\n",
      "For example, in Figure \n",
      ", jV j D 4, jEj D 6, and f D 4.  Sure enough,\n",
      "6 C 4 D 2, as Eulers Formula claims.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 181  #187\n",
      "\n",
      "Proof. The proof is by structural induction on the definition of planar embeddings.\n",
      "Let P .E/ be the proposition that v\n",
      "\t\n",
      "e C f D 2 for an embedding, E.\n",
      "Base case: (E is the one-vertex planar embedding). By definition, v D 1, e D 0, and f D 1, so P .E/ indeed holds.\n",
      "Constructor case (split a face): Suppose G is a connected graph with a planar embedding, and suppose a and b are distinct, nonadjacent vertices of G that appear on some discrete face, D a : : : b a, of the planar embedding.\n",
      "Then the graph obtained by adding the edge fa; bg to the edges of G has a planar embedding with one more face and one more edge than G. So the quantity v eCf will remain the same for both graphs, and since by structural induction this quantity is 2 for Gs embedding, its also 2 for the embedding of G with the added edge. So\n",
      "holds for the constructed embedding.\n",
      "Constructor case (add bridge): Suppose G and H are connected graphs with pla-nar embeddings and disjoint sets of vertices. Then connecting these two graphs with a bridge merges the two bridged faces into a single face, and leaves all other faces unchanged. So the bridge operation yields a planar embedding of a connected graph with v\n",
      "G\n",
      " C v\n",
      "H\n",
      " vertices, e\n",
      "G\n",
      " C e\n",
      "H\n",
      " C 1 edges, and f\n",
      "G\n",
      " C f\n",
      "H\n",
      " 1 faces. Since\n",
      ".v\n",
      "G\n",
      " C v\n",
      "H\n",
      " /\t.e\n",
      "G\n",
      " C e\n",
      "H\n",
      " C 1/ C .f\n",
      "G\n",
      " C f\n",
      "H\n",
      "\t\n",
      "1/\n",
      "D .v\n",
      "G\n",
      "\t\n",
      "e\n",
      "G\n",
      " C f\n",
      "G\n",
      "/ C .v\n",
      "H\n",
      "\te\n",
      "H\n",
      " C f\n",
      "H\n",
      " /\n",
      "\t\n",
      "2\n",
      "D .2/ C .2/\n",
      "\t\n",
      "2\n",
      "\t\n",
      "(by structural induction hypothesis)\n",
      "2;\n",
      "v e C f remains equal to 2 for the constructed embedding. That is, P .E/ also holds in this case.\n",
      "This completes the proof of the constructor cases, and the theorem follows by\n",
      "structural induction.\n",
      "5.8.4\n",
      "\t\n",
      "Bounding the Number of Edges in a Planar Graph\n",
      "Like Eulers formula, the following lemmas follow by structural induction from Definition \n",
      ".\n",
      "Lemma 5.8.4. In a planar embedding of a connected graph, each edge is traversed once by each of two different faces, or is traversed exactly twice by one face.\n",
      "Lemma 5.8.5. In a planar embedding of a connected graph with at least three vertices, each face is of length at least three.\n",
      "Combining Lemmas \n",
      "and \n",
      "with Eulers Formula, we can now prove that planar graphs have a limited number of edges:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 182  #188\n",
      "\n",
      "182\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "Theorem 5.8.6. Suppose a connected planar graph has v 3 vertices and e edges. Then\n",
      "e\t3v\n",
      "\t\n",
      "6:\n",
      "Proof. By definition, a connected graph is planar iff it has a planar embedding. So suppose a connected graph with v vertices and e edges has a planar embedding with f faces. By Lemma \n",
      ", every edge is traversed exactly twice by the face boundaries. So the sum of the lengths of the face boundaries is exactly 2e. Also by Lemma \n",
      ", when v 3, each face boundary is of length at least three, so this sum is at least 3f . This implies that\n",
      "But f D e\n",
      "\t\n",
      "v C 2 by Eulers formula, and substituting into (\n",
      ") gives\n",
      "3.e\tv C 2/\n",
      "\t\n",
      "2e\n",
      "3v C 6  0\n",
      "e\t3v\t6\n",
      "5.8.5\n",
      "\t\n",
      "Returning to K\n",
      "5\n",
      " and K\n",
      "3;3\n",
      "Theorem \n",
      "lets us prove that the quadrapi cant all shake hands without cross-ing. Representing quadrapi by vertices and the necessary handshakes by edges, we get the complete graph, K\n",
      "5\n",
      ". Shaking hands without crossing amounts to show-ing that K\n",
      "5\n",
      " is planar. But K\n",
      "5\n",
      " is connected, has 5 vertices and 10 edges, and 10 > 3 5 6. This violates the condition of Theorem \n",
      "required for K\n",
      "5\n",
      " to be planar, which proves\n",
      "Corollary 5.8.7. K\n",
      "5\n",
      " is not planar.\n",
      "We can also use Eulers Formula to show that K\n",
      "3;3\n",
      " is not planar. The proof is similar to that of Theorem \n",
      "except that we use the additional fact that K\n",
      "3;3\n",
      " is a bipartite graph.\n",
      "Theorem 5.8.8. K\n",
      "3;3\n",
      " is not planar.\n",
      "Proof. By contradiction. Assume K\n",
      "3;3\n",
      " is planar and consider any planar embed-ding of K\n",
      "3;3\n",
      " with f faces. Since K\n",
      "3;3\n",
      " is bipartite, we know by Theorem \n",
      "that K\n",
      "3;3\n",
      " does not contain any closed walks of odd length. By Lemma \n",
      ", every face has length at least 3. This means that every face in any embedding of K\n",
      "3;3\n",
      " must have length at least 4. Plugging this fact into the proof of Theorem \n",
      ", we find that the sum of the lengths of the face boundaries is exactly 2e and at least 4f . Hence,\n",
      "4f\n",
      "\t\n",
      "2e\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 183  #189\n",
      "\n",
      "5.8.6\n",
      "\t\n",
      "Another Characterization for Planar Graphs\n",
      "We did not choose to pick on K\n",
      "5\n",
      " and K\n",
      "3;3\n",
      " because of their application to dog houses or quadrapi shaking hands. Rather, we selected these graphs as examples because they provide another way to characterize the set of planar graphs.\n",
      "Theorem 5.8.9 (Kuratowski). A graph is not planar if and only if it contains K\n",
      "5\n",
      " or K\n",
      "3;3\n",
      " as a minor.\n",
      "Definition 5.8.10. A minor of a graph G is a graph that can be obtained by re-peatedly\n",
      "deleting vertices, deleting edges, and merging adjacent vertices of G. Merging two adjacent vertices, n\n",
      "1\n",
      " and n\n",
      "2\n",
      " of a graph means deleting the two ver-tices and then replacing them by a new merged vertex, m, adjacent to all the vertices that were adjacent to either of n\n",
      "1\n",
      " or n\n",
      "2\n",
      ", as illustrated in Figure \n",
      ".\n",
      "For example, Figure \n",
      "illustrates why C\n",
      "3\n",
      " is a minor of the graph in Fig-ure \n",
      "(a). In fact C\n",
      "3\n",
      " is a minor of a connected graph G if and only if G is not a tree.\n",
      "We will not prove Theorem \n",
      "here, nor will we prove the following handy facts, which are obvious given the continuous Definition \n",
      ", and which can be proved using the recursive Definition \n",
      ".\n",
      "Lemma 5.8.11. Deleting an edge from a planar graph leaves another planar graph.\n",
      "Corollary 5.8.12. Deleting a vertex from a planar graph, along with all its incident edges, leaves another planar graph.\n",
      "Theorem 5.8.13. Any subgraph of a planar graph is planar.\n",
      "Theorem 5.8.14. Merging two adjacent vertices of a planar graph leaves another planar graph.\n",
      "\n",
      "The three operations can be performed in any order and in any quantities, or not at all.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 184  #190\n",
      "\n",
      "184\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "\n",
      "n\n",
      "1\n",
      "\n",
      "!\n",
      "\t\n",
      "n\n",
      "1\n",
      "\n",
      "  !\n",
      "\t\n",
      "m\n",
      "\n",
      "n\n",
      "2\n",
      "\n",
      "n\n",
      "2\n",
      "\n",
      "Figure 5.45\n",
      "\t\n",
      "Merging adjacent vertices n\n",
      "1\n",
      " and n\n",
      "2\n",
      " into new vertex, m.\n",
      "5.8.7\n",
      "\t\n",
      "Coloring Planar Graphs\n",
      "Weve covered a lot of ground with planar graphs, but not nearly enough to prove the famous 4-color theorem. But we can get awfully close. Indeed, we have done almost enough work to prove that every planar graph can be colored using only 5 colors. We need only one more lemma:\n",
      "Lemma 5.8.15. Every planar graph has a vertex of degree at most five.\n",
      "Proof. By contradiction. If every vertex had degree at least 6, then the sum of the vertex degrees is at least 6v, but since the sum of the vertex degrees equals 2e, by the Handshake Lemma (Lemma \n",
      "), we have e 3v contradicting the fact that\n",
      "e\t3v\t6 < 3v by Theorem \n",
      ".\n",
      "Theorem 5.8.16. Every planar graph is five-colorable.\n",
      "Proof. The proof will be by strong induction on the number, v, of vertices, with induction hypothesis:\n",
      "Every planar graph with v vertices is five-colorable.\n",
      "Base cases (v\n",
      "\t\n",
      "5): immediate.\n",
      "Inductive case: Suppose G is a planar graph with v C 1 vertices. We will describe a five-coloring of G.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 185  #191\n",
      "\n",
      "\n",
      "\n",
      "v\n",
      "2\n",
      "e\n",
      "1\n",
      "\n",
      "v\n",
      "1\n",
      "(a)\n",
      "\t\n",
      "(b)\n",
      "\t\n",
      "(c)\n",
      "v\n",
      "3\n",
      "\n",
      "e\n",
      "2\n",
      "\n",
      "(d)\n",
      "\t\n",
      "(e)\n",
      "\t\n",
      "(f)\n",
      "Figure 5.46 One method by which the graph in (a) can be reduced to C\n",
      "3\n",
      " (f), thereby showing that C\n",
      "3\n",
      " is a minor of the graph. The steps are: merging the nodes incident to e\n",
      "1\n",
      " (b), deleting v\n",
      "1\n",
      " and all edges incident to it (c), deleting v\n",
      "2\n",
      " (d), delet-ing e\n",
      "2\n",
      ", and deleting v\n",
      "3\n",
      " (f).\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 186  #192\n",
      "\n",
      "a geometric construct that were about to rediscover!\n",
      "A polyhedron is a convex, three-dimensional region bounded by a finite number of polygonal faces. If the faces are identical regular polygons and an equal number of polygons meet at each corner, then the polyhedron is regular. Three examples of regular polyhedra are shown in Figure \n",
      ": the tetrahedron, the cube, and the octahedron.\n",
      "We can determine how many more regular polyhedra there are by thinking about planarity. Suppose we took any polyhedron and placed a sphere inside it. Then we could project the polyhedron face boundaries onto the sphere, which would give an image that was a planar graph embedded on the sphere, with the images of the\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 187  #193\n",
      "\n",
      "\n",
      "(a)\n",
      "\t\n",
      "(b)\n",
      "\t\n",
      "(c)\n",
      "Figure 5.47\n",
      "\t\n",
      "The tetrahedron (a), cube (b), and octahedron (c).\n",
      "\n",
      "(a)\n",
      "\t\n",
      "(b)\n",
      "\t\n",
      "(c)\n",
      "Figure 5.48 Planar embeddings of the tetrahedron (a), cube (b, and octahe-dron (c).\n",
      "corners of the polyhedron corresponding to vertices of the graph. Weve already observed that embeddings on a sphere are the same as embeddings on the plane, so Eulers formula for planar graphs can help guide our search for regular polyhedra.\n",
      "For example, planar embeddings of the three polyhedra in Figure \n",
      "are shown in Figure \n",
      ".\n",
      "Let m be the number of faces that meet at each corner of a polyhedron, and let n be the number of edges on each face. In the corresponding planar graph, there are m edges incident to each of the v vertices. By the Handshake Lemma \n",
      ", we know:\n",
      "mv D 2e:\n",
      "Also, each face is bounded by n edges. Since each edge is on the boundary of two faces, we have:\n",
      "nf D 2e\n",
      "Solving for v and f in these equations and then substituting into Eulers formula\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 188  #194\n",
      "\n",
      "188\n",
      "\t\n",
      "Chapter 5\n",
      "\t\n",
      "Graph Theory\n",
      "Figure 5.49\n",
      "\t\n",
      "The only possible regular polyhedra.\n",
      "Equation \n",
      "places strong restrictions on the structure of a polyhedron. Every nondegenerate polygon has at least 3 sides, so n 3. And at least 3 polygons must meet to form a corner, so m 3. On the other hand, if either n or m were 6 or more, then the left side of the equation could be at most 1=3 C 1=6 D 1=2, which is less than the right side. Checking the finitely-many cases that remain turns up only five solutions, as shown in Figure \n",
      ". For each valid combination of n and m, we can compute the associated number of vertices v, edges e, and faces f . And polyhedra with these properties do actually exist. The largest polyhedron, the dodecahedron, was the other great mathematical secret of the Pythagorean sect.\n",
      "The 5 polyhedra in Figure \n",
      "are the only possible regular polyhedra. So if you want to put more than 20 geocentric satellites in orbit so that they uniformly blanket the globetough luck!\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 189  #195\n",
      "\n",
      "Directed Graphs\n",
      "\n",
      "6.1\n",
      "\t\n",
      "Definitions\n",
      "So far, we have been working with graphs with undirected edges. A directed edge is an edge where the endpoints are distinguishedone is the head and one is the tail. In particular, a directed edge is specified as an ordered pair of vertices u, v and is denoted by .u; v/ or u ! v. In this case, u is the tail of the edge and v is the head. For example, see Figure \n",
      ".\n",
      "A graph with directed edges is called a directed graph or digraph.\n",
      "Definition 6.1.1. A directed graph G D .V; E/ consists of a nonempty set of nodes V and a set of directed edges E. Each edge e of E is specified by an ordered pair of vertices u; v 2 V . A directed graph is simple if it has no loops (that is, edges of the form u ! u) and no multiple edges.\n",
      "Since we will focus on the case of simple directed graphs in this chapter, we will generally omit the word simple when referring to them. Note that such a graph can contain an edge u ! v as well as the edge v ! u since these are different edges (for example, they have a different tail).\n",
      "Directed graphs arise in applications where the relationship represented by an edge is 1-way or asymmetric. Examples include: a 1-way street, one person likes another but the feeling is not necessarily reciprocated, a communication channel such as a cable modem that has more capacity for downloading than uploading, one entity is larger than another, and one job needs to be completed before another job can begin. Well see several such examples in this chapter and also in Chapter \n",
      ".\n",
      "Most all of the definitions for undirected graphs from Chapter \n",
      "carry over in a natural way for directed graphs. For example, two directed graphs G\n",
      "1\n",
      " D .V\n",
      "1\n",
      "; E\n",
      "1\n",
      "/ and G\n",
      "2\n",
      " D .V\n",
      "2\n",
      "; E\n",
      "2\n",
      "/ are isomorphic if there exists a bijection f W V\n",
      "1\n",
      " ! V\n",
      "2\n",
      " such that for every pair of vertices u; v 2 V\n",
      "1\n",
      ",\n",
      "u ! v 2 E\n",
      "1\n",
      "\t\n",
      "IFF\n",
      "\t\n",
      "f .u/ ! f .v/ 2 E\n",
      "2\n",
      ":\n",
      "tail\n",
      "\t\n",
      "e\n",
      "\t\n",
      "head\n",
      "\n",
      "u\n",
      "\t\n",
      "v\n",
      "Figure 6.1\n",
      "\t\n",
      "A directed edge e D .u; v/. u is the tail of e and v is the head of e.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 190  #196\n",
      "\n",
      "190\n",
      "\t\n",
      "Chapter 6\n",
      "\t\n",
      "Directed Graphs\n",
      "b\n",
      "\n",
      "a\n",
      "\n",
      "c\n",
      "d\n",
      "Figure 6.2\n",
      "\t\n",
      "A 4-node directed graph with 6 edges.\n",
      "Directed graphs have adjacency matrices just like undirected graphs. In the case of a directed graph G D .V; E/, the adjacency matrix A\n",
      "G\n",
      " D fa\n",
      "ij\n",
      " g is defined so that\n",
      "(\n",
      "a\n",
      "ij \n",
      "D\n",
      "\n",
      "\n",
      "1\n",
      "\t\n",
      "if i ! j 2 E\n",
      "0\n",
      "\t\n",
      "otherwise.\n",
      "The only difference is that the adjacency matrix for a directed graph is not neces-sarily symmetric (that is, it may be that A\n",
      "T\n",
      "G\n",
      "  A\n",
      "G\n",
      ").\n",
      "6.1.1\n",
      "\t\n",
      "Degrees\n",
      "With directed graphs, the notion of degree splits into indegree and outdegree. For example, indegree.c/ D 2 and outdegree.c/ D 1 for the graph in Figure \n",
      ". If a node has outdegree 0, it is called a sink; if it has indegree 0, it is called a source. The graph in Figure \n",
      "has one source (node a) and no sinks.\n",
      "6.1.2\n",
      "\t\n",
      "Directed Walks, Paths, and Cycles\n",
      "The definitions for (directed) walks, paths, and cycles in a directed graph are similar to those for undirected graphs except that the direction of the edges need to be consistent with the order in which the walk is traversed.\n",
      "Definition 6.1.2. A directed walk (or more simply, a walk) in a directed graph G is a sequence of vertices v\n",
      "0\n",
      ", v\n",
      "1\n",
      ", . . . , v\n",
      "k\n",
      " and edges\n",
      "v\n",
      "0\n",
      " ! v\n",
      "1\n",
      "; v\n",
      "1\n",
      " ! v\n",
      "2\n",
      "; : : : ; v\n",
      "k1\n",
      "\t\n",
      "! v\n",
      "k\n",
      "such that v\n",
      "i1\n",
      " ! v\n",
      "i\n",
      " is an edge of G for all i where 0 i < k. A directed path (or path) in a directed graph is a walk where the nodes in the walk are all different. A directed closed walk (or closed walk) in a directed graph is a walk\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 191  #197\n",
      "\n",
      "where v\n",
      "0\n",
      " D v\n",
      "k\n",
      ". A directed cycle (or cycle) in a directed graph is a closed walk where all the vertices v\n",
      "i\n",
      " are different for 0 i < k.\n",
      "As with undirected graphs, we will typically refer to a walk in a directed graph by a sequence of vertices. For example, for the graph in Figure \n",
      ",\n",
      "a, b, c, b, d is a walk, a, b, d is a path,\n",
      "d , c, b, c, b, d is a closed walk, and b, d , c, b is a cycle.\n",
      "Note that b, c, b is also a cycle for the graph in Figure \n",
      ". This is a cycle of length 2. Such cycles are not possible with undirected graphs.\n",
      "Also note that\n",
      "c; b; a; d\n",
      "is not a walk in the graph shown in Figure \n",
      ", since b ! a is not an edge in this graph. (You are not allowed to traverse edges in the wrong direction as part of a walk.)\n",
      "A path or cycle in a directed graph is said to be Hamiltonian if it visits every node in the graph. For example, a, b, d , c is the only Hamiltonian path for the graph in Figure \n",
      ". The graph in Figure \n",
      "does not have a Hamiltonian cycle.\n",
      "A walk in a directed graph is said to be Eulerian if it contains every edge. The graph shown in Figure \n",
      "does not have an Eulerian walk. Can you see why not? (Hint: Look at node a.)\n",
      "6.1.3\n",
      "\t\n",
      "Strong Connectivity\n",
      "The notion of being connected is a little more complicated for a directed graph than it is for an undirected graph. For example, should we consider the graph in Figure \n",
      "to be connected? There is a path from node a to every other node so on that basis, we might answer Yes. But there is no path from nodes b, c, or d to node a, and so on that basis, we might answer No. For this reason, graph theorists have come up with the notion of strong connectivity for directed graphs.\n",
      "Definition 6.1.3. A directed graph G D .V; E/ is said to be strongly connected if for every pair of nodes u; v 2 V , there is a directed path from u to v (and vice-versa) in G.\n",
      "For example, the graph in Figure \n",
      "is not strongly connected since there is no directed path from node b to node a. But if node a is removed, the resulting graph would be strongly connected.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 192  #198\n",
      "\n",
      "192\n",
      "\t\n",
      "Chapter 6\n",
      "\t\n",
      "Directed Graphs\n",
      "b\n",
      "\n",
      "\n",
      "e\n",
      "\n",
      "a\n",
      "\n",
      "c\n",
      "d\n",
      "Figure 6.3\n",
      "\t\n",
      "A 4-node directed acyclic graph (DAG).\n",
      "A directed graph is said to be weakly connected (or, more simply, connected) if the corresponding undirected graph (where directed edges u ! v and/or v ! u are replaced with a single undirected edge fu; vg is connected. For example, the graph in Figure \n",
      "is weakly connected.\n",
      "6.1.4\n",
      "\t\n",
      "DAGs\n",
      "If an undirected graph does not have any cycles, then it is a tree or a forest. But what does a directed graph look like if it has no cycles? For example, consider the graph in Figure \n",
      ". This graph is weakly connected and has no directed cycles but it certainly does not look like a tree.\n",
      "Definition 6.1.4. A directed graph is called a directed acyclic graph (or, DAG) if it does not contain any directed cycles.\n",
      "A first glance, DAGs dont appear to be particularly interesting. But first im-pressions are not always accurate. In fact, DAGs arise in many scheduling and optimization problems and they have several interesting properties. We will study them extensively in Chapter \n",
      ".\n",
      "\n",
      "6.2\n",
      "\t\n",
      "Tournament Graphs\n",
      "Suppose that n players compete in a round-robin tournament and that for every pair of players u and v, either u beats v or v beats u. Interpreting the results of a round-robin tournament can be problematicthere might be all sorts of cycles where x beats y and y beats z, yet z beats x. Who is the best player? Graph theory does not solve this problem but it can provide some interesting perspectives.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 193  #199\n",
      "\n",
      "a\n",
      "\t\n",
      "b\n",
      "\n",
      "e\n",
      "\n",
      "c\n",
      "d\n",
      "Figure 6.4\n",
      "\t\n",
      "A 5-node tournament graph.\n",
      "The results of a round-robin tournament can be represented with a tournament graph. This is a directed graph in which the vertices represent players and the edges indicate the outcomes of games. In particular, an edge from u to v indicates that player u defeated player v. In a round-robin tournament, every pair of players has a match. Thus, in a tournament graph there is either an edge from u to v or an edge from v to u (but not both) for every pair of distinct vertices u and v. An example of a tournament graph is shown in Figure \n",
      ".\n",
      "6.2.1\n",
      "\t\n",
      "Finding a Hamiltonian Path in a Tournament Graph\n",
      "Were going to prove that in every round-robin tournament, there exists a ranking of the players such that each player lost to the player one position higher. For example, in the tournament corresponding to Figure \n",
      ", the ranking\n",
      "a > b > d > e > c\n",
      "satisfies this criterion, because b lost to a, d lost to b, e lost to d , and c lost to e. In graph terms, proving the existence of such a ranking amounts to proving that every tournament graph has a Hamiltonian path.\n",
      "Theorem 6.2.1. Every tournament graph contains a directed Hamiltonian path.\n",
      "Proof. We use strong induction. Let P .n/ be the proposition that every tournament graph with n vertices contains a directed Hamiltonian path.\n",
      "Base case: P .1/ is trivially true; every graph with a single vertex has a Hamiltonian path consisting of only that vertex.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 194  #200\n",
      "\n",
      "194\n",
      "\t\n",
      "Chapter 6\n",
      "\t\n",
      "Directed Graphs\n",
      "\n",
      "T\n",
      "v \n",
      "\n",
      "F\n",
      "Figure 6.5\n",
      "\t\n",
      "The sets T and F in a tournament graph.\n",
      "Inductive step: For n 1, we assume that P .1/, . . . , P .n/ are all true and prove P .n C 1/. Consider a tournament graph G D .V; E/ with n C 1 players. Select one vertex v arbitrarily. Every other vertex in the tournament either has an edge to vertex v or an edge from vertex v. Thus, we can partition the remaining vertices into two corresponding sets, T and F , each containing at most n vertices, where\n",
      "D f u j u ! v 2 E g and F D f u j v ! u 2 E g. For example, see Figure \n",
      ".\n",
      "The vertices in T together with the edges that join them form a smaller tourna-ment. Thus, by strong induction, there is a Hamiltonian path within T . Similarly, there is a Hamiltonian path within the tournament on the vertices in F . Joining the path in T to the vertex v followed by the path in F gives a Hamiltonian path through the whole tournament. As special cases, if T or F is empty, then so is the\n",
      "corresponding portion of the path.\n",
      "The ranking defined by a Hamiltonian path is not entirely satisfactory. For ex-ample, in the tournament associated with Figure \n",
      ", notice that the lowest-ranked player, c, actually defeated the highest-ranked player, a.\n",
      "In practice, players are typically ranked according to how many victories they achieve. This makes sense for several reasons. One not-so-obvious reason is that if the player with the most victories does not beat some other player v, he is guaran-teed to have at least beaten a third player who beat v. Well prove this fact shortly. But first, lets talk about chickens.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 195  #201\n",
      "\n",
      "6.2. Tournament Graphs\n",
      "\t\n",
      "195\n",
      "king \n",
      "a\n",
      "\t\n",
      "b \n",
      "king\n",
      "\n",
      "king \n",
      "\n",
      " not a king\n",
      "d\n",
      "\t\n",
      "c\n",
      "Figure 6.6\n",
      "\t\n",
      "A 4-chicken tournament in which chickens a, b, and d are kings.\n",
      ".\n",
      "6.2.2\n",
      "\t\n",
      "The King Chicken Theorem\n",
      "Suppose that there are n chickens in a farmyard. Chickens are rather aggressive birds that tend to establish dominance in relationships by pecking. (Hence the term pecking order.) In particular, for each pair of distinct chickens, either the first pecks the second or the second pecks the first, but not both. We say that chicken u virtually pecks chicken v if either:\n",
      "Chicken u directly pecks chicken v, or\n",
      "Chicken u pecks some other chicken w who in turn pecks chicken v.\n",
      "A chicken that virtually pecks every other chicken is called a king chicken.\n",
      "We can model this situation with a tournament digraph. The vertices are chick-ens, and an edge u ! v indicates that chicken u pecks chicken v. In the tournament shown in Figure \n",
      ", three of the four chickens are kings. Chicken c is not a king in this example since it does not peck chicken b and it does not peck any chicken that pecks chicken b. Chicken a is a king since it pecks chicken d , who in turn pecks chickens b and c.\n",
      "Theorem 6.2.2 (King Chicken Theorem). The chicken with the largest outdegree in an n-chicken tournament is a king.\n",
      "Proof. By contradiction. Let u be a node in a tournament graph G D .V; E/ with maximum outdegree and suppose that u is not a king. Let Y D f v j u ! v 2 E g be the set of chickens that chicken u pecks. Then outdegree.u/ D jY j.\n",
      "Since u is not a king, there is a chicken x Y (that is, x is not pecked by chicken u) and that is not pecked by any chicken in Y . Since for any pair of chickens, one pecks the other, this means that x pecks u as well as every chicken in Y . This means that\n",
      "outdegree.x/ D jY j C 1 > outdegree.u/:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 196  #202\n",
      "\n",
      "196\n",
      "\t\n",
      "Chapter 6\n",
      "\t\n",
      "Directed Graphs\n",
      "\n",
      "Figure 6.7\n",
      "\t\n",
      "A 5-chicken tournament in which every chicken is a king.\n",
      "But u was assumed to be the node with the largest degree in the tournament, so\n",
      "we have a contradiction. Hence, u must be a king.\n",
      "Theorem \n",
      "means that if the player with the most victories is defeated by another player x, then at least he/she defeats some third player that defeats x. In this sense, the player with the most victories has some sort of bragging rights over every other player. Unfortunately, as Figure \n",
      "illustrates, there can be many other players with such bragging rights, even some with fewer victories. Indeed, for some tournaments, it is possible that every player is a king. For example, consider the tournament illustrated in Figure \n",
      ".\n",
      "\n",
      "6.3\n",
      "\t\n",
      "Communication Networks\n",
      "While reasoning about chickens pecking each other may be amusing (to mathe-maticians, at least), the use of directed graphs to model communication networks is very serious business. In the context of communication problems, vertices repre-sent computers, processors, or switches, and edges represent wires, fiber, or other transmission lines through which data flows. For some communication networks, like the Internet, the corresponding graph is enormous and largely chaotic. Highly structured networks, such as an array or butterfly, by contrast, find application in telephone switching systems and the communication hardware inside parallel com-puters.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 197  #203\n",
      "\n",
      "6.3.1\n",
      "\t\n",
      "Packet Routing\n",
      "Whatever architecture is chosen, the goal of a communication network is to get data from inputs to outputs. In this text, we will focus on a model in which the data to be communicated is in the form of a packet. In practice, a packet would consist of a fixed amount of data, and a message (such as a web page or a movie) would consist of many packets.\n",
      "For simplicity, we will restrict our attention to the scenario where there is just one packet at every input and where there is just one packet destined for each output. We will denote the number of inputs and output by N and we will often assume that N is a power of two.\n",
      "We will specify the desired destinations of the packets by a permutation\n",
      "of 0, 1, . . . , N 1. So a permutation, , defines a routing problem: get a packet that starts at input i to output .i/ for 0 i < N . A routing P that solves a routing problem is a set of paths from each input to its specified output. That is, P is a set of paths, P\n",
      "i\n",
      " , for i D 0; : : : ; N 1, where P\n",
      "i\n",
      " goes from input i to output .i/.\n",
      "Of course, the goal is to get all the packets to their destinations as quickly as possible using as little hardware as possible. The time needed to get the packages to their destinations depends on several factors, such as how many switches they need to go through and how many packets will need to cross the same wire. We will assume that only one packet can cross a wire at a time. The complexity of the hardware depends on factors such as the number of switches needed and the size of the switches.\n",
      "Lets see how all this works with an examplerouting packets on a complete binary tree.\n",
      "6.3.2\n",
      "\t\n",
      "The Complete Binary Tree\n",
      "One of the simplest structured communications networks is a complete binary tree.\n",
      "A complete binary tree with 4 inputs and 4 outputs is shown in Figure \n",
      ".\n",
      "In this diagram and many that follow, the squares represent terminals (that is, the inputs and outputs), and the circles represent switches, which direct packets through the network. A switch receives packets on incoming edges and relays them forward along the outgoing edges. Thus, you can imagine a data packet hopping through the network from an input terminal, through a sequence of switches joined by directed edges, to an output terminal.\n",
      "Recall that there is a unique simple path between every pair of vertices in a tree. So the natural way to route a packet of data from an input terminal to an output terminal in the complete binary tree is along the corresponding directed path. For\n",
      "\n",
      "1\n",
      "A permutation of a sequence is a reordering of the sequence.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 198  #204\n",
      "\n",
      "198\n",
      "\t\n",
      "Chapter 6\n",
      "\t\n",
      "Directed Graphs\n",
      "\n",
      "in\n",
      "0\n",
      "\tout\n",
      "0\n",
      "\tin\n",
      "1\n",
      "\tout\n",
      "1\n",
      "\tin\n",
      "2\n",
      "\tout\n",
      "2\n",
      "\tin\n",
      "3\n",
      "\t\n",
      "out\n",
      "3\n",
      "Figure 6.8 A 4-input, 4-output complete binary tree. The squares represent termi-nals (input and output registers) and the circles represent switches. Directed edges represent communication channels in the network through which data packets can move. The unique path from input 1 to output 3 is shown in bold.\n",
      "example, the route of a packet traveling from input 1 to output 3 is shown in bold in Figure \n",
      ".\n",
      "6.3.3\n",
      "\t\n",
      "Network Diameter\n",
      "The delay between the time that a packet arrives at an input and the time that it reaches its designated output is referred to as latency and it is a critical issue in communication networks. If congestion is not a factor, then this delay is generally proportional to the length of the path a packet follows. Assuming it takes one time unit to travel across a wire, and that there are no additional delays at switches, the delay of a packet will be the number of wires it crosses going from input to output.\n",
      "Generally a packet is routed from input to output using the shortest path possible. The length of this shortest path is the distance between the input and output. With a shortest path routing, the worst possible delay is the distance between the input and output that are farthest apart. This is called the diameter of the network. In other words, the diameter of a network\n",
      "is the maximum length of any shortest\n",
      "\n",
      "Latency can also be measured as the number of switches that a packet must pass through when traveling between the most distant input and output, since switches usually have the biggest impact on network speed. For example, in the complete binary tree example, the packet traveling from input 1 to output 3 crosses 5 switches, which is 1 less than the number of edges traversed.\n",
      "The usual definition of diameter for a general graph (simple or directed) is the largest distance between any two vertices, but in the context of a communication network, were only interested in the distance between inputs and outputs, not between arbitrary pairs of vertices.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 199  #205\n",
      "\n",
      "\n",
      "path between an input and an output. For example, in the complete binary tree shown in Figure \n",
      ", the distance from input 1 to output 3 is six. No input and output are farther apart than this, so the diameter of this tree is also six.\n",
      "More generally, the diameter of a complete binary tree with N inputs and outputs is 2 log N C 2. (All logarithms in this lectureand in most of computer science are base 2.) This is quite good, because the logarithm function grows very slowly. We could connect 2\n",
      "20\n",
      " D 1;048;576 inputs and outputs using a complete binary tree and the worst input-output delay for any packet would be this diameter, namely, 2 log.2\n",
      "20\n",
      "/ C 2 D 42.\n",
      "6.3.4\n",
      "\t\n",
      "Switch Size\n",
      "One way to reduce the diameter of a network (and hence the latency needed to route packets) is to use larger switches. For example, in the complete binary tree, most of the switches have three incoming edges and three outgoing edges, which makes them 3 3 switches. If we had 4 4 switches, then we could construct a complete ternary tree with an even smaller diameter. In principle, we could even connect up all the inputs and outputs via a single monster N N switch, as shown in Figure \n",
      ". In this case, the network would consist of a single switch and the latency would be 2.\n",
      "This isnt very productive, however, since weve just concealed the original net-work design problem inside this abstract monster switch. Eventually, well have to design the internals of the monster switch using simpler components, and then were right back where we started. So the challenge in designing a communication network is figuring out how to get the functionality of an N N switch using fixed size, elementary devices, like 3 3 switches.\n",
      "6.3.5\n",
      "\t\n",
      "Switch Count\n",
      "Another goal in designing a communication network is to use as few switches as possible. The number of switches in a complete binary tree is 1 C 2 C 4 C 8 C\n",
      "C N D 2N 1, since there is 1 switch at the top (the root switch), 2 below it, 4 below those, and so forth. This is nearly the best possible with 3 3 switches,\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 200  #206\n",
      "\n",
      "200\n",
      "\t\n",
      "Chapter 6\n",
      "\t\n",
      "Directed Graphs\n",
      "since at least one switch will be needed for each pair of inputs and outputs.\n",
      "6.3.6\n",
      "\t\n",
      "Congestion\n",
      "The complete binary tree has a fatal drawback: the root switch is a bottleneck. At best, this switch must handle an enormous amount of traffic: every packet traveling from the left side of the network to the right or vice-versa. Passing all these packets through a single switch could take a long time. At worst, if this switch fails, the network is broken into two equal-sized pieces.\n",
      "The traffic through the root depends on the routing problem. For example, if the routing problem is given by the identity permutation, .i/ WWD i, then there is an easy routing P that solves the problem: let P\n",
      "i\n",
      " be the path from input i up through one switch and back down to output i. On the other hand, if the problem was given by .i/ WWD .N 1/ i, then in any solution P for , each path P\n",
      "i\n",
      " beginning at input i must eventually loop all the way up through the root switch and then travel back down to output .N 1/ i.\n",
      "We can distinguish between a good set of paths and a bad set based on congestion. The congestion of a routing, P , is equal to the largest number of paths in P that pass through a single switch. Generally, lower congestion is better since packets can be delayed at an overloaded switch.\n",
      "By extending the notion of congestion to networks, we can also distinguish be-tween good and bad networks with respect to bottleneck problems. For each routing problem, , for the network, we assume a routing is chosen that optimizes congestion, that is, that has the minimum congestion among all routings that solve\n",
      ". Then the largest congestion that will ever be suffered by a switch will be the maximum congestion among these optimal routings. This maxi-min congestion is called the congestion of the network.\n",
      "You may find it helpful to think about max congestion in terms of a value game. You design your spiffy, new communication network; this defines the game. Your opponent makes the first move in the game: she inspects your network and specifies a permutation routing problem that will strain your network. You move second: given her specification, you choose the precise paths that the packets should take through your network; youre trying to avoid overloading any one switch. Then her next move is to pick a switch with as large as possible a number of packets passing through it; this number is her score in the competition. The max congestion of your network is the largest score she can ensure; in other words, it is precisely the max-value of this game.\n",
      "For example, if your enemy were trying to defeat the complete binary tree, she\n",
      "would choose a permutation like .i/ D .N 1/ i. Then for every packet i, you would be forced to select a path P\n",
      "i; .i/\n",
      " passing through the root switch. Then, your\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 201  #207\n",
      "\n",
      "Table 6.1\n",
      "\t\n",
      "A summary of the attributes of the complete binary tree.\n",
      "in\n",
      "0\n",
      "\n",
      "in\n",
      "1\n",
      "\n",
      "in\n",
      "2\n",
      "\n",
      "in\n",
      "3\n",
      "\n",
      "out\n",
      "0\n",
      "\t\n",
      "out\n",
      "1\n",
      "\t\n",
      "out\n",
      "2\n",
      "\t\n",
      "out\n",
      "3\n",
      "Figure 6.10\n",
      "\t\n",
      "A 4\n",
      "\t\n",
      "4 2-dimensional array.\n",
      "enemy would choose the root switch and achieve a score of N . In other words, the max congestion of the complete binary tree is N which is horrible!\n",
      "We have summarized the results of our analysis of the complete binary tree in Table \n",
      ". Overall, the complete binary tree does well in every category except the lastcongestion, and that is a killer in practice. Next, we will look at a network that solves the congestion problem, but at a very high cost.\n",
      "6.3.7\tThe 2-d Array\n",
      "An illustration of the N N 2-d array (also known as the grid or crossbar) is shown in Figure \n",
      "for the case when N D 4.\n",
      "The diameter of the 4 4 2-d array is 8, which is the number of edges between input 0 and output 3. More generally, the diameter of a 2-d array with N inputs and outputs is 2N , which is much worse than the diameter of the complete binary tree (2 log N C 2). On the other hand, replacing a complete binary tree with a 2-d array almost eliminates congestion.\n",
      "Theorem 6.3.1. The congestion of an N -input 2-d array is 2.\n",
      "Proof. First, we show that the congestion is at most 2. Let be any permutation. Define a solution, P , for to be the set of paths, P\n",
      "i\n",
      " , where P\n",
      "i\n",
      " goes to the right\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 202  #208\n",
      "\n",
      "Table 6.2\n",
      "\t\n",
      "Comparing the N -input 2-d array to the N -input complete binary tree.\n",
      "from input i to column .i/ and then goes down to output .i/. In this solution, the switch in row i and column j encounters at most two packets: the packet originating at input i and the packet destined for output j .\n",
      "Next, we show that the congestion is at least 2.  This follows because in any\n",
      "routing problem,\t, where\n",
      "\t\n",
      ".0/ D 0 and\t.N\t1/ D N\n",
      "\t\n",
      "1, two packets must\n",
      "pass through the lower left switch.\n",
      "The characteristics of the 2-d array are recorded in Table \n",
      ". The crucial entry in this table is the number of switches, which is N \n",
      "2\n",
      ". This is a major defect of the 2-d array; a network with N D 1000 inputs would require a million 2 2 switches! Still, for applications where N is small, the simplicity and low congestion of the array make it an attractive choice.\n",
      "6.3.8\tThe Butterfly\n",
      "The Holy Grail of switching networks would combine the best properties of the complete binary tree (low diameter, few switches) and the array (low congestion). The butterfly is a widely-used compromise between the two. A butterfly network with N D 8 inputs is shown in Figure \n",
      ".\n",
      "The structure of the butterfly is certainly more complicated than that of the com-plete binary or 2-d array. Lets see how it is constructed.\n",
      "All the terminals and switches in the network are in N rows. In particular, input i is at the left end of row i, and output i is at the right end of row i. Now lets label the rows in binary so that the label on row i is the binary number b\n",
      "1\n",
      "b\n",
      "2\n",
      " : : : b\n",
      "log\n",
      " \n",
      "N\n",
      " that represents the integer i.\n",
      "Between the inputs and outputs, there are log.N / C 1 levels of switches, num-bered from 0 to log N . Each level consists of a column of N switches, one per row. Thus, each switch in the network is uniquely identified by a sequence .b\n",
      "1\n",
      ", b\n",
      "2\n",
      ", . . . , b\n",
      "log\n",
      " \n",
      "N\n",
      " , l/, where b\n",
      "1\n",
      "b\n",
      "2\n",
      " : : : b\n",
      "log\n",
      " \n",
      "N\n",
      " is the switchs row in binary and l is the switchs level.\n",
      "All that remains is to describe how the switches are connected up. The basic\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 203  #209\n",
      "\n",
      "levels\n",
      "0\n",
      "\t\n",
      "1\n",
      "\t\n",
      "2\n",
      "\t\n",
      "3\n",
      "in\n",
      "0\n",
      "\n",
      " out\n",
      "0\n",
      "\n",
      "000\n",
      "in\n",
      "1\n",
      "\n",
      " out\n",
      "1\n",
      "\n",
      "001\n",
      "in\n",
      "2\n",
      "\n",
      " out\n",
      "2\n",
      "\n",
      "010\n",
      "in\n",
      "3\n",
      "\n",
      " out\n",
      "3\n",
      "\n",
      "011\n",
      "in\n",
      "4\n",
      "\n",
      " out\n",
      "4\n",
      "\n",
      "100\n",
      "in\n",
      "5\n",
      "\n",
      " out\n",
      "5\n",
      "\n",
      "101\n",
      "in\n",
      "6\n",
      "\n",
      " out\n",
      "6\n",
      "\n",
      "110\n",
      "in\n",
      "7\n",
      "\n",
      " out\n",
      "7\n",
      "\n",
      "111\n",
      "Figure 6.11\n",
      "\t\n",
      "An 8-input/output butterfly.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 204  #210\n",
      "\n",
      "204\n",
      "\t\n",
      "Chapter 6\n",
      "\t\n",
      "Directed Graphs\n",
      "connection pattern is expressed below in a compact notation:\n",
      "This says that there are directed edges from switch .b\n",
      "1\n",
      "; b\n",
      "2\n",
      "; : : : ; b\n",
      "log\n",
      " \n",
      "N\n",
      " ; l/ to two switches in the next level. One edges leads to the switch in the same row, and the other edge leads to the switch in the row obtained by inverting the .l C1/st bit b\n",
      "lC1\n",
      ". For example, referring back to the illustration of the size N D 8 butterfly, there is an edge from switch .0; 0; 0; 0/ to switch (0, 0, 0, 1), which is in the same row, and to switch .1; 0; 0; 1/, which is in the row obtained by inverting bit l C 1 D 1.\n",
      "The butterfly network has a recursive structure; specifically, a butterfly of size 2N consists of two butterflies of size N and one additional level of switches. Each switch in the additional level has directed edges to a corresponding switch in each of the smaller butterflies. For example, see Figure \n",
      ".\n",
      "Despite the relatively complicated structure of the butterfly, there is a simple way to route packets through its switches. In particular, suppose that we want to send a packet from input x\n",
      "1\n",
      "x\n",
      "2\n",
      " : : : x\n",
      "log\n",
      " \n",
      "N\n",
      " to output y\n",
      "1\n",
      "y\n",
      "2\n",
      " : : : y\n",
      "log\n",
      " \n",
      "N\n",
      " . (Here we are specifying the input and output numbers in binary.) Roughly, the plan is to correct the first bit on the first level, correct the second bit on the second level, and so forth. Thus, the sequence of switches visited by the packet is:\n",
      ".x\n",
      "1\n",
      "; x\n",
      "2\n",
      "; x\n",
      "3\n",
      "; : : : ; x\n",
      "log\n",
      " \n",
      "N\n",
      " ; 0/ ! .y\n",
      "1\n",
      "; x\n",
      "2\n",
      "; x\n",
      "3\n",
      "; : : : ; x\n",
      "log\n",
      " \n",
      "N\n",
      " ; 1/\n",
      "! .y\n",
      "1\n",
      "; y\n",
      "2\n",
      "; x\n",
      "3\n",
      "; : : : ; x\n",
      "log\n",
      " \n",
      "N\n",
      " ; 2/\n",
      "! .y\n",
      "1\n",
      "; y\n",
      "2\n",
      "; y\n",
      "3\n",
      "; : : : ; x\n",
      "log\n",
      " \n",
      "N\n",
      " ; 3/\n",
      "!\n",
      "\t\n",
      ": : :\n",
      "! .y\n",
      "1\n",
      "; y\n",
      "2\n",
      "; y\n",
      "3\n",
      "; : : : ; y\n",
      "log\n",
      " \n",
      "N\n",
      " ; log N /\n",
      "In fact, this is the\n",
      "\t\n",
      "path from the input to the output!\n",
      "only\n",
      "\t\n",
      "p\n",
      "\n",
      "The congestion of the butterfly network is about\n",
      "\t\n",
      "N . More precisely, the con-\n",
      "p\n",
      "\t\n",
      "p\n",
      "\n",
      "gestion is N if N is an even power of 2 and N=2 if N is an odd power of 2. The task of proving this fact has been left to the problem section.\n",
      "A comparison of the butterfly with the complete binary tree and the 2-d array is provided in Table \n",
      ". As you can see, the butterfly has lower congestion than the complete binary tree. And it uses fewer switches and has lower diameter than the\n",
      "p\n",
      "\n",
      "4\n",
      "The routing problems that result in N congestion do arise in practice, but for most routing problems, the congestion is much lower (around log N ), which is one reason why the butterfly is useful in practice.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 205  #211\n",
      "\n",
      "levels\n",
      "0\n",
      "\t\n",
      "1\n",
      "\t\n",
      "2\n",
      "\t\n",
      "3\n",
      "in\n",
      "0\n",
      "\n",
      " out\n",
      "0\n",
      "\n",
      "000\n",
      "in\n",
      "1\n",
      "\n",
      " out\n",
      "1\n",
      "\n",
      "001\n",
      "in\n",
      "2\n",
      "\n",
      " out\n",
      "2\n",
      "\n",
      "010\n",
      "in\n",
      "3\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " out\n",
      "3\n",
      "\n",
      "011\n",
      "in\n",
      "4\n",
      "\n",
      " out\n",
      "4\n",
      "\n",
      "100\n",
      "in\n",
      "5\n",
      "\n",
      " out\n",
      "5\n",
      "\n",
      "101\n",
      "in\n",
      "6\n",
      "\n",
      " out\n",
      "6\n",
      "\n",
      "110\n",
      "in\n",
      "7\n",
      "\n",
      " out\n",
      "7\n",
      "\n",
      "111\n",
      "Figure 6.12 An N -input butterfly contains two N=2-input butterflies (shown in the dashed boxes). Each switch on the first level is adjacent to a corresponding switch in each of the sub-butterflies. For example, we have used dashed lines to show these edges for the node .0; 1; 1; 0/.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 206  #212\n",
      "\n",
      "Table 6.3 \n",
      "A comparison of the\n",
      " N \n",
      "-input butterfly with the\n",
      " N \n",
      "-input complete bi-nary tree and the \n",
      "N\n",
      " -input 2-d array.\n",
      "in\n",
      "0 \n",
      "\n",
      " out\n",
      "0\n",
      "\n",
      "in\n",
      "1 \n",
      "\n",
      " out\n",
      "1\n",
      "\n",
      "in\n",
      "2 \n",
      "\n",
      " out\n",
      "2\n",
      "\n",
      "in\n",
      "3 \n",
      "\n",
      " out\n",
      "3\n",
      "\n",
      "in\n",
      "4 \n",
      "\n",
      " out\n",
      "4\n",
      "\n",
      "in\n",
      "5 \n",
      "\n",
      " out\n",
      "5\n",
      "\n",
      "in\n",
      "6 \n",
      "\n",
      " out\n",
      "6\n",
      "\n",
      "in\n",
      "7 \n",
      "\n",
      " out\n",
      "7\n",
      "\n",
      "Figure 6.13\n",
      "\t\n",
      "The 8-input Benes network.\n",
      "array. However, the butterfly does not capture the best qualities of each network, but rather is a compromise somewhere between the two. So our quest for the Holy Grail of routing networks goes on.\n",
      "6.3.9\n",
      "\t\n",
      "Benes Network\n",
      "In the 1960s, a researcher at Bell Labs named Vaclav Benes had a remarkable idea. He obtained a marvelous communication network with congestion 1 by placing \n",
      "two \n",
      "butterflies back-to-back. For example, the 8-input Benes network is shown in\n",
      " \n",
      "Figure \n",
      ".\n",
      "Putting two butterflies back-to-back roughly doubles the number of switches and the diameter of a single butterfly, but it completely eliminates congestion problems! The proof of this fact relies on a clever induction argument that well come to in a\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 207  #213\n",
      "\n",
      "Table 6.4 \n",
      "A comparison of the\n",
      " N \n",
      "-input Benes network with the\n",
      " N \n",
      "-input com-plete binary tree, 2-d array, and butterfly.\n",
      "in\n",
      "0  \n",
      "\n",
      " out\n",
      "0\n",
      "\n",
      "in\n",
      "1  \n",
      "\n",
      " out\n",
      "1\n",
      "Figure 6.14\n",
      "\t\n",
      "The 2-input Benes network.\n",
      "moment. Lets first see how the Benes network stacks up against the other networks we have been studying. As you can see in Table \n",
      ", the Benes network has small size and diameter, and completely eliminates congestion. The Holy Grail of routing networks is in hand!\n",
      "Theorem 6.3.2. \n",
      "The congestion of the\n",
      " N \n",
      "-input Benes network is 1 for any\n",
      " N \n",
      "that\n",
      " \n",
      "is a power of 2.\n",
      "Proof. We use induction. Let \n",
      "P .a/\n",
      " be the proposition that the congestion of the \n",
      "2\n",
      "a\n",
      "-input Benes network is 1.\n",
      "Base case \n",
      "(\n",
      "a D 1\n",
      "): We must show that the congestion of the\n",
      " 2\n",
      "1\n",
      "-input Benes net-work is 1. The network is shown in Figure \n",
      ".\n",
      "There are only two possible permutation routing problems for a 2-input network. If \n",
      ".0/\n",
      " \n",
      "D\n",
      " \n",
      "0\n",
      " and \n",
      ".1/\n",
      " \n",
      "D\n",
      " \n",
      "1\n",
      ", then we can route both packets along the straight edges. On the other hand, if \n",
      ".0/\n",
      " \n",
      "D\n",
      " \n",
      "1\n",
      " and \n",
      ".1/\n",
      " \n",
      "D\n",
      " \n",
      "0\n",
      ", then we can route both packets along the diagonal edges. In both cases, a single packet passes through each switch.\n",
      "Inductive step\n",
      ": We must show that\n",
      " P .a/ \n",
      "implies\n",
      " P .a C1/ \n",
      "where\n",
      " a 1\n",
      ". Thus, we\n",
      " \n",
      "assume that the congestion of a \n",
      "2\n",
      "a\n",
      "-input Benes network is 1 in order to prove that the congestion of a \n",
      "2\n",
      "aC1\n",
      "-input Benes network is also 1.\n",
      "Digression\n",
      "Time out! Lets work through an example, develop some intuition, and then com-plete the proof. Notice that inside a Benes network of size \n",
      "2N\n",
      " lurk two Benes subnetworks of size \n",
      "N\n",
      " . This follows from our earlier observation that a butterfly\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 208  #214\n",
      "\n",
      "208\n",
      "\t\n",
      "Chapter 6\n",
      "\t\n",
      "Directed Graphs\n",
      "in\n",
      "0 \n",
      "\n",
      " out\n",
      "0\n",
      "\n",
      "in\n",
      "1 \n",
      "\n",
      " out\n",
      "1\n",
      "\n",
      "in\n",
      "2 \n",
      "\n",
      " out\n",
      "2\n",
      "\n",
      "in\n",
      "3 \n",
      "\n",
      " out\n",
      "3\n",
      "\n",
      "in\n",
      "4 \n",
      "\n",
      " out\n",
      "4\n",
      "\n",
      "in\n",
      "5 \n",
      "\n",
      " out\n",
      "5\n",
      "\n",
      "in\n",
      "6 \n",
      "\n",
      " out\n",
      "6\n",
      "\n",
      "in\n",
      "7 \n",
      "\n",
      " out\n",
      "7\n",
      "\n",
      "Figure 6.15 \n",
      "A\n",
      " 2N \n",
      "-input Benes network contains two\n",
      " N \n",
      "-input Benes networks\n",
      " \n",
      "shown here for \n",
      "N\n",
      " \n",
      "D\n",
      " \n",
      "4\n",
      ".\n",
      "of size \n",
      "2N\n",
      " contains two butterflies of size \n",
      "N\n",
      " . In the Benes network shown in Fig-ure \n",
      "with \n",
      "N\n",
      " \n",
      "D\n",
      " \n",
      "8\n",
      " inputs and outputs, the two 4-input/output subnetworks are shown in dashed boxes.\n",
      "By the inductive assumption, the subnetworks can each route an arbitrary per-mutation with congestion 1. So if we can guide packets safely through just the first and last levels, then we can rely on induction for the rest! Lets see how this works in an example. Consider the following permutation routing problem:\n",
      ".0/D1\n",
      "\t\n",
      ".4/D3\n",
      ".1/D5\n",
      "\t\n",
      ".5/D6\n",
      ".2/D4\n",
      "\t\n",
      ".6/D0\n",
      ".3/D7\n",
      "\t\n",
      ".7/D2\n",
      "We can route each packet to its destination through either the upper subnetwork or the lower subnetwork. However, the choice for one packet may constrain the choice for another. For example, we can not route the packets at inputs 0 and 4 both through the same network since that would cause two packets to collide at a single switch, resulting in congestion. So one packet must go through the upper network and the other through the lower network. Similarly, the packets at inputs 1 and 5,\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 209  #215\n",
      "\n",
      "1\n",
      "\n",
      " 5\n",
      "0\n",
      "\t\n",
      "2\n",
      "\n",
      "4\n",
      "\t\n",
      "6\n",
      "7\n",
      "\n",
      "3\n",
      "Figure 6.16\n",
      "\t\n",
      "The beginnings of a constraint graph for our packet routing problem.\n",
      "Adjacent packets cannot be routed using the same sub-Benes network.\n",
      "1\n",
      "\n",
      " 5\n",
      "\n",
      "0\n",
      "\t\n",
      "2\n",
      "\n",
      "4\n",
      "\t\n",
      "6\n",
      "7\n",
      "\n",
      "3\n",
      "Figure 6.17\n",
      "\t\n",
      "The updated constraint graph.\n",
      "2 and 6, and 3 and 7 must be routed through different networks. Lets record these constraints in a graph. The vertices are the 8 packets (labeled according to their input position). If two packets must pass through different networks, then there is an edge between them. The resulting constraint graph is illustrated in Figure \n",
      ". Notice that at most one edge is incident to each vertex.\n",
      "The output side of the network imposes some further constraints. For example, the packet destined for output 0 (which is packet 6) and the packet destined for output 4 (which is packet 2) can not both pass through the same network since that would require both packets to arrive from the same switch. Similarly, the packets destined for outputs 1 and 5, 2 and 6, and 3 and 7 must also pass through different switches. We can record these additional constraints in our constraint graph with gray edges, as is illustrated in Figure \n",
      ".\n",
      "Notice that at most one new edge is incident to each vertex. The two lines drawn between vertices 2 and 6 reflect the two different reasons why these packets must be routed through different networks. However, we intend this to be a simple graph;\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 210  #216\n",
      "\n",
      "210\n",
      "\t\n",
      "Chapter 6\n",
      "\t\n",
      "Directed Graphs\n",
      "the two lines still signify a single edge.\n",
      "Now heres the key insight: \n",
      "a 2-coloring of the graph corresponds to a solution\n",
      " \n",
      "to the routing problem\n",
      ". In particular, suppose that we could color each vertex either\n",
      " \n",
      "red or blue so that adjacent vertices are colored differently. Then all constraints are satisfied if we send the red packets through the upper network and the blue packets through the lower network.\n",
      "The only remaining question is whether the constraint graph is 2-colorable. For-tunately, this is easy to verify:\n",
      "Lemma 6.3.3. If the edges of an undirected graph G can be grouped into two sets such that every vertex is incident to at most 1 edge from each set, then the graph is 2-colorable.\n",
      "Proof. \n",
      "Since the two sets of edges may overlap, lets call an edge that is in both sets\n",
      " \n",
      "a \n",
      "doubled edge\n",
      ". Note that no other edge can be incident to either of the endpoints of a doubled edge, since that endpoint would then be incident to two edges from the same set. This means that doubled edges form connected components with 2 nodes. Such connected components are easily colored with 2 colors and so we can henceforth ignore them and focus on the remaining nodes and edges, which form a simple graph.\n",
      "By Theorem \n",
      ", we know that if a simple graph has no odd cycles, then it is 2-colorable. So all we need to do is show that every cycle in \n",
      "G\n",
      " has even length. This is easy since any cycle in \n",
      "G\n",
      " must traverse successive edges that alternate from one set to the other. In particular, a closed walk must traverse a path of alternating edges that begins and ends with edges from different sets. This means that the cycle\n",
      "has to be of even length.\n",
      "For example, a 2-coloring of the constraint graph in Figure \n",
      "is shown in Figure \n",
      ". The solution to this graph-coloring problem provides a start on the packet routing problem. We can complete the routing in the two smaller Benes networks by induction. With this insight in hand, the digression is over and we can now complete the proof of Theorem \n",
      ".\n",
      "Proof of Theorem \n",
      "(\n",
      "continued\n",
      ")\n",
      ". \n",
      "Let be an arbitrary permutation of 0, 1, . . . ,\n",
      " N 1\n",
      ". Let\n",
      " G \n",
      "be the graph whose vertices are packet numbers\n",
      " 0; 1; : : : ; N 1 \n",
      "and\n",
      " \n",
      "whose edges come from the union of these two sets:\n",
      "E\n",
      "1\n",
      "WWDf fu; vg j ju\n",
      "\t\n",
      "vj D N=2 g; \n",
      "and\n",
      "E\n",
      "2\n",
      "WWDf fu; wg j j .u/\n",
      "\t\n",
      ".w/j D N=2 g:\n",
      "Now any vertex, \n",
      "u\n",
      ", is incident to at most two edges: a unique edge \n",
      "fu; vg 2\n",
      " \n",
      "E\n",
      "1\n",
      " and a unique edge \n",
      "fu; wg 2\n",
      " \n",
      "E\n",
      "2\n",
      ". So according to Lemma \n",
      ", there is a 2-coloring for\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 211  #217\n",
      "\n",
      "\n",
      "blue  \n",
      "4\n",
      "\t\n",
      "6  \n",
      "blue\n",
      "7\n",
      "\n",
      "3\n",
      "blue\n",
      "\t\n",
      "red\n",
      "Figure 6.18\n",
      "\t\n",
      "A 2-coloring of the constraint graph in Figure \n",
      ".\n",
      "the vertices of G. Now route packets of one color through the upper subnetwork and packets of the other color through the lower subnetwork. Since for each edge in E\n",
      "1\n",
      ", one vertex goes to the upper subnetwork and the other to the lower subnetwork, there will not be any conflicts in the first level. Since for each edge in E\n",
      "2\n",
      ", one vertex comes from the upper subnetwork and the other from the lower subnetwork, there will not be any conflicts in the last level. We can complete the routing within each\n",
      "subnetwork by the induction hypothesis P .n/.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 212  #218\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 213  #219\n",
      "\n",
      "Relations and Partial Orders\n",
      "A relation is a mathematical tool for describing associations between elements of sets. Relations are widely used in computer science, especially in databases and scheduling applications. A relation can be defined across many items in many sets, but in this text, we will focus on binary relations, which represent an association between two items in one or two sets.\n",
      "\n",
      "7.1\n",
      "\t\n",
      "Binary Relations\n",
      "7.1.1\n",
      "\t\n",
      "Definitions and Examples\n",
      "Definition 7.1.1. Given sets A and B, a binary relation R W A ! B from\n",
      "A to B is a subset of A B. The sets A and B are called the domain and codomain of R, respectively. We commonly use the notation aRb or a \n",
      "R\n",
      " b to denote that\n",
      ".a; b/ 2 R.\n",
      "A relation is similar to a function. In fact, every function f W A ! B is a rela-tion. In general, the difference between a function and a relation is that a relation might associate multiple elements ofB with a single element ofA, whereas a func-tion can only associate at most one element of B (namely, f .a/) with each element a 2 A.\n",
      "We have already encountered examples of relations in earlier chapters. For ex-ample, in Section \n",
      ", we talked about a relation between the set of men and the set of women where mRw if man m likes woman w. In Section \n",
      ", we talked about a relation on the set of MIT courses where c\n",
      "1\n",
      "Rc\n",
      "2\n",
      " if the exams for c\n",
      "1\n",
      " and c\n",
      "2\n",
      " cannot be given at the same time. In Section \n",
      ", we talked about a relation on the set of switches in a network where s\n",
      "1\n",
      "Rs\n",
      "2\n",
      " if s\n",
      "1\n",
      " and s\n",
      "2\n",
      " are directly connected by a wire that can send a packet from s\n",
      "1\n",
      " to s\n",
      "2\n",
      ". We did not use the formal definition of a relation in any of these cases, but they are all examples of relations.\n",
      "As another example, we can define an in-charge-of relation T from the set of MIT faculty F to the set of subjects in the 2010 MIT course catalog. This relation contains pairs of the form\n",
      ".hinstructor-namei; hsubject-numi/\n",
      "\n",
      "1\n",
      "We also say that the relationship is between A and B, or on A if B D A.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 214  #220\n",
      "\n",
      "214\n",
      "\t\n",
      "Chapter 7\n",
      "\t\n",
      "Relations and Partial Orders\n",
      "(Meyer,\n",
      "\t\n",
      "6.042),\n",
      "(Meyer,\n",
      "\t\n",
      "18.062),\n",
      "(Meyer,\n",
      "\t\n",
      "6.844),\n",
      "(Leighton,\t6.042),\n",
      "(Leighton,\t18.062),\n",
      "(Freeman,\t6.011),\n",
      "(Freeman,\t6.881)\n",
      "(Freeman,\t6.882)\n",
      "(Freeman,\t6.UAT)\n",
      "(Eng,\n",
      "\t\n",
      "6.UAT)\n",
      "(Guttag,\n",
      "\t\n",
      "6.00)\n",
      "Figure 7.1 Some items in the in-charge-of relation T between faculty and sub-ject numbers.\n",
      "where the faculty member named hinstructor-namei is in charge of the subject with number hsubject-numi. So T contains pairs like those shown in Figure \n",
      ".\n",
      "This is a surprisingly complicated relation: Meyer is in charge of subjects with three numbers. Leighton is also in charge of subjects with two of these three numbersbecause the same subject, Mathematics for Computer Science, has two numbers (6.042 and 18.062) and Meyer and Leighton are jointly in-charge-of the subject. Freeman is in-charge-of even more subjects numbers (around 20), since as Department Education Officer, he is in charge of whole blocks of special sub-ject numbers. Some subjects, like 6.844 and 6.00 have only one person in-charge. Some faculty, like Guttag, are in-charge-of only one subject number, and no one else is jointly in-charge-of his subject, 6.00.\n",
      "Some subjects in the codomain, N , do not appear in the listthat is, they are not an element of any of the pairs in the graph of T ; these are the Fall term only subjects. Similarly, there are faculty in the domain, F , who do not appear in the list because all their in-charge-of subjects are Fall term only.\n",
      "7.1.2\n",
      "\t\n",
      "Representation as a Bipartite Graph\n",
      "Every relation R W A ! B can be easily represented as a bipartite graph G D .V; E/ by creating a left node for each element of A and a right node for each element of B. We then create an edge between a left node u and a right node v whenever aRb. Similarly, every bipartite graph (and every partition of the nodes into a left and right set for which no edge connects a pair of left nodes or a pair of right nodes) determines a relation between the nodes on the left and the nodes on the right.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 215  #221\n",
      "\n",
      "\n",
      " 6:042\n",
      "\n",
      "\n",
      " 18:062\n",
      "Meyer \n",
      "\n",
      "\n",
      " 6:844\n",
      "Leighton\n",
      "\n",
      " 6:011\n",
      "\n",
      "Freeman \n",
      "\n",
      "\n",
      " 6:881\n",
      "Eng\n",
      "\n",
      " 6:882\n",
      "Guttag \n",
      "\n",
      "\n",
      " 6:\n",
      "UAT\n",
      "\n",
      " 6:\n",
      "00\n",
      "Figure 7.2 Part of the bipartite graph for the in charge of relation T from Fig-ure \n",
      ".\n",
      "For example, we have shown part of the bipartite graph for the in-charge-of relation from Figure \n",
      "in Figure \n",
      ". In this case, there is an edge between\n",
      "hinstructor-namei and hsubject-numberi if hinstructor-namei is in charge of hsubject-numberi. A relation R W A ! B between finite sets can also be represented as a matrix\n",
      "A D fa\n",
      "ij\n",
      " g where\n",
      "for 1 i jAj and 1 j jBj. For example, the matrix for the relation in Figure \n",
      "(but restricted to the five faculty and eight subject numbers shown in Figure \n",
      ", ordering them as they appear top-to-bottom in Figure \n",
      ") is shown in Figure \n",
      ".\n",
      "7.1.3\n",
      "\t\n",
      "Relational Images\n",
      "The idea of the image of a set under a function extends directly to relations.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 216  #222\n",
      "\n",
      "216\n",
      "\t\n",
      "Chapter 7\n",
      "\t\n",
      "Relations and Partial Orders\n",
      "Figure 7.3 The matrix for the in charge of relation T restricted to the five faculty and eight subject numbers shown in Figure \n",
      ". The .3; 4/ entry of this matrix is 1 since the third professor (Freeman) is in charge of the fourth subject number (6.011).\n",
      "Definition 7.1.2. The image of a set Y under a relation R W A ! B, written R.Y /, is the set of elements that are related to some element in Y , namely,\n",
      "R.Y / WWD f b 2 B j yRb for some y 2 Y g:\n",
      "The image of the domain, R.A/, is called the range of R.\n",
      "For example, to find the subject numbers that Meyer is in charge of, we can look for all the pairs of the form\n",
      ".Meyer; hsubject-numberi/\n",
      "in the graph of the teaching relation T , and then just list the right-hand sides of these pairs. These right-hand sides are exactly the image T .Meyer/, which happens to be f6:042; 18:062; 6:844g. Similarly, since the domain F is the set of all in-charge faculty, T .F /, the range of T , is exactly the set of all subjects being taught.\n",
      "7.1.4\n",
      "\t\n",
      "Inverse Relations and Images\n",
      "Definition 7.1.3. The inverse R\n",
      "1\n",
      " of a relation R W A ! B is the relation from B to A defined by the rule\n",
      "bR\n",
      "1\n",
      "  a if and only if aRb:\n",
      "The image of a set under the relation R\n",
      "1\n",
      "\t\n",
      "is called the inverse image of the set.\n",
      "That is, the inverse image of a set X under the relation R is R\n",
      "1\n",
      "  .X/.\n",
      "Continuing with the in-charge-of example above, we can find the faculty in charge of 6.UAT by taking the pairs of the form\n",
      ".hinstructor-namei; 6.UAT/\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 217  #223\n",
      "\n",
      "for the teaching relation T , and then just listing the left-hand sides of these pairs; these turn out to be just Eng and Freeman. These left-hand sides are exactly the inverse image of f6.UATg under T .\n",
      "7.1.5\n",
      "\t\n",
      "Combining Relations\n",
      "There are at least two natural ways to combine relations to form new relations. For example, given relations R W B ! C and S W A ! B, the composition of R with S is the relation .R B S/ W A ! C defined by the rule\n",
      "a.R B S/c \n",
      "IFF\n",
      "  9b 2 B: .bRc/ \n",
      "AND\n",
      " .aSb/\n",
      "where a 2 A and c 2 C .\n",
      "As a special case, the composition of two functions f W B ! C and g W A ! B is the function f B g W A ! C defined by\n",
      ".f B g/.a/ D f .g.a//\n",
      "for all a 2 A. For example, if A D B D C D R, g.x/ D x C 1 and f .x/ D x\n",
      "2\n",
      ", then\n",
      ".f B g/.x/ D .x C 1/\n",
      "2\n",
      "D x\n",
      "2\n",
      " C 2x C 1:\n",
      "One can also define the product of two relations R\n",
      "1\n",
      " W A\n",
      "1\n",
      " ! B\n",
      "1\n",
      " and R\n",
      "2\n",
      " W A\n",
      "2\n",
      " ! B\n",
      "2\n",
      " to be the relation S D R\n",
      "1\n",
      " R\n",
      "2\n",
      " where\n",
      "SWA\n",
      "1\n",
      "\tA\n",
      "2\n",
      "!B\n",
      "1\n",
      "\t\n",
      "B\n",
      "2\n",
      "and\n",
      ".a\n",
      "1\n",
      "; a\n",
      "2\n",
      "/S.b\n",
      "1\n",
      "; b\n",
      "2\n",
      "/\n",
      "\t\n",
      "iff\n",
      "\t\n",
      "a\n",
      "1\n",
      "R\n",
      "1\n",
      "b\n",
      "1\n",
      " and a\n",
      "2\n",
      "R\n",
      "2\n",
      "b\n",
      "2\n",
      ":\n",
      "\n",
      "7.2\n",
      "\t\n",
      "Relations and Cardinality\n",
      "7.2.1\n",
      "\t\n",
      "Surjective and Injective Relations\n",
      "There are some properties of relations that will be useful when we take up the topic of counting in Part \n",
      "because they imply certain relations between the sizes of domains and codomains. In particular, we say that a binary relation R W A ! B is\n",
      "surjective if every element of B is assigned to at least one element of A. More concisely, R is surjective iff R.A/ D B (that is, if the range of R is the codomain of R),\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 218  #224\n",
      "\n",
      "Chapter 7  Relations and Partial Orders\n",
      "total when every element of A is assigned to some element of B. More concisely, R is total iff A D R\n",
      "1\n",
      " .B/,\n",
      "injective if every element of B is mapped at most once, and bijective if R is total, surjective, injective, and a function\n",
      ".\n",
      "We can illustrate these properties of a relation R W A ! B in terms of the cor-responding bipartite graph G for the relation, where nodes on the left side of G correspond to elements of A and nodes on the right side of G correspond to ele-ments of B. For example:\n",
      "R is a function means that every node on the left is incident to at most one edge.\n",
      "R is total means that every node on the left is incident to at least one edge. So if R is a function, being total means that every node on the left is incident to exactly one edge.\n",
      "R is surjective means that every node on the right is incident to at least one edge.\n",
      "R is injective means that every node on the right is incident to at most one edge.\n",
      "R is bijective means that every node on both sides is incident to precisely one edge (that is, there is a perfect matching between A and B).\n",
      "For example, consider the relations R\n",
      "1\n",
      " and R\n",
      "2\n",
      " shown in Figure \n",
      ". R\n",
      "1\n",
      " is a total surjective function (every node in the left column is incident to exactly one edge, and every node in the right column is incident to at least one edge), but not injective (node 3 is incident to 2 edges). R\n",
      "2\n",
      " is a total injective function (every node in the left column is incident to exactly one edge, and every node in the right column is incident to at most one edge), but not surjective (node 4 is not incident to any edges).\n",
      "Notice that we need to know what the domain is to determine whether a relation is total, and we need to know the codomain to determine whether its surjective. For example, the function defined by the formula 1=x\n",
      "2\n",
      " is total if its domain is R\n",
      "C\n",
      " but partial if its domain is some set of real numbers that includes 0. It is bijective if its domain and codomain are both R\n",
      "C\n",
      ", but neither injective nor surjective it is domain and codomain are both R.\n",
      "\n",
      "These words surjective, injective, and bijective are not very memorable. Some authors use the possibly more memorable phrases onto for surjective, one-to-one for injective, and exact correspon-dence for bijective.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 219  #225\n",
      "\n",
      "\n",
      "is shown in (b).\n",
      "7.2.2\tCardinality\n",
      "The relational properties in Section \n",
      "are useful in figuring out the relative sizes of domains and codomains.\n",
      "If A is a finite set, we use jAj to denote the number of elements in A. This is called the cardinality of A. In general, a finite set may have no elements (the empty set), or one element, or two elements, . . . , or any nonnegative integer number of elements, so for any finite set, jAj 2 N.\n",
      "Now suppose R W A ! B is a function. Then every edge in the bipartite graph G D .V; E/ for R is incident to exactly one element of A, so the num-ber of edges is at most the number of elements of A. That is, if R is a function, then\n",
      "jEj\tjAj:\n",
      "Similarly, if R is surjective, then every element of B is incident to an edge, so there must be at least as many edges in the graph as the size of B. That is\n",
      "jEj\tjBj:\n",
      "Combining these inequalities implies that R W A ! B is a surjective function, then jAj jB j. This fact and two similar rules relating domain and codomain size to relational properties are captured in the following theorem.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 220  #226\n",
      "\n",
      "220\n",
      "\t\n",
      "Chapter 7\n",
      "\t\n",
      "Relations and Partial Orders\n",
      "Theorem 7.2.1 (Mapping Rules). Let A and B be finite sets.\n",
      "If there is a surjection from A to B, then jAj  jBj.\n",
      "If there is an injection from A to B, then jAj  jBj:\n",
      "If there is a bijection between A and B, then jAj D jBj.\n",
      "Mapping rule \n",
      "can be explained by the same kind of reasoning we used for rule \n",
      ". Rule \n",
      "is an immediate consequence of the first two mapping rules.\n",
      "We will see many examples where Theorem \n",
      "is used to determine the car-dinality of a finite set. Later, in Chapter \n",
      ", we will consider the case when the sets are infinite and well use surjective and injective relations to prove that some infinite sets are bigger than other infinite sets.\n",
      "\n",
      "7.3\n",
      "\t\n",
      "Relations on One Set\n",
      "For the rest of this chapter, we are going to focus on relationships between elements of a single set; that is, relations from a set A to a set B where A D B. Thus, a relation on a set A is a subset R A A. Here are some examples:\n",
      "Let A be a set of people and the relation R describe who likes whom: that is,\n",
      ".x; y/ 2 R if and only if x likes y.\n",
      "Let A be a set of cities. Then we can define a relation R such that xRy if and only if there is a nonstop flight from city x to city y.\n",
      "Let A D Z and let xRy hold if and only if x y .mod 5/. Let A D N and let xRy if and only if x j y.\n",
      "Let A D N and let xRy if and only if x   y.\n",
      "The last examples clarify the reason for using xRy or x \n",
      "R\n",
      " y to indicate that the relation R holds between x and y: many common relations (<, , D, j, ) are expressed with the relational symbol in the middle.\n",
      "7.3.1\n",
      "\t\n",
      "Representation as a Digraph\n",
      "Every relation on a single set A can be modeled as a directed graph (albeit one that may contain loops). For example, the graph in Figure \n",
      "describes the likes relation for a particular set of 3 people.\n",
      "In this case, we see that:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 221  #227\n",
      "\n",
      "\n",
      "Julie \n",
      "\n",
      " Bill\n",
      "\n",
      "Bob\n",
      "Figure 7.5\n",
      "\t\n",
      "The directed graph for the likes relation on the set fBill; Bob; Julieg.\n",
      "\n",
      "4\n",
      "\t\n",
      "\n",
      "2\n",
      "\t\n",
      "8\n",
      "\t\n",
      "10\n",
      "5\n",
      "3\n",
      "\t\n",
      "9\n",
      "\t\n",
      "11\n",
      "Figure 7.6\n",
      "\t\n",
      "The digraph for divisibility on f1; 2; : : : ; 12g.\n",
      "Julie likes Bill and Bob, but not herself. Bill likes only himself.\n",
      "Bob likes Julie, but not Bill nor himself.\n",
      "Everything about the relationship is conveyed by the directed graph and nothing more. This is no coincidence; a set A together with a relation R is precisely the same thing as directed graph G D .V; E/ with vertex set V D A and edge set\n",
      "D R (where E may have loops).\n",
      "As another example, we have illustrated the directed graph for the divisibility\n",
      "relationship on the set f1; 2; : : : ; 12g in Figure \n",
      ". In this graph, every node has a loop (since every positive number divides itself) and the composite numbers are the nodes with indegree more than 1 (not counting the loop).\n",
      "Relations on a single set can also be represented as a 0; 1-matrix. In this case, the matrix is identical to the adjacency matrix for the corresponding digraph. For\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 222  #228\n",
      "\n",
      "222\n",
      "\t\n",
      "Chapter 7\n",
      "\t\n",
      "Relations and Partial Orders\n",
      "example, the matrix for the relation shown in Figure \n",
      "is simply\n",
      "where v\n",
      "1\n",
      " D Julie, v\n",
      "2\n",
      " D Bill, and v\n",
      "3\n",
      " D Bob.\n",
      "7.3.2\n",
      "\t\n",
      "Symmetry, Transitivity, and Other Special Properties\n",
      "Many relations on a single set that arise in practice possess one or more noteworthy properties. These properties are summarized in the box on the following page. In each case, we provide the formal of the definition of the property, explain what the property looks like in a digraph G for the relation, and give an example of what the property means for the likes relation.\n",
      "For example, the congruence relation modulo 5 on Z is reflexive symmetric, and transitive, but not irreflexive, antisymmetric, or asymmetric. The same is true for the connected relation R W V ! V on an undirected graph G D .V; E/ where uRv if u and v are in the same connected component of graph G. In fact, relations that have these three properties are so common that we give them a special name: equivalence relations. We will discuss them in greater detail in just a moment.\n",
      "As another example, the divides relation on Z\n",
      "C\n",
      " is reflexive, antisymmetric, and transitive, but not irreflexive, symmetric, or asymmetric. The same is true for the   relation on R. Relations that have these three properties are also very common and they fall into a special case of relations called a partial order. We will discuss partial orders at length in Sections \n",
      "\n",
      ".\n",
      "As a final example, consider the likes relation on the set fJulie; Bill; Bobg il-lustrated in Figure \n",
      ". This relation has none of the six properties described in the box.\n",
      "\n",
      "7.4\n",
      "\t\n",
      "Equivalence Relations\n",
      "A relation is an equivalence relation if it is reflexive, symmetric, and transitive.\n",
      "Congruence modulo n is an excellent example of an equivalence relation:\n",
      "It is reflexive because x   x .mod n/.\n",
      "It is symmetric because x   y .mod n/ implies y   x .mod n/.\n",
      "It is transitive because x   y .mod n/ and y   z .mod n/ imply that x   z\n",
      ".mod n/.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 223  #229\n",
      "\n",
      "Properties of a Relation R W A ! A\n",
      "\n",
      "Reflexivity R is reflexive if\n",
      "8x 2 A: xRX:\n",
      "Everyone likes themselves.\n",
      "Every node in G has a loop.\n",
      "Irreflexivity R is irreflexive if\n",
      ":9x 2 A: xRx:\n",
      "No one likes themselves.\n",
      "There are no loops in G.\n",
      "Symmetry R is symmetric if\n",
      "8x; y 2 A: xRy \n",
      "IMPLIES\n",
      " yRx:\n",
      "If x likes y, then y likes x.\n",
      "If there is an edge from x to y in G, then there is an edge from y to x in G as well.\n",
      "Antisymmetry R is antisymmetric if\n",
      "8x; y 2 A .xRy \n",
      "AND\n",
      " yRx/ \n",
      "IMPLIES\n",
      " x D y:\n",
      "No pair of distinct people like each other.\n",
      "There is at most one directed edge between any pair of distinct nodes.\n",
      "Asymmetry R is asymmetric if\n",
      ":9x; y 2 A: xRy \n",
      "AND\n",
      " yRx:\n",
      "No one likes themselves and no pair of people like each other.\n",
      "There are no loops and there is at most one directed edge between any pair of nodes.\n",
      "Transitivity R is transitive if\n",
      "8x; y; z 2 A: .xRy \n",
      "AND\n",
      " yRz/ \n",
      "IMPLIES\n",
      " xRz:\n",
      "If x likes y and y likes z, then x likes z too.\n",
      "For any walk v\n",
      "0\n",
      "; v\n",
      "1\n",
      "; : : : ; v\n",
      "k\n",
      " in G where k 2, v\n",
      "0\n",
      " ! v\n",
      "k\n",
      " is in G (and, hence, v\n",
      "i\n",
      " ! v\n",
      "j\n",
      " is also in G for all i < j .\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 224  #230\n",
      "\n",
      "224\n",
      "\t\n",
      "Chapter 7\n",
      "\t\n",
      "Relations and Partial Orders\n",
      "There is an even more well-known example of an equivalence relation: equality itself. Thus, an equivalence relation is a relation that shares some key properties with D.\n",
      "7.4.1\n",
      "\t\n",
      "Partitions\n",
      "There is another way to think about equivalence relations, but well need a couple of definitions to understand this alternative perspective.\n",
      "Definition 7.4.1. Given an equivalence relation \n",
      "R\n",
      " W \n",
      "A\n",
      " ! \n",
      "A\n",
      ", the equivalence class of an element \n",
      "x\n",
      " 2 \n",
      "A\n",
      " is the set of all elements of \n",
      "A\n",
      " related to \n",
      "x\n",
      " by \n",
      "R\n",
      ". The equiva-lence class of \n",
      "x\n",
      " is denoted \n",
      "x\n",
      " . Thus, in symbols:\n",
      "x \n",
      "D f\n",
      " y \n",
      "j\n",
      " xRy \n",
      "g\n",
      ":\n",
      "For example, suppose that \n",
      "A\n",
      " D Z and \n",
      "xRy\n",
      " means that \n",
      "x\n",
      "\t\n",
      "y .\n",
      "mod\n",
      " 5/\n",
      ". Then\n",
      "7 \n",
      "D f\n",
      ": : : ; 3; 2; 7; 12; 22; : : :\n",
      "\t\n",
      "g\n",
      ":\n",
      "Notice that 7, 12, 17, etc., all have the same equivalence class; that is, \n",
      "7\n",
      " D \n",
      "12\n",
      " D \n",
      "17\n",
      "D\n",
      " \n",
      ".\n",
      "Definition 7.4.2. A partition of a finite set \n",
      "A\n",
      " is a collection of disjoint, nonempty subsets \n",
      "A\n",
      "1\n",
      ", \n",
      "A\n",
      "2\n",
      ", . . . , \n",
      "A\n",
      "n\n",
      " whose union is all of \n",
      "A\n",
      ". The subsets are usually called the blocks of the partition.\n",
      "For example, one possible partition of \n",
      "A\n",
      " D f\n",
      "a; b; c; d; e\n",
      "g is\n",
      "A\n",
      "1\n",
      " \n",
      "D f\n",
      "a; c\n",
      "g\n",
      "\t\n",
      "A\n",
      "2\n",
      " \n",
      "D f\n",
      "b; e\n",
      "g\n",
      "\t\n",
      "A\n",
      "3\n",
      " \n",
      "D f\n",
      "d \n",
      "g\n",
      ":\n",
      "Heres the connection between all this stuff: there is an exact correspondence between equivalence relations on \n",
      "A\n",
      " and partitions of \n",
      "A\n",
      ". We can state this as a theorem:\n",
      "Theorem 7.4.3. The equivalence classes of an equivalence relation on a set \n",
      "A\n",
      " form a partition of \n",
      "A\n",
      ".\n",
      "We wont prove this theorem (too dull even for us!), but lets look at an example.\n",
      "\n",
      "3\n",
      "We think they should be called the parts of the partition. Dont you think that makes a lot more sense?\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 225  #231\n",
      "\n",
      "The congruent-mod-5 relation partitions the integers into five equivalence classes:\n",
      "f: : : ; 5; 0; 5; 10; 15; 20; : : :  g\n",
      "f: : : ; 4; 1; 6; 11; 16; 21; : : :  g\n",
      "f: : : ; 3; 2; 7; 12; 17; 22; : : :  g\n",
      "f: : : ; 2; 3; 8; 13; 18; 23; : : :  g\n",
      "f: : : ; 1; 4; 9; 14; 19; 24; : : :  g\n",
      "In these terms, x y .mod 5/ is equivalent to the assertion that x and y are both in the same block of this partition. For example, 6 16 .mod 5/, because theyre both in the second block, but 2  9 .mod 5/ because 2 is in the third block while 9 is in the last block.\n",
      "In social terms, if likes were an equivalence relation, then everyone would be partitioned into cliques of friends who all like each other and no one else.\n",
      "\n",
      "7.5\tPartial Orders\n",
      "7.5.1\n",
      "\t\n",
      "Strong and Weak Partial Orders\n",
      "Definition 7.5.1. A relation R on a set A is a weak partial order if it is transitive, antisymmetric, and reflexive. The relation is said to be a strong partial order if it is transitive, antisymmetric, and irreflexive.\n",
      "Some authors defined partial orders to be what we call weak partial orders, but well use the phrase partial order to mean either a weak or a strong partial order. The difference between a weak partial order and a strong one has to do with the reflexivity property: in a weak partial order, every element is related to itself, but in a strong partial order, no element is related to itself. Otherwise, they are the same in that they are both transitive and antisymmetric.\n",
      "Examples of weak partial orders include   on R,   on the set of subsets of (say) Z, and the divides relation on N\n",
      "C\n",
      ". Examples of strict partial orders include < on R, and   on the set of subsets of Z.\n",
      "\n",
      "Equivalently, the relation is transitive and asymmetric, but stating it this way might have obscured the irreflexivity property.\n",
      "5\n",
      "If you are not feeling comfortable with all the definitions that weve been throwing at you, its probably a good idea to verify that each of these relations are indeed partial orders by checking that they have the transitivity and antisymmetry properties.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 226  #232\n",
      "\n",
      "226\n",
      "\t\n",
      "Chapter 7\n",
      "\t\n",
      "Relations and Partial Orders\n",
      "We often denote a weak partial order with a symbol such as or v instead of a letter such as R. This makes sense from one perspective since the symbols call to mind and , which define common partial orders. On the other hand, a partial order is really a set of related pairs of items, and so a letter like R would be more normal.\n",
      "Likewise, we will often use a symbol like\n",
      "\t\n",
      "or @ to denote a strong partial order.\n",
      "7.5.2\n",
      "\t\n",
      "Total Orders\n",
      "A partial order is partial because there can be two elements with no relation between them. For example, in the divides partial order on f1; 2; : : : ; 12g, there is no relation between 3 and 5 (since neither divides the other).\n",
      "In general, we say that two elements a and b are incomparable if neither a b nor b a. Otherwise, if a b or b a, then we say that a and b are comparable.\n",
      "Definition 7.5.2. A total order is a partial order in which every pair of distinct elements is comparable.\n",
      "For example, the   partial order on R is a total order because for any pair of real numbers x and y, either x y or y x. The divides partial order on f1; 2; : : : ; 12g is not a total order because 3  5 and 5  3.\n",
      "\n",
      "7.6\n",
      "\t\n",
      "Posets and DAGs\n",
      "7.6.1\n",
      "\t\n",
      "Partially Ordered Sets\n",
      "Definition 7.6.1. Given a partial order on a set A, the pair .A; / is called a partially ordered set or poset.\n",
      "In terms of graph theory, a poset is simply the directed graph G D .A; / with vertex set A and edge set . For example, Figure \n",
      "shows the graph form of the poset for the divides relation on f1; 2; : : : ; 12g. We have shown the graph form of the poset for the <-relation on f1; 2; 3; 4g in Figure \n",
      ".\n",
      "7.6.2\n",
      "\t\n",
      "Posets Are Acyclic\n",
      "Did you notice anything that is common to Figures \n",
      "and \n",
      "? Of course, they both exhibit the transitivity and antisymmetry properties. And, except for the loops in Figure \n",
      ", they both do not contain any cycles. This is not a coincidence. In fact, the combination of the transitivity and asymmetry properties imply that the digraph\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 227  #233\n",
      "\n",
      "\n",
      " 1\n",
      "\n",
      "\n",
      " 2\n",
      "\n",
      " 3\n",
      "\n",
      " 4\n",
      "Figure 7.7\n",
      "\t\n",
      "Representing the poset for the <-relation on f1; 2; 3; 4g as a digraph.\n",
      "for any poset is an acyclic graph (that is, a DAG), at least if you dont count loops as cycles. We prove this fact in the following theorem.\n",
      "Theorem 7.6.2. A poset has no directed cycles other than self-loops.\n",
      "Proof. We use proof by contradiction. Let .A; / be a poset. Suppose that there exist n 2 distinct elements a\n",
      "1\n",
      ", a\n",
      "2\n",
      ", . . . , a\n",
      "n\n",
      " such that\n",
      "a\n",
      "1\n",
      "\ta\n",
      "2\n",
      "\ta\n",
      "3\n",
      "\t\n",
      "a\n",
      "n1\n",
      "\t\n",
      "a\n",
      "n\n",
      "\t\n",
      "a\n",
      "1\n",
      ":\n",
      "Since a\n",
      "1\n",
      " a\n",
      "2\n",
      " and a\n",
      "2\n",
      " a\n",
      "3\n",
      ", transitivity implies a\n",
      "1\n",
      " a\n",
      "3\n",
      ". Another application of transitivity shows that a\n",
      "1\n",
      " a\n",
      "4\n",
      " and a routine induction argument establishes that a\n",
      "1\n",
      " a\n",
      "n\n",
      ". Since we know that a\n",
      "n\n",
      " a\n",
      "1\n",
      ", antisymmetry implies a\n",
      "1\n",
      " D a\n",
      "n\n",
      ", contradicting the supposition that a\n",
      "1\n",
      ", . . . , a\n",
      "n\n",
      " are distinct and n 2. Thus, there is\n",
      "no such directed cycle.\n",
      "Thus, deleting the self-loops from a poset leaves a directed graph without cycles, which makes it a directed acyclic graph or DAG.\n",
      "7.6.3\n",
      "\t\n",
      "Transitive Closure\n",
      "Theorem \n",
      "tells us that every poset corresponds to a DAG. Is the reverse true? That is, does every DAG correspond to a poset? The answer is Yes, but we need to modify the DAG to make sure that it satisfies the transitivity property. For example, consider the DAG shown in Figure \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". As any DAG must, this graph satisfies the antisymmetry property\n",
      "but it does not satisfy the transitivity property because v\n",
      "1\n",
      " ! v\n",
      "2\n",
      " and v\n",
      "2\n",
      " ! v\n",
      "3\n",
      " are in the graph but v\n",
      "1\n",
      " ! v\n",
      "3\n",
      " is not in the graph.\n",
      "\n",
      "If u ! v and v ! u are in a digraph G, then G would have a cycle of length 2 and it could not be a DAG.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 228  #234\n",
      "\n",
      "228\n",
      "\t\n",
      "Chapter 7\n",
      "\t\n",
      "Relations and Partial Orders\n",
      "v\n",
      "1\n",
      "\t\n",
      "v\n",
      "2\n",
      "\n",
      "v\n",
      "5 \n",
      "\n",
      "      v\n",
      "4 \n",
      "\n",
      "v\n",
      "3\n",
      "\n",
      "v\n",
      "6\n",
      "Figure 7.8\n",
      "\t\n",
      "A 6-node digraph that does not satisfy the transitivity property.\n",
      "v\n",
      "1\n",
      "\t\n",
      "v\n",
      "2\n",
      "\n",
      "v\n",
      "5 \n",
      "\n",
      "      v\n",
      "4 \n",
      "\n",
      "v\n",
      "3\n",
      "\n",
      "v\n",
      "6\n",
      "Figure 7.9 The transitive closure for the digraph in Figure \n",
      ". The edges that were added to form the transitive closure are shown in bold.\n",
      "Definition 7.6.3. Given a digraph G D .V; E/, the transitive closure of G is the digraph G\n",
      "C\n",
      " D .V; E\n",
      "C\n",
      "/ where\n",
      "E\n",
      "C\n",
      " D f u ! v j there is a directed path of positive length from u to v in G g:\n",
      "Similarly, if R is the relation corresponding to G, the transitive closure of R (de-noted R\n",
      "C\n",
      ") is the relation corresponding to G\n",
      "C\n",
      ".\n",
      "For example, the transitive closure for the graph in Figure \n",
      "is shown in Fig-ure \n",
      ".\n",
      "If G is a DAG, then the transitive closure of G is a strong partial order. The proof of this fact is left as an exercise in the problem section.\n",
      "7.6.4\n",
      "\t\n",
      "The Hasse Diagram\n",
      "One problem with viewing a poset as a digraph is that there tend to be lots of edges due to the transitivity property. Fortunately, we do not necessarily have to draw\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 229  #235\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "Figure 7.10\n",
      "\t\n",
      "The Hasse diagrams for the posets in Figure \n",
      "and \n",
      ".\n",
      "all the edges if we know that the digraph corresponds to a poset. For example, we could choose not to draw any edge which would be implied by the transitivity property, knowing that it is really there by implication. In general, a Hasse diagram for a poset .A; / is a digraph with vertex set A and edge set minus all self-loops and edges implied by transitivity. For example, the Hasse diagrams of the posets shown in Figures \n",
      "and \n",
      "are shown in Figure \n",
      ".\n",
      "\n",
      "7.7\n",
      "\t\n",
      "Topological Sort\n",
      "A total order that is consistent with a partial order is called a topological sort. More precisely,\n",
      "Definition 7.7.1. A topological sort of a poset .A; / is a total order .A; \n",
      "T\n",
      " / such that\n",
      "x\ty \n",
      "IMPLIES\n",
      " x\n",
      "\t\n",
      "T \n",
      "y:\n",
      "For example, consider the poset that describes how a guy might get dressed for a formal occasion. The Hasse diagram for such a poset is shown in Figure \n",
      ".\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 230  #236\n",
      "\n",
      "230\n",
      "\t\n",
      "Chapter 7\n",
      "\t\n",
      "Relations and Partial Orders\n",
      "left sock\tright sock\tunderwear\n",
      "\t\n",
      "shirt\n",
      "\n",
      "\n",
      " pants    \n",
      "\n",
      " tie\n",
      "left shoe\tright shoe\n",
      "\t\n",
      "belt\n",
      "jacket\n",
      "Figure 7.11 The Hasse diagram for a poset that describes which items much pre-cede others when getting dressed.\n",
      "In this poset, the set is all the garments and the partial order specifies which items much precede others when getting dressed.\n",
      "There are several total orders that are consistent with the partial order shown in Figure \n",
      ". We have shown two of them in list form in Figure \n",
      ". Each such list is a topological sort for the partial order in Figure \n",
      ". In what follows, we will prove that every finite poset has a topological sort. You can think of this as a mathematical proof that you can get dressed in the morning (and then show up for math lecture).\n",
      "Theorem 7.7.2. Every finite poset has a topological sort.\n",
      "Well prove the theorem constructively. The basic idea is to pull the smallest element a out of the poset, find a topological sort of the remainder recursively, and then add a back into the topological sort as an element smaller than all the others.\n",
      "The first hurdle is that smallest is not such a simple concept in a set that is only partially ordered. In a poset .A; /, an element x 2 A is minimal if there is no other element y 2 A such that y x. For example, there are four minimal elements in the getting-dressed poset: left sock, right sock, underwear, and shirt. (It may seem\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 231  #237\n",
      "\n",
      "Figure 7.12 Two possible topological sorts of the poset shown in Figure \n",
      ". In each case, the elements are listed so that x y iff x is above y in the list.\n",
      "odd that the minimal elements are at the top of the Hasse diagram rather than the bottom. Some people adopt the opposite convention. If youre not sure whether minimal elements are on the top or bottom in a particular context, ask.) Similarly, an element x 2 A is maximal if there is no other element y 2 A such that x y.\n",
      "Proving that every poset has a minimal element is extremely difficult, because it is not true. For example, the poset .Z; / has no minimal element. However, there is at least one minimal element in every finite poset.\n",
      "Lemma 7.7.3. Every finite poset has a minimal element.\n",
      "Proof. Let .A; / be an arbitrary poset. Let a\n",
      "1\n",
      ", a\n",
      "2\n",
      ", . . . , a\n",
      "n\n",
      " be a maximum-length sequence of distinct elements in A such that\n",
      "a\n",
      "1\n",
      "\ta\n",
      "2\n",
      "\t\n",
      "a\n",
      "n\n",
      ":\n",
      "The existence of such a maximum-length sequence follows from the Well Ordering Principle and the fact that A is finite. Now a\n",
      "0\n",
      " a\n",
      "1\n",
      " cannot hold for any element a\n",
      "0\n",
      " 2 A not in the chain, since the chain already has maximum length. And a\n",
      "i\n",
      " a\n",
      "1\n",
      " cannot hold for any i 2, since that would imply a cycle\n",
      "a\n",
      "i\n",
      "\ta\n",
      "1\n",
      "\ta\n",
      "2\n",
      "\t\n",
      "a\n",
      "i\n",
      "and no cycles exist in a poset by Theorem \n",
      ". Therefore a\n",
      "1\n",
      " is a minimal element.\n",
      "Now were ready to prove Theorem \n",
      ", which says that every finite poset has a topological sort. The proof is rather intricate; understanding the argument requires a clear grasp of all the mathematical machinery related to posets and relations!\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 232  #238\n",
      "\n",
      "232\n",
      "\t\n",
      "Chapter 7\n",
      "\t\n",
      "Relations and Partial Orders\n",
      "Proof of Theorem \n",
      ". We use induction. Let P .n/ be the proposition that every n-element poset has a topological sort.\n",
      "Base case: Every 1-element poset is already a total order and thus is its own topo-logical sort. So P .1/ is true.\n",
      "Inductive step: Now we assume P .n/ in order to prove P .n C 1/ where n 1. Let .A; / be an .n C 1/-element poset. By Lemma \n",
      ", there exists a minimal element in a 2 A. Remove a and all pairs in involving a to obtain an n-element poset .A\n",
      "0\n",
      "; \n",
      "0\n",
      "/. This has a topological sort .A\n",
      "0\n",
      "; \n",
      "0\n",
      "T\n",
      " / by the assumption P .n/. Now we construct a total order .A; \n",
      "T\n",
      " / by adding a back as an element smaller than all the others. Formally, let\n",
      "T\n",
      " D \n",
      "0\n",
      "T\n",
      " [f .a; z/ j z 2 A g:\n",
      "All that remains is to check that this total order is consistent with the original partial order .A; /; that is, we must show that\n",
      "x\ty \n",
      "IMPLIES\n",
      " x\n",
      "\t\n",
      "T \n",
      "y:\n",
      "We assume that the left side is true and show that the right side follows. There are two cases.\n",
      "Case 1 If x D a, then a\n",
      "\t\n",
      "T \n",
      "y\n",
      " \n",
      "holds, because\n",
      " \n",
      "a\n",
      "  \n",
      "T\n",
      " \n",
      "z\n",
      " \n",
      "for all\n",
      " \n",
      "z\n",
      " \n",
      "2\n",
      " \n",
      "A.\n",
      "Case 2 if x  a, then y can not equal a either, since a is a minimal element in the partial order . Thus, both x and y are in A\n",
      "0\n",
      " and so x \n",
      "0\n",
      " y. This means\n",
      "0\n",
      "T\n",
      " y, since \n",
      "0\n",
      "T\n",
      " is a topological sort of the partial order \n",
      "0\n",
      ". And this implies x \n",
      "T\n",
      " y since \n",
      "T\n",
      " contains \n",
      "0\n",
      "T\n",
      " .\n",
      "Thus, .A; \n",
      "T\n",
      " / is a topological sort of .A; /. This shows that P .n/ implies P .n C 1/ for all n 1. Therefore P .n/ is true for all n 1 by the principle of\n",
      "induction, which proves the theorem.\n",
      "\n",
      "7.8\n",
      "\t\n",
      "Parallel Task Scheduling\n",
      "When items of a poset are tasks that need to be done and the partial order is a precedence constraint, topological sorting provides us with a way to execute the tasks sequentially without violating the precedence constraints.\n",
      "But what if we have the ability to execute more than one task at the same time? For example, suppose that the tasks are programs, the partial order indicates data\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 233  #239\n",
      "\n",
      "7.8. Parallel Task Scheduling\n",
      "\t\n",
      "233\n",
      "A\n",
      "1\n",
      "\t\n",
      "left sock\tright sock\tunderwear\n",
      "\t\n",
      "shirt\n",
      "\n",
      "A\n",
      "2                                     \n",
      "\n",
      " pants    \n",
      "\n",
      " tie\n",
      "A\n",
      "3\n",
      "\t\n",
      "left shoe\tright shoe\n",
      "\t\n",
      "belt\n",
      "A\n",
      "4\n",
      "\t\n",
      "jacket\n",
      "Figure 7.13 A parallel schedule for the tasks-in-getting-dressed poset in Fig-ure \n",
      ". The tasks in A\n",
      "i\n",
      " can be performed in step i for 1 i 4. A chain of length 4 (the critical path in this example) is shown with bold edges.\n",
      "dependence, and we have a parallel machine with lots of processors instead of a sequential machine with only one processor. How should we schedule the tasks so as to minimize the total time used?\n",
      "For simplicity, assume all tasks take 1 unit of time and we have an unlimited number of identical processors. For example, in the clothes example in Figure \n",
      ", how long would it take to handle all the garments?\n",
      "In the first unit of time, we should do all minimal items, so we would put on our left sock, our right sock, our underwear, and our shirt.\n",
      "In the second unit of time, we should put on our pants and our tie. Note that we cannot put on our left or right shoe yet, since we have not yet put on our pants. In the third unit of time, we should put on our left shoe, our right shoe, and our belt. Finally, in the last unit of time, we can put on our jacket. This schedule is illustrated in Figure \n",
      ".\n",
      "The total time to do these tasks is 4 units. We cannot do better than 4 units of\n",
      "\n",
      "Yes, we know that you cant actually put on both socks at once, but imagine you are being dressed by a bunch of robot processors and you are in a big hurry. Still not working for you? Ok, forget about the clothes and imagine they are programs with the precedence constraints shown in Figure \n",
      ".\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 234  #240\n",
      "\n",
      "234\n",
      "\t\n",
      "Chapter 7\n",
      "\t\n",
      "Relations and Partial Orders\n",
      "time because there is a sequence of 4 tasks, each needing to be done before the next, of length 4. For example, we must put on our shirt before our pants, our pants before our belt, and our belt before our jacket. Such a sequence of items is known as a chain\n",
      "Definition 7.8.1. A chain is a sequence a\n",
      "1\n",
      "\t\n",
      "a\n",
      "2\n",
      "\t\n",
      "a\n",
      "t\n",
      " , where a\n",
      "i\n",
      "  a\n",
      "j\n",
      " for all\n",
      " j , such that each item is comparable to the next in the chain, and it is smaller with respect to . The length of the chain is t, the number of elements in the chain.\n",
      "Thus, the time it takes to schedule tasks, even with an unlimited number of pro-cessors, is at least the length of the longest chain. Indeed, if we used less time, then two items from a longest chain would have to be done at the same time, which con-tradicts the precedence constraints. For this reason, a longest chain is also known as a critical path. For example, Figure \n",
      "shows the critical path for the getting-dressed poset.\n",
      "In this example, we were in fact able to schedule all the tasks in t steps, where\n",
      "is the length of the longest chain. The really nice thing about posets is that this is always possible! In other words, for any poset, there is a legal parallel schedule that runs in t steps, where t is the length of the longest chain.\n",
      "There are lots of ways to prove this fact. Our proof will also give us the corre-sponding schedule in t time steps, and allow us to obtain some nice corollaries.\n",
      "Theorem 7.8.2. Given any finite poset .A; / for which the longest chain has length t, it is possible to partition A into t subsets A\n",
      "1\n",
      ", A\n",
      "2\n",
      ", . . . , A\n",
      "t\n",
      " such that for all i 2 f1; 2; : : : ; tg and for all a 2 A\n",
      "i\n",
      " , we have that all b a appear in the set A\n",
      "1\n",
      " [ : : : [ A\n",
      "i1\n",
      " .\n",
      "Before proving this theorem, first note that for each i, all items in A\n",
      "i\n",
      " can be scheduled in time step i. This is because all preceding tasks are scheduled in pre-ceding time steps, and thus are already completed. So the theorem implies that\n",
      "Corollary 7.8.3. The total amount of parallel time needed to complete the tasks is the same as the length of the longest chain.\n",
      "Proof of Theorem \n",
      ". For all a 2 A\n",
      "i\n",
      " , put a in A\n",
      "i\n",
      " , where i is the length of the longest chain ending at a. For example, the A\n",
      "i\n",
      " for the getting-dressed poset are shown in Figure \n",
      ". In what follows, we show that for all i, for all a 2 A\n",
      "i\n",
      " and for all b a with b  a, we have b 2 A\n",
      "1\n",
      " [ A\n",
      "2\n",
      " [ : : : [ A\n",
      "i1\n",
      " .\n",
      "We prove this by contradiction. Assume there is some i, a 2 A\n",
      "i\n",
      " , and b a with b  a and b A\n",
      "1\n",
      " [ A\n",
      "2\n",
      " [ : : : [ A\n",
      "i1\n",
      " . By the way we defined A\n",
      "i\n",
      " , this implies there is a chain of length at least i ending at b. Since b a and b  a, we can extend this chain to a chain of length at least i C 1, ending at a. But then a could\n",
      "not be in A\n",
      "i\n",
      " . This is a contradiction.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 235  #241\n",
      "\n",
      "If we have an unlimited number of processors, then the time to complete all tasks is equal to the length of the longest chain of dependent tasks. The case where there are only a limited number of processors is very useful in practice and it is covered in the Problems section.\n",
      "\n",
      "7.9\tDilworths Lemma\n",
      "Definition 7.9.1. An antichain in a poset is a set of elements such that any two elements in the set are incomparable.\n",
      "For example, each A\n",
      "i\n",
      " in the proof of Theorem \n",
      "and in Figure \n",
      "is an antichain since its elements have no dependencies between them (which is why they could be executed at the same time).\n",
      "Our conclusions about scheduling also tell us something about antichains.\n",
      "Corollary 7.9.2. If the largest chain in a partial order on a set A is of size t, then A can be partitioned into t antichains.\n",
      "Proof. Let the antichains be the sets A\n",
      "1\n",
      ", A\n",
      "2\n",
      ", . . . , A\n",
      "t\n",
      " defined in Theorem \n",
      ".\n",
      "Corollary \n",
      "implies a famous result\n",
      "about partially ordered sets:\n",
      "Lemma 7.9.3 (Dilworth). For all t > 0, every partially ordered set with n elements must have either a chain of size greater than t or an antichain of size at least n=t.\n",
      "Proof. By contradiction. Assume that the longest chain has length at most t and the longest antichain has size less than n=t. Then by Corollary \n",
      ", the n elements can be partitioned into at most t antichains. Hence, there are fewer than t n=t D n elements in the poset, which is a contradiction. Hence there must be a chain longer\n",
      "than t or an antichain with at least n=t elements.\n",
      "As an application, consider a permutation of the numbers from 1 to n arranged\n",
      "as a sequence from left to right on a line. Corollary \n",
      "can be used to show p\n",
      "\n",
      "that there must be a\n",
      "\t\n",
      "n-length subsequence of these numbers that is completely\n",
      "\n",
      "8\n",
      "Lemma \n",
      "also follows from a more general result known as Dilworths Theorem that we will not discuss.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 236  #242\n",
      "\n",
      "236\n",
      "\t\n",
      "Chapter 7\n",
      "\t\n",
      "Relations and Partial Orders\n",
      "increasing or completely decreasing as you move from left to right. For example, the sequence\n",
      "7;8;9;4;5;6;1;2;3\n",
      "has an increasing subsequence of length 3 (for example, 7, 8, 9) and a decreasing subsequence of length 3 (for example, 9, 6, 3). The proof of this result is left as an exercise that will test your ability to find the right partial order on the numbers in the sequence.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 237  #243\n",
      "\n",
      "State Machines\n",
      "This chapter needs to be reworked.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 238  #244\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 239  #245\n",
      "\n",
      "III\n",
      "\t\n",
      "Counting\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 240  #246\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 241  #247\n",
      "\n",
      "Introduction\n",
      "Counting seems easy enough: 1, 2, 3, 4, etc. This direct approach works well for counting simple thingslike your toesand may be the only approach for ex-tremely complicated things with no identifiable structure. However, subtler meth-ods can help you count many things in the vast middle ground, such as:\n",
      "The number of different ways to select a dozen doughnuts when there are five varieties available.\n",
      "The number of 16-bit numbers with exactly 4 ones.\n",
      "Perhaps surprisingly, but certainly not coincidentally, the number in each of these two situations is the same: 1820.\n",
      "Counting is useful in computer science for several reasons:\n",
      "Determining the time and storage required to solve a computational problem a central objective in computer scienceoften comes down to solving a counting problem.\n",
      "Counting is the basis of probability theory, which plays a central role in all sciences, including computer science.\n",
      "Two remarkable proof techniques, the pigeonhole principle and combi-natorial proof, rely on counting. These lead to a variety of interesting and useful insights.\n",
      "In the next several chapters, were going to present a lot of rules for counting. These rules are actually theorems, and we will prove some of them, but our focus wont be on the proofs per seour objective is to teach you simple counting as a practical skill, like integration.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 242  #248\n",
      "\n",
      "242\n",
      "\t\n",
      "Part III\n",
      "\t\n",
      "Counting\n",
      "We begin our study of counting in Chapter \n",
      "with a collection of rules and meth-ods for finding closed-form expressions for commonly-occurring sums and prod-\n",
      "how a quantity such as the running time of a program grows with the size of the input.\n",
      "In Chapter \n",
      ", we show how to solve a variety of recurrences that arise in com-putational problems. These methods are especially useful when you need to design or analyze recursive programs.\n",
      "In Chapters \n",
      "and \n",
      ", we describe the most basic rules for determining the cardinality of a set. This material is simple yet powerful, and it provides a great tool set for use in your future career.\n",
      "We conclude in Chapter \n",
      "with a brief digression into the final frontier of countinginfinity. Well define what it means for a set to be countable and show you some examples of sets that are really bigbigger even than the set of real numbers.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 243  #249\n",
      "\n",
      "Sums and Asymptotics\n",
      "Sums and products arise regularly in the analysis of algorithms, financial applica-tions, physical problems, and probabilistic systems. For example, we have already encountered the sum \n",
      "1\n",
      " C \n",
      "2\n",
      " C \n",
      "4\n",
      " C C \n",
      "N\n",
      " when counting the number of nodes in a complete binary tree with \n",
      "N\n",
      " inputs. Although such a sum can be represented compactly using the sigma notation\n",
      "iD0\n",
      "it is a lot easier and more helpful to express the sum by its closed form value\n",
      "2N\t1:\n",
      "By closed form, we mean an expression that does not make use of summation or product symbols or otherwise need those handy (but sometimes troublesome) dots. . . . Expressions in closed form are usually easier to evaluate (it doesnt get much simpler than \n",
      "2N 1\n",
      ", for example) and it is usually easier to get a feel for their magnitude than expressions involving large sums and products.\n",
      "But how do you find a closed form for a sum or product? Well, its part math and part art. And it is the subject of this chapter.\n",
      "We will start the chapter with a motivating example involving annuities. Figuring out the value of the annuity will involve a large and nasty-looking sum. We will then describe several methods for finding closed forms for all sorts of sums, including the annuity sums. In some cases, a closed form for a sum may not exist and so we will provide a general method for finding good upper and lower bounds on the sum (which are closed form, of course).\n",
      "The methods we develop for sums will also work for products since you can convert any product into a sum by taking a logarithm of the product. As an example, we will use this approach to find a good closed-form approximation to\n",
      "n \n",
      "WWD\n",
      " 1 2 3\n",
      "\t\n",
      "n:\n",
      "We conclude the chapter with a discussion of asymptotic notation. Asymptotic notation is often used to bound the error terms when there is no exact closed form expression for a sum or product. It also provides a convenient way to express the growth rate or order of magnitude of a sum or product.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 244  #250\n",
      "\n",
      "244\n",
      "\t\n",
      "Chapter 9\n",
      "\t\n",
      "Sums and Asymptotics\n",
      "\n",
      "9.1\n",
      "\t\n",
      "The Value of an Annuity\n",
      "Would you prefer a million dollars today or $50,000 a year for the rest of your life? On the one hand, instant gratification is nice. On the other hand, the total dollars received at $50K per year is much larger if you live long enough.\n",
      "Formally, this is a question about the value of an annuity. An annuity is a finan-cial instrument that pays out a fixed amount of money at the beginning of every year for some specified number of years. In particular, an n-year, m-payment annuity pays m dollars at the start of each year for n years. In some cases, n is finite, but not always. Examples include lottery payouts, student loans, and home mortgages. There are even Wall Street people who specialize in trading annuities.\n",
      "A key question is, What is an annuity worth? For example, lotteries often pay out jackpots over many years. Intuitively, $50,000 a year for 20 years ought to be worth less than a million dollars right now. If you had all the cash right away, you could invest it and begin collecting interest. But what if the choice were between $50,000 a year for 20 years and a half million dollars today? Now it is not clear which option is better.\n",
      "9.1.1\n",
      "\t\n",
      "The Future Value of Money\n",
      "In order to answer such questions, we need to know what a dollar paid out in the future is worth today. To model this, lets assume that money can be invested at a fixed annual interest rate p. Well assume an 8% rate\n",
      "for the rest of the discussion.\n",
      "Here is why the interest rate p matters. Ten dollars invested today at interest rate\n",
      "will become .1 C p/ 10 D 10:80 dollars in a year, .1 C p/\n",
      "2\n",
      " 10 11:66 dollars in two years, and so forth. Looked at another way, ten dollars paid out a year from now is only really worth 1=.1 C p/ 10 9:26 dollars today. The reason is that if we had the $9.26 today, we could invest it and would have $10.00 in a year anyway. Therefore, p determines the value of money paid out in the future.\n",
      "So for an n-year, m-payment annuity, the first payment of m dollars is truly worth m dollars. But the second payment a year later is worth only m=.1 C p/ dollars. Similarly, the third payment is worth m=.1 C p/\n",
      "2\n",
      ", and the n-th payment is worth only m=.1 C p/\n",
      "n1\n",
      " . The total value, V , of the annuity is equal to the sum of the\n",
      "1\n",
      "Such trading ultimately led to the subprime mortgage disaster in 20082009. Well talk more about that in Section \n",
      ".\n",
      "2\n",
      "U.S. interest rates have dropped steadily for several years, and ordinary bank deposits now earn around 1.5%. But just a few years ago the rate was 8%; this rate makes some of our examples a little more dramatic. The rate has been as high as 17% in the past thirty years.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 245  #251\n",
      "\n",
      "payment values. This gives:\n",
      "\n",
      "C\n",
      "D\n",
      "n1\n",
      "m\n",
      "  \n",
      "X\n",
      " \n",
      "x\n",
      "j\n",
      "j D0\n",
      "\n",
      "\n",
      "The goal of the preceding substitutions was to get the summation into a simple special form so that we can solve it with a general formula. In particular, the terms of the sum\n",
      "n1\n",
      "X\n",
      " x\n",
      "j\n",
      " D 1 C x C x\n",
      "2\n",
      " C x\n",
      "3\n",
      " C\n",
      "\t\n",
      "C x\n",
      "n1\n",
      "D0\n",
      "form a geometric series, which means that the ratio of consecutive terms is always the same and it is a positive value less than one. In this case, the ratio is always x, and 0 < x < 1 since we assumed that p > 0. It turns out that there is a nice closed-form expression for any geometric series; namely\n",
      "Equation \n",
      "can be verified by induction, but, as is often the case, the proof by induction gives no hint about how the formula was found in the first place. So well take this opportunity to describe a method that you could use to figure it out for yourself. It is called the Perturbation Method.\n",
      "9.1.2\n",
      "\t\n",
      "The Perturbation Method\n",
      "Given a sum that has a nice structure, it is often useful to perturb the sum so that we can somehow combine the sum with the perturbation to get something much simpler. For example, suppose\n",
      "S D 1 C x C x\n",
      "2\n",
      " C\n",
      "\t\n",
      "C x\n",
      "n1\n",
      "  :\n",
      "An example of a perturbation would be\n",
      "xS D x C x\n",
      "2\n",
      " C\n",
      "\t\n",
      "C x\n",
      "n\n",
      ":\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 246  #252\n",
      "\n",
      "246\n",
      "\t\n",
      "Chapter 9\n",
      "\t\n",
      "Sums and Asymptotics\n",
      "The difference between S and xS is not so great, and so if we were to subtract xS from S, there would be massive cancellation:\n",
      "D 1 C x C x\n",
      "2\n",
      " C x\n",
      "3\n",
      " C  C x\n",
      "n1\n",
      "xS\n",
      "\t\n",
      "D\n",
      "\t\n",
      "x\tx\n",
      "2\n",
      "\tx\n",
      "3\n",
      "\t\n",
      "x\n",
      "n1\n",
      "\tx\n",
      "n\n",
      ":\n",
      "The result of the subtraction is\n",
      "S\txS D 1\tx\n",
      "n\n",
      ":\n",
      "Solving for S gives the desired closed-form expression in Equation \n",
      ":\n",
      "S\n",
      " \n",
      "D\n",
      " 1\n",
      "\t\n",
      "x\n",
      "n\n",
      " \n",
      ":\n",
      "\n",
      "1\tx\n",
      "Well see more examples of this method when we introduce generating functions in Chapter \n",
      ".\n",
      "9.1.3\n",
      "\t\n",
      "A Closed Form for the Annuity Value\n",
      "Using Equation \n",
      ", we can derive a simple formula for V , the value of an annuity that pays m dollars at the start of each year for n years.\n",
      "Equation \n",
      "is much easier to use than a summation with dozens of terms. For example, what is the real value of a winning lottery ticket that pays $50,000 per year for 20 years? Plugging in m D $50,000, n D 20, and p D 0:08 gives\n",
      "$530,180. So because payments are deferred, the million dollar lottery is really only worth about a half million dollars! This is a good trick for the lottery advertisers.\n",
      "9.1.4\n",
      "\t\n",
      "Infinite Geometric Series\n",
      "The question we began with was whether you would prefer a million dollars today or $50,000 a year for the rest of your life. Of course, this depends on how long you live, so optimistically assume that the second option is to receive $50,000 a year forever. This sounds like infinite money! But we can compute the value of an annuity with an infinite number of payments by taking the limit of our geometric sum in Equation \n",
      "as n tends to infinity.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 247  #253\n",
      "\n",
      "Theorem 9.1.1. If jxj < 1, then\n",
      "1\n",
      "X\n",
      " x\n",
      "i\n",
      " D \n",
      "1\n",
      " \n",
      "1\n",
      " \n",
      "x\n",
      " :\n",
      "\n",
      "iD0\n",
      "Proof.\n",
      "n1\n",
      "1\n",
      " \n",
      "1\n",
      " \n",
      "x\n",
      " :\n",
      "\n",
      "The final line follows from that fact that lim\n",
      "n!1\n",
      " x\n",
      "n\n",
      " D 0 when jxj < 1.\n",
      "In our annuity problem, x D 1=.1 C p/ < 1, so Theorem \n",
      "applies, and we get\n",
      "1\n",
      "V D m  \n",
      "X\n",
      " x\n",
      "j\n",
      "j D0\n",
      "1\n",
      "D m  \n",
      "1\n",
      "\t\n",
      "x\n",
      "\n",
      "\n",
      "\n",
      "(by Equation \n",
      ")\n",
      "(by Theorem \n",
      ")\n",
      ".x D 1=.1 C p//:\n",
      "Plugging in m D $50,000 and p D 0:08, we see that the value V is only $675,000. Amazingly, a million dollars today is worth much more than $50,000 paid every year forever! Then again, if we had a million dollars today in the bank earning 8% interest, we could take out and spend $80,000 a year forever. So on second thought, this answer really isnt so amazing.\n",
      "9.1.5\n",
      "\t\n",
      "Examples\n",
      "Equation \n",
      "and Theorem \n",
      "are incredibly useful in computer science. In fact, we already used Equation \n",
      "implicitly when we claimed in Chapter \n",
      "than an N -input complete binary tree has\n",
      "1C2C4C\n",
      "\t\n",
      "CN D2N\n",
      "\t\n",
      "1\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 248  #254\n",
      "\n",
      "248\n",
      "\t\n",
      "Chapter 9\n",
      "\t\n",
      "Sums and Asymptotics\n",
      "nodes. Here are some other common sums that can be put into closed form using\n",
      "Equation \n",
      "and Theorem \n",
      ":\n",
      "If the terms in a geometric sum grow smaller, as in Equation \n",
      ", then the sum is said to be geometrically decreasing. If the terms in a geometric sum grow progres-sively larger, as in Equations \n",
      "and \n",
      ", then the sum is said to be geometrically increasing. In either case, the sum is usually approximately equal to the term in the sum with the greatest absolute value. For example, in Equations \n",
      "and \n",
      ", the largest term is equal to 1 and the sums are 2 and 2/3, both relatively close to 1. In Equation \n",
      ", the sum is about twice the largest term. In Equation \n",
      ", the largest term is 3\n",
      "n1\n",
      " and the sum is .3\n",
      "n\n",
      " 1/=2, which is only about a factor of 1:5 greater. You can see why this rule of thumb works by looking carefully at Equation \n",
      "and Theorem \n",
      ".\n",
      "9.1.6\n",
      "\t\n",
      "Variations of Geometric Sums\n",
      "We now know all about geometric sumsif you have one, life is easy. But in practice one often encounters sums that cannot be transformed by simple variable substitutions to the form \n",
      "P\n",
      " x\n",
      "i\n",
      " .\n",
      "A non-obvious, but useful way to obtain new summation formulas from old is by differentiating or integrating with respect to x. As an example, consider the following sum:\n",
      "n1\n",
      "X\n",
      " ix\n",
      "i\n",
      " D x C 2x\n",
      "2\n",
      " C 3x\n",
      "3\n",
      " C\n",
      "\t\n",
      "C .n\n",
      "\t\n",
      "1/x\n",
      "n1\n",
      "D1\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 249  #255\n",
      "\n",
      "This is not a geometric sum, since the ratio between successive terms is not fixed, and so our formula for the sum of a geometric sum cannot be directly applied. But suppose that we differentiate Equation \n",
      ":\n",
      "D\n",
      "The left-hand side of Equation \n",
      "is simply\n",
      "Hence, Equation \n",
      "means that\n",
      "Often, differentiating or integrating messes up the exponent of x in every term. In this case, we now have a formula for a sum of the form \n",
      "P\n",
      " ix\n",
      "i1\n",
      " , but we want a formula for the series \n",
      "P\n",
      " ix\n",
      "i\n",
      " . The solution is simple: multiply by x. This gives:\n",
      "and we have the desired closed-form expression for our sum\n",
      ". Its a little compli-cated looking, but its easier to work with than the sum.\n",
      "Notice that if jxj < 1, then this series converges to a finite value even if there are infinitely many terms. Taking the limit of Equation \n",
      "as n tends infinity gives the following theorem:\n",
      "\n",
      "Since we could easily have made a mistake in the calculation, it is always a good idea to go back and validate a formula obtained this way with a proof by induction.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 250  #256\n",
      "\n",
      "250\n",
      "\t\n",
      "Chapter 9\n",
      "\t\n",
      "Sums and Asymptotics\n",
      "Theorem 9.1.2. If jxj < 1, then\n",
      "As a consequence, suppose that there is an annuity that pays im dollars at the end of each year i forever. For example, if m D $50,000, then the payouts are $50,000 and then $100,000 and then $150,000 and so on. It is hard to believe that the value of this annuity is finite! But we can use Theorem \n",
      "to compute the value:\n",
      "1\n",
      "X\n",
      "\t\n",
      "im\n",
      "V D\n",
      "\n",
      "The second line follows by an application of Theorem \n",
      ". The third line is obtained by multiplying the numerator and denominator by .1 C p/\n",
      "2\n",
      ".\n",
      "For example, if m D $50,000, and p D 0:08 as usual, then the value of the annuity is V D $8,437,500. Even though the payments increase every year, the in-crease is only additive with time; by contrast, dollars paid out in the future decrease in value exponentially with time. The geometric decrease swamps out the additive increase. Payments in the distant future are almost worthless, so the value of the annuity is finite.\n",
      "The important thing to remember is the trick of taking the derivative (or integral) of a summation formula. Of course, this technique requires one to compute nasty derivatives correctly, but this is at least theoretically possible!\n",
      "\n",
      "9.2\n",
      "\t\n",
      "Power Sums\n",
      "In Chapter \n",
      ", we verified the formula\n",
      "But the source of this formula is still a mystery. Sure, we can prove it is true using well ordering or induction, but where did the expression on the right come from in\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 251  #257\n",
      "\n",
      "the first place? Even more inexplicable is the closed form expression for the sum of consecutive squares:\n",
      "n\n",
      "X\n",
      " \n",
      "i\n",
      "2 \n",
      "D\n",
      " \n",
      ".2n\n",
      " \n",
      "C\n",
      " \n",
      "1/.n\n",
      " \n",
      "C\n",
      " \n",
      "1/n\n",
      ":\n",
      "\t\n",
      "(9.14)\n",
      "\n",
      "6\n",
      "D1\n",
      "It turns out that there is a way to derive these expressions, but before we explain it, we thought it would be fun\n",
      "to show you how Gauss proved Equation \n",
      "when he was a young boy.\n",
      "Gausss idea is related to the perturbation method we used in Section \n",
      ". Let\n",
      "n\n",
      "X\n",
      "S D\n",
      "\t\n",
      "i:\n",
      "iD1\n",
      "Then we can write the sum in two orders:\n",
      "S D 1 C\t2\n",
      "\t\n",
      "C : : : C .n\n",
      "\t\n",
      "1/ C n;\n",
      "S D n C .n\t1/ C : : : C\t2\n",
      "\t\n",
      "C 1:\n",
      "Adding these two equations gives\n",
      "2S D .n C 1/ C .n C 1/ C\n",
      "\t\n",
      "C .n C 1/ C .n C 1/\n",
      "n.n C 1/:\n",
      "Hence,\n",
      "D\n",
      " n.n C 1/\n",
      ":\n",
      " 2\n",
      "\n",
      "Not bad for a young child. Looks like Gauss had some potential.. . .\n",
      "Unfortunately, the same trick does not work for summing consecutive squares. However, we can observe that the result might be a third-degree polynomial in n, since the sum contains n terms that average out to a value that grows quadratically in n. So we might guess that\n",
      "n\n",
      "X\n",
      " i\n",
      "2\n",
      " D an\n",
      "3\n",
      " C bn\n",
      "2\n",
      " C cn C d:\n",
      "D1\n",
      "If the guess is correct, then we can determine the parameters a, b, c, and d by plugging in a few values for n. Each such value gives a linear equation in a, b,\n",
      "\n",
      "Remember that we are mathematicians, so our definition of fun may be different than yours.\n",
      "5\n",
      "We suspect that Gauss was probably not an ordinary boy.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 252  #258\n",
      "\n",
      "252\n",
      "\t\n",
      "Chapter 9\n",
      "\t\n",
      "Sums and Asymptotics\n",
      "c, and d . If we plug in enough values, we may get a linear system with a unique solution. Applying this method to our example gives:\n",
      "Solving this system gives the solution a D 1=3, b D 1=2, c D 1=6, d D 0. Therefore, if our initial guess at the form of the solution was correct, then the summation is equal to n\n",
      "3\n",
      "=3 C n\n",
      "2\n",
      "=2 C n=6, which matches Equation \n",
      ".\n",
      "The point is that if the desired formula turns out to be a polynomial, then once you get an estimate of the degree of the polynomial, all the coefficients of the polynomial can be found automatically.\n",
      "Be careful! This method lets you discover formulas, but it doesnt guarantee they are right! After obtaining a formula by this method, its important to go back and prove it using induction or some other method, because if the initial guess at the solution was not of the right form, then the resulting formula will be completely wrong!\n",
      "\n",
      "9.3\n",
      "\t\n",
      "Approximating Sums\n",
      "Unfortunately, it is not always possible to find a closed-form expression for a sum. For example, consider the sum\n",
      "n\n",
      "  p\n",
      "X\n",
      "\n",
      "S D\n",
      "\t\n",
      "i:\n",
      "iD1\n",
      "No closed form expression is known for S.\n",
      "In such cases, we need to resort to approximations for S if we want to have a closed form. The good news is that there is a general method to find closed-form upper and lower bounds that work for most any sum. Even better, the method is simple and easy to remember. It works by replacing the sum by an integral and then adding either the first or last term in the sum.\n",
      "\n",
      "Alternatively, you can use the method based on generating functions described in Chapter \n",
      ", which does not require any guessing at all.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 253  #259\n",
      "\n",
      "Theorem 9.3.1. Let f W R\n",
      "C\n",
      " ! R\n",
      "C\n",
      " be a nondecreasing\n",
      "continuous function and let\n",
      "n\n",
      "X\n",
      "S D\n",
      "\t\n",
      "f .i/\n",
      "D1\n",
      "and\n",
      "Z \n",
      "n\n",
      "I D\n",
      "\t\n",
      "f .x/ dx:\n",
      "1\n",
      "Then\n",
      "I C f .1/\tS\tI C f .n/:\n",
      "Similarly, if f is nonincreasing, then\n",
      "I C f .n/\tS\tI C f .1/:\n",
      "p\n",
      "\n",
      "Proof. Let f W R\n",
      "C\n",
      " ! R\n",
      "C\n",
      " be a nondecreasing function. For example, f .x/ D x is such a function.\n",
      "Consider the graph shown in Figure \n",
      ". The value of\n",
      "n\n",
      "X\n",
      "S D\n",
      "\t\n",
      "f .i/\n",
      "D1\n",
      "is represented by the shaded area in this figure. This is because the ith rectangle in the figure (counting from left to right) has width 1 and height f .i/.\n",
      "The value of\n",
      "n\n",
      "I D\n",
      "\t\n",
      "f .x/ dx\n",
      "1\n",
      "is the shaded area under the curve of f .x/ from 1 to n shown in Figure \n",
      ". Comparing the shaded regions in Figures \n",
      "and \n",
      ", we see that S is at least\n",
      "plus the area of the leftmost rectangle. Hence,\n",
      "This is the lower bound for S. We next derive the upper bound.\n",
      "Figure \n",
      "shows the curve of f .x/ from 1 to n shifted left by 1. This is the same as the curve f .x C 1/ from 0 to n 1 and it has the same area I .\n",
      "Comparing the shaded regions in Figures \n",
      "and \n",
      ", we see that S is at most\n",
      "plus the area of the rightmost rectangle. Hence,\n",
      "\n",
      "7\n",
      "A function f is nondecreasing if f .x/ f .y/ whenever x y. It is nonincreasing if f .x/ f .y/ whenever x y.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 254  #260\n",
      "\n",
      "254\n",
      "\t\n",
      "Chapter 9\n",
      "\t\n",
      "Sums and Asymptotics\n",
      "f.n/\n",
      "\n",
      "f.n\n",
      "\n",
      "1/\n",
      "\n",
      "f.3/\n",
      "\n",
      "f.2/\n",
      "\n",
      "f.1/\n",
      "\n",
      "0\n",
      "\t\n",
      "1\n",
      "\t\n",
      "2\n",
      "\t\n",
      "3\n",
      "\t\n",
      "n\n",
      "\n",
      "2\tn\n",
      "\n",
      "1\n",
      "\t\n",
      "n\n",
      "Figure 9.1\n",
      "P\n",
      "n\n",
      "iD1\n",
      " f .i/.\n",
      "f.n/\n",
      "f.n\n",
      "\n",
      "1/\n",
      "f.3/\n",
      "f.2/\n",
      "f.1/\n",
      "\n",
      "\n",
      "The area of the ith rectangle is f .i/.  The shaded region has area\n",
      "\n",
      "f.x/\n",
      "\n",
      "0\n",
      "\t\n",
      "1\n",
      "\t\n",
      "2\n",
      "\t\n",
      "3\n",
      "\t\n",
      "n\n",
      "\n",
      "2\tn\n",
      "\n",
      "1\n",
      "\t\n",
      "n\n",
      "Figure 9.2\n",
      "\t\n",
      "The shaded area under the curve of f .x/ from 1 to n (shown in bold)\n",
      "R\n",
      "is I D \n",
      "1\n",
      "n\n",
      " f .x/ dx.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 255  #261\n",
      "\n",
      "\n",
      "f.n/\n",
      "\n",
      "f.n\n",
      "\n",
      "1/\n",
      "\t\n",
      "f.x\n",
      "C\n",
      "1/\n",
      "\n",
      "f.3/\n",
      "\n",
      "f.2/\n",
      "\n",
      "f.1/\n",
      "\n",
      "0\n",
      "\t\n",
      "1\n",
      "\t\n",
      "2\n",
      "\t\n",
      "3\n",
      "\t\n",
      "n\n",
      "\n",
      "2\tn\n",
      "\n",
      "1\n",
      "\t\n",
      "n\n",
      "Figure 9.3 The shaded area under the curve of f .x C 1/ from 0 to n 1 is I , the same as the area under the curve of f .x/ from 1 to n. This curve is the same as the curve in Figure \n",
      "except that has been shifted left by 1.\n",
      "Combining Equations \n",
      "and \n",
      ", we find that\n",
      "I C f .1/\tS\tI C f .n/;\n",
      "for any nondecreasing function f , as claimed\n",
      "The argument for the case when f is nonincreasing is very similar. The analo-gous graphs to those shown in Figures \n",
      "\n",
      "are provided in Figure \n",
      ". As you can see by comparing the shaded regions in Figures \n",
      "(a) and \n",
      "(b),\n",
      "S\tI C f .1/:\n",
      "Similarly, comparing the shaded regions in Figures \n",
      "(a) and \n",
      "(c) reveals that\n",
      "S\tI C f .n/:\n",
      "Hence, if f is nonincreasing,\n",
      "I C f .n/\tS\tI C f .1/:\n",
      "as claimed.\n",
      "Theorem \n",
      "provides good bounds for most sums. At worst, the bounds will be off by the largest term in the sum. For example, we can use Theorem \n",
      "to bound the sum\n",
      "n  \n",
      "p\n",
      "X\n",
      "\n",
      "S D\n",
      "\t\n",
      "i\n",
      "D1\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 256  #262\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 257  #263\n",
      "\n",
      "as follows.\n",
      "In other words, the sum is very close to \n",
      "2\n",
      "3\n",
      " n\n",
      "3=2\n",
      ".\n",
      "Well be using Theorem \n",
      "extensively going forward. At the end of this chapter, we will also introduce some notation that expresses phrases like the sum is very close to in a more precise mathematical manner. But first, well see how Theorem \n",
      "can be used to resolve a classic paradox in structural engineering.\n",
      "\n",
      "9.4\n",
      "\t\n",
      "Hanging Out Over the Edge\n",
      "Suppose that you have n identical blocks\n",
      "and that you stack them one on top of the next on a table as shown in Figure \n",
      ". Is there some value of n for which it is possible to arrange the stack so that one of the blocks hangs out completely over the edge of the table without having the stack fall over? (You are not allowed to use glue or otherwise hold the stack in position.)\n",
      "Most peoples first response to this questionsometimes also their second and third responsesis No. No block will ever get completely past the edge of the table. But in fact, if n is large enough, you can get the top block to stick out as far as you want: one block-length, two block-lengths, any number of block-lengths!\n",
      "\n",
      "8\n",
      "We will assume that the blocks are rectangular, uniformly weighted and of length 1.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 258  #264\n",
      "\n",
      "258\n",
      "\t\n",
      "Chapter 9\n",
      "\t\n",
      "Sums and Asymptotics\n",
      "\n",
      "table\n",
      "Figure 9.5 A stack of 5 identical blocks on a table. The top block is hanging out over the edge of the table, but if you try stacking the blocks this way, the stack will fall over.\n",
      "9.4.1\tStability\n",
      "A stack of blocks is said to be stable if it will not fall over of its own accord. For example, the stack illustrated in Figure \n",
      "is not stable because the top block is sure to fall over. This is because the center or mass of the top block is hanging out over air.\n",
      "In general, a stack of n blocks will be stable if and only if the center of mass of the top i blocks sits over the .i C 1/st block for i D 1, 2, . . . , n 1, and over the table for i D n.\n",
      "We define the overhang of a stable stack to be the distance between the edge of the table and the rightmost end of the rightmost block in the stack. Our goal is thus to maximize the overhang of a stable stack.\n",
      "For example, the maximum possible overhang for a single block is 1=2. That is because the center of mass of a single block is in the middle of the block (which is distance 1=2 from the right edge of the block). If we were to place the block so that its right edge is more than 1=2 from the edge of the table, the center of mass would be over air and the block would tip over. But we can place the block so the center of mass is at the edge of the table, thereby achieving overhang 1=2. This position is illustrated in Figure \n",
      ".\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 259  #265\n",
      "\n",
      "center of mass\n",
      "of block\n",
      "\n",
      "table\n",
      "1=2\n",
      "Figure 9.6\n",
      "\t\n",
      "One block can overhang half a block length.\n",
      "In general, the overhang of a stack of blocks is maximized by sliding the entire stack rightward until its center of mass is at the edge of the table. The overhang will then be equal to the distance between the center of mass of the stack and the rightmost edge of the rightmost block. We call this distance the spread of the stack. Note that the spread does not depend on the location of the stack on the tableit is purely a property of the blocks in the stack. Of course, as we just observed, the maximum possible overhang is equal to the maximum possible spread. This relationship is illustrated in Figure \n",
      ".\n",
      "9.4.2\n",
      "\t\n",
      "A Recursive Solution\n",
      "Our goal is to find a formula for the maximum possible spread S\n",
      "n\n",
      " that is achievable with a stable stack of n blocks.\n",
      "We already know that S\n",
      "1\n",
      " D 1=2 since the right edge of a single block with length 1 is always distance 1=2 from its center of mass. Lets see if we can use a recursive approach to determine S\n",
      "n\n",
      " for all n. This means that we need to find a formula for S\n",
      "n\n",
      " in terms of S\n",
      "i\n",
      " where i < n.\n",
      "Suppose we have a stable stack S of n blocks with maximum possible spread S\n",
      "n\n",
      ". There are two cases to consider depending on where the rightmost block is in the stack.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 260  #266\n",
      "\n",
      "260\n",
      "\t\n",
      "Chapter 9\n",
      "\t\n",
      "Sums and Asymptotics\n",
      "\n",
      "center of mass\n",
      "\n",
      "of whole stack \n",
      "\n",
      "\n",
      "overhang\n",
      "Figure 9.7 The overhang is maximized by maximizing the spread and then plac-ing the stack so that the center of mass is at the edge of the table.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 261  #267\n",
      "\n",
      "Case 1: The rightmost block in S is the bottom block. Since the center of mass of the top n 1 blocks must be over the bottom block for stability, the spread is maximized by having the center of mass of the top n 1 blocks be directly over the left edge of the bottom block. In this case the center of mass of S is\n",
      "For example, see Figure \n",
      ".\n",
      "In fact, the scenario just described is easily achieved by arranging the blocks as shown in Figure \n",
      ", in which case we have the spread given by Equation \n",
      ". For example, the spread is 3=4 for 2 blocks, 5=6 for 3 blocks, 7=8 for 4 blocks, etc.\n",
      "Can we do any better? The best spread in Case 1 is always less than 1, which means that we cannot get a block fully out over the edge of the table in this scenario. Maybe our intuition was right that we cant do better. Before we jump to any false conclusions, however, lets see what happens in the other case.\n",
      "Case 2: The rightmost block in S is among the top n 1 blocks. In this case, the spread is maximized by placing the top n 1 blocks so that their center of mass is directly over the right end of the bottom block. This means that the center of mass for S is at location\n",
      "where C is the location of the center of mass of the top n 1 blocks. In other words, the center of mass of S is 1=2n to the left of the center of mass of the top\n",
      "1 blocks. (The difference is due to the effect of the bottom block, whose center of mass is 1=2 unit to the left of C .) This means that the spread of S is 1=2n greater than the spread of the top n 1 blocks (because we are in the case where\n",
      "\n",
      "The center of mass of a stack of blocks is the average of the centers of mass of the individual blocks.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 262  #268\n",
      "\n",
      "262\n",
      "\t\n",
      "Chapter 9\n",
      "\t\n",
      "Sums and Asymptotics\n",
      "\n",
      "\n",
      " bottom block\n",
      "\n",
      "center of mass of \n",
      "S\n",
      "Figure 9.8 The scenario where the bottom block is the rightmost block. In this case, the spread is maximized by having the center of mass of the top n 1 blocks be directly over the left edge of the bottom block.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 263  #269\n",
      "\n",
      "\n",
      "n\n",
      "\n",
      "1\n",
      "blocks\n",
      "table\n",
      "1=2\n",
      "\t\n",
      "1\n",
      "\n",
      "1=2n\n",
      "Figure 9.9 A method for achieving spread (and hence overhang) 1 1=2n with n blocks, where the bottom block is the rightmost block.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 264  #270\n",
      "\n",
      "for any n > 1.\n",
      "Uh-oh. This looks complicated. Maybe we are not almost done after all! Equation \n",
      "is an example of a recurrence. We will describe numerous tech-\n",
      "niques for solving recurrences in Chapter \n",
      ", but, fortunately, Equation \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is simple enough that we can solve it without waiting for all the hardware in Chap-ter \n",
      ".\n",
      "One of the first things to do when you have a recurrence is to get a feel for it by computing the first few terms. This often gives clues about a way to solve the recurrence, as it will in this case.\n",
      "We already know that S\n",
      "1\n",
      " D 1=2. What about S\n",
      "2\n",
      "? From Equation \n",
      ", we find that\n",
      "D 3=4:\n",
      "Both cases give the same spread, albeit by different approaches. For example, see Figure \n",
      ".\n",
      "That was easy enough. What about S\n",
      "3\n",
      "?\n",
      "max  \n",
      "5\n",
      "6\n",
      "; \n",
      "11\n",
      "12\n",
      "11\n",
      "12\n",
      ":\n",
      "\n",
      "As we can see, the method provided by Case 2 is the best. Lets check n D 4.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 265  #271\n",
      "\n",
      "table\n",
      "\n",
      "1=2\n",
      "\t\n",
      "3=4\n",
      "(a)\n",
      "table\n",
      "\n",
      "1=4\n",
      "\t\n",
      "1=2\n",
      "(b)\n",
      "Figure 9.10 Two ways to achieve spread (and hence overhang) 3=4 with n D 2 blocks. The first way (a) is from Case 1 and the second (b) is from Case 2.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 266  #272\n",
      "\n",
      "266\n",
      "\t\n",
      "Chapter 9\n",
      "\t\n",
      "Sums and Asymptotics\n",
      "Wow! This is a breakthroughfor two reasons. First, Equation \n",
      "tells us that by using only 4 blocks, we can make a stack so that one of the blocks is hanging out completely over the edge of the table. The two ways to do this are shown in Figure \n",
      ".\n",
      "The second reason that Equation \n",
      "is important is that we now know that S\n",
      "4\n",
      " > 1, which means that we no longer have to worry about Case 1 for n > 4 since Case 1 never achieves spread greater than 1. Moreover, even for n 4, we have now seen that the spread achieved by Case 1 never exceeds the spread achieved by Case 2, and they can be equal only for n D 1 and n D 2. This means that\n",
      "\n",
      "for all n > 1 since we have shown that the best spread can always be achieved using Case 2.\n",
      "The recurrence in Equation \n",
      "is much easier to solve than the one we started with in Equation \n",
      ". We can solve it by expanding the equation as follows:\n",
      "which is, indeed, the case.\n",
      "Equation \n",
      "can be verified by induction. The base case when n D 1 is true since we know that S\n",
      "1\n",
      " D 1=2. The inductive step follows from Equation \n",
      ".\n",
      "So we now know the maximum possible spread and hence the maximum possible overhang for any stable stack of books. Are we done? Not quite. Although we\n",
      "number H\n",
      "n\n",
      ".\n",
      "9.4.3\n",
      "\t\n",
      "Harmonic Numbers\n",
      "Definition 9.4.1. The nth Harmonic number is\n",
      "n\n",
      "X 1\n",
      "H\n",
      "n\n",
      " \n",
      "WWD\n",
      " \n",
      "iD1\n",
      " i \n",
      ":\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 267  #273\n",
      "\n",
      "1=2\n",
      "\n",
      "table\n",
      "1=8 1=6\n",
      "\t\n",
      "3=4\n",
      "(a)\n",
      "\n",
      "table\n",
      "1=8 1=6  1=4\n",
      "\t\n",
      "1=2\n",
      "(b)\n",
      "Figure 9.11 The two ways to achieve spread (and overhang) 25=24. The method in (a) uses Case 1 for the top 2 blocks and Case 2 for the others. The method in (b) uses Case 2 for every block that is added to the stack.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 268  #274\n",
      "\n",
      "There is good news and bad news about Harmonic numbers. The bad news is that there is no closed-form expression known for the Harmonic numbers. The good news is that we can use Theorem \n",
      "to get close upper and lower bounds on H\n",
      "n\n",
      ". In particular, since\n",
      "In other words, the nth Harmonic number is very close to ln.n/.\n",
      "Because the Harmonic numbers frequently arise in practice, mathematicians have worked hard to get even better approximations for them. In fact, it is now\n",
      "Here is a value 0:577215664 : : : called Eulers constant, and .n/ is between 0 and 1 for all n. We will not prove this formula.\n",
      "We are now finally done with our analysis of the block stacking problem. Plug-ging the value of H\n",
      "n\n",
      " into Equation \n",
      ", we find that the maximum overhang for n blocks is very close to \n",
      "1\n",
      "2\n",
      " ln.n/. Since ln.n/ grows to infinity as n increases, this means that if we are given enough blocks (in theory anyway), we can get a block to hang out arbitrarily far over the edge of the table. Of course, the number of blocks we need will grow as an exponential function of the overhang, so it will probably take you a long time to achieve an overhang of 2 or 3, never mind an overhang of 100.\n",
      "9.4.4\tAsymptotic Equality\n",
      "For cases like Equation \n",
      "where we understand the growth of a function like H\n",
      "n\n",
      " up to some (unimportant) error terms, we use a special notation, , to denote the leading term of the function. For example, we say that H\n",
      "n\n",
      " ln.n/ to indicate that the leading term of H\n",
      "n\n",
      " is ln.n/. More precisely:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 269  #275\n",
      "\n",
      "Definition 9.4.2. For functions f; g W R ! R, we say f is asymptotically equal to g, in symbols,\n",
      "f .x/\tg.x/\n",
      "iff\n",
      "lim f .x/=g.x/ D 1:\n",
      "x!1\n",
      "Although it is tempting to write H\n",
      "n\n",
      " ln.n/ C to indicate the two leading terms, this is not really right. According to Definition \n",
      ", H\n",
      "n\n",
      " ln.n/ Cc where c is any constant. The correct way to indicate that is the second-largest term is\n",
      "H\n",
      "n\n",
      "\t\n",
      "ln.n/\n",
      "\t\n",
      ".\n",
      "The reason that the notation is useful is that often we do not care about lower order terms. For example, if n D 100, then we can compute H.n/ to great precision\n",
      "We will spend a lot more time talking about asymptotic notation at the end of the chapter. But for now, lets get back to sums.\n",
      "\n",
      "9.5\n",
      "\t\n",
      "Double Trouble\n",
      "Sometimes we have to evaluate sums of sums, otherwise known as double summa-\n",
      "tions. This sounds hairy, and sometimes it is. But usually, it is straightforward\n",
      "you just evaluate the inner sum, replace it with a closed form, and then evaluate the\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 270  #276\n",
      "\n",
      "270\n",
      "\t\n",
      "Chapter 9\n",
      "\t\n",
      "Sums and Asymptotics\n",
      "outer sum (which no longer has a summation inside it). For example,\n",
      "When theres no obvious closed form for the inner sum, a special trick that is often useful is to try exchanging the order of summation. For example, suppose we want to compute the sum of the first n Harmonic numbers\n",
      "For intuition about this sum, we can apply Theorem \n",
      "to Equation \n",
      "to con-clude that the sum is close to\n",
      "Now lets look for an exact answer. If we think about the pairs .k; j / over which\n",
      "\n",
      "Ok, so maybe this one is a little hairy, but it is also fairly straightforward. Wait till you see the next one!\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 271  #277\n",
      "\n",
      "we are summing, they form a triangle:\n",
      "The summation in Equation \n",
      "is summing each row and then adding the row sums. Instead, we can sum the columns and then add the column sums. Inspecting the table we see that this double sum can be written as\n",
      "n\n",
      "\t\n",
      "n\n",
      "X\n",
      "D\n",
      "1 j\n",
      "X\n",
      "\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 272  #278\n",
      "\n",
      "272\n",
      "\t\n",
      "Chapter 9\n",
      "\t\n",
      "Sums and Asymptotics\n",
      "\n",
      "9.6\n",
      "\t\n",
      "Products\n",
      "Weve covered several techniques for finding closed forms for sums but no methods for dealing with products. Fortunately, we do not need to develop an entirely new set of tools when we encounter a product such as\n",
      "iD1\n",
      "Thats because we can convert any product into a sum by taking a logarithm. For example, if\n",
      "X\n",
      "ln\n",
      ".P /\n",
      " D\n",
      "\t\n",
      "ln\n",
      ".f .i//:\n",
      "iD1\n",
      "We can then apply our summing tools to find a closed form (or approximate closed form) for ln\n",
      ".P /\n",
      " and then exponentiate at the end to undo the logarithm.\n",
      "For example, lets see how this works for the factorial function \n",
      "n\n",
      " We start by taking the logarithm:\n",
      "ln\n",
      ".n /\n",
      " D ln\n",
      ".1 2 3\n",
      "\t\n",
      ".n\t1/ n/\n",
      "D ln\n",
      ".1/\n",
      " C ln\n",
      ".2/\n",
      " C ln\n",
      ".3/\n",
      " C\tC ln\n",
      ".n\n",
      "\t\n",
      "1/ \n",
      "C\n",
      " \n",
      "ln\n",
      ".n/\n",
      "n\n",
      "X\n",
      "ln\n",
      ".i/:\n",
      "iD1\n",
      "Unfortunately, no closed form for this sum is known. However, we can apply Theorem \n",
      "to find good closed-form bounds on the sum. To do this, we first compute\n",
      "Plugging into Theorem \n",
      ", this means that\n",
      "n\n",
      "X\n",
      "n \n",
      "ln\n",
      ".n/\tn \n",
      "C\n",
      " 1\n",
      "\t\n",
      "ln\n",
      ".i/\n",
      "\t\n",
      "n \n",
      "ln\n",
      ".n/\tn \n",
      "C\n",
      " 1 \n",
      "C\n",
      " \n",
      "ln\n",
      ".n/:\n",
      "D1\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 273  #279\n",
      "\n",
      "Exponentiating then gives\n",
      "This means that \n",
      "n\n",
      " is within a factor of \n",
      "n\n",
      " of \n",
      "n\n",
      "n\n",
      "=e\n",
      "n1\n",
      "  .\n",
      "9.6.1\tStirlings Formula\n",
      "n \n",
      "is probably the most commonly used product in discrete mathematics, and so\n",
      " \n",
      "mathematicians have put in the effort to find much better closed-form bounds on its value. The most useful bounds are given in Theorem \n",
      ".\n",
      "Theorem 9.6.1 (Stirlings Formula). For all \n",
      "n\n",
      "\t\n",
      "1\n",
      ",\n",
      "p\n",
      "\t\n",
      "n \n",
      "n\n",
      "n\n",
      " \n",
      "D\n",
      "\t\n",
      "2  n  e\n",
      "\t\n",
      "e \n",
      ".n/\n",
      "\n",
      "where\n",
      ".n/    \n",
      "1\n",
      " :\n",
      "12n \n",
      "C\n",
      " 1\n",
      "12n\n",
      "\n",
      "Theorem \n",
      "can be proved by induction on \n",
      "n\n",
      ", but the details are a bit painful (even for us) and so we will not go through them here.\n",
      "There are several important things to notice about Stirlings Formula. First, \n",
      ".n/\n",
      " is always positive. This means that\n",
      "which is rather surprising. After all, who would expect both and \n",
      "e\n",
      " to show up in a closed-form expression that is asymptotically equal to \n",
      "n\n",
      " ?\n",
      "Third, \n",
      ".n/\n",
      " is small even for small values of \n",
      "n\n",
      ". This means that Stirlings For-mula provides good approximations for \n",
      "n\n",
      " for most all values of \n",
      "n\n",
      ". For example, if\n",
      "\n",
      "The   notation was defined in Section \n",
      ".\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 274  #280\n",
      "\n",
      "274\n",
      "\t\n",
      "Chapter 9\n",
      "\t\n",
      "Sums and Asymptotics\n",
      "Table 9.1\n",
      "\t\n",
      "Error bounds on common approximations for \n",
      "n\n",
      " from Theorem \n",
      ".\n",
      "p\n",
      "\t\n",
      "n\n",
      " n\n",
      "\n",
      "as the approximation for \n",
      "n\n",
      " , as many people do, we are guaranteed to be within a factor of\n",
      "e \n",
      ".n/\n",
      "\t\n",
      "e \n",
      "1\n",
      "\n",
      "12n\n",
      "of the correct value. For \n",
      "n 10\n",
      ", this means we will be within 1% of the correct value. For \n",
      "n 100\n",
      ", the error will be less than 0.1%.\n",
      "If we need an even closer approximation for \n",
      "n\n",
      " , then we could use either\n",
      "depending on whether we want an upper bound or a lower bound, respectively. By Theorem \n",
      ", we know that both bounds will be within a factor of\n",
      "of the correct value. For \n",
      "n 10\n",
      ", this means that either bound will be within 0.01% of the correct value. For \n",
      "n 100\n",
      ", the error will be less than 0.0001%.\n",
      "For quick future reference, these facts are summarized in Corollary \n",
      "and Table \n",
      ".\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 275  #281\n",
      "\n",
      "\n",
      "9.7\n",
      "\t\n",
      "Asymptotic Notation\n",
      "Asymptotic notation is a shorthand used to give a quick measure of the behavior of a function f .n/ as n grows large. For example, the asymptotic notation of Defi-nition \n",
      "is a binary relation indicating that two functions grow at the same rate. There is also a binary relation indicating that one function grows at a significantly slower rate than another.\n",
      "9.7.1\tLittle Oh\n",
      "Definition 9.7.1. For functions f; g W R ! R, with g nonnegative, we say f is asymptotically smaller than g, in symbols,\n",
      "f .x/ D o.g.x//;\n",
      "iff\n",
      "lim f .x/=g.x/ D 0:\n",
      "x!1\n",
      "For example, 1000x\n",
      "1:9\n",
      " D o.x\n",
      "2\n",
      "/, because 1000x\n",
      "1:9\n",
      "=x \n",
      "2\n",
      " D 1000=x\n",
      "0:1\n",
      " and since x\n",
      "0:1\n",
      " goes to infinity with x and 1000 is constant, we have lim\n",
      "x!1\n",
      " 1000x\n",
      "1:9\n",
      "=x\n",
      "2\n",
      " D 0. This argument generalizes directly to yield\n",
      "Lemma 9.7.2. x\n",
      "a\n",
      " D o.x\n",
      "b\n",
      "/ for all nonnegative constants a < b.\n",
      "Using the familiar fact that log x < x for all x > 1, we can prove\n",
      "Lemma 9.7.3. log x D o.x / for all\n",
      "\t\n",
      "> 0.\n",
      "Proof. Choose\n",
      "\t\n",
      ">\n",
      "\t\n",
      "> 0 and let x D z  in the inequality log x < x. This implies\n",
      "log z < z =\n",
      "\t\n",
      "D o.z /\n",
      "\t\n",
      "by Lemma \n",
      ":\t\n",
      "(9.32)\n",
      "Corollary 9.7.4. x\n",
      "b\n",
      " D o.a\n",
      "x\n",
      "/ for any a; b 2 R with a > 1.\n",
      "Lemma \n",
      "and Corollary \n",
      "can also be proved using lHopitals Rule or the McLaurin Series for log x and e\n",
      "x\n",
      ". Proofs can be found in most calculus texts.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 276  #282\n",
      "\n",
      "276\n",
      "\t\n",
      "Chapter 9\n",
      "\t\n",
      "Sums and Asymptotics\n",
      "9.7.2\n",
      "\t\n",
      "Big Oh\n",
      "Big Oh is the most frequently used asymptotic notation. It is used to give an upper bound on the growth of a function, such as the running time of an algorithm.\n",
      "Definition 9.7.5. Given nonnegative functions f; g W R ! R, we say that\n",
      "f D O.g/\n",
      "iff\n",
      "lim sup f .x/=g.x/ < 1:\n",
      "x!1\n",
      "This definition\n",
      "makes it clear that\n",
      "Lemma 9.7.6. If f D o.g/ or f\n",
      "\t\n",
      "g, then f D O.g/.\n",
      "Proof. lim f =g D 0 or lim f =g D 1 implies lim f =g < 1.\n",
      "It is easy to see that the converse of Lemma \n",
      "is not true. For example, 2x D O.x/, but 2x 6 x and 2x  o.x/.\n",
      "The usual formulation of Big Oh spells out the definition of lim sup without mentioning it. Namely, here is an equivalent definition:\n",
      "Definition 9.7.7. Given functions f; g W R ! R, we say that\n",
      "f D O.g/\n",
      "iff there exists a constant c\n",
      "\t\n",
      "0 and an x\n",
      "0\n",
      " such that for all x\tx\n",
      "0\n",
      ", jf .x/j\tcg.x/.\n",
      "This definition is rather complicated, but the idea is simple: f .x/ D O.g.x// means f .x/ is less than or equal to g.x/, except that were willing to ignore a constant factor, namely, c, and to allow exceptions for small x, namely, x < x\n",
      "0\n",
      ".\n",
      "We observe,\n",
      "Lemma 9.7.8. If f D o.g/, then it is not true that g D O.f /.\n",
      "\n",
      "12\n",
      "We cant simply use the limit as x ! 1 in the definition of O./, because if f .x/=g.x/ oscillates between, say, 3 and 5 as x grows, then f D O.g/ because f 5g, but lim\n",
      "x\n",
      " \n",
      "!1\n",
      " f .x/=g.x/ does not exist. So instead of limit, we use the technical notion of lim sup. In this oscillating case, lim sup\n",
      "x!1\n",
      " f .x/=g.x/ D 5.\n",
      "The precise definition of lim sup is\n",
      "lim sup h.x/ WWD lim  lub\n",
      "y  x\n",
      "h.y/;\n",
      "x!1\n",
      "\t\n",
      "x\n",
      "!1\n",
      "where lub abbreviates least upper bound.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 277  #283\n",
      "\n",
      "so g  O.f /.\n",
      "Proposition 9.7.9. 100x\n",
      "2\n",
      " D O.x\n",
      "2\n",
      "/.\n",
      "Well omit the routine proof.\n",
      "Big Oh notation is especially useful when describing the running time of an algorithm. For example, the usual algorithm for multiplying n n matrices uses a number of operations proportional to n\n",
      "3\n",
      " in the worst case. This fact can be expressed concisely by saying that the running time is O.n\n",
      "3\n",
      "/. So this asymptotic notation allows the speed of the algorithm to be discussed without reference to constant factors or lower-order terms that might be machine specific. It turns out that there is another, ingenious matrix multiplication procedure that uses O.n\n",
      "2:55\n",
      "/ operations. This procedure will therefore be much more efficient on large enough matrices. Unfortunately, the O.n\n",
      "2:55\n",
      "/-operation multiplication procedure is almost never used in practice because it happens to be less efficient than the usual O.n\n",
      "3\n",
      "/ procedure on matrices of practical size.\n",
      "9.7.3\n",
      "\t\n",
      "Omega\n",
      "Suppose you want to make a statement of the form the running time of the algo-rithm is a least. . . . Can you say it is at least O.n\n",
      "2\n",
      "/? No! This statement is meaningless since big-oh can only be used for upper bounds. For lower bounds, we use a different symbol, called big-Omega.\n",
      "\n",
      "It is even conceivable that there is an O.n\n",
      "2\n",
      "/ matrix multiplication procedure, but none is known.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 278  #284\n",
      "\n",
      "p\n",
      "\n",
      "For example, x\n",
      "2\n",
      " D\n",
      "\t\n",
      ".x/, 2\n",
      "x\n",
      " D\t.x\n",
      "2\n",
      "/, and x=100 D\t.100x C\tx/.\n",
      "So if the running time of your algorithm on inputs of size n is T .n/, and you want to say it is at least quadratic, say\n",
      "T .n/ D\t.n\n",
      "2\n",
      "/:\n",
      "Little Omega\n",
      "There is also a symbol called little-omega, analogous to little-oh, to denote that one function grows strictly faster than another function.\n",
      "Definition 9.7.14. For functions f; g W R ! R with f nonnegative, we say that\n",
      "f .x/ D !.g.x//\n",
      "iff\n",
      "g.x/\n",
      "lim\n",
      "\t\n",
      "D 0:\n",
      "\n",
      "In other words,\n",
      "f .x/ D !.g.x//\n",
      "iff\n",
      "g.x/ D o.f .x//:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 279  #285\n",
      "\n",
      "For example, x\n",
      "1:5\n",
      " D !.x/ and \n",
      "p\n",
      "x D !.ln\n",
      "2\n",
      ".x//.\n",
      "\n",
      "The little-omega symbol is not as widely used as the other asymptotic symbols we have been discussing.\n",
      "9.7.4\n",
      "\t\n",
      "Theta\n",
      "Sometimes we want to specify that a running time T .n/ is precisely quadratic up to constant factors (both upper bound and lower bound). We could do this by saying that T .n/ D O.n\n",
      "2\n",
      "/ and T .n/ D .n\n",
      "2\n",
      "/, but rather than say both, mathematicians have devised yet another symbol, , to do the job.\n",
      "Definition 9.7.15.\n",
      "f D\t.g/\n",
      "\t\n",
      "iff\n",
      "\t\n",
      "f D O.g/ and g D O.f /:\n",
      "The statement f D .g/ can be paraphrased intuitively as f and g are equal to within a constant factor. Indeed, by Theorem \n",
      ", we know that\n",
      "f D\t.g/\n",
      "\t\n",
      "iff\n",
      "\t\n",
      "f D O.g/ and f D\t.g/:\n",
      "The Theta notation allows us to highlight growth rates and allow suppression of distracting factors and low-order terms. For example, if the running time of an algorithm is\n",
      "T .n/ D 10n\n",
      "3\n",
      "\t\n",
      "20n\n",
      "2\n",
      " C 1;\n",
      "then we can more simply write\n",
      "T .n/ D\t.n\n",
      "3\n",
      "/:\n",
      "In this case, we would say that T is of order n\n",
      "3\n",
      " or that T .n/ grows cubically, which is probably what we really want to know. Another such example is\n",
      "Just knowing that the running time of an algorithm is .n\n",
      "3\n",
      "/, for example, is use-ful, because if n doubles we can predict that the running time will by and large\n",
      " increase by a factor of at most 8 for large n. In this way, Theta notation preserves in-formation about the scalability of an algorithm or system. Scalability is, of course, a big issue in the design of algorithms and systems.\n",
      "\n",
      "14\n",
      "Since\n",
      "\t\n",
      ".n\n",
      "3\n",
      "/ only implies that the running time, T .n/, is between cn\n",
      "3\n",
      " and d n\n",
      "3\n",
      " for constants\n",
      "0 < c < d , the time T .2n/ could regularly exceed T .n/ by a factor as large as 8d=c. The factor is sure to be close to 8 for all large n only if T .n/ n\n",
      "3\n",
      ".\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 280  #286\n",
      "\n",
      "280\n",
      "\t\n",
      "Chapter 9\n",
      "\t\n",
      "Sums and Asymptotics\n",
      "9.7.5\n",
      "\t\n",
      "Pitfalls with Asymptotic Notation\n",
      "There is a long list of ways to make mistakes with asymptotic notation. This section presents some of the ways that Big Oh notation can lead to ruin and despair. With minimal effort, you can cause just as much chaos with the other symbols.\n",
      "The Exponential Fiasco\n",
      "Sometimes relationships involving Big Oh are not so obvious. For example, one might guess that 4\n",
      "x\n",
      " D O.2\n",
      "x\n",
      "/ since 4 is only a constant factor larger than 2. This reasoning is incorrect, however; 4\n",
      "x\n",
      " actually grows as the square of 2\n",
      "x\n",
      ".\n",
      "Constant Confusion\n",
      "Every constant is O.1/. For example, 17 D O.1/. This is true because if we let f .x/ D 17 and g.x/ D 1, then there exists a c > 0 and an x\n",
      "0\n",
      " such that jf .x/j cg.x/. In particular, we could choose c = 17 and x\n",
      "0\n",
      " D 1, since j17j 17 1 for all\n",
      "1. We can construct a false theorem that exploits this fact.\n",
      "False Theorem 9.7.16.\n",
      "n\n",
      "X\n",
      "i D O.n/\n",
      "iD1\n",
      "The error stems from confusion over what is meant in the statement i D O.1/. For any constant i 2 N it is true that i D O.1/. More precisely, if f is any constant function, then f D O.1/. But in this False Theorem, i is not constantit ranges over a set of values 0, 1,. . . , n that depends on n.\n",
      "And anyway, we should not be adding O.1/s as though they were numbers. We never even defined what O.g/ means by itself; it should only be used in the context f D O.g/ to describe a relation between functions f and g.\n",
      "Lower Bound Blunder\n",
      "Sometimes people incorrectly use Big Oh in the context of a lower bound. For example, they might say, The running time, T .n/, is at least O.n\n",
      "2\n",
      "/, when they probably mean\n",
      "T .n/ D .n\n",
      "2\n",
      "/.\n",
      "\n",
      "15\n",
      "This can also be correctly expressed as n\n",
      "2\n",
      " D O.T .n//, but such notation is rare.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 281  #287\n",
      "\n",
      "Equality Blunder\n",
      "The notation \n",
      "f\n",
      " D \n",
      "O.g/\n",
      " is too firmly entrenched to avoid, but the use of = is really regrettable. For example, if \n",
      "f\n",
      " D \n",
      "O.g/\n",
      ", it seems quite reasonable to write \n",
      "O.g/\n",
      " D \n",
      "f\n",
      " . But doing so might tempt us to the following blunder: because \n",
      "2n \n",
      "D\n",
      " O.n/\n",
      ", we can say\n",
      " O.n/ \n",
      "D\n",
      " 2n\n",
      ". But\n",
      " n \n",
      "D\n",
      " O.n/\n",
      ", so we conclude that\n",
      " n \n",
      "D\n",
      " O.n/ \n",
      "D\n",
      " 2n\n",
      ", and therefore\n",
      " n \n",
      "D\n",
      " 2n\n",
      ". To avoid such nonsense, we will never write\n",
      " \n",
      "\n",
      "O.f /\n",
      " D \n",
      "g\n",
      ".\n",
      "where \n",
      "g.n/\n",
      " D \n",
      "o.1/\n",
      ". These transgressions are OK as long as you (and you reader)\n",
      "know what you mean.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 282  #288\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 283  #289\n",
      "\n",
      "10\n",
      "\t\n",
      "Recurrences\n",
      "A recurrence describes a sequence of numbers. Early terms are specified explic-itly and later terms are expressed as a function of their predecessors. As a trivial example, this recurrence describes the sequence 1, 2, 3, etc.:\n",
      "T\n",
      "1\n",
      "D1\n",
      "T\n",
      "n\n",
      " D T\n",
      "n1\n",
      "  C 1\n",
      "\t\n",
      "(for n\n",
      "\t\n",
      "2):\n",
      "Here, the first term is defined to be 1 and each subsequent term is one more than its predecessor.\n",
      "Recurrences turn out to be a powerful tool. In this chapter, well emphasize using recurrences to analyze the performance of recursive algorithms. However, recur-rences have other applications in computer science as well, such as enumeration of structures and analysis of random processes. And, as we saw in Section \n",
      ", they also arise in the analysis of problems in the physical sciences.\n",
      "A recurrence in isolation is not a very useful description of a sequence. One can not easily answer simple questions such as, What is the hundredth term? or What is the asymptotic growth rate? So one typically wants to solve a recurrence; that is, to find a closed-form expression for the nth term.\n",
      "Well first introduce two general solving techniques: guess-and-verify and plug-and-chug. These methods are applicable to every recurrence, but their success re-quires a flash of insightsometimes an unrealistically brilliant flash. So well also introduce two big classes of recurrences, linear and divide-and-conquer, that often come up in computer science. Essentially all recurrences in these two classes are solvable using cookbook techniques; you follow the recipe and get the answer. A drawback is that calculation replaces insight. The Aha! moment that is essential in the guess-and-verify and plug-and-chug methods is replaced by a Huh at the end of a cookbook procedure.\n",
      "At the end of the chapter, well develop rules of thumb to help you assess many recurrences without any calculation. These rules can help you distinguish promis-ing approaches from bad ideas early in the process of designing an algorithm.\n",
      "Recurrences are one aspect of a broad theme in computer science: reducing a big problem to progressively smaller problems until easy base cases are reached. This same idea underlies both induction proofs and recursive algorithms. As well see, all three ideas snap together nicely. For example, one might describe the running time of a recursive algorithm with a recurrence and use induction to verify the solution.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 284  #290\n",
      "\n",
      "284\n",
      "\t\n",
      "Chapter 10\n",
      "\t\n",
      "Recurrences\n",
      "\n",
      "Figure 10.1\n",
      "\t\n",
      "The initial configuration of the disks in the Towers of Hanoi problem.\n",
      "\n",
      "10.1\n",
      "\t\n",
      "The Towers of Hanoi\n",
      "According to legend, there is a temple in Hanoi with three posts and 64 gold disks of different sizes. Each disk has a hole through the center so that it fits on a post. In the misty past, all the disks were on the first post, with the largest on the bottom and the smallest on top, as shown in Figure \n",
      ".\n",
      "Monks in the temple have labored through the years since to move all the disks to one of the other two posts according to the following rules:\n",
      "The only permitted action is removing the top disk from one post and drop-ping it onto another post.\n",
      "A larger disk can never lie above a smaller disk on any post.\n",
      "So, for example, picking up the whole stack of disks at once and dropping them on another post is illegal. Thats good, because the legend says that when the monks complete the puzzle, the world will end!\n",
      "To clarify the problem, suppose there were only 3 gold disks instead of 64. Then the puzzle could be solved in 7 steps as shown in Figure \n",
      ".\n",
      "The questions we must answer are, Given sufficient time, can the monks suc-ceed? If so, How long until the world ends? And, most importantly, Will this happen before the final exam?\n",
      "10.1.1\n",
      "\t\n",
      "A Recursive Solution\n",
      "The Towers of Hanoi problem can be solved recursively. As we describe the pro-cedure, well also analyze the running time. To that end, let T\n",
      "n\n",
      " be the minimum number of steps required to solve the n-disk problem. For example, some experi-mentation shows that T\n",
      "1\n",
      " D 1 and T\n",
      "2\n",
      " = 3. The procedure illustrated above shows that T\n",
      "3\n",
      " is at most 7, though there might be a solution with fewer steps.\n",
      "The recursive solution has three stages, which are described below and illustrated in Figure \n",
      ". For clarity, the largest disk is shaded in the figures.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 285  #291\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "4\n",
      "\n",
      "5\n",
      "\n",
      "6\n",
      "\n",
      "7\n",
      "\n",
      "Figure 10.2 The 7-step solution to the Towers of Hanoi problem when there are n D 3 disks.\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "Figure 10.3\n",
      "\t\n",
      "A recursive solution to the Towers of Hanoi problem.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 286  #292\n",
      "\n",
      "Stage 3. Move the n\n",
      "the solution for n\n",
      "\n",
      "\n",
      "1 disks from the second post to the third post, again using\n",
      "1 disks. This can also be done in T\n",
      "n1\n",
      "  steps.\n",
      "This algorithm shows that T\n",
      "n\n",
      ", the minimum number of steps required to move n disks to a different post, is at most T\n",
      "n1\n",
      " C1 CT\n",
      "n1\n",
      " D 2T\n",
      "n1\n",
      " C1. We can use this fact to upper bound the number of operations required to move towers of various heights:\n",
      "T\n",
      "3\n",
      "\t2 T\n",
      "2\n",
      "C1D7\n",
      "T\n",
      "4\n",
      "\t2 T\n",
      "3\n",
      "C1\n",
      "\t\n",
      "15\n",
      "Continuing in this way, we could eventually compute an upper bound on T\n",
      "64\n",
      ", the number of steps required to move 64 disks. So this algorithm answers our first question: given sufficient time, the monks can finish their task and end the world. This is a shame. After all that effort, theyd probably want to smack a few high-fives and go out for burgers and ice cream, but nopeworlds over.\n",
      "10.1.2\n",
      "\t\n",
      "Finding a Recurrence\n",
      "We can not yet compute the exact number of steps that the monks need to move the 64 disks, only an upper bound. Perhaps, having pondered the problem since the beginning of time, the monks have devised a better algorithm.\n",
      "In fact, there is no better algorithm, and here is why. At some step, the monks must move the largest disk from the first post to a different post. For this to happen, the n 1 smaller disks must all be stacked out of the way on the only remaining post. Arranging the n 1 smaller disks this way requires at least T\n",
      "n1\n",
      " moves. After the largest disk is moved, at least another T\n",
      "n1\n",
      " moves are required to pile the n 1 smaller disks on top.\n",
      "This argument shows that the number of steps required is at least 2T\n",
      "n1\n",
      " C 1. Since we gave an algorithm using exactly that number of steps, we can now write an expression for T\n",
      "n\n",
      ", the number of moves required to complete the Towers of\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 287  #293\n",
      "\n",
      "This is a typical recurrence. These two lines define a sequence of values, T\n",
      "1\n",
      "; T\n",
      "2\n",
      "; T\n",
      "3\n",
      "; : : :. The first line says that the first number in the sequence, T\n",
      "1\n",
      ", is equal to 1. The sec-ond line defines every other number in the sequence in terms of its predecessor. So\n",
      "we can use this recurrence to compute any number of terms in the sequence:\n",
      "T\n",
      "1\n",
      "D1\n",
      "T\n",
      "2\n",
      "D2 T\n",
      "1\n",
      "C1D3\n",
      "T\n",
      "3\n",
      "D2 T\n",
      "2\n",
      "C1D7\n",
      "T\n",
      "4\n",
      "D2 T\n",
      "3\n",
      "C1D15\n",
      "T\n",
      "5\n",
      "D2 T\n",
      "4\n",
      "C1D31\n",
      "T\n",
      "6\n",
      "D2 T\n",
      "5\n",
      "C1D63:\n",
      "10.1.3\n",
      "\t\n",
      "Solving the Recurrence\n",
      "We could determine the number of steps to move a 64-disk tower by computing T\n",
      "7\n",
      ", T\n",
      "8\n",
      ", and so on up to T\n",
      "64\n",
      ". But that would take a lot of work. It would be nice to have a closed-form expression for T\n",
      "n\n",
      ", so that we could quickly find the number of steps required for any given number of disks. (For example, we might want to know how much sooner the world would end if the monks melted down one disk to purchase burgers and ice cream before the end of the world.)\n",
      "There are several methods for solving recurrence equations. The simplest is to guess the solution and then verify that the guess is correct with an induction proof. As a basis for a good guess, lets look for a pattern in the values of T\n",
      "n\n",
      " computed above: 1, 3, 7, 15, 31, 63. A natural guess is T\n",
      "n\n",
      " D 2\n",
      "n\n",
      " 1. But whenever you guess a solution to a recurrence, you should always verify it with a proof, typically by induction. After all, your guess might be wrong. (But why bother to verify in this case? After all, if were wrong, its not the end of the... no, lets check.)\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 288  #294\n",
      "\n",
      "Such verification proofs are especially tidy because recurrence equations and induction proofs have analogous structures. In particular, the base case relies on the first line of the recurrence, which defines T\n",
      "1\n",
      ". And the inductive step uses the second line of the recurrence, which defines T\n",
      "n\n",
      " as a function of preceding terms.\n",
      "Our guess is verified. So we can now resolve our remaining questions about the\n",
      "64-disk puzzle. Since T\n",
      "64\n",
      " D 2\n",
      "64\n",
      " 1, the monks must complete more than 18 billion billion steps before the world ends. Better study for the final.\n",
      "10.1.4\n",
      "\t\n",
      "The Upper Bound Trap\n",
      "When the solution to a recurrence is complicated, one might try to prove that some simpler expression is an upper bound on the solution. For example, the exact so-lution to the Towers of Hanoi recurrence is T\n",
      "n\n",
      " D 2\n",
      "n\n",
      " 1. Lets try to prove the nicer upper bound T\n",
      "n\n",
      " 2\n",
      "n\n",
      ", proceeding exactly as before.\n",
      "Proof. (Failed attempt.) The proof is by induction on n. The induction hypothesis\n",
      "The first equality is the recurrence relation, the second follows from the induction\n",
      "hypothesis, and the third step is a flaming train wreck.\n",
      "The proof doesnt work! As is so often the case with induction proofs, the ar-gument only goes through with a stronger hypothesis. This isnt to say that upper bounding the solution to a recurrence is hopeless, but this is a situation where in-duction and recurrences do not mix well.\n",
      "10.1.5\n",
      "\t\n",
      "Plug and Chug\n",
      "Guess-and-verify is a simple and general way to solve recurrence equations. But there is one big drawback: you have to guess right. That was not hard for the Towers of Hanoi example. But sometimes the solution to a recurrence has a strange form that is quite difficult to guess. Practice helps, of course, but so can some other methods.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 289  #295\n",
      "\n",
      "Plug-and-chug is another way to solve recurrences. This is also sometimes called expansion or iteration. As in guess-and-verify, the key step is identifying a pattern. But instead of looking at a sequence of numbers, you have to spot a pattern in a sequence of expressions, which is sometimes easier. The method consists of three steps, which are described below and illustrated with the Towers of Hanoi example.\n",
      "Step 1: Plug and Chug Until a Pattern Appears\n",
      "The first step is to expand the recurrence equation by alternately plugging (apply-ing the recurrence) and chugging (simplifying the result) until a pattern appears. Be careful: too much simplification can make a pattern harder to spot. The rule to rememberindeed, a rule applicable to the whole of college lifeis chug in moderation.\n",
      "Above, we started with the recurrence equation. Then we replaced T\n",
      "n1\n",
      " with 2T\n",
      "n2\n",
      " C 1, since the recurrence says the two are equivalent. In the third step, we simplified a littlebut not too much! After several similar rounds of plugging and chugging, a pattern is apparent. The following formula seems to hold:\n",
      "T\n",
      "n\n",
      " D 2\n",
      "k\n",
      "T\n",
      "nk\n",
      "  C 2\n",
      "k1\n",
      "  C 2\n",
      "k2\n",
      "  C : : : C 2\n",
      "2\n",
      " C 2\n",
      "1\n",
      " C 2\n",
      "0\n",
      "D 2\n",
      "k\n",
      "T\n",
      "nk\n",
      "  C 2\n",
      "k\n",
      "\t\n",
      "1\n",
      "Once the pattern is clear, simplifying is safe and convenient. In particular, weve collapsed the geometric sum to a closed form on the second line.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 290  #296\n",
      "\n",
      "290\n",
      "\t\n",
      "Chapter 10\n",
      "\t\n",
      "Recurrences\n",
      "Step 2: Verify the Pattern\n",
      "The next step is to verify the general formula with one more round of plug-and-chug.\n",
      "The final expression on the right is the same as the expression on the first line, except that k is replaced by k C 1. Surprisingly, this effectively proves that the formula is correct for all k. Here is why: we know the formula holds for k D 1, because thats the original recurrence equation. And weve just shown that if the formula holds for some k 1, then it also holds for k C 1. So the formula holds for all k 1 by induction.\n",
      "Step 3: Write T\n",
      "n\n",
      " Using Early Terms with Known Values\n",
      "The last step is to express T\n",
      "n\n",
      " as a function of early terms whose values are known. Here, choosing k D n 1 expresses T\n",
      "n\n",
      " in terms of T\n",
      "1\n",
      ", which is equal to 1. Sim-plifying gives a closed-form expression for T\n",
      "n\n",
      ":\n",
      "Were done! This is the same answer we got from guess-and-verify.\n",
      "Lets compare guess-and-verify with plug-and-chug. In the guess-and-verify method, we computed several terms at the beginning of the sequence, T\n",
      "1\n",
      ", T\n",
      "2\n",
      ", T\n",
      "3\n",
      ", etc., until a pattern appeared. We generalized to a formula for the nth term, T\n",
      "n\n",
      ". In contrast, plug-and-chug works backward from the nth term. Specifically, we started with an expression for T\n",
      "n\n",
      " involving the preceding term, T\n",
      "n1\n",
      " , and rewrote this us-ing progressively earlier terms, T\n",
      "n2\n",
      " , T\n",
      "n3\n",
      " , etc. Eventually, we noticed a pattern, which allowed us to express T\n",
      "n\n",
      " using the very first term, T\n",
      "1\n",
      ", whose value we knew. Substituting this value gave a closed-form expression for T\n",
      "n\n",
      ". So guess-and-verify and plug-and-chug tackle the problem from opposite directions.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 291  #297\n",
      "\n",
      "\n",
      "10.2\n",
      "\t\n",
      "Merge Sort\n",
      "Algorithms textbooks traditionally claim that sorting is an important, fundamental problem in computer science. Then they smack you with sorting algorithms until life as a disk-stacking monk in Hanoi sounds delightful. Here, well cover just one well-known sorting algorithm, Merge Sort. The analysis introduces another kind of recurrence.\n",
      "Here is how Merge Sort works. The input is a list of n numbers, and the output is those same numbers in nondecreasing order. There are two cases:\n",
      "If the input is a single number, then the algorithm does nothing, because the list is already sorted.\n",
      "Otherwise, the list contains two or more numbers. The first half and the second half of the list are each sorted recursively. Then the two halves are merged to form a sorted list with all n numbers.\n",
      "Lets work through an example. Suppose we want to sort this list:\n",
      "10, 7, 23, 5, 2, 8, 6, 9.\n",
      "Since there is more than one number, the first half (10, 7, 23, 5) and the second half (2, 8, 6, 9) are sorted recursively. The results are 5, 7, 10, 23 and 2, 6, 8, 9. All that remains is to merge these two lists. This is done by repeatedly emitting the smaller of the two leading terms. When one list is empty, the whole other list is emitted. The example is worked out below. In this table, underlined numbers are about to be emitted.\n",
      "The leading terms are initially 5 and 2. So we output 2. Then the leading terms are 5 and 6, so we output 5. Eventually, the second list becomes empty. At that point, we output the whole first list, which consists of 10 and 23. The complete output consists of all the numbers in sorted order.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 292  #298\n",
      "\n",
      "292\n",
      "\t\n",
      "Chapter 10\n",
      "\t\n",
      "Recurrences\n",
      "10.2.1\n",
      "\t\n",
      "Finding a Recurrence\n",
      "A traditional question about sorting algorithms is, What is the maximum number of comparisons used in sorting n items? This is taken as an estimate of the running time. In the case of Merge Sort, we can express this quantity with a recurrence. Let T\n",
      "n\n",
      " be the maximum number of comparisons used while Merge Sorting a list of n numbers. For now, assume that n is a power of 2. This ensures that the input can be divided in half at every stage of the recursion.\n",
      "If there is only one number in the list, then no comparisons are required, so T\n",
      "1\n",
      "D0.\n",
      "Otherwise, T\n",
      "n\n",
      " includes comparisons used in sorting the first half (at most\n",
      "T\n",
      "n=2\n",
      "), in sorting the second half (also at most T\n",
      "n=2\n",
      "), and in merging the two halves. The number of comparisons in the merging step is at most n 1.\n",
      "This is because at least one number is emitted after each comparison and one more number is emitted at the end when one list becomes empty. Since n items are emitted in all, there can be at most n 1 comparisons.\n",
      "Therefore, the maximum number of comparisons needed to Merge Sort n items is given by this recurrence:\n",
      "T\n",
      "1\n",
      "D0\n",
      "T\n",
      "n\n",
      " D 2T\n",
      "n=2\n",
      " C n\t1\n",
      "\t\n",
      "(for n\n",
      "\t\n",
      "2 and a power of 2):\n",
      "This fully describes the number of comparisons, but not in a very useful way; a closed-form expression would be much more helpful. To get that, we have to solve the recurrence.\n",
      "10.2.2\n",
      "\t\n",
      "Solving the Recurrence\n",
      "Lets first try to solve the Merge Sort recurrence with the guess-and-verify tech-nique. Here are the first few values:\n",
      "Were in trouble! Guessing the solution to this recurrence is hard because there is no obvious pattern. So lets try the plug-and-chug method instead.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 293  #299\n",
      "\n",
      "Step 1: Plug and Chug Until a Pattern Appears\n",
      "First, we expand the recurrence equation by alternately plugging and chugging until a pattern appears.\n",
      "A pattern is emerging. In particular, this formula seems holds:\n",
      "On the second line, we grouped the n terms and powers of 2. On the third, we collapsed the geometric sum.\n",
      "Step 2: Verify the Pattern\n",
      "Next, we verify the pattern with one additional round of plug-and-chug. If we guessed the wrong pattern, then this is where well discover the mistake.\n",
      "The formula is unchanged except that k is replaced by k C 1. This amounts to the induction step in a proof that the formula holds for all k 1.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 294  #300\n",
      "\n",
      "294\n",
      "\t\n",
      "Chapter 10\n",
      "\t\n",
      "Recurrences\n",
      "Step 3: Write T\n",
      "n\n",
      " Using Early Terms with Known Values\n",
      "Finally, we express T\n",
      "n\n",
      " using early terms whose values are known. Specifically, if we let k D log n, then T\n",
      "n=2\n",
      "k\n",
      " D T\n",
      "1\n",
      ", which we know is 0:\n",
      "Were done! We have a closed-form expression for the maximum number of com-parisons used in Merge Sorting a list of n numbers. In retrospect, it is easy to see why guess-and-verify failed: this formula is fairly complicated.\n",
      "As a check, we can confirm that this formula gives the same values that we computed earlier:\n",
      "As a double-check, we could write out an explicit induction proof. This would be straightforward, because we already worked out the guts of the proof in step 2 of the plug-and-chug procedure.\n",
      "\n",
      "10.3\n",
      "\t\n",
      "Linear Recurrences\n",
      "So far weve solved recurrences with two techniques: guess-and-verify and plug-and-chug. These methods require spotting a pattern in a sequence of numbers or expressions. In this section and the next, well give cookbook solutions for two large classes of recurrences. These methods require no flash of insight; you just follow the recipe and get the answer.\n",
      "10.3.1\tClimbing Stairs\n",
      "How many different ways are there to climb n stairs, if you can either step up one stair or hop up two? For example, there are five different ways to climb four stairs:\n",
      "1. step, step, step, step\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 295  #301\n",
      "\n",
      "hop, hop\n",
      "hop, step, step\n",
      "step, hop step\n",
      "step, step, hop\n",
      "Working through this problem will demonstrate the major features of our first cook-book method for solving recurrences. Well fill in the details of the general solution afterward.\n",
      "Finding a Recurrence\n",
      "As special cases, there is 1 way to climb 0 stairs (do nothing) and 1 way to climb 1 stair (step up). In general, an ascent of n stairs consists of either a step followed by an ascent of the remaining n 1 stairs or a hop followed by an ascent of n 2 stairs. So the total number of ways to climb n stairs is equal to the number of ways\n",
      "Here, f .n/ denotes the number of ways to climb n stairs. Also, weve switched from subscript notation to functional notation, from T\n",
      "n\n",
      " to f\n",
      "n\n",
      ". Here the change is cosmetic, but the expressiveness of functions will be useful later.\n",
      "This is the Fibonacci recurrence, the most famous of all recurrence equations. Fibonacci numbers arise in all sorts of applications and in nature. Fibonacci intro-duced the numbers in 1202 to study rabbit reproduction. Fibonacci numbers also appear, oddly enough, in the spiral patterns on the faces of sunflowers. And the input numbers that make Euclids GCD algorithm require the greatest number of steps are consecutive Fibonacci numbers.\n",
      "Solving the Recurrence\n",
      "The Fibonacci recurrence belongs to the class of linear recurrences, which are es-sentially all solvable with a technique that you can learn in an hour. This is some-what amazing, since the Fibonacci recurrence remained unsolved for almost six centuries!\n",
      "In general, a homogeneous linear recurrence has the form\n",
      "f .n/ D a\n",
      "1\n",
      "f .n\t1/ C a\n",
      "2\n",
      "f .n\t2/ C : : : C a\n",
      "d\n",
      " f .n\n",
      "\t\n",
      "d /\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 296  #302\n",
      "\n",
      "296\n",
      "\t\n",
      "Chapter 10\n",
      "\t\n",
      "Recurrences\n",
      "where a\n",
      "1\n",
      "; a\n",
      "2\n",
      "; : : : ; a\n",
      "d\n",
      " and d are constants. The order of the recurrence is d . Com-monly, the value of the function f is also specified at a few points; these are called boundary conditions. For example, the Fibonacci recurrence has order d D 2 with coefficients a\n",
      "1\n",
      " D a\n",
      "2\n",
      " D 1 and g.n/ D 0. The boundary conditions are f .0/ D 1 and f .1/ D 1. The word homogeneous sounds scary, but effectively means the simpler kind. Well consider linear recurrences with a more complicated form later.\n",
      "Lets try to solve the Fibonacci recurrence with the benefit centuries of hindsight. In general, linear recurrences tend to have exponential solutions. So lets guess that\n",
      "f .n/ D x\n",
      "n\n",
      "where x is a parameter introduced to improve our odds of making a correct guess. Well figure out the best value for x later. To further improve our odds, lets neglect the boundary conditions, f .0/ D 0 and f .1/ D 1, for now. Plugging this guess into the recurrence f .n/ D f .n 1/ C f .n 2/ gives\n",
      "x\n",
      "n\n",
      " D x\n",
      "n1\n",
      "  C x\n",
      "n2\n",
      "  :\n",
      "Dividing both sides by x\n",
      "n2\n",
      "\t\n",
      "leaves a quadratic equation:\n",
      "x\n",
      "2\n",
      " D x C 1:\n",
      "Solving this equation gives two plausible values for the parameter x:\n",
      "This suggests that there are at least two different solutions to the recurrence, ne-glecting the boundary conditions.\n",
      "p !\n",
      "n\n",
      "\t\n",
      "p !\n",
      "n\n",
      "\n",
      "f .n/ D\n",
      "\t\n",
      "1 \n",
      "C\n",
      "\t\n",
      "5\n",
      "\t\n",
      "or\n",
      "\t\n",
      "f .n/ D\n",
      "\t\n",
      "1\n",
      "\t\n",
      "5\n",
      "\n",
      "2\n",
      "\t\n",
      "2\n",
      "A charming features of homogeneous linear recurrences is that any linear com-bination of solutions is another solution.\n",
      "Theorem 10.3.1. If f .n/ and g.n/ are both solutions to a homogeneous linear recurrence, then h.n/ D sf .n/ C tg.n/ is also a solution for all s; t 2 R.\n",
      "Proof.\n",
      "h.n/ D sf .n/ C tg.n/\n",
      "D s .a\n",
      "1\n",
      "f .n\n",
      "\t\n",
      "1/ C : : : C a\n",
      "d\n",
      " f .n\td // C t .a\n",
      "1\n",
      "g.n\t1/ C : : : C a\n",
      "d\n",
      " g.n\n",
      "\t\n",
      "d //\n",
      "D a\n",
      "1\n",
      ".sf .n\n",
      "\t\n",
      "1/ C tg.n\t1// C : : : C a\n",
      "d\n",
      " .sf .n\td / C tg.n\td //\n",
      "D a\n",
      "1\n",
      "h.n\n",
      "\t\n",
      "1/ C : : : C a\n",
      "d\n",
      " h.n\n",
      "\t\n",
      "d /\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 297  #303\n",
      "\n",
      "The first step uses the definition of the function h, and the second uses the fact that\n",
      "and g are solutions to the recurrence. In the last two steps, we rearrange terms and use the definition of h again. Since the first expression is equal to the last, h is\n",
      "also a solution to the recurrence.\n",
      "The phenomenon described in this theorema linear combination of solutions is another solutionalso holds for many differential equations and physical systems. In fact, linear recurrences are so similar to linear differential equations that you can safely snooze through that topic in some future math class.\n",
      "Returning to the Fibonacci recurrence, this theorem implies that\n",
      "p !\n",
      "n\n",
      "\t\n",
      "p !\n",
      "n\n",
      "\n",
      "is a solution for all real numbers s and t. The theorem expanded two solutions to a whole spectrum of possibilities! Now, given all these options to choose from, we can find one solution that satisfies the boundary conditions, f .0/ D 1 and f .1/ D 1. Each boundary condition puts some constraints on the parameters s and t. In particular, the first boundary condition implies that\n",
      "p !\n",
      "0\n",
      "\t\n",
      "p !\n",
      "0\n",
      "\n",
      "Similarly, the second boundary condition implies that\n",
      "p !\n",
      "1\n",
      "\t\n",
      "p !\n",
      "1\n",
      "\n",
      "Now we have two linear equations in two unknowns. The system is not degenerate, so there is a unique solution:\n",
      "These values of s and t identify a solution to the Fibonacci recurrence that also satisfies the boundary conditions:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 298  #304\n",
      "\n",
      "\n",
      "10.3.2\n",
      "\t\n",
      "Solving Homogeneous Linear Recurrences\n",
      "The method we used to solve the Fibonacci recurrence can be extended to solve any homogeneous linear recurrence; that is, a recurrence of the form\n",
      "f .n/ D a\n",
      "1\n",
      "f .n\t1/ C a\n",
      "2\n",
      "f .n\t2/ C : : : C a\n",
      "d\n",
      " f .n\n",
      "\t\n",
      "d /\n",
      "where a\n",
      "1\n",
      "; a\n",
      "2\n",
      "; : : : ; a\n",
      "d\n",
      " and d are constants. Substituting the guess f .n/ D x\n",
      "n\n",
      ", as with the Fibonacci recurrence, gives\n",
      "x\n",
      "n\n",
      " D a\n",
      "1\n",
      "x\n",
      "n1\n",
      "  C a\n",
      "2\n",
      "x\n",
      "n2\n",
      "  C : : : C a\n",
      "d\n",
      " x\n",
      "nd\n",
      "  :\n",
      "Dividing by x\n",
      "nd\n",
      "\t\n",
      "gives\n",
      "x\n",
      "d\n",
      " D a\n",
      "1\n",
      "x\n",
      "d1\n",
      "  C a\n",
      "2\n",
      "x\n",
      "d2\n",
      "  C : : : C a\n",
      "d1\n",
      "  x C a\n",
      "d\n",
      " :\n",
      "This is called the characteristic equation of the recurrence. The characteristic equa-tion can be read off quickly since the coefficients of the equation are the same as the coefficients of the recurrence.\n",
      "The solutions to a linear recurrence are defined by the roots of the characteristic equation. Neglecting boundary conditions for the moment:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 299  #305\n",
      "\n",
      "If r is a nonrepeated root of the characteristic equation, then r\n",
      "n\n",
      " is a solution to the recurrence.\n",
      "If r is a repeated root with multiplicity k then r\n",
      "n\n",
      ", nr\n",
      "n\n",
      ", n\n",
      "2\n",
      "r\n",
      "n\n",
      ", . . . , n\n",
      "k1\n",
      " r\n",
      "n\n",
      " are all solutions to the recurrence.\n",
      "Theorem \n",
      "implies that every linear combination of these solutions is also a solution.\n",
      "For example, suppose that the characteristic equation of a recurrence has roots s, t, and u twice. These four roots imply four distinct solutions:\n",
      "f .n/ D s\n",
      "n\n",
      "\t\n",
      "f .n/ D t\n",
      "n\n",
      "\t\n",
      "f .n/ D u\n",
      "n\n",
      "\t\n",
      "f .n/ D nu\n",
      "n\n",
      ":\n",
      "Furthermore, every linear combination\n",
      "is also a solution.\n",
      "All that remains is to select a solution consistent with the boundary conditions by choosing the constants appropriately. Each boundary condition implies a linear equation involving these constants. So we can determine the constants by solving a system of linear equations. For example, suppose our boundary conditions were f .0/ D 0, f .1/ D 1, f .2/ D 4, and f .3/ D 9. Then we would obtain four equations in four unknowns:\n",
      "This looks nasty, but remember that s, t, and u are just constants. Solving this sys-tem gives values for a, b, c, and d that define a solution to the recurrence consistent with the boundary conditions.\n",
      "10.3.3\n",
      "\t\n",
      "Solving General Linear Recurrences\n",
      "We can now solve all linear homogeneous recurrences, which have the form\n",
      "f .n/ D a\n",
      "1\n",
      "f .n\t1/ C a\n",
      "2\n",
      "f .n\t2/ C : : : C a\n",
      "d\n",
      " f .n\n",
      "\t\n",
      "d /:\n",
      "Many recurrences that arise in practice do not quite fit this mold. For example, the\n",
      "Towers of Hanoi problem led to this recurrence:\n",
      "f .1/ D 1\n",
      "f .n/ D 2f .n\t1/ C 1\n",
      "\t\n",
      "(for n\n",
      "\t\n",
      "2):\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 300  #306\n",
      "\n",
      "300\n",
      "\t\n",
      "Chapter 10\n",
      "\t\n",
      "Recurrences\n",
      "The problem is the extra C1; that is not allowed in a homogeneous linear recur-rence. In general, adding an extra function g.n/ to the right side of a linear recur-rence gives an inhomogeneous linear recurrence:\n",
      "f .n/ D a\n",
      "1\n",
      "f .n\t1/ C a\n",
      "2\n",
      "f .n\t2/ C : : : C a\n",
      "d\n",
      " f .n\td / C g.n/:\n",
      "Solving inhomogeneous linear recurrences is neither very different nor very dif-ficult. We can divide the whole job into five steps:\n",
      "Replace g.n/ by 0, leaving a homogeneous recurrence. As before, find roots of the characteristic equation.\n",
      "Write down the solution to the homogeneous recurrence, but do not yet use the boundary conditions to determine coefficients. This is called the homo-geneous solution.\n",
      "Now restore g.n/ and find a single solution to the recurrence, ignoring bound-ary conditions. This is called a particular solution. Well explain how to find a particular solution shortly.\n",
      "Add the homogeneous and particular solutions together to obtain the general solution.\n",
      "Now use the boundary conditions to determine constants by the usual method of generating and solving a system of linear equations.\n",
      "As an example, lets consider a variation of the Towers of Hanoi problem. Sup-pose that moving a disk takes time proportional to its size. Specifically, moving the smallest disk takes 1 second, the next-smallest takes 2 seconds, and moving the nth disk then requires n seconds instead of 1. So, in this variation, the time to complete the job is given by a recurrence with a Cn term instead of a C1:\n",
      "f .1/ D 1\n",
      "f .n/ D 2f .n\t1/ C n\n",
      "\t\n",
      "for n\n",
      "\t\n",
      "2:\n",
      "Clearly, this will take longer, but how much longer? Lets solve the recurrence with the method described above.\n",
      "In Steps 1 and 2, dropping the Cn leaves the homogeneous recurrence f .n/ D\n",
      "2f .n 1/. The characteristic equation is x D 2. So the homogeneous solution is f .n/ D c2\n",
      "n\n",
      ".\n",
      "In Step 3, we must find a solution to the full recurrence f .n/ D 2f .n 1/ C n, without regard to the boundary condition. Lets guess that there is a solution of the\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 301  #307\n",
      "\n",
      "form f .n/ D an C b for some constants a and b. Substituting this guess into the recurrence gives\n",
      "an C b D 2.a.n\t1/ C b/ C n\n",
      "0 D .a C 1/n C .b\t2a/:\n",
      "The second equation is a simplification of the first. The second equation holds for all n if both a C 1 D 0 (which implies a D 1) and b 2a D 0 (which implies that b D 2). So f .n/ D an C b D n 2 is a particular solution.\n",
      "In the Step 4, we add the homogeneous and particular solutions to obtain the general solution\n",
      "f .n/ D c2\n",
      "n\n",
      "\tn\n",
      "\t\n",
      "2:\n",
      "Finally, in step 5, we use the boundary condition, f .1/ D 1, determine the value of the constant c:\n",
      "f .1/ D 1\n",
      "\t\n",
      ")\n",
      "\t\n",
      "c2\n",
      "1\n",
      "\t1\t2 D 1\n",
      "c D 2:\n",
      "Therefore, the function f .n/ D 2 2\n",
      "n\n",
      " n 2 solves this variant of the Towers of Hanoi recurrence. For comparison, the solution to the original Towers of Hanoi problem was 2\n",
      "n\n",
      " 1. So if moving disks takes time proportional to their size, then the monks will need about twice as much time to solve the whole puzzle.\n",
      "10.3.4\n",
      "\t\n",
      "How to Guess a Particular Solution\n",
      "Finding a particular solution can be the hardest part of solving inhomogeneous recurrences. This involves guessing, and you might guess wrong.\n",
      "However, some rules of thumb make this job fairly easy most of the time.\n",
      "Generally, look for a particular solution with the same form as the inhomo-geneous term g.n/.\n",
      "If g.n/ is a constant, then guess a particular solution f .n/ D c. If this doesnt work, try polynomials of progressively higher degree: f .n/ D bn C c, then f .n/ D an\n",
      "2\n",
      " C bn C c, etc.\n",
      "More generally, if g.n/ is a polynomial, try a polynomial of the same degree, then a polynomial of degree one higher, then two higher, etc. For example, if g.n/ D 6n C 5, then try f .n/ D bn C c and then f .n/ D an\n",
      "2\n",
      " C bn C c.\n",
      "1\n",
      "In Chapter \n",
      ", we will show how to solve linear recurrences with generating functionsits a little more complicated, but it does not require guessing.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 302  #308\n",
      "\n",
      "Chapter 10  Recurrences\n",
      "If g.n/ is an exponential, such as 3\n",
      "n\n",
      ", then first guess that f .n/ D c3\n",
      "n\n",
      ".\n",
      "Failing that, try f .n/ D bn3\n",
      "n\n",
      " C c3\n",
      "n\n",
      " and then an\n",
      "2\n",
      "3\n",
      "n\n",
      " C bn3\n",
      "n\n",
      " C c3\n",
      "n\n",
      ", etc.\n",
      "The entire process is summarized on the following page.\n",
      "\n",
      "10.4\n",
      "\t\n",
      "Divide-and-Conquer Recurrences\n",
      "We now have a recipe for solving general linear recurrences. But the Merge Sort recurrence, which we encountered earlier, is not linear:\n",
      "T.1/ D 0\n",
      "T .n/ D 2T .n=2/ C n\t1\n",
      "\t\n",
      "(for n\n",
      "\t\n",
      "2):\n",
      "In particular, T .n/ is not a linear combination of a fixed number of immediately preceding terms; rather, T .n/ is a function of T .n=2/, a term halfway back in the sequence.\n",
      "Merge Sort is an example of a divide-and-conquer algorithm: it divides the in-put, conquers the pieces, and combines the results. Analysis of such algorithms commonly leads to divide-and-conquer recurrences, which have this form:\n",
      "k\n",
      "X\n",
      "T .n/ D\n",
      "\t\n",
      "a\n",
      "i\n",
      " T .b\n",
      "i\n",
      " n/ C g.n/\n",
      "iD1\n",
      "Here a\n",
      "1\n",
      "; : : : a\n",
      "k\n",
      " are positive constants, b\n",
      "1\n",
      "; : : : ; b\n",
      "k\n",
      " are constants between 0 and 1, and g.n/ is a nonnegative function. For example, setting a\n",
      "1\n",
      " D 2, b\n",
      "1\n",
      " D 1=2, and g.n/ D n 1 gives the Merge Sort recurrence.\n",
      "10.4.1\n",
      "\t\n",
      "The Akra-Bazzi Formula\n",
      "The solution to virtually all divide and conquer solutions is given by the amazing Akra-Bazzi formula. Quite simply, the asymptotic solution to the general divide-and-conquer recurrence\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 303  #309\n",
      "\n",
      "Short Guide to Solving Linear Recurrences\n",
      "\n",
      "A linear recurrence is an equation\n",
      "\n",
      "together with boundary conditions such as f .0/ D b\n",
      "0\n",
      ", f .1/ D b\n",
      "1\n",
      ", etc. Linear recurrences are solved as follows:\n",
      "1. Find the roots of the characteristic equation\n",
      "x\n",
      "n\n",
      " D a\n",
      "1\n",
      "x\n",
      "n1\n",
      "  C a\n",
      "2\n",
      "x\n",
      "n2\n",
      "  C : : : C a\n",
      "k1\n",
      "  x C a\n",
      "k\n",
      ":\n",
      "Write down the homogeneous solution. Each root generates one term and the homogeneous solution is their sum. A nonrepeated root r generates the term cr\n",
      "n\n",
      ", where c is a constant to be determined later. A root r with multi-plicity k generates the terms\n",
      "d\n",
      "1\n",
      "r\n",
      "n\n",
      "\t\n",
      "d\n",
      "2\n",
      "nr\n",
      "n\n",
      "\t\n",
      "d\n",
      "3\n",
      "n\n",
      "2\n",
      "r\n",
      "n\n",
      "\t\n",
      ": : :\n",
      "\t\n",
      "d\n",
      "k\n",
      "n\n",
      "k1\n",
      "  r\n",
      "n\n",
      "where d\n",
      "1\n",
      "; : : : d\n",
      "k\n",
      " are constants to be determined later.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find a particular solution. This is a solution to the full recurrence that need not be consistent with the boundary conditions. Use guess-and-verify. If g.n/ is a constant or a polynomial, try a polynomial of the same degree, then of one higher degree, then two higher. For example, if g.n/ D n, then try f .n/ D bn Cc and then an\n",
      "2\n",
      " Cbn Cc. If g.n/ is an exponential, such as 3\n",
      "n\n",
      ", then first guess f .n/ D c3\n",
      "n\n",
      ". Failing that, try f .n/ D .bn C c/3\n",
      "n\n",
      " and then\n",
      ".an\n",
      "2\n",
      " C bn C c/3\n",
      "n\n",
      ", etc.\n",
      "Form the general solution, which is the sum of the homogeneous solution and the particular solution. Here is a typical general solution:\n",
      "f .n/ D c2\n",
      "n\n",
      " C d.1/ \n",
      "n\n",
      " C\n",
      "\t\n",
      "3n C 1.\n",
      "\n",
      "\n",
      "homogeneous solution\n",
      "\t\n",
      "inhomogeneous solution\n",
      "Substitute the boundary conditions into the general solution. Each boundary condition gives a linear equation in the unknown constants. For example, substituting f .1/ D 2 into the general solution above gives\n",
      "2 D c 2\n",
      "1\n",
      " C d  .1/ \n",
      "1\n",
      " C 3 1 C 1\n",
      "2  D 2c  d:\n",
      "Determine the values of these constants by solving the resulting system of linear equations.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 304  #310\n",
      "\n",
      "304\n",
      "\t\n",
      "Chapter 10\n",
      "\t\n",
      "Recurrences\n",
      "where p satisfies\n",
      "iD1\n",
      "A rarely-troublesome requirement is that the function g.n/ must not grow or oscillate too quickly. Specifically, jg\n",
      "0\n",
      ".n/j must be bounded by some polynomial. So, for example, the Akra-Bazzi formula is valid when g.n/ D x\n",
      "2\n",
      " log n, but not when g.n/ D 2\n",
      "n\n",
      ".\n",
      "Lets solve the Merge Sort recurrence again, using the Akra-Bazzi formula in-stead of plug-and-chug. First, we find the value p that satisfies\n",
      "2 .1=2/\n",
      "p\n",
      " D 1:\n",
      "Looks like p D 1 does the job. Then we compute the integral:\n",
      "Z \n",
      "n\n",
      " \n",
      "u\n",
      "\t\n",
      "1\n",
      "T .n/ D\n",
      "\t\n",
      "n  1 C \n",
      "1\n",
      "\t\n",
      "u\n",
      "2\n",
      "  \n",
      "du\n",
      "\n",
      "n 1\n",
      " \n",
      "C\n",
      " \n",
      "log\n",
      " \n",
      "u\n",
      " \n",
      "C\n",
      " 1 \n",
      "n\n",
      " \n",
      "u\n",
      " 1\n",
      "n\n",
      "  \n",
      "log\n",
      " \n",
      "n\n",
      " \n",
      "C\n",
      " \n",
      "n\n",
      "1\n",
      ".n log n/ :\n",
      "\n",
      "The first step is integration and the second is simplification. We can drop the 1=n term in the last step, because the log n term dominates. Were done!\n",
      "Lets try a scary-looking recurrence:\n",
      "T .n/ D 2T .n=2/ C 8=9T .3n=4/ C n\n",
      "2\n",
      ":\n",
      "Here, a\n",
      "1\n",
      " D 2, b\n",
      "1\n",
      " D 1=2, a\n",
      "2\n",
      " D 8=9, and b\n",
      "2\n",
      " D 3=4. So we find the value p that satisfies\n",
      "2 .1=2/\n",
      "p\n",
      " C .8=9/.3=4/\n",
      "p\n",
      " D 1:\n",
      "Equations of this form dont always have closed-form solutions, so you may need to approximate p numerically sometimes. But in this case the solution is simple: p D 2. Then we integrate:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 305  #311\n",
      "\n",
      "10.4.2\n",
      "\t\n",
      "Two Technical Issues\n",
      "Until now, weve swept a couple issues related to divide-and-conquer recurrences under the rug. Lets address those issues now.\n",
      "First, the Akra-Bazzi formula makes no use of boundary conditions. To see why, lets go back to Merge Sort. During the plug-and-chug analysis, we found that\n",
      "T\n",
      "n\n",
      " D nT\n",
      "1\n",
      " C n log n\n",
      "\t\n",
      "n C 1:\n",
      "This expresses the nth term as a function of the first term, whose value is specified in a boundary condition. But notice that T\n",
      "n\n",
      " D .n log n/ for every value of T\n",
      "1\n",
      ". The boundary condition doesnt matter!\n",
      "This is the typical situation: the asymptotic solution to a divide-and-conquer recurrence is independent of the boundary conditions. Intuitively, if the bottom-level operation in a recursive algorithm takes, say, twice as long, then the overall running time will at most double. This matters in practice, but the factor of 2 is concealed by asymptotic notation. There are corner-case exceptions. For example, the solution to T .n/ D 2T .n=2/ is either .n/ or zero, depending on whether T .1/ is zero. These cases are of little practical interest, so we wont consider them further.\n",
      "There is a second nagging issue with divide-and-conquer recurrences that does not arise with linear recurrences. Specifically, dividing a problem of size n may create subproblems of non-integer size. For example, the Merge Sort recurrence contains the term T .n=2/. So what if n is 15? How long does it take to sort seven-and-a-half items? Previously, we dodged this issue by analyzing Merge Sort only when the size of the input was a power of 2. But then we dont know what happens for an input of size, say, 100.\n",
      "Of course, a practical implementation of Merge Sort would split the input ap-proximately in half, sort the halves recursively, and merge the results. For example, a list of 15 numbers would be split into lists of 7 and 8. More generally, a list of n numbers would be split into approximate halves of size dn=2e and bn=2c. So the maximum number of comparisons is actually given by this recurrence:\n",
      "T.1/ D 0\n",
      "T .n/ D T .dn=2e/ C T .bn=2c/ C n\t1\n",
      "\t\n",
      "(for n\n",
      "\t\n",
      "2):\n",
      "This may be rigorously correct, but the ceiling and floor operations make the recur-rence hard to solve exactly.\n",
      "Fortunately, the asymptotic solution to a divide and conquer recurrence is un-affected by floors and ceilings. More precisely, the solution is not changed by replacing a term T .b\n",
      "i\n",
      " n/ with either T .db\n",
      "i\n",
      " ne/ or T .bb\n",
      "i\n",
      " nc/. So leaving floors and\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 306  #312\n",
      "\n",
      "306\n",
      "\t\n",
      "Chapter 10\n",
      "\t\n",
      "Recurrences\n",
      "ceilings out of divide-and-conquer recurrences makes sense in many contexts; those are complications that make no difference.\n",
      "10.4.3\n",
      "\t\n",
      "The Akra-Bazzi Theorem\n",
      "The Akra-Bazzi formula together with our assertions about boundary conditions and integrality all follow from the Akra-Bazzi Theorem, which is stated below.\n",
      "Theorem 10.4.1 (Akra-Bazzi). Suppose that the function T W R ! R satisfies the recurrence\n",
      ":\n",
      "D1\n",
      "where:\n",
      "a\n",
      "1\n",
      "; : : : ; a\n",
      "k\n",
      " are positive constants.\n",
      "b\n",
      "1\n",
      "; : : : ; b\n",
      "k\n",
      " are constants between 0 and 1.\n",
      "x\n",
      "0\n",
      " is large enough so that T is well-defined.\n",
      "g.x/ is a nonnegative function such that jg\n",
      "0\n",
      ".x/j is bounded by a polynomial.\n",
      "jh\n",
      "i\n",
      " .x/j D O.x= log\n",
      "2\n",
      " x/.\n",
      "where p satisfies\n",
      "k\n",
      "X\n",
      " a\n",
      "i\n",
      " b\n",
      "i\n",
      "p\n",
      " D 1:\n",
      "iD1\n",
      "The Akra-Bazzi theorem can be proved using a complicated induction argument, though we wont do that here. But lets at least go over the statement of the theorem.\n",
      "All the recurrences weve considered were defined over the integers, and that is the common case. But the Akra-Bazzi theorem applies more generally to functions defined over the real numbers.\n",
      "The Akra-Bazzi formula is lifted directed from the theorem statement, except that the recurrence in the theorem includes extra functions, h\n",
      "i\n",
      " . These functions\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 307  #313\n",
      "\n",
      "extend the theorem to address floors, ceilings, and other small adjustments to the sizes of subproblems. The trick is illustrated by this combination of parameters\n",
      "This is the rigorously correct Merge Sort recurrence valid for all input sizes, complete with floor and ceiling operators. In this case, the functions h\n",
      "1\n",
      ".x/ and h\n",
      "2\n",
      ".x/ are both at most 1, which is easily O.x= log\n",
      "2\n",
      " x/ as required by the theorem statement. These functions h\n",
      "i\n",
      " do not affector even appear inthe asymptotic solution to the recurrence. This justifies our earlier claim that applying floor and ceiling operators to the size of a subproblem does not alter the asymptotic solution to a divide-and-conquer recurrence.\n",
      "10.4.4\n",
      "\t\n",
      "The Master Theorem\n",
      "There is a special case of the Akra-Bazzi formula known as the Master Theorem that handles some of the recurrences that commonly arise in computer science. It is called the Master Theorem because it was proved long before Akra and Bazzi arrived on the scene and, for many years, it was the final word on solving divide-and-conquer recurrences. We include the Master Theorem here because it is still widely referenced in algorithms courses and you can use it without having to know anything about integration.\n",
      "Theorem 10.4.2 (Master Theorem). Let T be a recurrence of the form\n",
      "T .n/ D aT\n",
      "\t\n",
      "n\n",
      "b\n",
      "  \n",
      "C\n",
      " \n",
      "g.n/:\n",
      "\n",
      "Case 1: If g.n/ D O\n",
      "\t\n",
      "n\n",
      "log\n",
      "b\n",
      ".a/\n",
      "\t\n",
      "for some constant\n",
      "\t\n",
      "> 0, then\n",
      " \n",
      "T .n/\n",
      " \n",
      "D\n",
      "\t\n",
      "n\n",
      "log\n",
      "b\n",
      ".a/\n",
      "  \n",
      ":\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 308  #314\n",
      "\n",
      "T .n/ D\t.g.n//:\n",
      "The Master Theorem can be proved by induction on n or, more easily, as a corol-lary of Theorem \n",
      ". We will not include the details here.\n",
      "10.4.5\n",
      "\t\n",
      "Pitfalls with Asymptotic Notation and Induction\n",
      "Weve seen that asymptotic notation is quite useful, particularly in connection with recurrences. And induction is our favorite proof technique. But mixing the two is risky business; there is great potential for subtle errors and false conclusions!\n",
      "False Claim. If\n",
      "T .1/ D 1\n",
      "\t\n",
      "and\n",
      "T .n/ D 2T .n=2/ C n;\n",
      "then T .n/ D O.n/.\n",
      "The Akra-Bazzi theorem implies that the correct solution is T .n/ D .n log n/ and so this claim is false. But where does the following proof go astray?\n",
      "Bogus proof. The proof is by strong induction. Let P .n/ be the proposition that T .n/ D O.n/.\n",
      "Base case: P .1/ is true because T .1/ D 1 D O.1/.\n",
      "Inductive step: For n 2, assume P .1/, P .2/, . . . , P .n 1/ to prove P .n/. We have\n",
      "T .n/ D 2 T .n=2/ C n\n",
      "D 2 O.n=2/ C n\n",
      "D O.n/:\n",
      "The first equation is the recurrence, the second uses the assumption P .n=2/, and\n",
      "the third is a simplification.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 309  #315\n",
      "\n",
      "Wheres the bug? The proof is already far off the mark in the second sentence, which defines the induction hypothesis. The statement T .n/ D O.n/ is either true or false; its validity does not depend on a particular value of n. Thus the very idea of trying to prove that the statement holds for n D 1, 2, . . . , is wrong-headed.\n",
      "The safe way to reason inductively about asymptotic phenomena is to work di-rectly with the definition of the asymptotic notation. Lets try to prove the claim above in this way. Remember that f .n/ D O.n/ means that there exist constants n\n",
      "0\n",
      " and c > 0 such that jf .n/j cn for all n n\n",
      "0\n",
      ". (Lets not worry about the absolute value for now.) If all goes well, the proof attempt should fail in some blatantly obvious way, instead of in a subtle, hard-to-detect way like the earlier ar-gument. Since our perverse goal is to demonstrate that the proof wont work for any constants n\n",
      "0\n",
      " and c, well leave these as variables and assume only that theyre chosen so that the base case holds; that is, T .n\n",
      "0\n",
      "/ cn.\n",
      "Proof Attempt. We use strong induction. Let P .n/ be the proposition that T .n/ cn.\n",
      "Base case: P .n\n",
      "0\n",
      "/ is true, because T .n\n",
      "0\n",
      "/\n",
      "\t\n",
      "cn.\n",
      "Inductive step: For n > n\n",
      "0\n",
      ", assume that P .n\n",
      "0\n",
      "/, . . . , P .n 1/ are true in order to prove P .n/. We reason as follows:\n",
      "T .n/ D 2T .n=2/ C n\n",
      "2c.n=2/ C n\n",
      "D cn C n\n",
      "D .c C 1/n\n",
      "cn:\n",
      "The first equation is the recurrence. Then we use induction and simplify until the argument collapses!\n",
      "In general, it is a good idea to stay away from asymptotic notation altogether while you are doing the induction. Once the induction is over and done with, then you can safely use big-Oh to simplify your result.\n",
      "\n",
      "10.5\n",
      "\t\n",
      "A Feel for Recurrences\n",
      "Weve guessed and verified, plugged and chugged, found roots, computed integrals, and solved linear systems and exponential equations. Now lets step back and look for some rules of thumb. What kinds of recurrences have what sorts of solutions?\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 310  #316\n",
      "\n",
      "310\n",
      "\t\n",
      "Chapter 10\n",
      "\t\n",
      "Recurrences\n",
      "Here are some recurrences we solved earlier:\n",
      "Notice that the recurrence equations for Towers of Hanoi and Merge Sort are some-what similar, but the solutions are radically different. Merge Sorting n D 64 items takes a few hundred comparisons, while moving n D 64 disks takes more than 10\n",
      "19\n",
      " steps!\n",
      "Each recurrence has one strength and one weakness. In the Towers of Hanoi, we broke a problem of size n into two subproblem of size n 1 (which is large), but needed only 1 additional step (which is small). In Merge Sort, we divided the problem of size n into two subproblems of size n=2 (which is small), but needed .n 1/ additional steps (which is large). Yet, Merge Sort is faster by a mile!\n",
      "This suggests that generating smaller subproblems is far more important to al-gorithmic speed than reducing the additional steps per recursive call. For example, shifting to the variation of Towers of Hanoi increased the last term from C1 to Cn, but the solution only doubled. And one of the two subproblems in the Fibonacci recurrence is just slightly smaller than in Towers of Hanoi (size n 2 instead of\n",
      "1). Yet the solution is exponentially smaller! More generally, linear recurrences (which have big subproblems) typically have exponential solutions, while divide-and-conquer recurrences (which have small subproblems) usually have solutions bounded above by a polynomial.\n",
      "All the examples listed above break a problem of size n into two smaller prob-lems. How does the number of subproblems affect the solution? For example, suppose we increased the number of subproblems in Towers of Hanoi from 2 to 3, giving this recurrence:\n",
      "T\n",
      "n\n",
      " D 3T\n",
      "n1\n",
      "  C 1\n",
      "This increases the root of the characteristic equation from 2 to 3, which raises the solution exponentially, from .2\n",
      "n\n",
      "/ to .3\n",
      "n\n",
      "/.\n",
      "Divide-and-conquer recurrences are also sensitive to the number of subproblems.\n",
      "For example, for this generalization of the Merge Sort recurrence:\n",
      "T\n",
      "1\n",
      "D0\n",
      "T\n",
      "n\n",
      " D aT\n",
      "n=2\n",
      " C n\n",
      "\t\n",
      "1:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 311  #317\n",
      "\n",
      "So the solution takes on three completely different forms as a goes from 1.99 to 2.01!\n",
      "How do boundary conditions affect the solution to a recurrence? Weve seen that they are almost irrelevant for divide-and-conquer recurrences. For linear re-currences, the solution is usually dominated by an exponential whose base is de-termined by the number and size of subproblems. Boundary conditions matter greatly only when they give the dominant term a zero coefficient, which changes the asymptotic solution.\n",
      "So now we have a rule of thumb! The performance of a recursive procedure is usually dictated by the size and number of subproblems, rather than the amount of work per recursive call or time spent at the base of the recursion. In particular, if subproblems are smaller than the original by an additive factor, the solution is most often exponential. But if the subproblems are only a fraction the size of the original, then the solution is typically bounded by a polynomial.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 312  #318\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 313  #319\n",
      "\n",
      "11\n",
      "\t\n",
      "Cardinality Rules\n",
      "\n",
      "11.1\n",
      "\t\n",
      "Counting One Thing by Counting Another\n",
      "How do you count the number of people in a crowded room? You could count heads, since for each person there is exactly one head. Alternatively, you could count ears and divide by two. Of course, you might have to adjust the calculation if someone lost an ear in a pirate raid or someone was born with three ears. The point here is that you can often count one thing by counting another, though some fudge factors may be required. This is a central theme of counting, from the easiest problems to the hardest.\n",
      "In more formal terms, every counting problem comes down to determining the size of some set. The size or cardinality of a finite set S is the number of elements in S and it is denoted by jSj. In these terms, were claiming that we can often find the size of one set by finding the size of a related set. Weve already seen a general statement of this idea in the Mapping Rule of Theorem \n",
      ". Of particular interest here is part 3 of Theorem \n",
      ", where we state that if there is a bijection between two sets, then the sets have the same size. This important fact is commonly known as the Bijection Rule.\n",
      "11.1.1\n",
      "\t\n",
      "The Bijection Rule\n",
      "Rule 11.1.1 (Bijection Rule). If there is a bijection f W A ! B between A and B, then jAj D jBj.\n",
      "The Bijection Rule acts as a magnifier of counting ability; if you figure out the size of one set, then you can immediately determine the sizes of many other sets via bijections. For example, consider the two sets mentioned at the beginning of Part \n",
      ":\n",
      "A D all ways to select a dozen doughnuts when five varieties are available\n",
      "D all 16-bit sequences with exactly 4 ones Lets consider a particular element of set A:\n",
      "Weve depicted each doughnut with a 0 and left a gap between the different vari-eties. Thus, the selection above contains two chocolate doughnuts, no lemon-filled,\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 314  #320\n",
      "\n",
      "314\n",
      "\t\n",
      "Chapter 11\n",
      "\t\n",
      "Cardinality Rules\n",
      "six sugar, two glazed, and two plain. Now lets put a 1 into each of the four gaps:\n",
      "Weve just formed a 16-bit number with exactly 4 onesan element of B!\n",
      "This example suggests a bijection from set A to set B: map a dozen doughnuts consisting of:\n",
      "c chocolate, l lemon-filled, s sugar, g glazed, and p plain\n",
      "to the sequence:\n",
      "0:::0\t1\t0:::0\t1\t0:::0\t1\t0:::0\t1\t0:::0\n",
      "\n",
      "c\n",
      "\t\n",
      "l\n",
      "\t\n",
      "s\n",
      "\t\n",
      "g\n",
      "\t\n",
      "p\n",
      "The resulting sequence always has 16 bits and exactly 4 ones, and thus is an element of B. Moreover, the mapping is a bijection; every such bit sequence is mapped to by exactly one order of a dozen doughnuts. Therefore, jAj D jBj by the Bijection Rule!\n",
      "This example demonstrates the magnifying power of the bijection rule. We man-aged to prove that two very different sets are actually the same sizeeven though we dont know exactly how big either one is. But as soon as we figure out the size of one set, well immediately know the size of the other.\n",
      "This particular bijection might seem frighteningly ingenious if youve not seen it before. But youll use essentially this same argument over and over, and soon youll consider it routine.\n",
      "\n",
      "11.2\n",
      "\t\n",
      "Counting Sequences\n",
      "The Bijection Rule lets us count one thing by counting another. This suggests a general strategy: get really good at counting just a few things and then use bijections to count everything else. This is the strategy well follow. In particular, well get really good at counting sequences. When we want to determine the size of some other set T , well find a bijection from T to a set of sequences S. Then well use our super-ninja sequence-counting skills to determine jSj, which immediately gives us jT j. Well need to hone this idea somewhat as we go along, but thats pretty much the plan!\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 315  #321\n",
      "\n",
      "11.2.1\n",
      "\t\n",
      "The Product Rule\n",
      "The Product Rule gives the size of a product of sets. Recall that if P\n",
      "1\n",
      "; P\n",
      "2\n",
      "; : : : ; P\n",
      "n\n",
      " are sets, then\n",
      "P\n",
      "1\n",
      "\tP\n",
      "2\n",
      "\t: : :\n",
      "\t\n",
      "P\n",
      "n\n",
      "is the set of all sequences whose first term is drawn from P\n",
      "1\n",
      ", second term is drawn from P\n",
      "2\n",
      " and so forth.\n",
      "Rule 11.2.1 (Product Rule). If P\n",
      "1\n",
      "; P\n",
      "2\n",
      "; : : : P\n",
      "n\n",
      " are sets, then:\n",
      "jP\n",
      "1\n",
      "\t\n",
      "P\n",
      "2\n",
      "\t: : :\tP\n",
      "n\n",
      "j D jP\n",
      "1\n",
      "j jP\n",
      "2\n",
      "j\n",
      "\t\n",
      "jP\n",
      "n\n",
      "j\n",
      "For example, suppose a daily diet consists of a breakfast selected from set B, a lunch from set L, and a dinner from set D where:\n",
      "D fpancakes; bacon and eggs; bagel; Doritosg\n",
      "L D fburger and fries; garden salad; Doritosg\n",
      "D fmacaroni; pizza; frozen burrito; pasta; Doritosg\n",
      "Then B\n",
      "\t\n",
      "L  D is the set of all possible daily diets. Here are some sample elements:\n",
      ".pancakes; burger and fries; pizza/\n",
      ".bacon and eggs; garden salad; pasta/\n",
      ".Doritos; Doritos; frozen burrito/\n",
      "The Product Rule tells us how many different daily diets are possible:\n",
      "jB\n",
      "\t\n",
      "L\tDj D jBj jLj jDj\n",
      "D435\n",
      "60:\n",
      "11.2.2\n",
      "\t\n",
      "Subsets of an n-element Set\n",
      "How many different subsets of an n-element set X are there? For example, the set\n",
      "D fx\n",
      "1\n",
      "; x\n",
      "2\n",
      "; x\n",
      "3\n",
      "g has eight different subsets:\n",
      ";\n",
      "\t\n",
      "fx\n",
      "1\n",
      "g\n",
      "\t\n",
      "fx\n",
      "2\n",
      "g\n",
      "\t\n",
      "fx\n",
      "1\n",
      "; x\n",
      "2\n",
      "g\n",
      "fx\n",
      "3\n",
      "g fx\n",
      "1\n",
      "; x\n",
      "3\n",
      "g fx\n",
      "2\n",
      "; x\n",
      "3\n",
      "g fx\n",
      "1\n",
      "; x\n",
      "2\n",
      "; x\n",
      "3\n",
      "g:\n",
      "There is a natural bijection from subsets of X to n-bit sequences. Let x\n",
      "1\n",
      "; x\n",
      "2\n",
      "; : : : ; x\n",
      "n\n",
      "be the elements of X. Then a particular subset of X maps to the sequence .b\n",
      "1\n",
      "; : : : ; b\n",
      "n\n",
      "/\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 316  #322\n",
      "\n",
      "316\n",
      "\t\n",
      "Chapter 11\n",
      "\t\n",
      "Cardinality Rules\n",
      "where b\n",
      "i\n",
      " D 1 if and only if x\n",
      "i\n",
      " is in that subset. For example, if n D 10, then the subset fx\n",
      "2\n",
      "; x\n",
      "3\n",
      "; x\n",
      "5\n",
      "; x\n",
      "7\n",
      "; x\n",
      "10\n",
      "g maps to a 10-bit sequence as follows:\n",
      "We just used a bijection to transform the original problem into a question about sequencesexactly according to plan! Now if we answer the sequence question, then weve solved our original problem as well.\n",
      "But how many different n-bit sequences are there? For example, there are 8 different 3-bit sequences:\n",
      "Well, we can write the set of all n-bit sequences as a product of sets:\n",
      "f0; 1g\tf0; 1g\n",
      "\t\n",
      ": : :\n",
      "\t\n",
      "f0; 1g D f0; 1g\n",
      "n\n",
      "Then Product Rule gives the answer:\n",
      "jf0; 1g\n",
      "n\n",
      "j D jf0; 1gj\n",
      "n\n",
      "D 2\n",
      "n\n",
      "This means that the number of subsets of an n-element set X is also 2\n",
      "n\n",
      ". Well put this answer to use shortly.\n",
      "11.2.3\n",
      "\t\n",
      "The Sum Rule\n",
      "Linus allocates his big sister Lucy a quota of 20 crabby days, 40 irritable days, and 60 generally surly days. On how many days can Lucy be out-of-sorts one way or another? Let set C be her crabby days, I be her irritable days, and S be the generally surly. In these terms, the answer to the question is jC [ I [ Sj. Now assuming that she is permitted at most one bad quality each day, the size of this union of sets is given by the Sum Rule:\n",
      "Rule 11.2.2 (Sum Rule). If A\n",
      "1\n",
      "; A\n",
      "2\n",
      "; : : : ; A\n",
      "n\n",
      " are disjoint sets, then:\n",
      "jA\n",
      "1\n",
      " [ A\n",
      "2\n",
      " [ : : : [ A\n",
      "n\n",
      "j D jA\n",
      "1\n",
      "j C jA\n",
      "2\n",
      "j C : : : C jA\n",
      "n\n",
      "j\n",
      "Thus, according to Linus budget, Lucy can be out-of-sorts for:\n",
      "jC [ I [ Sj D jC j C jI j C jSj\n",
      "D20C40C60\n",
      "D 120 days\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 317  #323\n",
      "\n",
      "Notice that the Sum Rule holds only for a union of disjoint sets. Finding the size of a union of intersecting sets is a more complicated problem that well take up later.\n",
      "11.2.4\n",
      "\t\n",
      "Counting Passwords\n",
      "Few counting problems can be solved with a single rule. More often, a solution is a flurry of sums, products, bijections, and other methods. For example, the sum and product rules together are useful for solving problems involving passwords, telephone numbers, and license plates. For example, on a certain computer system, a valid password is a sequence of between six and eight symbols. The first symbol must be a letter (which can be lowercase or uppercase), and the remaining symbols must be either letters or digits. How many different passwords are possible?\n",
      "Lets define two sets, corresponding to valid symbols in the first and subsequent positions in the password.\n",
      "F D fa; b; : : : ; z; A; B; : : : ; Zg\n",
      "S D fa; b; : : : ; z; A; B; : : : ; Z; 0; 1; : : : ; 9g\n",
      "In these terms, the set of all possible passwords is:\n",
      ".F\tS\n",
      "5\n",
      "/ [ .F\tS\n",
      "6\n",
      "/ [ .F\tS\n",
      "7\n",
      "/\n",
      "Thus, the length-six passwords are in the set F S\n",
      "5\n",
      ", the length-seven passwords are in F S\n",
      "6\n",
      ", and the length-eight passwords are in F S\n",
      "7\n",
      ". Since these sets are disjoint, we can apply the Sum Rule and count the total number of possible passwords as follows:\n",
      "\n",
      "11.3\n",
      "\t\n",
      "The Generalized Product Rule\n",
      "We realize everyone has been working pretty hard this term, and were considering awarding some prizes for truly exceptional coursework. Here are some possible\n",
      "\n",
      "1\n",
      "The notation S\n",
      "5\n",
      " means S\n",
      "\t\n",
      "S\tS\tS\n",
      "\t\n",
      "S.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 318  #324\n",
      "\n",
      "318\n",
      "\t\n",
      "Chapter 11\n",
      "\t\n",
      "Cardinality Rules\n",
      "categories:\n",
      "Best Administrative Critique We asserted that the quiz was closed-book. On the cover page, one strong candidate for this award wrote, There is no book.\n",
      "Awkward Question Award Okay, the left sock, right sock, and pants are in an antichain, but howeven with assistancecould I put on all three at once?\n",
      "Best Collaboration Statement Inspired by a student who wrote I worked alone on Quiz 1.\n",
      "In how many ways can, say, three different prizes be awarded to n people? This is easy to answer using our strategy of translating the problem about awards into a problem about sequences. Let P be the set of n people taking the course. Then there is a bijection from ways of awarding the three prizes to the set P \n",
      "3\n",
      " WWD P\n",
      "P . In particular, the assignment:\n",
      "person x wins prize #1, y wins prize #2, and z wins prize #3\n",
      "maps to the sequence .x; y; z/. By the Product Rule, we have jP \n",
      "3\n",
      "j D jP j\n",
      "3\n",
      " D n\n",
      "3\n",
      ", so there are n\n",
      "3\n",
      " ways to award the prizes to a class of n people.\n",
      "But what if the three prizes must be awarded to different students? As before, we could map the assignment\n",
      "person x wins prize #1, y wins prize #2, and z wins prize #3\n",
      "to the triple .x; y; z/ 2 P \n",
      "3\n",
      ". But this function is no longer a bijection. For example, no valid assignment maps to the triple (Dave, Dave, Becky) because Dave is not allowed to receive two awards. However, there is a bijection from prize assignments to the set:\n",
      "D f.x; y; z/ 2 P \n",
      "3\n",
      " j x, y, and z are different peopleg\n",
      "This reduces the original problem to a problem of counting sequences. Unfortu-nately, the Product Rule is of no help in counting sequences of this type because the entries depend on one another; in particular, they must all be different. How-ever, a slightly sharper tool does the trick.\n",
      "Rule 11.3.1 (Generalized Product Rule). Let S be a set of length-k sequences. If there are:\n",
      "n\n",
      "1\n",
      " possible first entries,\n",
      "n\n",
      "2\n",
      " possible second entries for each first entry,\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 319  #325\n",
      "\n",
      "n\n",
      "3\n",
      " \n",
      "possible third entries for each combination of first and second entries, etc.\n",
      "then:\n",
      "j\n",
      "S\n",
      "j D \n",
      "n\n",
      "1\n",
      "  \n",
      "n\n",
      "2\n",
      "  \n",
      "n\n",
      "3\n",
      "\t\n",
      "n\n",
      "k\n",
      "In the awards example, \n",
      "S\n",
      " consists of sequences \n",
      ".x; y; z/\n",
      ". There are \n",
      "n\n",
      " ways to choose \n",
      "x\n",
      ", the recipient of prize #1. For each of these, there are \n",
      "n 1\n",
      " ways to choose \n",
      "y\n",
      ", the recipient of prize #2, since everyone except for person\n",
      " x \n",
      "is eligible. For each\n",
      " \n",
      "combination of \n",
      "x\n",
      " and \n",
      "y\n",
      ", there are \n",
      "n 2\n",
      " ways to choose \n",
      "z\n",
      ", the recipient of prize #3, because everyone except for \n",
      "x\n",
      " and \n",
      "y\n",
      " is eligible. Thus, according to the Generalized Product Rule, there are\n",
      "j\n",
      "S\n",
      "j D \n",
      "n .n\n",
      "\t\n",
      "1/ .n\n",
      "\t\n",
      "2/\n",
      "ways to award the 3 prizes to different people.\n",
      "11.3.1\n",
      "\t\n",
      "Defective Dollar Bills\n",
      "A dollar bill is defective if some digit appears more than once in the 8-digit serial number. If you check your wallet, youll be sad to discover that defective bills are all-too-common. In fact, how common are nondefective bills? Assuming that the digit portions of serial numbers all occur equally often, we could answer this question by computing\n",
      "Lets first consider the denominator. Here there are no restrictions; there are are 10 possible first digits, 10 possible second digits, 10 third digits, and so on. Thus, the total number of 8-digit serial numbers is \n",
      "10\n",
      "8\n",
      " by the Product Rule.\n",
      "Next, lets turn to the numerator. Now were not permitted to use any digit twice. So there are still 10 possible first digits, but only 9 possible second digits, 8 possible third digits, and so forth. Thus, by the Generalized Product Rule, there are\n",
      "10 9 8 7 6 5 4 3\n",
      "D\n",
      "10\n",
      "2\n",
      " \n",
      "D\n",
      "1;814;400\n",
      "\n",
      "serial numbers with all digits different. Plugging these results into Equation \n",
      ", we find:\n",
      "fraction of nondefective bills D \n",
      "100;000;000\n",
      "1;814;400\n",
      " D \n",
      "1:8144\n",
      "%\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 320  #326\n",
      "\n",
      "320\n",
      "\t\n",
      "Chapter 11\n",
      "\t\n",
      "Cardinality Rules\n",
      "\n",
      "0Z0Z0Z0Z  \n",
      "8\n",
      " 0Z0Z0Z0Z\n",
      "7 \n",
      "Z0Z0m0Z0\n",
      "7 \n",
      "Z0Z0Z0Z0\n",
      "6 \n",
      "0Z0Z0Z0Z\n",
      "6 \n",
      "0Z0ZpZ0Z\n",
      "5 \n",
      "Z0Z0Z0Z0\n",
      "5 \n",
      "Z0Z0Z0Z0\n",
      "4 \n",
      "0a0Z0Z0Z\n",
      "4 \n",
      "0Z0Z0Z0Z\n",
      "3 \n",
      "Z0Z0Z0Z0\n",
      "3 \n",
      "Z0a0ZnZ0\n",
      "2 \n",
      "0Z0Z0o0Z\n",
      "2 \n",
      "0Z0Z0Z0Z\n",
      "1 \n",
      "Z0Z0Z0Z0\n",
      "1 \n",
      "Z0Z0Z0Z0\n",
      "a\tb\tc\td\te\tf\tg\th\n",
      "\t\n",
      "a\tb\tc\td\te\tf\tg\n",
      "\t\n",
      "h\n",
      "(a) valid\n",
      "\t\n",
      "(b) invalid\n",
      "Figure 11.1 Two ways of placing a pawn (p), a knight (N), and a bishop (B) on a chessboard. The configuration shown in (b) is invalid because the bishop and the knight are in the same row.\n",
      "11.3.2\n",
      "\t\n",
      "A Chess Problem\n",
      "In how many different ways can we place a pawn (P ), a knight (N ), and a bishop (B) on a chessboard so that no two pieces share a row or a column? A valid con-figuration is shown in Figure \n",
      "(a), and an invalid configuration is shown in Fig-ure \n",
      "(b).\n",
      "First, we map this problem about chess pieces to a question about sequences. There is a bijection from configurations to sequences\n",
      ".r\n",
      "P\n",
      " ; c\n",
      "P\n",
      " ; r\n",
      "N\n",
      " ; c\n",
      "N\n",
      " ; r\n",
      "B\n",
      " ; c\n",
      "B\n",
      " /\n",
      "where r\n",
      "P\n",
      " , r\n",
      "N\n",
      " , and r\n",
      "B\n",
      " are distinct rows and c\n",
      "P\n",
      " , c\n",
      "N\n",
      " , and c\n",
      "B\n",
      " are distinct columns. In particular, r\n",
      "P\n",
      " is the pawns row, c\n",
      "P\n",
      " is the pawns column, r\n",
      "N\n",
      " is the knights row, etc. Now we can count the number of such sequences using the Generalized Product Rule:\n",
      "r\n",
      "P\n",
      " is one of 8 rows\n",
      "c\n",
      "P\n",
      " is one of 8 columns\n",
      "r\n",
      "N\n",
      " is one of 7 rows (any one but r\n",
      "P\n",
      " )\n",
      "c\n",
      "N\n",
      " is one of 7 columns (any one but c\n",
      "P\n",
      " ) r\n",
      "B\n",
      " is one of 6 rows (any one but r\n",
      "P\n",
      " or r\n",
      "N\n",
      " )\n",
      "c\n",
      "B\n",
      " is one of 6 columns (any one but c\n",
      "P\n",
      " or c\n",
      "N\n",
      " )\n",
      "Thus, the total number of configurations is .8 7 6/\n",
      "2\n",
      ".\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 321  #327\n",
      "\n",
      "11.3.3\n",
      "\t\n",
      "Permutations\n",
      "A permutation of a set \n",
      "S\n",
      " is a sequence that contains every element of \n",
      "S\n",
      " exactly once. For example, here are all the permutations of the set f\n",
      "a; b; c\n",
      "g:\n",
      ".a; b; c/\t.a; c; b/\n",
      "\t\n",
      ".b; a; c/\n",
      ".b; c; a/\t.c; a; b/\n",
      "\t\n",
      ".c; b; a/\n",
      "How many permutations of an \n",
      "n\n",
      "-element set are there? Well, there are \n",
      "n\n",
      " choices for the first element. For each of these, there are \n",
      "n 1\n",
      " remaining choices for the second element. For every combination of the first two elements, there are \n",
      "n 2\n",
      " ways to choose the third element, and so forth. Thus, there are a total of\n",
      "n .n\t1/ .n\t2/\t3 2 1 \n",
      "D\n",
      " n\n",
      "permutations of an \n",
      "n\n",
      "-element set. In particular, this formula says that there are \n",
      "3 \n",
      "D\n",
      " 6 \n",
      "permutations of the 3-element set\n",
      " \n",
      "f\n",
      "a; b; c\n",
      "g, which is the number we found\n",
      " \n",
      "above.\n",
      "Permutations will come up again in this course approximately 1.6 bazillion times. In fact, permutations are the reason why factorial comes up so often and why we taught you Stirlings approximation:\n",
      "n\n",
      "\t\n",
      "p\n",
      "2  n\n",
      "  \n",
      "n\n",
      "e\n",
      " \n",
      "n\n",
      " \n",
      ":\n",
      "\n",
      "11.4\n",
      "\t\n",
      "The Division Rule\n",
      "Counting ears and dividing by two is a silly way to count the number of people in a room, but this approach is representative of a powerful counting principle.\n",
      "A \n",
      "k\n",
      "-to-1 function maps exactly \n",
      "k\n",
      " elements of the domain to every element of the codomain. For example, the function mapping each ear to its owner is 2-to-1. Similarly, the function mapping each finger to its owner is 10-to-1, and the function mapping each finger and toe to its owner is 20-to-1. The general rule is:\n",
      "Rule 11.4.1 (Division Rule). If \n",
      "f\n",
      " W \n",
      "A\n",
      " ! \n",
      "B\n",
      " is \n",
      "k\n",
      "-to-1, then j\n",
      "A\n",
      "j D \n",
      "k\n",
      " j\n",
      "B\n",
      "j.\n",
      "For example, suppose \n",
      "A\n",
      " is the set of ears in the room and \n",
      "B\n",
      " is the set of people. There is a 2-to-1 mapping from ears to people, so by the Division Rule, j\n",
      "A\n",
      "j D \n",
      "2 \n",
      "j\n",
      "B\n",
      "j. Equivalently,\n",
      " \n",
      "j\n",
      "B\n",
      "j D j\n",
      "A\n",
      "j\n",
      "=2\n",
      ", expressing what we knew all along: the number\n",
      " \n",
      "of people is half the number of ears. Unlikely as it may seem, many counting problems are made much easier by initially counting every item multiple times and then correcting the answer using the Division Rule. Lets look at some examples.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 322  #328\n",
      "\n",
      "322\n",
      "\t\n",
      "Chapter 11\n",
      "\t\n",
      "Cardinality Rules\n",
      "\n",
      "0Z0Z0Z0s  \n",
      "8\n",
      " 0Z0Z0Z0Z\n",
      "7 \n",
      "Z0Z0Z0Z0\n",
      "7 \n",
      "Z0Z0Z0Z0\n",
      "6 \n",
      "0Z0Z0Z0Z\n",
      "6 \n",
      "0Z0s0Z0Z\n",
      "5 \n",
      "Z0Z0Z0Z0\n",
      "5 \n",
      "Z0Z0Z0Z0\n",
      "4 \n",
      "0Z0Z0Z0Z\n",
      "4 \n",
      "0Z0Z0Z0Z\n",
      "3 \n",
      "Z0Z0Z0Z0\n",
      "3 \n",
      "Z0Z0Z0Z0\n",
      "2 \n",
      "0Z0Z0Z0Z\n",
      "2 \n",
      "0Z0Z0Z0Z\n",
      "1 \n",
      "s0Z0Z0Z0\n",
      "1 \n",
      "Z0ZrZ0Z0\n",
      "a\tb\tc\td\te\tf\tg\th\n",
      "\t\n",
      "a\tb\tc\td\te\tf\tg\n",
      "\t\n",
      "h\n",
      "(a) valid\n",
      "\t\n",
      "(b) invalid\n",
      "Figure 11.2 Two ways to place 2 rooks (R) on a chessboard. The configuration in (b) is invalid because the rooks are in the same column.\n",
      "11.4.1\n",
      "\t\n",
      "Another Chess Problem\n",
      "In how many different ways can you place two identical rooks on a chessboard so that they do not share a row or column? A valid configuration is shown in Figure \n",
      "(a), and an invalid configuration is shown in Figure \n",
      "(b).\n",
      "Let A be the set of all sequences\n",
      ".r\n",
      "1\n",
      "; c\n",
      "1\n",
      "; r\n",
      "2\n",
      "; c\n",
      "2\n",
      "/\n",
      "where r\n",
      "1\n",
      " and r\n",
      "2\n",
      " are distinct rows and c\n",
      "1\n",
      " and c\n",
      "2\n",
      " are distinct columns. Let B be the set of all valid rook configurations. There is a natural function f from set A to set B; in particular, f maps the sequence .r\n",
      "1\n",
      "; c\n",
      "1\n",
      "; r\n",
      "2\n",
      "; c\n",
      "2\n",
      "/ to a configuration with one rook in row r\n",
      "1\n",
      ", column c\n",
      "1\n",
      " and the other rook in row r\n",
      "2\n",
      ", column c\n",
      "2\n",
      ".\n",
      "But now theres a snag. Consider the sequences:\n",
      ".1; 1; 8; 8/\n",
      "\t\n",
      "and\n",
      "\t\n",
      ".8; 8; 1; 1/\n",
      "The first sequence maps to a configuration with a rook in the lower-left corner and a rook in the upper-right corner. The second sequence maps to a configuration with a rook in the upper-right corner and a rook in the lower-left corner. The problem is that those are two different ways of describing the same configuration! In fact, this arrangement is shown in Figure \n",
      "(a).\n",
      "More generally, the function f maps exactly two sequences to every board con-figuration; that is f is a 2-to-1 function. Thus, by the quotient rule, jAj D 2 jBj.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 323  #329\n",
      "\n",
      "Rearranging terms gives:\n",
      "jBj D\n",
      " jAj \n",
      "D\n",
      " .8 7/\n",
      "2\n",
      " \n",
      ":\n",
      "\n",
      "2\n",
      "\t\n",
      "2\n",
      "On the second line, weve computed the size of A using the General Product Rule just as in the earlier chess problem.\n",
      "11.4.2\n",
      "\t\n",
      "Knights of the Round Table\n",
      "In how many ways can King Arthur seat n different knights at his round table? Two seatings are considered equivalent if one can be obtained from the other by rotation. For example, the following two arrangements are equivalent:\n",
      "Let A be all the permutations of the knights, and let B be the set of all possible seating arrangements at the round table. We can map each permutation in set A to a circular seating arrangement in set B by seating the first knight in the permutation anywhere, putting the second knight to his left, the third knight to the left of the second, and so forth all the way around the table. For example:\n",
      "This mapping is actually an n-to-1 function from A to B, since all n cyclic shifts of the original sequence map to the same seating arrangement. In the example, n D 4 different sequences map to the same seating arrangement:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 324  #330\n",
      "\n",
      "324\n",
      "\t\n",
      "Chapter 11\n",
      "\t\n",
      "Cardinality Rules\n",
      "Therefore, by the division rule, the number of circular seating arrangements is:\n",
      "Note that j\n",
      "A\n",
      "j D \n",
      "n\n",
      " since there are \n",
      "n\n",
      " permutations of \n",
      "n\n",
      " knights.\n",
      "\n",
      "11.5\n",
      "\t\n",
      "Counting Subsets\n",
      "How many \n",
      "k\n",
      "-element subsets of an \n",
      "n\n",
      "-element set are there? This question arises all the time in various guises:\n",
      "In how many ways can I select 5 books from my collection of 100 to bring on vacation?\n",
      "How many different 13-card Bridge hands can be dealt from a 52-card deck? In how many ways can I select 5 toppings for my pizza if there are 14 avail-\n",
      "able toppings?\n",
      "This number comes up so often that there is a special notation for it:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 325  #331\n",
      "\n",
      "11.5.1\n",
      "\t\n",
      "The Subset Rule\n",
      "We can derive a simple formula for the \n",
      "n\n",
      "-choose-\n",
      "k\n",
      " number using the Division Rule. We do this by mapping any permutation of an \n",
      "n\n",
      "-element set f\n",
      "a\n",
      "1\n",
      "; : : : ; a\n",
      "n\n",
      "g into a \n",
      "k\n",
      "-element subset simply by taking the first \n",
      "k\n",
      " elements of the permutation. That is, the permutation \n",
      "a\n",
      "1\n",
      "a\n",
      "2\n",
      " \n",
      ": : : a\n",
      "n\n",
      " will map to the set f\n",
      "a\n",
      "1\n",
      "; a\n",
      "2\n",
      "; : : : ; a\n",
      "k\n",
      "g.\n",
      "Notice that any other permutation with the same first \n",
      "k\n",
      " elements \n",
      "a\n",
      "1\n",
      "; : : : ; a\n",
      "k\n",
      " in any order and the same remaining elements \n",
      "n k\n",
      " elements in any order will also map to this set. Whats more, a permutation can only map to f\n",
      "a\n",
      "1\n",
      "; a\n",
      "2\n",
      "; : : : ; a\n",
      "k\n",
      "g if its first \n",
      "k\n",
      " elements are the elements \n",
      "a\n",
      "1\n",
      "; : : : ; a\n",
      "k\n",
      " in some order. Since there are \n",
      "k \n",
      "possible permutations of the first\n",
      " k \n",
      "elements and\n",
      " .n k/ \n",
      "permutations of the\n",
      " \n",
      "remaining elements, we conclude from the Product Rule that exactly \n",
      "k .n k/\n",
      " permutations of the \n",
      "n\n",
      "-element set map to the the particular subset, \n",
      "S\n",
      ". In other words, the mapping from permutations to \n",
      "k\n",
      "-element subsets is \n",
      "k .n k/\n",
      " -to-1.\n",
      "But we know there are \n",
      "n\n",
      " permutations of an \n",
      "n\n",
      "-element set, so by the Division Rule, we conclude that\n",
      "!\n",
      "n \n",
      "D\n",
      " k .n\tk/\n",
      "\t\n",
      "k\n",
      "n\n",
      "which proves:\n",
      "Rule 11.5.1 (Subset Rule). The number of \n",
      "k\n",
      "-element subsets of an \n",
      "n\n",
      "-element set is\n",
      "Notice that this works even for 0-element subsets: \n",
      "n =0 n\n",
      " D \n",
      "1\n",
      ". Here we use the fact that \n",
      "0\n",
      " is a product of 0 terms, which by convention\n",
      "equals 1.\n",
      "11.5.2\n",
      "\t\n",
      "Bit Sequences\n",
      "How many \n",
      "n\n",
      "-bit sequences contain exactly \n",
      "k\n",
      " ones? Weve already seen the straight-forward bijection between subsets of an \n",
      "n\n",
      "-element set and \n",
      "n\n",
      "-bit sequences. For example, here is a 3-element subset of f\n",
      "x\n",
      "1\n",
      "; x\n",
      "2\n",
      "; : : : ; x\n",
      "8\n",
      "g and the associated 8-bit sequence:\n",
      "f \n",
      "x\n",
      "1\n",
      ";\n",
      "\t\n",
      "x\n",
      "4\n",
      ";\tx\n",
      "5\n",
      "\t\n",
      "g\n",
      "1;0;0;1; 1;0;0;0/\n",
      "Notice that this sequence has exactly 3 ones, each corresponding to an element of the 3-element subset. More generally, the \n",
      "n\n",
      "-bit sequences corresponding to a \n",
      "k\n",
      "-element subset will have exactly\n",
      " k \n",
      "ones. So by the Bijection Rule,\n",
      "\n",
      "2\n",
      "We dont use it here, but a sum of zero terms equals 0.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 326  #332\n",
      "\n",
      "\n",
      "11.6\n",
      "\t\n",
      "Sequences with Repetitions\n",
      "11.6.1\n",
      "\t\n",
      "Sequences of Subsets\n",
      "Choosing a \n",
      "k\n",
      "-element subset of an \n",
      "n\n",
      "-element set is the same as splitting the set into a pair of subsets: the first subset of size \n",
      "k\n",
      " and the second subset consisting of the remaining \n",
      "n k\n",
      " elements. So the Subset Rule can be understood as a rule for counting the number of such splits into pairs of subsets.\n",
      "We can generalize this to splits into more than two subsets. Namely, let \n",
      "A\n",
      " be an \n",
      "n\n",
      "-element set and \n",
      "k\n",
      "1\n",
      "; k\n",
      "2\n",
      "; : : : ; k\n",
      "m\n",
      " be nonnegative integers whose sum is \n",
      "n\n",
      ". A\n",
      ".k\n",
      "1\n",
      "; k\n",
      "2\n",
      "; : : : ; k\n",
      "m\n",
      "/\n",
      "-split of\n",
      " A \n",
      "is a sequence\n",
      ".A\n",
      "1\n",
      "; A\n",
      "2\n",
      "; : : : ; A\n",
      "m\n",
      "/\n",
      "where the \n",
      "A\n",
      "i\n",
      " are disjoint subsets of \n",
      "A\n",
      " and j\n",
      "A\n",
      "i\n",
      " j D \n",
      "k\n",
      "i\n",
      " for \n",
      "i\n",
      " D \n",
      "1; : : : ; m\n",
      ".\n",
      "Rule 11.6.1 (Subset Split Rule). The number of \n",
      ".k\n",
      "1\n",
      "; k\n",
      "2\n",
      "; : : : ; k\n",
      "m\n",
      "/\n",
      "-splits of an \n",
      "n\n",
      "-element set is\n",
      "The proof of this Rule is essentially the same as for the Subset Rule. Namely, we map any permutation \n",
      "a\n",
      "1\n",
      "a\n",
      "2\n",
      " \n",
      ": : : a\n",
      "n\n",
      " of an \n",
      "n\n",
      "-element set \n",
      "A\n",
      " into a \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".k\n",
      "1\n",
      "; k\n",
      "2\n",
      "; : : : ; k\n",
      "m\n",
      "/\n",
      "-split by letting the 1st subset in the split be the first \n",
      "k\n",
      "1\n",
      " elements of the permutation, the 2nd subset of the split be the next \n",
      "k\n",
      "2\n",
      " elements, . . . , and the \n",
      "m\n",
      "th subset of the split be the final \n",
      "k\n",
      "m\n",
      " elements of the permutation. This map is a \n",
      "k\n",
      "1\n",
      " \n",
      "k\n",
      "2\n",
      " \n",
      "k\n",
      "m\n",
      " -to-1 func-tion from the \n",
      "n\n",
      " permutations to the \n",
      ".k\n",
      "1\n",
      "; k\n",
      "2\n",
      "; : : : ; k\n",
      " \n",
      "m\n",
      "/\n",
      "-splits of \n",
      "A\n",
      ", and the Subset Split Rule now follows from the Division Rule.\n",
      "11.6.2\n",
      "\t\n",
      "The Bookkeeper Rule\n",
      "We can also generalize our count of \n",
      "n\n",
      "-bit sequences with \n",
      "k\n",
      " ones to counting se-quences of \n",
      "n\n",
      " letters over an alphabet with more than two letters. For example, how many sequences can be formed by permuting the letters in the 10-letter word BOOKKEEPER?\n",
      "Notice that there are 1 B, 2 Os, 2 Ks, 3 Es, 1 P, and 1 R in BOOKKEEPER. This leads to a straightforward bijection between permutations of BOOKKEEPER and\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 327  #333\n",
      "\n",
      "(1,2,2,3,1,1)-splits of f\n",
      "1; 2; : : : ; 10\n",
      "g. Namely, map a permutation to the sequence of sets of positions where each of the different letters occur.\n",
      "For example, in the permutation BOOKKEEPER itself, the B is in the 1st posi-tion, the Os occur in the 2nd and 3rd positions, Ks in 4th and 5th, the Es in the 6th, 7th and 9th, P in the 8th, and R is in the 10th position. So BOOKKEEPER maps to\n",
      ".\n",
      "f\n",
      "1\n",
      "g\n",
      "; \n",
      "f\n",
      "2; 3\n",
      "g\n",
      "; \n",
      "f\n",
      "4; 5\n",
      "g\n",
      "; \n",
      "f\n",
      "6; 7; 9\n",
      "g\n",
      "; \n",
      "f\n",
      "8\n",
      "g\n",
      "; \n",
      "f\n",
      "10\n",
      "g\n",
      "/:\n",
      "From this bijection and the Subset Split Rule, we conclude that the number of ways to rearrange the letters in the word BOOKKEEPER is:\n",
      "total letters\n",
      "10\n",
      "\n",
      "1\n",
      "\t\n",
      "2\n",
      "\t\n",
      "2\n",
      "\t\n",
      "3\n",
      "\t\n",
      "1\n",
      "\t\n",
      "1\n",
      "Bs\n",
      "\t\n",
      "Os\n",
      "\t\n",
      "Ks\n",
      "\t\n",
      "Es\n",
      "\t\n",
      "Ps\n",
      "\t\n",
      "Rs\n",
      "This example generalizes directly to an exceptionally useful counting principle which we will call the\n",
      "Rule 11.6.2 (Bookkeeper Rule). Let \n",
      "l\n",
      "1\n",
      "; : : : ; l\n",
      "m\n",
      " be distinct elements. The number of sequences with \n",
      "k\n",
      "1\n",
      " occurrences of \n",
      "l\n",
      "1\n",
      ", and \n",
      "k\n",
      "2\n",
      " occurrences of \n",
      "l\n",
      "2\n",
      ", . . . , and \n",
      "k\n",
      "m\n",
      " occurrences of \n",
      "l\n",
      "m\n",
      " is\n",
      ".k\n",
      "1\n",
      " \n",
      "C\n",
      " k\n",
      "2\n",
      " \n",
      "C\n",
      " : : : \n",
      "C\n",
      " k\n",
      "m\n",
      "/\n",
      "\n",
      "k\n",
      "1\n",
      " k\n",
      "2\n",
      "  : : : k\n",
      "m\n",
      "For example, suppose you are planning a 20-mile walk, which should include 5 northward miles, 5 eastward miles, 5 southward miles, and 5 westward miles. How many different walks are possible?\n",
      "There is a bijection between such walks and sequences with 5 Ns, 5 Es, 5 Ss, and 5 Ws. By the Bookkeeper Rule, the number of such sequences is:\n",
      "20\n",
      "5\n",
      " 4 \n",
      ":\n",
      "\n",
      "11.6.3\n",
      "\t\n",
      "The Binomial Theorem\n",
      "Counting gives insight into one of the basic theorems of algebra. A binomial is a sum of two terms, such as \n",
      "a\n",
      " C \n",
      "b\n",
      ". Now consider its 4th power, \n",
      ".a\n",
      " C \n",
      "b/\n",
      "4\n",
      ".\n",
      "If we multiply out this 4th power expression completely, we get\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 328  #334\n",
      "\n",
      "In general, this reasoning gives the Binomial Theorem:\n",
      "Theorem 11.6.3 (Binomial Theorem). For all \n",
      "n\n",
      " 2 N and \n",
      "a; b\n",
      " 2 R:\n",
      "pearance here.\n",
      "This reasoning about binomials extends nicely to multinomials, which are sums of two or more terms. For example, suppose we wanted the coefficient of\n",
      "bo\n",
      "2\n",
      "k\n",
      "2\n",
      "e\n",
      "3\n",
      "pr\n",
      "in the expansion of \n",
      ".b\n",
      " C \n",
      "o\n",
      " C \n",
      "k\n",
      " C \n",
      "e\n",
      " C \n",
      "p\n",
      " C \n",
      "r/\n",
      "10\n",
      ". Each term in this expansion is a product of 10 variables where each variable is one of \n",
      "b\n",
      ", \n",
      "o\n",
      ", \n",
      "k\n",
      ", \n",
      "e\n",
      ", \n",
      "p\n",
      ", or \n",
      "r\n",
      ". Now, the coefficient of \n",
      "bo\n",
      "2\n",
      "k\n",
      " \n",
      "2\n",
      "e\n",
      "3\n",
      "pr\n",
      " is the number of those terms with exactly 1 \n",
      "b\n",
      ", 2 \n",
      "o\n",
      "s, 2 \n",
      "k\n",
      "s, 3\n",
      " e\n",
      "s, 1\n",
      " p\n",
      ", and 1\n",
      " r\n",
      ". And the number of such terms is precisely the number of\n",
      " \n",
      "rearrangements of the word BOOKKEEPER:\n",
      "The expression on the left is called a multinomial coefficient. This reasoning extends to a general theorem.\n",
      "Definition 11.6.4. For \n",
      "n; k\n",
      "1\n",
      "; : : : ; k\n",
      "m\n",
      " 2 N, such that \n",
      "k\n",
      "1\n",
      " C\n",
      "k\n",
      "2\n",
      " C C\n",
      "k\n",
      "m\n",
      " D \n",
      "n\n",
      ", define the multinomial coefficient\n",
      "!\n",
      "n\n",
      "\t\n",
      "n\n",
      "k\n",
      "1\n",
      "; k\n",
      "2\n",
      "; : : : ; k\n",
      "m\n",
      "\t\n",
      "WWD \n",
      "k\n",
      "1\n",
      " \n",
      "k\n",
      "2\n",
      "  \n",
      ": : : k\n",
      "m\n",
      " \n",
      ":\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 329  #335\n",
      "\n",
      "k\n",
      "1\n",
      "C   Ck\n",
      "m\n",
      "Dn\n",
      "Youll be better off remembering the reasoning behind the Multinomial Theorem rather than this ugly formal statement.\n",
      "11.6.4\n",
      "\t\n",
      "A Word about Words\n",
      "Someday you might refer to the Subset Split Rule or the Bookkeeper Rule in front of a roomful of colleagues and discover that theyre all staring back at you blankly. This is not because theyre dumb, but rather because we made up the name Book-keeper Rule. However, the rule is excellent and the name is apt, so we suggest that you play through: You know? The Bookkeeper Rule? Dont you guys know anything???\n",
      "The Bookkeeper Rule is sometimes called the formula for permutations with indistinguishable objects. The size k subsets of an n-element set are sometimes called k-combinations. Other similar-sounding descriptions are combinations with repetition, permutations with repetition, r-permutations, permutations with indis-tinguishable objects, and so on. However, the counting rules weve taught you are sufficient to solve all these sorts of problems without knowing this jargon, so we wont burden you with it.\n",
      "\n",
      "11.7\n",
      "\t\n",
      "Counting Practice: Poker Hands\n",
      "Five-Card Draw is a card game in which each player is initially dealt a hand con-sisting of 5 cards from a deck of 52 cards.\n",
      "(Then the game gets complicated, but lets not worry about that.) The number of different hands in Five-Card Draw is the\n",
      "\n",
      "There are 52 cards in a standard deck. Each card has a suit and a rank. There are four suits:\n",
      "(spades)\n",
      "\t\n",
      "~ (hearts)\t| (clubs)\n",
      "\t\n",
      "} (diamonds)\n",
      "And there are 13 ranks, listed here from lowest to highest:\n",
      "Ace\n",
      "\t\n",
      "Jack\tQueen\n",
      "\t\n",
      "King\n",
      "A;2;3;4;5;6;7;8;9; J ;\tQ ; K :\n",
      "Thus, for example, 8~ is the 8 of hearts and A\n",
      "\t\n",
      "is the ace of spades.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 330  #336\n",
      "\n",
      "330\n",
      "\t\n",
      "Chapter 11\n",
      "\t\n",
      "Cardinality Rules\n",
      "number of 5-element subsets of a 52-element set, which is\n",
      "!\n",
      "52\n",
      "5\n",
      "  D 2; 598; 960:\n",
      "Lets get some counting practice by working out the number of hands with various special properties.\n",
      "11.7.1\n",
      "\t\n",
      "Hands with a Four-of-a-Kind\n",
      "A Four-of-a-Kind is a set of four cards with the same rank. How many different hands contain a Four-of-a-Kind? Here are a couple examples:\n",
      "f8  ; 8}; Q~; 8~; 8|g\n",
      "fA|; 2|; 2~; 2}; 2  g\n",
      "As usual, the first step is to map this question to a sequence-counting problem. A hand with a Four-of-a-Kind is completely described by a sequence specifying:\n",
      "The rank of the four cards.\n",
      "The rank of the extra card.\n",
      "The suit of the extra card.\n",
      "Thus, there is a bijection between hands with a Four-of-a-Kind and sequences con-sisting of two distinct ranks followed by a suit. For example, the three hands above are associated with the following sequences:\n",
      ".8; Q; ~/ $ f 8  ; 8}; 8~; 8|; Q~g\n",
      ".2; A; |/ $ f2|; 2~; 2}; 2  ; A|g\n",
      "Now we need only count the sequences. There are 13 ways to choose the first rank, 12 ways to choose the second rank, and 4 ways to choose the suit. Thus, by the Generalized Product Rule, there are 13 12 4 D 624 hands with a Four-of-a-Kind. This means that only 1 hand in about 4165 has a Four-of-a-Kind. Not surprisingly, Four-of-a-Kind is considered to be a very good poker hand!\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 331  #337\n",
      "\n",
      "11.7.2\n",
      "\t\n",
      "Hands with a Full House\n",
      "A Full House is a hand with three cards of one rank and two cards of another rank.\n",
      "Here are some examples:\n",
      "f2  ; 2|; 2}; J |; J }g\n",
      "f5}; 5|; 5~; 7~; 7|g\n",
      "Again, we shift to a problem about sequences. There is a bijection between Full Houses and sequences specifying:\n",
      "The rank of the triple, which can be chosen in 13 ways.\n",
      "The suits of the triple, which can be selected in  \n",
      "4\n",
      "3\n",
      "  ways.\n",
      "The rank of the pair, which can be chosen in 12 ways.\n",
      "The suits of the pair, which can be selected in \n",
      "4\n",
      "2\n",
      " ways. The example hands correspond to sequences as shown below:\n",
      ".2; f ; |; }g; J; f|; }g/ $ f2  ; 2|; 2}; J |; J }g\n",
      ".5; f}; |; ~g; 7; f~; |g/ $ f5}; 5|; 5~; 7~; 7|g\n",
      "By the Generalized Product Rule, the number of Full Houses is:\n",
      "!\n",
      "\t\n",
      "!\n",
      "13\n",
      "\t\n",
      "4\n",
      "3\n",
      " \n",
      "12\n",
      " \n",
      "4\n",
      "2\n",
      ":\n",
      "Were on a rollbut were about to hit a speed bump.\n",
      "11.7.3\n",
      "\t\n",
      "Hands with Two Pairs\n",
      "How many hands have Two Pairs; that is, two cards of one rank, two cards of another rank, and one card of a third rank? Here are examples:\n",
      "f3}; 3  ; Q}; Q~; A|g\n",
      "f9~; 9}; 5~; 5|; K  g\n",
      "Each hand with Two Pairs is described by a sequence consisting of:\n",
      "The rank of the first pair, which can be chosen in 13 ways.\n",
      "The suits of the first pair, which can be selected  \n",
      "4\n",
      "2\n",
      "  ways.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 332  #338\n",
      "\n",
      "Chapter 11  Cardinality Rules\n",
      "The rank of the second pair, which can be chosen in 12 ways.\n",
      "The suits of the second pair, which can be selected in  \n",
      "4\n",
      "2\n",
      "  ways.\n",
      "The rank of the extra card, which can be chosen in 11 ways.\n",
      "The suit of the extra card, which can be selected in \n",
      "4\n",
      "1\n",
      " D 4 ways. Thus, it might appear that the number of hands with Two Pairs is:\n",
      "Wrong answer! The problem is that there is not a bijection from such sequences to hands with Two Pairs. This is actually a 2-to-1 mapping. For example, here are the pairs of sequences that map to the hands given above:\n",
      "The problem is that nothing distinguishes the first pair from the second. A pair of 5s and a pair of 9s is the same as a pair of 9s and a pair of 5s. We avoided this difficulty in counting Full Houses because, for example, a pair of 6s and a triple of kings is different from a pair of kings and a triple of 6s.\n",
      "We ran into precisely this difficulty last time, when we went from counting ar-rangements of different pieces on a chessboard to counting arrangements of two identical rooks. The solution then was to apply the Division Rule, and we can do the same here. In this case, the Division rule says there are twice as many sequences as hands, so the number of hands with Two Pairs is actually:\n",
      "13\n",
      "\t\n",
      "4\n",
      "\t\n",
      "12\n",
      "\t\n",
      "4\n",
      "\t\n",
      "114\n",
      "2\n",
      "\t\n",
      "2\n",
      "\t\n",
      ":\n",
      "\n",
      "2\n",
      "Another Approach\n",
      "The preceding example was disturbing! One could easily overlook the fact that the mapping was 2-to-1 on an exam, fail the course, and turn to a life of crime. You can make the world a safer place in two ways:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 333  #339\n",
      "\n",
      "Whenever you use a mapping f W A ! B to translate one counting problem to another, check that the same number elements in A are mapped to each element in B. If k elements of A map to each of element of B, then apply the Division Rule using the constant k.\n",
      "As an extra check, try solving the same problem in a different way. Multiple approaches are often availableand all had better give the same answer! (Sometimes different approaches give answers that look different, but turn out to be the same after some algebra.)\n",
      "We already used the first method; lets try the second. There is a bijection be-tween hands with two pairs and sequences that specify:\n",
      "The ranks of the two pairs, which can be chosen in  \n",
      "13\n",
      "2\n",
      "  ways.\n",
      "The suits of the lower-rank pair, which can be selected in  \n",
      "4\n",
      "2\n",
      "  ways.\n",
      "The suits of the higher-rank pair, which can be selected in  \n",
      "4\n",
      "2\n",
      "  ways.\n",
      "The rank of the extra card, which can be chosen in 11 ways.\n",
      "The suit of the extra card, which can be selected in \n",
      "4\n",
      "1\n",
      " D 4 ways. For example, the following sequences and hands correspond:\n",
      ".f3; Qg; f};\n",
      " \n",
      "g; f}; ~g; A; |/ $ f3}; 3 ; Q}; Q~; A|g .f9; 5g; f~; |g; f~; }g; K; / $ f9~; 9}; 5~; 5|; K g\n",
      "Thus, the number of hands with two pairs is:\n",
      "!\t!\t!\n",
      "13\n",
      "2\n",
      "\t\n",
      "4\n",
      "2\n",
      "\t\n",
      "4\n",
      "2\n",
      "   \n",
      "11 4:\n",
      "This is the same answer we got before, though in a slightly different form.\n",
      "11.7.4\n",
      "\t\n",
      "Hands with Every Suit\n",
      "How many hands contain at least one card from every suit? Here is an example of such a hand:\n",
      "f7}; K|; 3}; A~; 2  g\n",
      "Each such hand is described by a sequence that specifies:\n",
      "The ranks of the diamond, the club, the heart, and the spade, which can be selected in 13 13 13 13 D 13\n",
      "4\n",
      " ways.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 334  #340\n",
      "\n",
      "Chapter 11  Cardinality Rules\n",
      "The suit of the extra card, which can be selected in 4 ways.\n",
      "The rank of the extra card, which can be selected in 12 ways.\n",
      "For example, the hand above is described by the sequence:\n",
      ".7; K; A; 2; }; 3/ $ f7}; K|; A~; 2  ; 3}g:\n",
      "Are there other sequences that correspond to the same hand? There is one more! We could equally well regard either the 3} or the 7} as the extra card, so this is actually a 2-to-1 mapping. Here are the two sequences corresponding to the example hand:\n",
      "Therefore, the number of hands with every suit is:\n",
      "13\n",
      "4\n",
      "  4 12\n",
      ":\n",
      "\n",
      "2\n",
      "\n",
      "11.8\n",
      "\t\n",
      "Inclusion-Exclusion\n",
      "How big is a union of sets? For example, suppose there are 60 math majors, 200 EECS majors, and 40 physics majors. How many students are there in these three departments? Let M be the set of math majors, E be the set of EECS majors, and\n",
      "be the set of physics majors. In these terms, were asking for jM [ E [ P j. The Sum Rule says that if M , E, and P are disjoint, then the sum of their sizes\n",
      "is\n",
      "jM [ E [ P j D jM j C jEj C jP j:\n",
      "However, the sets M , E, and P might not be disjoint. For example, there might be a student majoring in both math and physics. Such a student would be counted twice on the right side of this equation, once as an element of M and once as an element of P . Worse, there might be a triple-major\n",
      "counted three times on the right side!\n",
      "Our most-complicated counting rule determines the size of a union of sets that are not necessarily disjoint. Before we state the rule, lets build some intuition by considering some easier special cases: unions of just two or three sets.\n",
      "\n",
      ". . . though not at MIT anymore.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 335  #341\n",
      "\n",
      "11.8.1\n",
      "\t\n",
      "Union of Two Sets\n",
      "For two sets, S\n",
      "1\n",
      " and S\n",
      "2\n",
      ", the Inclusion-Exclusion Rule is that the size of their union is:\n",
      "Intuitively, each element of S\n",
      "1\n",
      " is accounted for in the first term, and each element of S\n",
      "2\n",
      " is accounted for in the second term. Elements in both S\n",
      "1\n",
      " and S\n",
      "2\n",
      " are counted twiceonce in the first term and once in the second. This double-counting is cor-rected by the final term.\n",
      "11.8.2\n",
      "\t\n",
      "Union of Three Sets\n",
      "So how many students are there in the math, EECS, and physics departments? In other words, what is jM [ E [ P j if:\n",
      "jM j D 60\n",
      "jEj D 200\n",
      "jP j D 40:\n",
      "The size of a union of three sets is given by a more complicated Inclusion-Exclusion formula:\n",
      "jS\n",
      "1\n",
      " [ S\n",
      "2\n",
      " [ S\n",
      "3\n",
      "j D jS\n",
      "1\n",
      "j C jS\n",
      "2\n",
      "j C jS\n",
      "3\n",
      "j\n",
      "jS \n",
      "1\n",
      " \\ S\n",
      "2\n",
      "j jS \n",
      "1\n",
      " \\ S\n",
      "3\n",
      "j jS \n",
      "2\n",
      " \\ S\n",
      "3\n",
      "j\n",
      "C jS\n",
      "1\n",
      " \\ S\n",
      "2\n",
      " \\ S\n",
      "3\n",
      "j:\n",
      "Remarkably, the expression on the right accounts for each element in the union of S\n",
      "1\n",
      ", S\n",
      "2\n",
      ", and S\n",
      "3\n",
      " exactly once. For example, suppose that x is an element of all three sets. Then x is counted three times (by the jS\n",
      "1\n",
      "j, jS\n",
      "2\n",
      "j, and jS\n",
      "3\n",
      "j terms), subtracted off three times (by the jS\n",
      "1\n",
      " \\ S\n",
      "2\n",
      "j, jS\n",
      "1\n",
      " \\ S\n",
      "3\n",
      "j, and jS\n",
      "2\n",
      " \\ S\n",
      "3\n",
      "j terms), and then counted once more (by the jS\n",
      "1\n",
      " \\ S\n",
      "2\n",
      " \\ S\n",
      "3\n",
      "j term). The net effect is that x is counted just once.\n",
      "If x is in two sets (say, S\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and S\n",
      "2\n",
      "), then x is counted twice (by the jS\n",
      "1\n",
      " j and jS\n",
      "2\n",
      "j terms) and subtracted once (by the jS\n",
      "1\n",
      " \\ S\n",
      "2\n",
      "j term). In this case, x does not factor into any of the other terms, since x S\n",
      "3\n",
      ".\n",
      "So we cant answer the original question without knowing the sizes of the various intersections. Lets suppose that there are:\n",
      "math - EECS double majors\n",
      "3   math - physics double majors\n",
      "EECS - physics double majors\n",
      "2   triple majors\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 336  #342\n",
      "\n",
      "336\n",
      "\t\n",
      "Chapter 11\n",
      "\t\n",
      "Cardinality Rules\n",
      "Then j\n",
      "M\n",
      " \\\n",
      "E\n",
      "j D \n",
      "4\n",
      "C\n",
      "2\n",
      ", j\n",
      "M\n",
      " \\\n",
      "P\n",
      " j D \n",
      "3\n",
      "C\n",
      "2\n",
      ", j\n",
      "E\n",
      " \\\n",
      "P\n",
      " j D \n",
      "11\n",
      "C\n",
      "2\n",
      ", and j\n",
      "M\n",
      " \\\n",
      "E\n",
      " \\\n",
      "P\n",
      " j D \n",
      "2\n",
      ".\n",
      "Plugging all this into the formula gives:\n",
      "j\n",
      "M\n",
      " [ \n",
      "E\n",
      " [ \n",
      "P\n",
      " j D j\n",
      "M\n",
      " j C j\n",
      "E\n",
      "j C j\n",
      "P\n",
      " j j\n",
      "M\n",
      " \\ \n",
      "E\n",
      "j j\n",
      "M\n",
      " \\ \n",
      "P\n",
      " j j\n",
      "E\n",
      " \\ \n",
      "P\n",
      " j C j\n",
      "M\n",
      " \\ \n",
      "E\n",
      " \\ \n",
      "P\n",
      " j D\n",
      "60\n",
      "C\n",
      "200\n",
      "C\n",
      "40 6 5 13\n",
      "C\n",
      "2\n",
      "278\n",
      "11.8.3\n",
      "\t\n",
      "Sequences with 42, 04, or 60\n",
      "In how many permutations of the set f\n",
      "0; 1; 2; : : : ; 9\n",
      "g do either 4 and 2, 0 and 4, or 6 and 0 appear consecutively? For example, none of these pairs appears in:\n",
      ".7; 2; 9; 5; 4; 1; 3; 8; 0; 6/:\n",
      "The 06 at the end doesnt count; we need 60. On the other hand, both 04 and 60 appear consecutively in this permutation:\n",
      ".7; 2; 5; \n",
      "6\n",
      "; \n",
      "0\n",
      "; \n",
      "4\n",
      "; 3; 8; 1; 9/:\n",
      "Let \n",
      "P\n",
      "42\n",
      " be the set of all permutations in which 42 appears. Define \n",
      "P\n",
      "60\n",
      " and \n",
      "P\n",
      "04\n",
      " similarly. Thus, for example, the permutation above is contained in both \n",
      "P\n",
      "60\n",
      " and \n",
      "P\n",
      "04\n",
      ", but not\n",
      " P\n",
      "42\n",
      ". In these terms, were looking for the size of the set\n",
      " P\n",
      "42\n",
      " \n",
      "[\n",
      " P\n",
      "04\n",
      " \n",
      "[\n",
      "P\n",
      "60\n",
      ".\n",
      "First, we must determine the sizes of the individual sets, such as \n",
      "P\n",
      "60\n",
      ". We can use a trick: group the 6 and 0 together as a single symbol. Then there is a natural bijection between permutations of f\n",
      "0; 1; 2; : : : 9\n",
      "g containing 6 and 0 consecutively and permutations of:\n",
      "f\n",
      "60; 1; 2; 3; 4; 5; 7; 8; 9\n",
      "g\n",
      ":\n",
      "For example, the following two sequences correspond:\n",
      ".7; 2; 5; \n",
      "6\n",
      "; \n",
      "0\n",
      "; 4; 3; 8; 1; 9/\n",
      "\t\n",
      "! \n",
      ".7; 2; 5;\n",
      " \n",
      "60\n",
      "; 4; 3; 8; 1; 9/:\n",
      "There are \n",
      "9\n",
      " permutations of the set containing 60, so j\n",
      "P\n",
      "60\n",
      "j D \n",
      "9\n",
      " by the Bijection Rule. Similarly, j\n",
      "P\n",
      "04\n",
      "j D j\n",
      "P\n",
      "42\n",
      "j D \n",
      "9\n",
      " as well.\n",
      "Next, we must determine the sizes of the two-way intersections, such as \n",
      "P\n",
      "42\n",
      " \\ \n",
      "P\n",
      "60\n",
      ". Using the grouping trick again, there is a bijection with permutations of the\n",
      " \n",
      "set:\n",
      "f\n",
      "42; 60; 1; 3; 5; 7; 8; 9\n",
      "g\n",
      ":\n",
      "Thus, j\n",
      "P\n",
      "42\n",
      " \\ \n",
      "P\n",
      "60\n",
      "j D \n",
      "8\n",
      " . Similarly, j\n",
      "P\n",
      "60\n",
      " \\ \n",
      "P\n",
      "04\n",
      "j D \n",
      "8\n",
      " by a bijection with the set:\n",
      "f\n",
      "604; 1; 2; 3; 5; 7; 8; 9\n",
      "g\n",
      ":\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 337  #343\n",
      "\n",
      "And j\n",
      "P\n",
      "42\n",
      " \\ \n",
      "P\n",
      "04\n",
      "j D \n",
      "8\n",
      " as well by a similar argument. Finally, note that j\n",
      "P\n",
      "60\n",
      " \\\n",
      "P\n",
      "04\n",
      " \n",
      "\\\n",
      " P\n",
      "42\n",
      "j D\n",
      " 7 \n",
      "by a bijection with the set:\n",
      "f\n",
      "6042; 1; 3; 5; 7; 8; 9\n",
      "g\n",
      ":\n",
      "Plugging all this into the formula gives:\n",
      "j\n",
      "P\n",
      "42\n",
      " [ \n",
      "P\n",
      "04\n",
      " [ \n",
      "P\n",
      "60\n",
      "j D \n",
      "9\n",
      " C \n",
      "9\n",
      " C \n",
      "9\n",
      "\t\n",
      "8\t8\t8 \n",
      "C\n",
      " 7 :\n",
      "11.8.4\n",
      "\t\n",
      "Union of n Sets\n",
      "The size of a union of \n",
      "n\n",
      " sets is given by the following rule.\n",
      "Rule 11.8.1 (Inclusion-Exclusion).\n",
      "j\n",
      "S\n",
      "1\n",
      " [ \n",
      "S\n",
      "2\n",
      " [\t[ \n",
      "S\n",
      "n\n",
      "j D\n",
      "the sum of the sizes of the individual sets\n",
      "minus\n",
      "\t\n",
      "the sizes of all two-way intersections\n",
      "plus\n",
      "\t\n",
      "the sizes of all three-way intersections\n",
      "minus\n",
      "\t\n",
      "the sizes of all four-way intersections\n",
      "plus\n",
      "\t\n",
      "the sizes of all five-way intersections, etc.\n",
      "The formulas for unions of two and three sets are special cases of this general rule.\n",
      "This way of expressing Inclusion-Exclusion is easy to understand and nearly as precise as expressing it in mathematical symbols, but well need the symbolic version below, so lets work on deciphering it now.\n",
      "We already have a standard notation for the sum of sizes of the individual sets, namely,\n",
      "n\n",
      "X\n",
      "j\n",
      "S\n",
      "i\n",
      " j\n",
      ":\n",
      "D1\n",
      "A two-way intersection is a set of the form \n",
      "S\n",
      "i\n",
      " \\\n",
      "S\n",
      "j\n",
      " for \n",
      "i\n",
      "  \n",
      "j\n",
      " . We regard \n",
      "S\n",
      "j\n",
      " \\\n",
      "S\n",
      "i\n",
      " as the same two-way intersection as \n",
      "S\n",
      "i\n",
      " \\ \n",
      "S\n",
      "j\n",
      " , so we can assume that \n",
      "i < j\n",
      " . Now we can express the sum of the sizes of the two-way intersections as\n",
      "X\n",
      "j\n",
      "S\n",
      "i\n",
      " \\ \n",
      "S\n",
      "j\n",
      " j\n",
      ":\n",
      "1 i<j  n\n",
      "Similarly, the sum of the sizes of the three-way intersections is\n",
      "X\n",
      "j\n",
      "S\n",
      "i\n",
      " \\ \n",
      "S\n",
      "j\n",
      " \\ \n",
      "S\n",
      "k\n",
      "j\n",
      ":\n",
      "1 i<j <k  n\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 338  #344\n",
      "\n",
      "338\n",
      "\t\n",
      "Chapter 11\n",
      "\t\n",
      "Cardinality Rules\n",
      "These sums have alternating signs in the Inclusion-Exclusion formula, with the sum of the k-way intersections getting the sign .1/ \n",
      "k1\n",
      " . This finally leads to a symbolic version of the rule:\n",
      "Rule (Inclusion-Exclusion).\n",
      "n\n",
      "\t\n",
      "n\n",
      "X\n",
      "j\n",
      "\t\n",
      "S\n",
      "i\n",
      " j D\n",
      "\t\n",
      "jS\n",
      "i\n",
      " j\n",
      "iD1\n",
      "\t\n",
      "iD1\n",
      "X\n",
      "jS\n",
      "i\n",
      " \\ S\n",
      "j\n",
      " j\n",
      "1 i<j  n\n",
      "X\n",
      "jS\n",
      "i\n",
      " \\ S\n",
      "j\n",
      " \\ S\n",
      "k\n",
      "j C\n",
      "1 i<j <k  n\n",
      "11.8.5\n",
      "\t\n",
      "Computing Eulers Function\n",
      "As an example, lets use Inclusion-Exclusion to calculate Eulers function, .n/. By definition, .n/ is the number of nonnegative integers less than a positive inte-ger n that are relatively prime to n. But the set S of nonnegative integers less than n that are not relatively prime to n will be easier to count.\n",
      "Suppose the prime factorization of n is p\n",
      "1\n",
      "e\n",
      "1\n",
      " p\n",
      "m\n",
      "e\n",
      "m\n",
      " for distinct primes p\n",
      "i\n",
      " . This means that the integers in S are precisely the nonnegative integers less than n that are divisible by at least one of the p\n",
      "i\n",
      " s. Letting C\n",
      "i\n",
      " be the set of nonnegative integers less than n that are divisible by p\n",
      "i\n",
      " , we have\n",
      "m\n",
      "[\n",
      "S D\n",
      "\t\n",
      "C\n",
      "i\n",
      " :\n",
      "iD1\n",
      "Well be able to find the size of this union using Inclusion-Exclusion because the intersections of the C\n",
      "i\n",
      " s are easy to count. For example, C\n",
      "1\n",
      " \\ C\n",
      "2\n",
      " \\ C\n",
      "3\n",
      " is the set of nonnegative integers less than n that are divisible by each of p\n",
      "1\n",
      ", p\n",
      "2\n",
      " and p\n",
      "3\n",
      ". But since the p\n",
      "i\n",
      " s are distinct primes, being divisible by each of these primes is the same as being divisible by their product. Now observe that if r is a positive divisor of n, then exactly n=r nonnegative integers less than n are divisible by r, namely, 0; r; 2r; : : : ; ..n=r/ 1/r. So exactly n=p\n",
      "1\n",
      "p\n",
      "2\n",
      "p\n",
      "3\n",
      " nonnegative integers less than n are divisible by all three primes p\n",
      "1\n",
      ", p\n",
      "2\n",
      ", p\n",
      "3\n",
      ". In other words,\n",
      "n\n",
      "jC\n",
      "1 \n",
      "\\\n",
      " \n",
      "C\n",
      "2 \n",
      "\\\n",
      " \n",
      "C\n",
      "3\n",
      "j D\n",
      " \n",
      "p\n",
      "1\n",
      "p\n",
      "2\n",
      "p\n",
      "3\n",
      " \n",
      ":\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 339  #345\n",
      "\n",
      "Reasoning this way about all the intersections among the C\n",
      "i\n",
      " s and applying Inclusion-Exclusion, we get\n",
      "m\n",
      "[\n",
      "jSj D j\n",
      "\t\n",
      "C\n",
      "i\n",
      " j\n",
      "D1\n",
      "D\n",
      "Yikes! That was pretty hairy. Are you getting tired of all that nasty algebra? If so, then good news is on the way. In the next section, we will show you how to prove some heavy-duty formulas without using any algebra at all. Just a few words and you are done. No kidding.\n",
      "\n",
      "11.9\n",
      "\t\n",
      "Combinatorial Proofs\n",
      "Suppose you have n different T-shirts, but only want to keep k. You could equally well select the k shirts you want to keep or select the complementary set of n k shirts you want to throw out. Thus, the number of ways to select k shirts from among n must be equal to the number of ways to select n k shirts from among n.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 340  #346\n",
      "\n",
      "Jay is not selected for the team, and all \n",
      "k\n",
      " team members are selected from among the other \n",
      "n 1\n",
      " competitors. The number of teams that can be formed this way is:\n",
      "!\n",
      "n\t1\n",
      "k\n",
      "\n",
      "\n",
      ":\n",
      "All teams of the first type contain Jay, and no team of the second type does; therefore, the two sets of teams are disjoint. Thus, by the Sum Rule, the total number of possible Olympic boxing teams is:\n",
      "Jeremy, equally-famed Teaching Assistant, thinks Jay isnt so tough and so he might as well also try out. He reasons that \n",
      "n\n",
      " people (including himself) are trying out for \n",
      "k\n",
      " spots. Thus, the number of ways to select the team is simply:\n",
      "!\n",
      "n\n",
      "k\n",
      "\n",
      "\n",
      "\n",
      ":\n",
      "mcs-ftl  2010/9/8  0:40  page 341  #347\n",
      "\n",
      "Jeremy and Jay each correctly counted the number of possible boxing teams.\n",
      "Thus, their answers must be equal. So we know:\n",
      "This is called Pascals Identity. And we proved it without any algebra! Instead, we relied purely on counting techniques.\n",
      "11.9.2\n",
      "\t\n",
      "Finding a Combinatorial Proof\n",
      "A combinatorial proof is an argument that establishes an algebraic fact by relying on counting principles. Many such proofs follow the same basic outline:\n",
      "Define a set S.\n",
      "Show that jSj D n by counting one way.\n",
      "Show that jSj D m by counting another way.\n",
      "Conclude that n D m.\n",
      "In the preceding example, S was the set of all possible Olympic boxing teams. Jay computed\n",
      "by counting one way, and Jeremy computed\n",
      "!\n",
      "jSj D  \n",
      "k\n",
      "n\n",
      "by counting another way. Equating these two expressions gave Pascals Identity. More typically, the set S is defined in terms of simple sequences or sets rather\n",
      "than an elaborate story. Here is a less colorful example of a combinatorial argu-ment.\n",
      "Theorem 11.9.1.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 342  #348\n",
      "\n",
      "342\n",
      "\t\n",
      "Chapter 11\n",
      "\t\n",
      "Cardinality Rules\n",
      "Proof. We give a combinatorial proof. Let S be all n-card hands that can be dealt from a deck containing n red cards (numbered 1; : : : ; n) and 2n black cards (num-bered 1; : : : ; 2n). First, note that every 3n-element set has\n",
      "!\n",
      "jSj D  \n",
      "3n\n",
      "n\n",
      "n-element subsets.\n",
      "From another perspective, the number of hands with exactly r red cards is\n",
      "r black cards. Since the number of red cards can be anywhere from 0 to n, the total number of n-card hands is:\n",
      "Combinatorial proofs are almost magical. Theorem \n",
      "looks pretty scary, but we proved it without any algebraic manipulations at all. The key to constructing a combinatorial proof is choosing the set S properly, which can be tricky. Gener-ally, the simpler side of the equation should provide some guidance. For example, the right side of Theorem \n",
      "is \n",
      "3n\n",
      "n\n",
      " , which suggests that it will be helpful to choose S to be all n-element subsets of some 3n-element set.\n",
      "\n",
      "11.10\n",
      "\t\n",
      "The Pigeonhole Principle\n",
      "Here is an old puzzle:\n",
      "A drawer in a dark room contains red socks, green socks, and blue socks. How many socks must you withdraw to be sure that you have a matching pair?\n",
      "For example, picking out three socks is not enough; you might end up with one red, one green, and one blue. The solution relies on the Pigeonhole Principle, which is a friendly name for the contrapositive of the injective case of the Mapping Rule.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 343  #349\n",
      "\n",
      "11.10. The Pigeonhole Principle\n",
      "\t\n",
      "343\n",
      "A\n",
      "\t\n",
      "f\n",
      "\t\n",
      "B\n",
      "1\n",
      "st\n",
      " sock  \n",
      "\n",
      " red\n",
      "2\n",
      "nd\n",
      " sock  \n",
      "\n",
      " green\n",
      "\n",
      "3\n",
      "rd\n",
      " sock  \n",
      "\n",
      " blue\n",
      "4\n",
      "th\n",
      " sock\n",
      "Figure 11.3\n",
      "\t\n",
      "One possible mapping of four socks to three colors.\n",
      "Rule 11.10.1 (Pigeonhole Principle). If jXj > jY j, then for every total function\n",
      "W X ! Y , there exist two different elements of X that are mapped to the same element of Y .\n",
      "What this abstract mathematical statement has to do with selecting footwear un-der poor lighting conditions is maybe not obvious. However, let A be the set of socks you pick out, let B be the set of colors available, and let f map each sock to its color. The Pigeonhole Principle says that if jAj > jB j D 3, then at least two elements of A (that is, at least two socks) must be mapped to the same element of B (that is, the same color). Therefore, four socks are enough to ensure a matched pair. For example, one possible mapping of four socks to three colors is shown in Figure \n",
      ".\n",
      "Not surprisingly, the pigeonhole principle is often described in terms of pigeons:\n",
      "If there are more pigeons than holes they occupy, then at least two pigeons must be in the same hole.\n",
      "In this case, the pigeons form set A, the pigeonholes are set B, and f describes which hole each pigeon flies into.\n",
      "Mathematicians have come up with many ingenious applications for the pigeon-hole principle. If there were a cookbook procedure for generating such arguments, wed give it to you. Unfortunately, there isnt one. One helpful tip, though: when you try to solve a problem with the pigeonhole principle, the key is to clearly iden-tify three things:\n",
      "\n",
      "This Mapping Rule applies even if f is a total injective relation. Recall that a function is total if 8x 2 X 9y 2 Y: f .x/ D y.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 344  #350\n",
      "\n",
      "Chapter 11  Cardinality Rules\n",
      "The set A (the pigeons).\n",
      "The set B (the pigeonholes).\n",
      "The function f (the rule for assigning pigeons to pigeonholes).\n",
      "11.10.1\n",
      "\t\n",
      "Hairs on Heads\n",
      "There are a number of generalizations of the pigeonhole principle. For example:\n",
      "Rule 11.10.2 (Generalized Pigeonhole Principle). If jXj > k jY j, then every total function f W X ! Y maps at least k C 1 different elements of X to the same element of Y .\n",
      "For example, if you pick two people at random, surely they are extremely un-likely to have exactly the same number of hairs on their heads. However, in the remarkable city of Boston, Massachusetts there are actually three people who have exactly the same number of hairs! Of course, there are many bald people in Boston, and they all have zero hairs. But were talking about non-bald people; say a person is non-bald if they have at least ten thousand hairs on their head.\n",
      "Boston has about 500,000 non-bald people, and the number of hairs on a persons head is at most 200,000. Let A be the set of non-bald people in Boston, let B D f10; 000; 10; 001; : : : ; 200; 000g, and let f map a person to the number of hairs on his or her head. Since jAj > 2jBj, the Generalized Pigeonhole Principle implies that at least three people have exactly the same number of hairs. We dont know who they are, but we know they exist!\n",
      "11.10.2\n",
      "\t\n",
      "Subsets with the Same Sum\n",
      "For your reading pleasure, we have displayed ninety 25-digit numbers in Fig-ure \n",
      ". Are there two different subsets of these 25-digit numbers that have the same sum? For example, maybe the sum of the last ten numbers in the first column is equal to the sum of the first eleven numbers in the second column?\n",
      "Finding two subsets with the same sum may seem like a silly puzzle, but solving these sorts of problems turns out to be useful in diverse applications such as finding good ways to fit packages into shipping containers and decoding secret messages.\n",
      "It turns out that it is hard to find different subsets with the same sum, which is why this problem arises in cryptography. But it is easy to prove that two such subsets exist. Thats where the Pigeonhole Principle comes in.\n",
      "Let A be the collection of all subsets of the 90 numbers in the list. Now the sum of any subset of numbers is at most 90 10\n",
      "25\n",
      ", since there are only 90 numbers and every 25-digit number is less than 10\n",
      "25\n",
      ". So let B be the set of integers f0; 1; : : : ; 90 10\n",
      "25\n",
      "g, and let f map each subset of numbers (in A) to its sum (in B).\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 345  #351\n",
      "\n",
      "0020480135385502964448038\n",
      "\t\n",
      "3171004832173501394113017\n",
      "5763257331083479647409398\n",
      "\t\n",
      "8247331000042995311646021\n",
      "0489445991866915676240992\n",
      "\t\n",
      "3208234421597368647019265\n",
      "5800949123548989122628663\n",
      "\t\n",
      "8496243997123475922766310\n",
      "1082662032430379651370981\n",
      "\t\n",
      "3437254656355157864869113\n",
      "6042900801199280218026001\n",
      "\t\n",
      "8518399140676002660747477\n",
      "1178480894769706178994993\n",
      "\t\n",
      "3574883393058653923711365\n",
      "6116171789137737896701405\n",
      "\t\n",
      "8543691283470191452333763\n",
      "1253127351683239693851327\n",
      "\t\n",
      "3644909946040480189969149\n",
      "6144868973001582369723512\n",
      "\t\n",
      "8675309258374137092461352\n",
      "1301505129234077811069011\n",
      "\t\n",
      "3790044132737084094417246\n",
      "6247314593851169234746152\n",
      "\t\n",
      "8694321112363996867296665\n",
      "1311567111143866433882194\n",
      "\t\n",
      "3870332127437971355322815\n",
      "6814428944266874963488274\n",
      "\t\n",
      "8772321203608477245851154\n",
      "1470029452721203587686214\n",
      "\t\n",
      "4080505804577801451363100\n",
      "6870852945543886849147881\n",
      "\t\n",
      "8791422161722582546341091\n",
      "1578271047286257499433886\n",
      "\t\n",
      "4167283461025702348124920\n",
      "6914955508120950093732397\n",
      "\t\n",
      "9062628024592126283973285\n",
      "1638243921852176243192354\n",
      "\t\n",
      "4235996831123777788211249\n",
      "6949632451365987152423541\n",
      "\t\n",
      "9137845566925526349897794\n",
      "1763580219131985963102365\n",
      "\t\n",
      "4670939445749439042111220\n",
      "7128211143613619828415650\n",
      "\t\n",
      "9153762966803189291934419\n",
      "1826227795601842231029694\n",
      "\t\n",
      "4815379351865384279613427\n",
      "7173920083651862307925394\n",
      "\t\n",
      "9270880194077636406984249\n",
      "1843971862675102037201420\n",
      "\t\n",
      "4837052948212922604442190\n",
      "7215654874211755676220587\n",
      "\t\n",
      "9324301480722103490379204\n",
      "2396951193722134526177237\n",
      "\t\n",
      "5106389423855018550671530\n",
      "7256932847164391040233050\n",
      "\t\n",
      "9436090832146695147140581\n",
      "2781394568268599801096354\n",
      "\t\n",
      "5142368192004769218069910\n",
      "7332822657075235431620317\n",
      "\t\n",
      "9475308159734538249013238\n",
      "2796605196713610405408019\n",
      "\t\n",
      "5181234096130144084041856\n",
      "7426441829541573444964139\n",
      "\t\n",
      "9492376623917486974923202\n",
      "2931016394761975263190347\n",
      "\t\n",
      "5198267398125617994391348\n",
      "7632198126531809327186321\n",
      "\t\n",
      "9511972558779880288252979\n",
      "2933458058294405155197296\n",
      "\t\n",
      "5317592940316231219758372\n",
      "7712154432211912882310511\n",
      "\t\n",
      "9602413424619187112552264\n",
      "3075514410490975920315348\n",
      "\t\n",
      "5384358126771794128356947\n",
      "7858918664240262356610010\n",
      "\t\n",
      "9631217114906129219461111\n",
      "8149436716871371161932035\n",
      "\t\n",
      "3157693105325111284321993\n",
      "3111474985252793452860017\n",
      "\t\n",
      "5439211712248901995423441\n",
      "7898156786763212963178679\n",
      "\t\n",
      "9908189853102753335981319\n",
      "3145621587936120118438701\n",
      "\t\n",
      "5610379826092838192760458\n",
      "8147591017037573337848616\n",
      "\t\n",
      "9913237476341764299813987\n",
      "3148901255628881103198549\n",
      "\t\n",
      "5632317555465228677676044\n",
      "5692168374637019617423712\n",
      "\t\n",
      "8176063831682536571306791\n",
      "Figure 11.4 Ninety 25-digit numbers. Can you find two different subsets of these numbers that have the same sum?\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 346  #352\n",
      "\n",
      "346\n",
      "\t\n",
      "Chapter 11\n",
      "\t\n",
      "Cardinality Rules\n",
      "We proved that an n-element set has 2\n",
      "n\n",
      " different subsets in Section \n",
      ". There-fore:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jAj D 2\n",
      "90\n",
      "\t\n",
      "1:237\n",
      "\t\n",
      "10\n",
      "27\n",
      "On the other hand:\n",
      "jBj D 90 10\n",
      "25\n",
      " C 1\n",
      "\t\n",
      "0:901\n",
      "\t\n",
      "10\n",
      "27\n",
      ":\n",
      "Both quantities are enormous, but jAj is a bit greater than jBj. This means that f maps at least two elements of A to the same element of B. In other words, by the Pigeonhole Principle, two different subsets must have the same sum!\n",
      "Notice that this proof gives no indication which two sets of numbers have the same sum. This frustrating variety of argument is called a nonconstructive proof. To see if was possible to actually find two different subsets of the ninety 25-digit numbers with the same sum, we offered a $100 prize to the first student who did it. We didnt expect to have to pay off this bet, but we underestimated the ingenuity and initiative of the students. One computer science major wrote a program that cleverly searched only among a reasonably small set of plausible sets, sorted them by their sums, and actually found a couple with the same sum. He won the prize. A few days later, a math major figured out how to reformulate the sum problem as a lattice basis reduction problem; then he found a software package implementing an efficient basis reduction procedure, and using it, he very quickly found lots of pairs of subsets with the same sum. He didnt win the prize, but he got a standing ovation from the classstaff included.\n",
      "\n",
      "11.11\tA Magic Trick\n",
      "There is a Magician and an Assistant. The Assistant goes into the audience with a deck of 52 cards while the Magician looks away.\n",
      "Five audience members each select one card from the deck. The Assistant then gathers up the five cards and holds up four of them so the Magician can see them. The Magician concentrates for a short time and then correctly names the secret, fifth card!\n",
      "Since we dont really believe the Magician can read minds, we know the As-sistant has somehow communicated the secret card to the Magician. Since real Magicians and Assistants are not to be trusted, we can expect that the Assistant would illegitimately signal the Magician with coded phrases or body language, but they dont have to cheat in this way. In fact, the Magician and Assistant could be\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 347  #353\n",
      "\n",
      "Sets with Distinct Subset Sums\n",
      "\n",
      "How can we construct a set of \n",
      "n\n",
      " positive integers such that all its subsets have \n",
      "distinct \n",
      "sums? One way is to use powers of two:\n",
      "f1; 2; 4; 8; 16g\n",
      "This approach is so natural that one suspects all other such sets must involve larger numbers. (For example, we could safely replace 16 by 17, but not by 15.) Remark-ably, there are examples involving \n",
      "smaller\n",
      " numbers. Here is one:\n",
      "f6; 9; 11; 12; 13g\n",
      "One of the top mathematicians of the Twentieth Century, Paul Erdos, conjectured in 1931 that there are no such sets involving \n",
      "significantly\n",
      " smaller numbers. More pre-cisely, he conjectured that the largest number in such a set must be greater than \n",
      "c2\n",
      "n\n",
      " for some constant \n",
      "c > 0\n",
      ". He offered $500 to anyone who could prove or disprove his conjecture, but the problem remains unsolved.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 348  #354\n",
      "\n",
      "348\n",
      "\t\n",
      "Chapter 11\n",
      "\t\n",
      "Cardinality Rules\n",
      "kept out of sight of each other while some audience member holds up the 4 cards designated by the Assistant for the Magician to see.\n",
      "Of course, without cheating, there is still an obvious way the Assistant can com-municate to the Magician: he can choose any of the \n",
      "4\n",
      " D \n",
      "24\n",
      " permutations of the 4 cards as the order in which to hold up the cards. However, this alone wont quite work: there are 48 cards remaining in the deck, so the Assistant doesnt have enough choices of orders to indicate exactly what the secret card is (though he could narrow it down to two cards).\n",
      "11.11.1\n",
      "\t\n",
      "The Secret\n",
      "The method the Assistant can use to communicate the fifth card exactly is a nice application of what we know about counting and matching.\n",
      "The Assistant has a second legitimate way to communicate: he can choose which of the five cards to keep hidden. Of course, its not clear how the Magician could determine which of these five possibilities the Assistant selected by looking at the four visible cards, but there is a way, as well now explain.\n",
      "The problem facing the Magician and Assistant is actually a bipartite matching problem. Put all the sets of 5 cards in a collection \n",
      "X\n",
      " on the left. And put all the sequences of 4 distinct cards in a collection \n",
      "Y\n",
      " on the right. These are the two sets of vertices in the bipartite graph. There is an edge between a set of 5 cards and a sequence of 4 if every card in the sequence is also in the set. In other words, if the audience selects a set of 5 cards, then the Assistant must reveal a sequence of 4 cards that is adjacent in the bipartite graph. Some edges are shown in the diagram in Figure \n",
      ".\n",
      "For example,\n",
      "f\n",
      "8\n",
      "~\n",
      "; K  ; Q  ; 2\n",
      "}\n",
      "; 6\n",
      "}g\n",
      "\t\n",
      "(11.4)\n",
      "is an element of \n",
      "X\n",
      " on the left. If the audience selects this set of 5 cards, then there are many different 4-card sequences on the right in set \n",
      "Y\n",
      " that the Assis-tant could choose to reveal, including \n",
      ".8\n",
      "~\n",
      "; K ; Q ; 2\n",
      "}\n",
      "/\n",
      ", \n",
      ".K ; 8\n",
      "~\n",
      "; Q ; 2\n",
      "}\n",
      "/\n",
      ", and\n",
      ".K  ; 8\n",
      "~\n",
      "; 6\n",
      "}\n",
      "; Q  /\n",
      ".\n",
      "What the Magician and his Assistant need to perform the trick is a matching for the \n",
      "X\n",
      " vertices. If they agree in advance on some matching, then when the audience selects a set of 5 cards, the Assistant reveals the matching sequence of 4 cards. The Magician uses the matching to find the audiences chosen set of 5 cards, and so he can name the one not already revealed.\n",
      "For example, suppose the Assistant and Magician agree on a matching containing the two bold edges in Figure \n",
      ". If the audience selects the set\n",
      "f\n",
      "8\n",
      "~\n",
      "; K  ; Q  ; 9\n",
      "|\n",
      "; 6\n",
      "}g\n",
      ";\n",
      "\t\n",
      "(11.5)\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 349  #355\n",
      "\n",
      "\n",
      "Figure 11.5 The bipartite graph where the nodes on the left correspond to sets of 5 cards and the nodes on the right correspond to sequences of 4 cards. There is an edge between a set and a sequence whenever all the cards in the sequence are contained in the set.\n",
      "then the Assistant reveals the corresponding sequence\n",
      ".K  ; 8\n",
      "~\n",
      "; 6\n",
      "}\n",
      "; Q  /:\n",
      "\t\n",
      "(11.6)\n",
      "Using the matching, the Magician sees that the hand (\n",
      ") is matched to the se-quence (\n",
      "), so he can name the one card in the corresponding set not already revealed, namely, the \n",
      "9\n",
      "|. Notice that the fact that the sets are matched, that is, that different sets are paired with distinct sequences, is essential. For example, if the audience picked the previous hand (\n",
      "), it would be possible for the Assistant to reveal the same sequence (\n",
      "), but he better not do that; if he did, then the Magician would have no way to tell if the remaining card was the \n",
      "9\n",
      "| or the \n",
      "2\n",
      "}.\n",
      "So how can we be sure the needed matching can be found? The answer is that each vertex on the left has degree \n",
      "5 4\n",
      " D \n",
      "120\n",
      ", since there are five ways to select the card kept secret and there are \n",
      "4\n",
      " permutations of the remaining 4 cards. In addition, each vertex on the right has degree 48, since there are 48 possibilities for the fifth card. So this graph is degree-constrained according to Definition \n",
      ", and therefore satisfies Halls matching condition.\n",
      "In fact, this reasoning shows that the Magician could still pull off the trick if 120 cards were left instead of 48, that is, the trick would work with a deck as large as 124 different cardswithout any magic!\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 350  #356\n",
      "\n",
      "350\n",
      "\t\n",
      "Chapter 11\n",
      "\t\n",
      "Cardinality Rules\n",
      "A\n",
      "2\n",
      "Q\n",
      "\t\n",
      "3\n",
      "10\n",
      "\t\n",
      "5\n",
      "9\n",
      "\t\n",
      "6\n",
      "8\n",
      "\t\n",
      "7\n",
      "Figure 11.6\n",
      "\t\n",
      "The 13 card ranks arranged in cyclic order.\n",
      "11.11.2\n",
      "\t\n",
      "The Real Secret\n",
      "But wait a minute! Its all very well in principle to have the Magician and his Assistant agree on a matching, but how are they supposed to remember a matching with \n",
      "52\n",
      "5\n",
      " D 2; 598; 960 edges? For the trick to work in practice, there has to be a way to match hands and card sequences mentally and on the fly.\n",
      "Well describe one approach. As a running example, suppose that the audience selects:\n",
      "10~\t9}\t3~\tQ\n",
      "\t\n",
      "J}:\n",
      "The Assistant picks out two cards of the same suit. In the example, the assistant might choose the 3~ and 10~. This is always possible because of the Pigeonhole Principlethere are five cards and 4 suits so two cards must be in the same suit.\n",
      "The Assistant locates the ranks of these two cards on the cycle shown in Fig-ure \n",
      ". For any two distinct ranks on this cycle, one is always between 1 and 6 hops clockwise from the other. For example, the 3~ is 6 hops clock-wise from the 10~.\n",
      "The more counterclockwise of these two cards is revealed first, and the other becomes the secret card. Thus, in our example, the 10~ would be revealed, and the 3~ would be the secret card. Therefore:\n",
      " The suit of the secret card is the same as the suit of the first card re-vealed.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 351  #357\n",
      "\n",
      " The rank of the secret card is between 1 and 6 hops clockwise from the rank of the first card revealed.\n",
      "All that remains is to communicate a number between 1 and 6. The Magician and Assistant agree beforehand on an ordering of all the cards in the deck from smallest to largest such as:\n",
      "A|A}A~A\t2|2}2~2\t::: K~K\n",
      "The order in which the last three cards are revealed communicates the num-ber according to the following scheme:\n",
      "In the example, the Assistant wants to send 6 and so reveals the remaining three cards in large, medium, small order. Here is the complete sequence that the Magician sees:\n",
      "10~\tQ\n",
      "\t\n",
      "J}\t9}\n",
      "The Magician starts with the first card, 10~, and hops 6 ranks clockwise to reach 3~, which is the secret card!\n",
      "So thats how the trick can work with a standard deck of 52 cards. On the other hand, Halls Theorem implies that the Magician and Assistant can in principle per-form the trick with a deck of up to 124 cards. It turns out that there is a method which they could actually learn to use with a reasonable amount of practice for a 124-card deck, but we wont explain it here.\n",
      "11.11.3\n",
      "\t\n",
      "The Same Trick with Four Cards?\n",
      "Suppose that the audience selects only four cards and the Assistant reveals a se-quence of three to the Magician. Can the Magician determine the fourth card?\n",
      "Let X be all the sets of four cards that the audience might select, and let Y be all the sequences of three cards that the Assistant might reveal. Now, on one hand, we have\n",
      "\n",
      "See The Best Card Trick by Michael Kleber for more information.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 352  #358\n",
      "\n",
      "352\n",
      "\t\n",
      "Chapter 11\n",
      "\t\n",
      "Cardinality Rules\n",
      "by the Subset Rule. On the other hand, we have\n",
      "jY j D 52 51 50 D 132; 600\n",
      "by the Generalized Product Rule. Thus, by the Pigeonhole Principle, the Assistant must reveal the same sequence of three cards for at least\n",
      " \n",
      "270; 725\n",
      "\t\n",
      "D 3\n",
      "\n",
      "132; 600\n",
      "different four-card hands. This is bad news for the Magician: if he sees that se-quence of three, then there are at least three possibilities for the fourth card which he cannot distinguish. So there is no legitimate way for the Assistant to communi-cate exactly what the fourth card is!\n",
      "11.11.4\n",
      "\t\n",
      "Never Say Never\n",
      "No sooner than we finished proving that the Magician cant pull off the trick with four cards instead of five, a student showed us a way that it might be doable after all. The idea is to place the three cards on a table one at a time instead of revealing them all at once. This provides the Magician with two completely independent sequences of three cards: one for the temporal order in which the cards are placed on the table, and one for the spatial order in which they appear once placed.\n",
      "For example, suppose the audience selects\n",
      "10~\t9}\t3~\tQ\n",
      "and the assistant decides to reveal\n",
      "10~\t9}\tQ:\n",
      "The assistant might decide to reveal the Q first, the 10~ second, and the 9} third, thereby production the temporal sequence\n",
      ".Q  ; 10~; 9}/:\n",
      "If the Q is placed in the middle position on the table, the 10~ is placed in the rightmost position on the table, and the 9} is placed in the leftmost position on the table, the spatial sequence would be\n",
      ".9}; Q  ; 10~/:\n",
      "In this version of the card trick, X consists of all sets of 4 cards and Y consists of all pairs of sequences of the same 3 cards. As before, we can create a bipartite\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 353  #359\n",
      "\n",
      "graph where an edge connects a set \n",
      "S\n",
      " of 4 cards in \n",
      "X\n",
      " with a pair of sequences in \n",
      "Y\n",
      " if the 3 cards in the sequences are in \n",
      "S\n",
      ".\n",
      "The degree of every node in \n",
      "X\n",
      " is then\n",
      "43\t3\n",
      "D\n",
      "144\n",
      "since there are 4 choices for which card is not revealed and \n",
      "3\n",
      " orders for each sequence in the pair.\n",
      "The degree of every node in \n",
      "Y\n",
      " is 49 since there are \n",
      "52 3\n",
      " D \n",
      "49\n",
      " possible choices for the 4th card. Since \n",
      "144 49\n",
      ", we can use Halls Theorem to establish the existing of a matching for \n",
      "X\n",
      ".\n",
      "Hence, the magic trick is doable with 4 cardsthe assistant just has to convey more information. Can you figure out a convenient way to pull off the trick on the fly?\n",
      "So what about the 3-card version? Surely that is not doable.. . .\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 354  #360\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 355  #361\n",
      "\n",
      "12\n",
      "\t\n",
      "Generating Functions\n",
      "Generating Functions are one of the most surprising and useful inventions in Dis-crete Math. Roughly speaking, generating functions transform problems about se-quences into problems about functions. This is great because weve got piles of mathematical machinery for manipulating functions. Thanks to generating func-tions, we can then apply all that machinery to problems about sequences. In this way, we can use generating functions to solve all sorts of counting problems. They can also be used to find closed-form expressions for sums and to solve recurrences. In fact, many of the problems we addressed in Chapters \n",
      "\n",
      "can be formulated and solved using generating functions.\n",
      "\n",
      "12.1\n",
      "\t\n",
      "Definitions and Examples\n",
      "The ordinary generating function for the sequence\n",
      "hg\n",
      "0\n",
      "; g\n",
      "1\n",
      "; g\n",
      "2\n",
      "; g\n",
      "3\n",
      " : : : i is the power series:\n",
      "G.x/ D g\n",
      "0\n",
      " C g\n",
      "1\n",
      "x C g\n",
      "2\n",
      "x\n",
      "2\n",
      " C g\n",
      "3\n",
      "x\n",
      "3\n",
      " C\n",
      "\t\n",
      ":\n",
      "There are a few other kinds of generating functions in common use, but ordinary generating functions are enough to illustrate the power of the idea, so well stick to them and from now on, generating function will mean the ordinary kind.\n",
      "A generating function is a formal power series in the sense that we usually regard x as a placeholder rather than a number. Only in rare cases will we actually evaluate a generating function by letting x take a real number value, so we generally ignore the issue of convergence.\n",
      "Throughout this chapter, well indicate the correspondence between a sequence and its generating function with a double-sided arrow as follows:\n",
      "hg\n",
      "0\n",
      "; g\n",
      "1\n",
      "; g\n",
      "2\n",
      "; g\n",
      "3\n",
      "; : : : i\t! g\n",
      "0\n",
      " C g\n",
      "1\n",
      "x C g\n",
      "2\n",
      "x\n",
      "2\n",
      " C g\n",
      "3\n",
      "x\n",
      "3\n",
      " C\n",
      "\t\n",
      ":\n",
      "For example, here are some sequences and their generating functions:\n",
      "h0; 0; 0; 0; : : : i\t! 0 C 0x C 0x\n",
      "2\n",
      " C 0x\n",
      "3\n",
      " C\n",
      "\t\n",
      "D 0\n",
      "h1; 0; 0; 0; : : : i\t! 1 C 0x C 0x\n",
      "2\n",
      " C 0x\n",
      "3\n",
      " C\n",
      "\t\n",
      "D 1\n",
      "h3; 2; 1; 0; : : : i\t! 3 C 2x C 1x\n",
      "2\n",
      " C 0x\n",
      "3\n",
      " C\n",
      "\t\n",
      "D 3 C 2x C x\n",
      "2\n",
      "\n",
      "In this chapter, well put sequences in angle brackets to more clearly distinguish them from the many other mathematical expressions floating around.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 356  #362\n",
      "\n",
      "356\n",
      "\t\n",
      "Chapter 12\n",
      "\t\n",
      "Generating Functions\n",
      "The pattern here is simple: the ith term in the sequence (indexing from 0) is the coefficient of x\n",
      "i\n",
      " in the generating function.\n",
      "Recall that the sum of an infinite geometric series is:\n",
      "1 C z C z\n",
      "2\n",
      " C z\n",
      "3\n",
      " C\n",
      "\t\n",
      "D \n",
      "1\n",
      " \n",
      "1\n",
      " \n",
      "z\n",
      " :\n",
      "\n",
      "This equation does not hold when jzj 1, but as remarked, we wont worry about convergence issues for now. This formula gives closed form generating functions for a whole range of sequences. For example:\n",
      "\n",
      "12.2\n",
      "\t\n",
      "Operations on Generating Functions\n",
      "The magic of generating functions is that we can carry out all sorts of manipulations on sequences by performing mathematical operations on their associated generating functions. Lets experiment with various operations and characterize their effects in terms of sequences.\n",
      "12.2.1\n",
      "\t\n",
      "Scaling\n",
      "Multiplying a generating function by a constant scales every term in the associated sequence by the same constant. For example, we noted above that:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 357  #363\n",
      "\n",
      "which generates the sequence:\n",
      "h2; 0; 2; 0; 2; 0; : : : i :\n",
      "hcf\n",
      "0\n",
      "; cf\n",
      "1\n",
      "; cf\n",
      "2\n",
      "; : : : i\t! cf\n",
      "0\n",
      " C cf\n",
      "1\n",
      "x C cf\n",
      "2\n",
      "x\n",
      "2\n",
      " C\n",
      "c .f\n",
      "0\n",
      " C f\n",
      "1\n",
      "x C f\n",
      "2\n",
      "x\n",
      "2\n",
      " C  /\n",
      "cF .x/:\n",
      "12.2.2\tAddition\n",
      "Adding generating functions corresponds to adding the two sequences term by term. For example, adding two of our earlier examples gives:\n",
      "Weve now derived two different expressions that both generate the sequence h2; 0; 2; 0; : : : i.\n",
      "They are, of course, equal:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 358  #364\n",
      "\n",
      "358\n",
      "\t\n",
      "Chapter 12\n",
      "\t\n",
      "Generating Functions\n",
      "The idea behind this rule is that:\n",
      "12.2.3\tRight Shifting\n",
      "Lets start over again with a simple sequence and its generating function:\n",
      "h1; 1; 1; 1; : : : i\t! \n",
      "1\n",
      " \n",
      "1\n",
      " \n",
      "x\n",
      " :\n",
      "\n",
      "Now lets right-shift the sequence by adding k leading zeros:\n",
      "zeroes\n",
      "h0; 0; : : : ; 0; 1; 1; 1; : : : i\t! x\n",
      "k\n",
      " C x\n",
      "kC1\n",
      " C x\n",
      "kC2\n",
      " C x\n",
      "kC3\n",
      " C\n",
      "\n",
      "D x\n",
      "k\n",
      "  .1 C x C x\n",
      "2\n",
      " C x\n",
      "3\n",
      " C\n",
      "\t\n",
      "/\n",
      "D \n",
      "1\n",
      "x\n",
      "k\n",
      "x\n",
      " :\n",
      "\n",
      "Evidently, adding k leading zeros to the sequence corresponds to multiplying the generating function by x\n",
      "k\n",
      ". This holds true in general.\n",
      "Rule 12.2.3 (Right-Shift Rule). If hf\n",
      "0\n",
      "; f\n",
      "1\n",
      "; f\n",
      "2\n",
      "; : : : i\n",
      "\t\n",
      "! F .x/, then:\n",
      "zeroes\n",
      "The idea behind this rule is that:\n",
      "zeroes\n",
      "h0; 0; : : : ; 0; f\n",
      "0\n",
      "; f\n",
      "1\n",
      "; f\n",
      "2\n",
      "; : : : i\t! f\n",
      "0\n",
      "x\n",
      "k\n",
      " C f\n",
      "1\n",
      "x\n",
      "kC1\n",
      " C f\n",
      "2\n",
      "x\n",
      "kC2\n",
      " C\n",
      "\n",
      "D x\n",
      "k\n",
      "  .f\n",
      "0\n",
      " C f\n",
      "1\n",
      "x C f\n",
      "2\n",
      "x\n",
      "2\n",
      " C f\n",
      "3\n",
      "x\n",
      "3\n",
      " C\n",
      "\t\n",
      "/\n",
      "D x\n",
      "k\n",
      "  F .x/:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 359  #365\n",
      "\n",
      "12.2.4\tDifferentiation\n",
      "What happens if we take the derivative of a generating function? As an exam-ple, lets differentiate the now-familiar generating function for an infinite sequence of 1s:\n",
      "We found a generating function for the sequence h1; 2; 3; 4; : : : i of positive inte-gers!\n",
      "In general, differentiating a generating function has two effects on the corre-sponding sequence: each term is multiplied by its index and the entire sequence is shifted left one place.\n",
      "hf\n",
      "1\n",
      "; 2f\n",
      "2\n",
      "; 3f\n",
      "3\n",
      "; : : : i\t! f\n",
      "1\n",
      " C 2f\n",
      "2\n",
      "x C 3f\n",
      "3\n",
      "x\n",
      "2\n",
      " C\n",
      "dx\n",
      "d\n",
      " .f\n",
      "0\n",
      " C f\n",
      "1\n",
      "x C f\n",
      "2\n",
      "x\n",
      "2\n",
      " C f\n",
      "3\n",
      "x\n",
      "3\n",
      " C  /\n",
      "dx\n",
      "d\n",
      " F .x/:\n",
      "\n",
      "The Derivative Rule is very useful. In fact, there is frequent, independent need for each of differentiations two effects, multiplying terms by their index and left-shifting one place. Typically, we want just one effect and must somehow cancel out the other. For example, lets try to find the generating function for the sequence of squares, h0; 1; 4; 9; 16; : : : i. If we could start with the sequence h1; 1; 1; 1; : : : i and multiply each term by its index two times, then wed have the desired result:\n",
      "h0 0; 1 1; 2 2; 3 3; : : : i D h0; 1; 4; 9; : : : i :\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 360  #366\n",
      "\n",
      "360\n",
      "\t\n",
      "Chapter 12\n",
      "\t\n",
      "Generating Functions\n",
      "A challenge is that differentiation not only multiplies each term by its index, but also shifts the whole sequence left one place. However, the Right-Shift Rule \n",
      " tells how to cancel out this unwanted left-shift: multiply the generating function by x.\n",
      "Our procedure, therefore, is to begin with the generating function for h1; 1; 1; 1; : : : i, differentiate, multiply by x, and then differentiate and multiply by x once more. Then\n",
      "Derivative Rule:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right-shift Rule:\n",
      "Derivative Rule:\n",
      "Right-shift Rule:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "D\n",
      " \n",
      ".1\n",
      "\t\n",
      "x/\n",
      "2\n",
      "\n",
      "x\n",
      ".1  x/\n",
      "2\n",
      "1 C x\n",
      ".1  x/\n",
      "3\n",
      "\n",
      "x.1 C x/\n",
      ".1  x/\n",
      "3\n",
      "\n",
      "12.2.5\n",
      "\t\n",
      "Products\n",
      "Rule 12.2.5 ( Product Rule). If\n",
      "nD0\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 361  #367\n",
      "\n",
      "We can evaluate the product A.x/ B.x/ by using a table to identify all the cross-terms from the product of the sums:\n",
      "b\n",
      "0\n",
      "x\n",
      "0\n",
      "\t\n",
      "b\n",
      "1\n",
      "x\n",
      "1\n",
      "\t\n",
      "b\n",
      "2\n",
      "x\n",
      "2\n",
      "\t\n",
      "b\n",
      "3\n",
      "x\n",
      "3\n",
      "\t\n",
      ": : :\n",
      "\n",
      "Notice that all terms involving the same power of x lie on a diagonal. Collecting these terms together, we find that the coefficient of x\n",
      "n\n",
      " in the product is the sum of all the terms on the .n C 1/st diagonal, namely,\n",
      "This expression (\n",
      ") may be familiar from a signal processing course; the se-quence hc\n",
      "0\n",
      "; c\n",
      "1\n",
      "; c\n",
      "2\n",
      "; : : : i is called the convolution of sequences ha\n",
      "0\n",
      "; a\n",
      "1\n",
      "; a\n",
      "2\n",
      "; : : : i and hb\n",
      "0\n",
      "; b\n",
      "1\n",
      "; b\n",
      "2\n",
      "; : : : i.\n",
      "\n",
      "12.3\n",
      "\t\n",
      "Evaluating Sums\n",
      "The product rule looks complicated. But it is surprisingly useful. For example, suppose that we set\n",
      "B.x/ D \n",
      "1\n",
      " \n",
      "1\n",
      " \n",
      "x\n",
      " :\n",
      "\n",
      "Then b\n",
      "i\n",
      " D 1 for i\n",
      "\t\n",
      "0 and the nth coefficient of A.x/B.x/ is\n",
      "n\n",
      "X\n",
      "a\n",
      "0\n",
      "  1 C a\n",
      "1\n",
      "  1 C a\n",
      "2\n",
      "  1 C\n",
      "\t\n",
      "C a\n",
      "n\n",
      "  1 D\n",
      "\t\n",
      "a\n",
      "i\n",
      " :\n",
      "iD0\n",
      "In other words, given any sequence ha\n",
      "0\n",
      "; a\n",
      "1\n",
      "; a\n",
      "2\n",
      "; : : : i, we can compute\n",
      "n\n",
      "X\n",
      "s\n",
      "n\n",
      " D\n",
      "\t\n",
      "a\n",
      "i\n",
      "iD0\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 362  #368\n",
      "\n",
      "362\n",
      "\t\n",
      "Chapter 12\n",
      "\t\n",
      "Generating Functions\n",
      "for all n by simply multiplying the sequences generating function by 1=.1\n",
      "\t\n",
      "x/.\n",
      "This is the Summation Rule.\n",
      "Rule 12.3.1 (Summation Rule). If\n",
      "ha\n",
      "0\n",
      "; a\n",
      "1\n",
      "; a\n",
      "2\n",
      "; : : : i\t! A.x/;\n",
      "then\n",
      "A.x/\n",
      "hs\n",
      "0\n",
      "; s\n",
      "1\n",
      "; s\n",
      "2\n",
      "; : : :\n",
      " \n",
      "i\n",
      "\t\n",
      "!\n",
      "\n",
      "1\n",
      "\t\n",
      "x\n",
      "where\n",
      "n\n",
      "X\n",
      "s\n",
      "n\n",
      " D\n",
      "\t\n",
      "a\n",
      "i\n",
      "\t\n",
      "for n\n",
      "\t\n",
      "0:\n",
      "iD0\n",
      "The Summation Rule sounds powerful, and it is! We know from Chapter \n",
      "that computing sums is often not easy. But multiplying by 1=.1 x/ is about as easy as it gets.\n",
      "For example, suppose that we want to compute the sum of the first n squares\n",
      "n\n",
      "s\n",
      "n\n",
      " D \n",
      "X\n",
      " i\n",
      "2\n",
      "iD0\n",
      "and we forgot the method in Chapter \n",
      ". All we need to do is compute the generating function for h0; 1; 4; 9; : : : i and multiply by 1=.1 x/. We already computed the generating function for h0; 1; 4; 9; : : : i in Equation \n",
      "it is\n",
      "x.1 C x/\n",
      ":\n",
      "\n",
      ".1\tx/\n",
      "3\n",
      "Hence, the generating function for hs\n",
      "0\n",
      "; s\n",
      "1\n",
      "; s\n",
      "2\n",
      "; : : : i is\n",
      "x.1 C x/\n",
      ":\n",
      "\n",
      ".1\tx/\n",
      "4\n",
      "This means that \n",
      "P\n",
      "n\n",
      "\t\n",
      "i\n",
      "2\n",
      " is the coefficient of x\n",
      "n\n",
      " in x.1 C x/=.1\tx/\n",
      "4\n",
      ".\n",
      "D0\n",
      "That was pretty easy, but there is one problemwe have no idea how to deter-mine the coefficient of x\n",
      "n\n",
      " in x.1 C x/=.1 x/\n",
      "4\n",
      "! And without that, this whole endeavor (while magical) would be useless. Fortunately, there is a straightforward way to produce the sequence of coefficients from a generating function.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 363  #369\n",
      "\n",
      "\n",
      "12.4\n",
      "\t\n",
      "Extracting Coefficients\n",
      "12.4.1\n",
      "\t\n",
      "Taylor Series\n",
      "Given a sequence of coefficients h\n",
      "f\n",
      "0\n",
      "; f\n",
      "1\n",
      "; f\n",
      "2\n",
      "; : : :\n",
      " i, computing the generating func-tion \n",
      "F .x/\n",
      " is easy since\n",
      "F .x/ \n",
      "D\n",
      " f\n",
      "0\n",
      " \n",
      "C\n",
      " f\n",
      "1\n",
      "x \n",
      "C\n",
      " f\n",
      "2\n",
      "x\n",
      "2\n",
      " \n",
      "C\n",
      "\t\n",
      ":\n",
      "To compute the sequence of coefficients from the generating function, we need to compute the Taylor Series for the generating function.\n",
      "Rule 12.4.1 (Taylor Series). Let \n",
      "F .x/\n",
      " be the generating function for the sequence\n",
      "h\n",
      "f\n",
      "0\n",
      "; f\n",
      "1\n",
      "; f\n",
      "2\n",
      "; : : :\n",
      " i\n",
      ":\n",
      "Then\n",
      "f\n",
      "0\n",
      " \n",
      "D\n",
      " F .0/\n",
      "and\n",
      "f\n",
      "n\n",
      " \n",
      "D\n",
      " F \n",
      ".n/\n",
      ".0/\n",
      "\n",
      "n\n",
      "for \n",
      "n\n",
      "\t\n",
      "1\n",
      ", where\n",
      " F \n",
      ".n/\n",
      ".0/ \n",
      "is the\n",
      " n\n",
      "th derivative of\n",
      " F .x/ \n",
      "evaluated at\n",
      " x \n",
      "D\n",
      " 0\n",
      ".\n",
      "This is because if\n",
      "F .x/ \n",
      "D\n",
      " f\n",
      "0\n",
      " \n",
      "C\n",
      " f\n",
      "1\n",
      "x \n",
      "C\n",
      " f\n",
      "2\n",
      "x\n",
      "2\n",
      " \n",
      "C\n",
      "\t\n",
      ";\n",
      "then\n",
      "F .0/ \n",
      "D\n",
      " f\n",
      "0\n",
      " \n",
      "C\n",
      " f\n",
      "1\n",
      "  0 \n",
      "C\n",
      " f\n",
      "2\n",
      "  0\n",
      "2\n",
      " \n",
      "C\n",
      "f\n",
      "0\n",
      ":\n",
      "Also,\n",
      "F \n",
      "0\n",
      ".x/ \n",
      "D\n",
      " \n",
      "dx\n",
      "d\n",
      " .F .x//\n",
      "\n",
      "D \n",
      "f\n",
      "1\n",
      " C \n",
      "2f\n",
      "2\n",
      "x\n",
      " C \n",
      "3f\n",
      "3\n",
      "x\n",
      "2\n",
      " C \n",
      "4f\n",
      "4\n",
      "x\n",
      "3\n",
      " C\n",
      "and so\n",
      "F \n",
      "0\n",
      ".0/ \n",
      "D\n",
      " f\n",
      "1\n",
      ";\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 364  #370\n",
      "\n",
      "364\n",
      "\t\n",
      "Chapter 12\n",
      "\t\n",
      "Generating Functions\n",
      "as desired. Taking second derivatives, we find that\n",
      "F \n",
      "00\n",
      ".x/ \n",
      "D\n",
      " \n",
      "dx\n",
      "d\n",
      " .F \n",
      "0\n",
      ".x//\n",
      "\n",
      "D \n",
      "2f\n",
      "2\n",
      " C \n",
      "3 2f\n",
      "3\n",
      "x\n",
      " C \n",
      "4 3f\n",
      "4\n",
      "x\n",
      "2\n",
      " C\n",
      "and so\n",
      "F \n",
      "00\n",
      ".0/ \n",
      "D\n",
      " 2f\n",
      "2\n",
      ";\n",
      "which means that\n",
      "In general,\n",
      "\n",
      "\n",
      "F \n",
      "00\n",
      ".0/\n",
      "f\n",
      "2 \n",
      "D\n",
      "\t\n",
      ":\n",
      "\n",
      "2\n",
      "F \n",
      ".n/\n",
      " \n",
      "D\n",
      " n f\n",
      "n\n",
      " \n",
      "C\n",
      " .n \n",
      "C\n",
      " 1/ f\n",
      "nC1\n",
      "x \n",
      "C\n",
      " \n",
      ".n\n",
      " \n",
      "C\n",
      " \n",
      "2/\n",
      " f\n",
      "nC2\n",
      "x\n",
      "2\n",
      " \n",
      "C\n",
      "\n",
      "2\n",
      ".n\n",
      " \n",
      "C\n",
      " \n",
      "k/\n",
      " \n",
      "f\n",
      "nCk\n",
      "x\n",
      "k \n",
      "C\n",
      "k\n",
      "\n",
      "and so\n",
      "F \n",
      ".n/\n",
      ".0/ \n",
      "D\n",
      " n f\n",
      "n\n",
      "and\n",
      "f\n",
      "n\n",
      " \n",
      "D\n",
      " F \n",
      ".n/\n",
      ".0/\n",
      ";\n",
      "\n",
      "n\n",
      "as claimed.\n",
      "This means that\n",
      "The sequence on the left-hand side of Equation \n",
      "gives the well-known Taylor Series expansion for a function\n",
      "12.4.2\n",
      "\t\n",
      "Examples\n",
      "Lets try this out on a familiar example:\n",
      "F .x/ \n",
      "D\n",
      " \n",
      "1\n",
      " \n",
      "1\n",
      " \n",
      "x\n",
      " :\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 365  #371\n",
      "\n",
      "F \n",
      "00\n",
      ".x/ \n",
      "D\n",
      " \n",
      ".1\n",
      " \n",
      "2\n",
      "x/\n",
      "3\n",
      " ;\n",
      "\n",
      "F \n",
      "000\n",
      ".x/ \n",
      "D\n",
      " \n",
      ".1\n",
      "2\n",
      " \n",
      "x/\n",
      "3\n",
      "4\n",
      " ;\n",
      "\n",
      ":\n",
      ":\n",
      ":\n",
      "In other words, we have reconfirmed what we already knew; namely, that\n",
      "1\n",
      " \n",
      "1\n",
      " \n",
      "x\n",
      " D \n",
      "1\n",
      " C \n",
      "x\n",
      " C \n",
      "x\n",
      "2\n",
      " C\n",
      "\t\n",
      ":\n",
      "\n",
      "In particular, we need to know the coefficient of \n",
      "x\n",
      "n\n",
      " in \n",
      "F .x/\n",
      " to determine\n",
      "n\n",
      "s\n",
      "n\n",
      " \n",
      "D\n",
      " \n",
      "X\n",
      " i\n",
      "2\n",
      ":\n",
      "D0\n",
      "While it is theoretically possible to compute the \n",
      "n\n",
      "th derivative of \n",
      "F .x/\n",
      ", the result is a bloody mess. Maybe these generating functions werent such a great idea after all. . . .\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 366  #372\n",
      "\n",
      "366\n",
      "\t\n",
      "Chapter 12\n",
      "\t\n",
      "Generating Functions\n",
      "12.4.3\n",
      "\t\n",
      "Massage Helps\n",
      "In times of stress, a little massage can often help relieve the tension. The same is true for polynomials with painful derivatives. For example, lets take a closer look at Equation \n",
      ". If we massage it a little bit, we find that\n",
      "The goal is to find the coefficient of \n",
      "x\n",
      "n\n",
      " in \n",
      "F .x/\n",
      ". If you stare at Equation \n",
      "long enough (or if you combine the Right-Shift Rule with the Addition Rule), you will notice that the coefficient of \n",
      "x\n",
      "n\n",
      " in \n",
      "F .x/\n",
      " is just the sum of\n",
      "Maybe there is some hope after all. Lets see if we can produce the coefficients for \n",
      "1=.1 x/\n",
      "4\n",
      ". Well start by looking at the derivatives:\n",
      "We are now almost done.\n",
      "\t\n",
      "Equation \n",
      "means that the coefficient of \n",
      "x\n",
      "n1\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 367  #373\n",
      "\n",
      "This matches Equation \n",
      "from Chapter \n",
      ". Using generating functions to get the result may have seemed to be more complicated, but at least there was no need for guessing or solving a linear system of equations over 4 variables.\n",
      "You might argue that the massage step was a little tricky. After all, how were you supposed to know that by converting \n",
      "F .x/\n",
      " into the form shown in Equation \n",
      ", it would be sufficient to compute derivatives of \n",
      "1=.1 x/\n",
      "4\n",
      ", which is easy, instead of derivatives of \n",
      "x.1\n",
      " C \n",
      "x/=.1 x/\n",
      "4\n",
      ", which could be harder than solving a 64-disk Tower of Hanoi problem step-by-step?\n",
      "The good news is that this sort of massage works for any generating function that is a ratio of polynomials. Even better, you probably already know how to do it from calculusits the method of partial fractions!\n",
      "12.4.4\n",
      "\t\n",
      "Partial Fractions\n",
      "The idea behind partial fractions is to express a ratio of polynomials as a sum of a polynomial and terms of the form\n",
      "cx\n",
      "a\n",
      "\n",
      ".1\tx/\n",
      "b\n",
      "\n",
      "\n",
      "(12.10)\n",
      "where \n",
      "a\n",
      " and \n",
      "b\n",
      " are integers and \n",
      "b > a 0\n",
      ". Thats because it is easy to com-pute derivatives of \n",
      "1=.1 x/\n",
      "b\n",
      " and thus it is easy to compute the coefficients of Equation \n",
      ". Lets see why.\n",
      "Lemma 12.4.2. If \n",
      "b\n",
      " 2 N\n",
      "C\n",
      ", then the \n",
      "n\n",
      "th derivative of \n",
      "1=.1\n",
      "\t\n",
      "x/\n",
      "b\n",
      " \n",
      "is\n",
      "\n",
      "To be precise, Equation \n",
      "holds for n 1 and Equation \n",
      "holds for n 2. But since Equation \n",
      "is 0 for n D 1 and Equation \n",
      "is 0 for n D 1; 2, both equations hold for all n 0.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 368  #374\n",
      "\n",
      "368\n",
      "\t\n",
      "Chapter 12\n",
      "\t\n",
      "Generating Functions\n",
      "Proof. The proof is by induction on \n",
      "n\n",
      ". The induction hypothesis \n",
      "P .n/\n",
      " is the state-ment of the lemma.\n",
      "Corollary 12.4.3. If \n",
      "a; b\n",
      " 2 N and \n",
      "b > a 0\n",
      ", then for any \n",
      "n a\n",
      ", the coefficient of \n",
      "x\n",
      "n\n",
      " in\n",
      "Proof. By the Taylor Series Rule, the \n",
      "n\n",
      "th coefficient of\n",
      "1\n",
      "\n",
      ".1\tx/\n",
      "b\n",
      "is the \n",
      "n\n",
      "th derivative of this expression evaluated at \n",
      "x\n",
      " D \n",
      "0\n",
      " and then divided by \n",
      "n\n",
      " .\n",
      "By Lemma \n",
      ", this is\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 369  #375\n",
      "\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 370  #376\n",
      "\n",
      "370\n",
      "\t\n",
      "Chapter 12\n",
      "\t\n",
      "Generating Functions\n",
      "For Equation \n",
      "to hold, we need\n",
      "8 \n",
      "D\n",
      " c\n",
      "1\n",
      " \n",
      "C\n",
      " 2c\n",
      "3\n",
      ";\n",
      "3 \n",
      "D\n",
      " 2c \n",
      "1\n",
      " \n",
      "C\n",
      " 2c\n",
      "2\n",
      " \n",
      "C\n",
      " c\n",
      "3\n",
      ";\n",
      "4 \n",
      "D\n",
      " c\n",
      "1\n",
      " \n",
      "C\n",
      " c\n",
      "2\n",
      ":\n",
      "Our massage is done! We can now compute the coefficients of \n",
      "F .x/\n",
      " using Corol-lary \n",
      "and the Sum Rule. The result is\n",
      "f\n",
      "0\n",
      " \n",
      "D\n",
      " 2 \n",
      "C\n",
      " 2 \n",
      "C\n",
      " 2 \n",
      "D\n",
      " 6\n",
      "and\n",
      "for \n",
      "n\n",
      "\t\n",
      "1\n",
      ".\n",
      "Arent you glad that you know that? Actually, this method turns out to be useful in solving linear recurrences, as well see in the next section.\n",
      "\n",
      "12.5\n",
      "\t\n",
      "Solving Linear Recurrences\n",
      "Generating functions can be used to find a solution to any linear recurrence. Well show you how this is done by means of a familiar example, the Fibonacci recur-rence, so that you can more easily understand the similarities and differences of this approach and the method we showed you in Chapter \n",
      ".\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 371  #377\n",
      "\n",
      "12.5.1\n",
      "\t\n",
      "Finding the Generating Function\n",
      "Lets begin by recalling the definition of the Fibonacci numbers:\n",
      "We can expand the final clause into an infinite sequence of equations. Thus, the\n",
      "Fibonacci numbers are defined by:\n",
      "f\n",
      "0\n",
      " D0\n",
      "f\n",
      "1\n",
      " D1\n",
      "f\n",
      "2\n",
      " Df\n",
      "1\n",
      " C f\n",
      "0\n",
      "f\n",
      "3\n",
      " Df\n",
      "2\n",
      " C f\n",
      "1\n",
      "f\n",
      "4\n",
      " Df\n",
      "3\n",
      " C f\n",
      "2\n",
      ":\n",
      ":\n",
      ":\n",
      "The overall plan is to define a function F .x/ that generates the sequence on the left side of the equality symbols, which are the Fibonacci numbers. Then we derive a function that generates the sequence on the right side. Finally, we equate the two and solve for F .x/. Lets try this. First, we define:\n",
      "F .x/ D f\n",
      "0\n",
      " C f\n",
      "1\n",
      "x C f\n",
      "2\n",
      "x\n",
      "2\n",
      " C f\n",
      "3\n",
      "x\n",
      "3\n",
      " C f\n",
      "4\n",
      "x\n",
      "4\n",
      " C\n",
      "\t\n",
      ":\n",
      "Now we need to derive a generating function for the sequence:\n",
      "h0; 1; f\n",
      "1\n",
      " C f\n",
      "0\n",
      "; f\n",
      "2\n",
      " C f\n",
      "1\n",
      "; f\n",
      "3\n",
      " C f\n",
      "2\n",
      "; : : : i :\n",
      "One approach is to break this into a sum of three sequences for which we know generating functions and then apply the Addition Rule:\n",
      "This sequence is almost identical to the right sides of the Fibonacci equations. The one blemish is that the second term is 1 C f\n",
      "0\n",
      " instead of simply 1. However, this amounts to nothing, since f\n",
      "0\n",
      " D 0 anyway.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 372  #378\n",
      "\n",
      "372\n",
      "\t\n",
      "Chapter 12\n",
      "\t\n",
      "Generating Functions\n",
      "If we equate F .x/ with the new function x C xF .x/ C x\n",
      "2\n",
      "F .x/, then were implicitly writing down all of the equations that define the Fibonacci numbers in one fell swoop:\n",
      "F .x/\n",
      "\t\n",
      "D f\n",
      "0\n",
      " C\n",
      "\t\n",
      "f\n",
      "1\n",
      "\tx C\tf\n",
      "2\n",
      "\tx\n",
      "2\n",
      " C\tf\n",
      "3\n",
      "\tx\n",
      "3\n",
      " C\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "x C xF .x/ C x\n",
      "2\n",
      "F .x/ D 0 C .1 C f\n",
      "0\n",
      "/x C .f\n",
      "1\n",
      " C f\n",
      "0\n",
      "/x\n",
      "2\n",
      " C .f\n",
      "2\n",
      " C f\n",
      "1\n",
      "/x\n",
      "3\n",
      " C\n",
      "Solving for F .x/ gives the generating function for the Fibonacci sequence:\n",
      "This is pretty cool. After all, who would have thought that the Fibonacci numbers are precisely the coefficients of such a simple function? Even better, this function is a ratio of polynomials and so we can use the method of partial fractions from Section \n",
      "to find a closed-form expression for the nth Fibonacci number.\n",
      "12.5.2\n",
      "\t\n",
      "Extracting the Coefficients\n",
      "Repeated differentiation of Equation \n",
      "would be very painful. But it is easy to use the method of partial fractions to compute the coefficients. Since the degree of the numerator in Equation \n",
      "is less than the degree of the denominator, the first step is to factor the denominator:\n",
      "roots of the characteristic equation for the Fibonacci recurrence that we found in Chapter \n",
      ". That is not a coincidence.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 373  #379\n",
      "\n",
      "We can now use Corollary \n",
      "and the Sum Rule to conclude that\n",
      "n\n",
      "f\n",
      "n\n",
      " D \n",
      "p\n",
      "1\n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "n\n",
      "p\n",
      "2\n",
      "\n",
      "5\n",
      "p !\n",
      "n\n",
      "\t\n",
      "p !\n",
      "n\n",
      "!\n",
      "\n",
      "This is exactly the same formula we derived for the nth Fibonacci number in Chap-ter \n",
      ".\n",
      "12.5.3\n",
      "\t\n",
      "General Linear Recurrences\n",
      "The method that we just used to solve the Fibonacci recurrence can also be used to solve general linear recurrences of the form\n",
      "f\n",
      "n\n",
      " D a\n",
      "1\n",
      "f\n",
      "n1\n",
      "  C a\n",
      "2\n",
      "f\n",
      "n2\n",
      "  C\n",
      "\t\n",
      "C a\n",
      "d\n",
      " f\n",
      "nd\n",
      "  C g\n",
      "n\n",
      "for n\n",
      "\t\n",
      "d . The generating function for hf\n",
      "0\n",
      "; f\n",
      "1\n",
      "; f\n",
      "2\n",
      "; : : : i is\n",
      "\n",
      "for 0\n",
      "\t\n",
      "i < d .\n",
      "To solve the recurrence, we use the method of partial fractions described in Sec-tion \n",
      "to find a closed-form expression for F .x/. This can be easy or hard to do depending on G.x/.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 374  #380\n",
      "\n",
      "374\n",
      "\t\n",
      "Chapter 12\n",
      "\t\n",
      "Generating Functions\n",
      "\n",
      "12.6\n",
      "\t\n",
      "Counting with Generating Functions\n",
      "Generating functions are particularly useful for solving counting problems. In par-ticular, problems involving choosing items from a set often lead to nice generating functions by letting the coefficient of x\n",
      "n\n",
      " be the number of ways to choose n items.\n",
      "12.6.1\n",
      "\t\n",
      "Choosing Distinct Items from a Set\n",
      "The generating function for binomial coefficients follows directly from the Bino-mial Theorem:\n",
      "D .1 C x/\n",
      "Thus, the coefficient of x\n",
      "n\n",
      " in .1 C x/\n",
      "k\n",
      " is \n",
      "k\n",
      "n\n",
      " , the number of ways to choose n distinct items\n",
      "from a set of size k. For example, the coefficient of x\n",
      "2\n",
      " is \n",
      "k\n",
      "2\n",
      " , the number of ways to choose 2 items from a set with k elements. Similarly, the coefficient of x\n",
      "kC1\n",
      " is the number of ways to choose k C 1 items from a size k set, which is zero.\n",
      "12.6.2\n",
      "\t\n",
      "Building Generating Functions that Count\n",
      "Often we can translate the description of a counting problem directly into a gen-erating function for the solution. For example, we could figure out that .1 C x/\n",
      "k\n",
      " generates the number of ways to select n distinct items from a k-element set with-out resorting to the Binomial Theorem or even fussing with binomial coefficients! Lets see how.\n",
      "First, consider a single-element set fa\n",
      "1\n",
      "g. The generating function for the number of ways to select n elements from this set is simply 1 C x: we have 1 way to select zero elements, 1 way to select one element, and 0 ways to select more than one element. Similarly, the number of ways to select n elements from the set fa\n",
      "2\n",
      " g is also given by the generating function 1 C x. The fact that the elements differ in the two cases is irrelevant.\n",
      "Now here is the main trick: the generating function for choosing elements from a union of disjoint sets is the product of the generating functions for choosing from each set. Well justify this in a moment, but lets first look at an example. Ac-cording to this principle, the generating function for the number of ways to select\n",
      "\n",
      "Watch out for the reversal of the roles that k and n played in earlier examples; were led to this reversal because weve been using n to refer to the power of x in a power series.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 375  #381\n",
      "\n",
      "elements from the fa\n",
      "1\n",
      "; a\n",
      "2\n",
      "g is:\n",
      "Sure enough, for the set fa\n",
      "1\n",
      "; a\n",
      "2\n",
      "g, we have 1 way to select zero elements, 2 ways to select one element, 1 way to select two elements, and 0 ways to select more than two elements.\n",
      "Repeated application of this rule gives the generating function for selecting n items from a k-element set fa\n",
      "1\n",
      "; a\n",
      "2\n",
      "; : : : ; a\n",
      "k\n",
      "g:\n",
      "This is the same generating function that we obtained by using the Binomial Theo-rem. But this time around, we translated directly from the counting problem to the generating function.\n",
      "We can extend these ideas to a general principle:\n",
      "Rule 12.6.1 (Convolution Rule). Let A.x/ be the generating function for selecting items from set A, and let B.x/ be the generating function for selecting items from set B. If A and B are disjoint, then the generating function for selecting items from the union A [ B is the product A.x/ B.x/.\n",
      "This rule is rather ambiguous: what exactly are the rules governing the selection of items from a set? Remarkably, the Convolution Rule remains valid under many interpretations of selection. For example, we could insist that distinct items be selected or we might allow the same item to be picked a limited number of times or any number of times. Informally, the only restrictions are that (1) the order in which items are selected is disregarded and (2) restrictions on the selection of items from sets A and B also apply in selecting items from A [ B. (Formally, there must be a bijection between n-element selections from A [ B and ordered pairs of selections from A and B containing a total of n elements.)\n",
      "To count the number of ways to select n items from A [ B, we observe that we\n",
      "can select n items by choosing j items from A and n\n",
      "\t\n",
      "j items from B, where j is\n",
      "any number from 0 to n. This can be done in a\n",
      "j\n",
      " b\n",
      "nj\n",
      " ways. Summing over all the possible values of j gives a total of\n",
      "a\n",
      "0\n",
      "b\n",
      "n\n",
      " C a\n",
      "1\n",
      "b\n",
      "n1\n",
      "  C a\n",
      "2\n",
      "b\n",
      "n2\n",
      "  C\n",
      "\t\n",
      "C a\n",
      "n\n",
      "b\n",
      "0\n",
      "ways to select n items from A [ B. By the Product Rule, this is precisely the coefficient of x\n",
      "n\n",
      " in the series for A.x/B.x/.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 376  #382\n",
      "\n",
      "376\n",
      "\t\n",
      "Chapter 12\n",
      "\t\n",
      "Generating Functions\n",
      "12.6.3\n",
      "\t\n",
      "Choosing Items with Repetition\n",
      "The first counting problem we considered was the number of ways to select a dozen doughnuts when five flavors were available. We can generalize this question as follows: in how many ways can we select n items from a k-element set if were allowed to pick the same item multiple times? In these terms, the doughnut problem asks how many ways we can select n D 12 doughnuts from the set of k D 5 flavors\n",
      "fchocolate; lemon-filled; sugar; glazed; plaing\n",
      "where, of course, were allowed to pick several doughnuts of the same flavor. Lets approach this question from a generating functions perspective.\n",
      "Suppose we make n choices (with repetition allowed) of items from a set con-taining a single item. Then there is one way to choose zero items, one way to choose one item, one way to choose two items, etc. Thus, the generating function for choosing n elements with repetition from a 1-element set is:\n",
      "h1; 1; 1; 1; : : : i\t! 1 C x C x\n",
      "2\n",
      " C x\n",
      "3\n",
      " C\n",
      "\t\n",
      "D \n",
      "1\n",
      " \n",
      "1\n",
      " \n",
      "x\n",
      " :\n",
      "\n",
      "The Convolution Rule says that the generating function for selecting items from a union of disjoint sets is the product of the generating functions for selecting items\n",
      "Therefore, the generating function for choosing items from a k-element set with repetition allowed is 1=.1 x/\n",
      "k\n",
      ". Computing derivatives and applying the Taylor Series Rule, we can find that the coefficient of x\n",
      "n\n",
      " in 1=.1 x/\n",
      "k\n",
      " is\n",
      "This is the Bookkeeper Rule from Chapter \n",
      "namely there are select n items with replication from a set of k items.\n",
      "\n",
      "\n",
      "12.6.4\n",
      "\t\n",
      "Fruit Salad\n",
      "In this chapter, we have covered a lot of methods and rules for using generating functions. Well now do an example that demonstrates how the rules and methods can be combined to solve a more challenging problemmaking fruit salad.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 377  #383\n",
      "\n",
      "In how many ways can we make a salad with n fruits subject to the following constraints?\n",
      "The number of apples must be even.\n",
      "The number of bananas must be a multiple of 5. There can be at most four oranges.\n",
      "There can be at most one pear.\n",
      "For example, there are 7 ways to make a salad with 6 fruits:\n",
      "These constraints are so complicated that the problem seems hopeless! But gener-ating functions can solve the problem in a straightforward way.\n",
      "Lets first construct a generating function for choosing apples. We can choose a set of 0 apples in one way, a set of 1 apple in zero ways (since the number of apples must be even), a set of 2 apples in one way, a set of 3 apples in zero ways, and so forth. So we have:\n",
      "A.x/ D 1 C x\n",
      "2\n",
      " C x\n",
      "4\n",
      " C x\n",
      "6\n",
      " C\n",
      "\t\n",
      "D \n",
      "1\n",
      " \n",
      "1\n",
      "x\n",
      "2\n",
      " :\n",
      "\n",
      "Similarly, the generating function for choosing bananas is:\n",
      "We can choose a set of 0 oranges in one way, a set of 1 orange in one way, and so on. However, we can not choose more than four oranges, so we have the generating function:\n",
      "Here were using the geometric sum formula. Finally, we can choose only zero or one pear, so we have:\n",
      "P .x/ D 1 C x:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 378  #384\n",
      "\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 379  #385\n",
      "\n",
      "13\n",
      "\t\n",
      "Infinite Sets\n",
      "So you might be wondering how much is there to say about an infinite set other than, well, it has an infinite number of elements. Of course, an infinite set does have an infinite number of elements, but it turns out that not all infinite sets have the same sizesome are bigger than others! And, understanding infinity is not as easy as you might think. Some of the toughest questions in mathematics involve infinite sets.\n",
      "Why should you care? Indeed, isnt computer science only about finite sets? Not exactly. For example, we deal with the set of natural numbers N all the time and it is an infinite set. In fact, that is why we have induction: to reason about predicates over N. Infinite sets are also important in Part \n",
      "of the text when we talk about random variables over potentially infinite sample spaces.\n",
      "So sit back and open your mind for a few moments while we take a very brief look at infinity.\n",
      "\n",
      "13.1\n",
      "\t\n",
      "Injections, Surjections, and Bijections\n",
      "We know from Theorem \n",
      "that if there is an injection or surjection between two finite sets, then we can say something about the relative sizes of the two sets. The same is true for infinite sets. In fact, relations are the primary tool for determining the relative size of infinite sets.\n",
      "Definition 13.1.1. Given any two sets A and B, we say that\n",
      "A surj B\n",
      "\t\n",
      "iff there is a surjection from A to B,\n",
      "A inj B\n",
      "\t\n",
      "iff there is an injection from A to B,\n",
      "A bij B\n",
      "\t\n",
      "iff there is a bijection between A and B, and\n",
      "A strict B\n",
      "\t\n",
      "iff there is a surjection from A to B but there is no bijection from B to A.\n",
      "Restating Theorem \n",
      "with this new terminology, we have:\n",
      "Theorem 13.1.2. For any pair of finite sets A and B,\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 380  #386\n",
      "\n",
      "380\n",
      "\t\n",
      "Chapter 13\n",
      "\t\n",
      "Infinite Sets\n",
      "Theorem \n",
      "suggests a way to generalize size comparisons to infinite sets; namely, we can think of the relation surj as an at least as big relation between sets, even if they are infinite. Similarly, the relation bij can be regarded as a same size relation between (possibly infinite) sets, and strict can be thought of as a strictly bigger relation between sets.\n",
      "Note that we havent, and wont, define what the size of an infinite set is. The definition of infinite sizes is cumbersome and technical, and we can get by just fine without it. All we need are the as big as and same size relations, surj and bij, between sets.\n",
      "But theres something else to watch out for. Weve referred to surj as an as big as relation and bij as a same size relation on sets. Most of the as big as and same size properties of surj and bij on finite sets do carry over to infinite sets, but some important ones dontas were about to show. So you have to be careful: dont assume that surj has any particular as big as property on infinite sets until its been proved.\n",
      "Lets begin with some familiar properties of the as big as and same size relations on finite sets that do carry over exactly to infinite sets:\n",
      "Theorem 13.1.3. For any sets, A, B, and C ,\n",
      "A surj B and B surj C \n",
      "IMPLIES\n",
      " A surj C .\n",
      "A bij B and B bij C \n",
      "IMPLIES\n",
      " A bij C .\n",
      "A bij B \n",
      "IMPLIES\n",
      " B bij A.\n",
      "Parts 1 and 2 of Theorem \n",
      "follow immediately from the fact that composi-tions of surjections are surjections, and likewise for bijections. Part 3 follows from the fact that the inverse of a bijection is a bijection. Well leave a proof of these facts to the problems.\n",
      "Another familiar property of finite sets carries over to infinite sets, but this time its not so obvious:\n",
      "Theorem 13.1.4 (Schroder-Bernstein). For any pair of sets A and B, if A surj B and B surj A, then A bij B.\n",
      "The Schroder-Bernstein Theorem says that if A is at least as big as B and, con-versely, B is at least as big as A, then A is the same size as B. Phrased this way, you might be tempted to take this theorem for granted, but that would be a mis-take. For infinite sets A and B, the Schroder-Bernstein Theorem is actually pretty technical. Just because there is a surjective function f W A ! Bwhich need not be a bijectionand a surjective function g W B ! Awhich also need not\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 381  #387\n",
      "\n",
      "be a bijectionits not at all clear that there must be a bijection h W A ! B. The challenge is to construct h from parts of both f and g. Well leave the actual construction to the problems.\n",
      "13.1.1\tInfinity Is Different\n",
      "A basic property of finite sets that does not carry over to infinite sets is that adding something new makes a set bigger. That is, if A is a finite set and b A, then jA [ fb gj D jAj C 1, and so A and A [ fbg are not the same size. But if A is infinite, then these two sets are the same size!\n",
      "Theorem 13.1.5. Let A be a set and b\n",
      "\t\n",
      "A. Then A is infinite iff A bij A [ fbg.\n",
      "Proof. Since A is not the same size as A [ fbg when A is finite, we only have to show that A [ fbg is the same size as A when A is infinite.\n",
      "That is, we have to find a bijection between A [ fbg and A when A is infinite. Since A is infinite, it certainly has at least one element; call it a\n",
      "0\n",
      ". Since A is infinite, it has at least two elements, and one of them must not be equal to a\n",
      "0\n",
      "; call this new element a\n",
      "1\n",
      ". Since A is infinite, it has at least three elements, one of which must not equal a\n",
      "0\n",
      " or a\n",
      "1\n",
      "; call this new element a\n",
      "2\n",
      ". Continuing in this way, we conclude that there is an infinite sequence a\n",
      "0\n",
      ", a\n",
      "1\n",
      ", a\n",
      "2\n",
      ", . . . , a\n",
      "n\n",
      ", . . . , of different elements of A. Now its easy to define a bijection f W A [ fbg ! A:\n",
      "\n",
      "13.2\n",
      "\t\n",
      "Countable Sets\n",
      "13.2.1\n",
      "\t\n",
      "Definitions\n",
      "A set C is countable iff its elements can be listed in order, that is, the distinct elements in C are precisely\n",
      "c\n",
      "0\n",
      "; c\n",
      "1\n",
      "; : : : ; c\n",
      "n\n",
      "; : : : :\n",
      "This means that if we defined a function f on the nonnegative integers by the rule that f .i/ WWD c\n",
      "i\n",
      " , then f would be a bijection from N to C . More formally,\n",
      "Definition 13.2.1. A set C is countably infinite iff N bij C . A set is countable iff it is finite or countably infinite.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 382  #388\n",
      "\n",
      "382\n",
      "\t\n",
      "Chapter 13\n",
      "\t\n",
      "Infinite Sets\n",
      "Discrete mathematics is often defined as the mathematics of countable sets and so it is probably worth spending a little time understanding what it means to be countable and why countable sets are so special. For example, a small modification of the proof of Theorem \n",
      "shows that countably infinite sets are the smallest infinite sets; namely, if A is any infinite set, then A surj N.\n",
      "13.2.2\n",
      "\t\n",
      "Unions\n",
      "Since adding one new element to an infinite set doesnt change its size, its obvi-ous that neither will adding any finite number of elements. Its a common mis-take to think that this proves that you can throw in countably infinitely many new elementsjust because its ok to do something any finite number of times doesnt make it ok to do it an infinite number of times.\n",
      "For example, suppose that you have two countably infinite sets A D fa\n",
      "0\n",
      "; a\n",
      "1\n",
      "; a\n",
      "2\n",
      "; : : : g and B D fb\n",
      "0\n",
      "; b\n",
      "1\n",
      "; b\n",
      "2\n",
      "; : : : g. You might try to show that A[B is countable by making the following list for A [ B:\n",
      "a\n",
      "0\n",
      "; a\n",
      "1\n",
      "; a\n",
      "2\n",
      "; : : : ; b\n",
      "0\n",
      "; b\n",
      "1\n",
      "; b\n",
      "2\n",
      "; : : :\n",
      "\t\n",
      "(13.1)\n",
      "But this is not a valid argument because Equation \n",
      "is not a list. The key property required for listing the elements in a countable set is that for any element in the set, you can determine its finite index in the list. For example, a\n",
      "i\n",
      " shows up in position i in Equation \n",
      ", but there is no index in the supposed list for any of the b\n",
      "i\n",
      " . Hence, Equation \n",
      "is not a valid list for the purposes of showing that A [ B is countable when A is infinite. Equation \n",
      "is only useful when A is finite.\n",
      "It turns out you really can add a countably infinite number of new elements to a countable set and still wind up with just a countably infinite set, but another argument is needed to prove this.\n",
      "Theorem 13.2.2. If A and B are countable sets, then so is A [ B.\n",
      "Proof. Suppose the list of distinct elements of A is a\n",
      "0\n",
      ", a\n",
      "1\n",
      ", . . . , and the list of B is b\n",
      "0\n",
      ", b\n",
      "1\n",
      ", . . . . Then a valid way to list all the elements of A [ B is\n",
      "a\n",
      "0\n",
      "; b\n",
      "0\n",
      "; a\n",
      "1\n",
      "; b\n",
      "1\n",
      "; : : : ; a\n",
      "n\n",
      "; b\n",
      "n\n",
      "; : : : :\n",
      "\t\n",
      "(13.2)\n",
      "Of course this list will contain duplicates if A and B have elements in common, but then deleting all but the first occurrence of each element in Equation \n",
      "leaves a\n",
      "list of all the distinct elements of A and B.\n",
      "Note that the list in Equation \n",
      "does not have the same defect as the purported list in Equation \n",
      ", since every item in A [ B has a finite index in the list created in Theorem \n",
      ".\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 383  #389\n",
      "\n",
      "b\n",
      "0\n",
      "\tb\n",
      "1\n",
      "\tb\n",
      "2\n",
      "\tb\n",
      "3\n",
      "\t\n",
      ": : :\n",
      "a\n",
      "0\n",
      "\t\n",
      "c\n",
      "0\n",
      "a\n",
      "1\n",
      "\t\n",
      "c\n",
      "3\n",
      "a\n",
      "2\n",
      "\t\n",
      "c\n",
      "8\n",
      "a\n",
      "3\n",
      "\t\n",
      "c\n",
      "15\n",
      ":\n",
      ":\n",
      ":\n",
      "\n",
      "\n",
      "\n",
      ":\n",
      ":\n",
      ":\n",
      "Figure 13.1\n",
      "\t\n",
      "A listing of the elements of C D A\n",
      "\t\n",
      "B where A D fa\n",
      "0\n",
      "; a\n",
      "1\n",
      "; a\n",
      "2\n",
      "; : : : g\n",
      "and B D fb\n",
      "0\n",
      "; b\n",
      "1\n",
      "; b\n",
      "2\n",
      "; : : : g are countably infinite sets. For example, c\n",
      "5\n",
      " D .a\n",
      "1\n",
      "; b\n",
      "2\n",
      "/.\n",
      "13.2.3\n",
      "\t\n",
      "Cross Products\n",
      "Somewhat surprisingly, cross products of countable sets are also countable. At first, you might be tempted to think that infinity times infinity (whatever that means) somehow results in a larger infinity, but this is not the case.\n",
      "Theorem 13.2.3. The cross product of two countable sets is countable.\n",
      "Proof. Let A and B be any pair of countable sets. To show that C D A B is also countable, we need to find a listing of the elements\n",
      "f .a; b/ j a 2 A; b 2 B g:\n",
      "There are many such listings. One is shown in Figure \n",
      "for the case when A and B are both infinite sets. In this listing, .a\n",
      "i\n",
      " ; b\n",
      "j\n",
      " / is the kth element in the list for C where\n",
      "a\n",
      "i\n",
      " is the ith element in A,\n",
      "b\n",
      "j\n",
      " is the j th element in B, and\n",
      "k D max.i; j /\n",
      "2\n",
      " C i C max.i\tj; 0/:\n",
      "The task of finding a listing when one or both of A and B are finite is left to the problems at the end of the chapter.\n",
      "13.2.4\n",
      "\t\n",
      "Q Is Countable\n",
      "Theorem \n",
      "also has a surprising Corollary; namely that the set of rational numbers is countable.\n",
      "Corollary 13.2.4. The set of rational numbers Q is countable.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 384  #390\n",
      "\n",
      "384\n",
      "\t\n",
      "Chapter 13\n",
      "\t\n",
      "Infinite Sets\n",
      "Proof. Since Z Z is countable by Theorem \n",
      ", it suffices to find a surjection f from Z Z to Q. This is easy to to since\n",
      "(\n",
      "f .a; b/ D\n",
      "\n",
      "\n",
      "a=b\n",
      "\t\n",
      "if b  0\n",
      "0\n",
      "\t\n",
      "if b D 0\n",
      "is one such surjection.\n",
      "At this point, you may be thinking that every set is countable. That is not the case. In fact, as we will shortly see, there are many infinite sets that are uncountable, including the set of real numbers R.\n",
      "\n",
      "13.3\n",
      "\t\n",
      "Power Sets Are Strictly Bigger\n",
      "It turns out that the ideas behind Russells Paradox, which caused so much trouble for the early efforts to formulate Set Theory, also lead to a correct and astonishing fact discovered by Georg Cantor in the late nineteenth century: infinite sets are not all the same size.\n",
      "Theorem 13.3.1. For any set A, the power set P.A/ is strictly bigger than A.\n",
      "Proof. First of all, P.A/ is as big as A: for example, the partial function f W P.A/ ! A where f .fag/ WWD a for a 2 A is a surjection.\n",
      "To show that P.A/ is strictly bigger than A, we have to show that if g is a function from A to P.A/, then g is not a surjection. So, mimicking Russells Paradox, define\n",
      "A\n",
      "g\n",
      " WWD f a 2 A j a\n",
      "\t\n",
      "g.a/ g:\n",
      "A\n",
      "g\n",
      " is a well-defined subset of A, which means it is a member of P.A/. But A\n",
      "g\n",
      " cant be in the range of g, because if it were, we would have\n",
      "A\n",
      "g\n",
      " D g.a\n",
      "0\n",
      "/\n",
      "for some a\n",
      "0\n",
      " 2 A. So by definition of A\n",
      "g\n",
      " ,\n",
      "a 2 g.a\n",
      "0\n",
      "/\n",
      "\t\n",
      "iff\n",
      "\t\n",
      "a 2 A\n",
      "g\n",
      "\t\n",
      "iff\n",
      "\t\n",
      "a\tg.a/\n",
      "for all a 2 A. Now letting a D a\n",
      "0\n",
      " yields the contradiction\n",
      "a\n",
      "0\n",
      " 2 g.a\n",
      "0\n",
      "/\n",
      "\t\n",
      "iff\n",
      "\t\n",
      "a\n",
      "0\n",
      "\tg.a\n",
      "0\n",
      "/:\n",
      "So g is not a surjection, because there is an element in the power set of A, namely\n",
      "the set A\n",
      "g\n",
      " , that is not in the range of g.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 385  #391\n",
      "\n",
      "13.3.1\n",
      "\t\n",
      "R Is Uncountable\n",
      "To prove that the set of real numbers is uncountable, we will show that there is a surjection from R to P.N/ and then apply Theorem \n",
      "to P.N/.\n",
      "Lemma 13.3.2. R surj P.N/.\n",
      "Proof. Let A N be any subset of the natural numbers. Since N is countable, this means that A is countable and thus that A D fa\n",
      "0\n",
      "; a\n",
      "1\n",
      "; a\n",
      "2\n",
      "; : : : g. For each i 0, define bin.a\n",
      "i\n",
      " / to be the binary representation of a\n",
      "i\n",
      " . Let x\n",
      "A\n",
      " be the real number using only digits 0, 1, 2 as follows:\n",
      "We can then define a surjection f W R ! P.N/ as follows:\n",
      "(\n",
      "f .x/\n",
      " \n",
      "D\n",
      "\t\n",
      "A\n",
      "\t\n",
      "if x D x\n",
      "A\n",
      " \n",
      "for some\n",
      " \n",
      "A\n",
      " \n",
      "2\n",
      " \n",
      "N;\n",
      "otherwise:\n",
      "Hence R surj P.N/.\n",
      "Corollary 13.3.3. R is uncountable.\n",
      "Proof. By contradiction. Assume R is countable. Then N surj R. By Lemma \n",
      ", R surj P.N/. Hence N surj P.N/. This contradicts Theorem \n",
      "for the case\n",
      "when A D N.\n",
      "So the set of rational numbers and the set of natural numbers have the same size, but the set of real numbers is strictly larger. In fact, R bij P.N /, but we wont prove that here.\n",
      "Is there anything bigger?\n",
      "13.3.2\tEven Larger Infinities\n",
      "There are lots of different sizes of infinite sets. For example, starting with the infinite set N of nonnegative integers, we can build the infinite sequence of sets\n",
      "N; P.N/; P.P.N//; P.P.P.N///; : : :\n",
      "By Theorem \n",
      ", each of these sets is strictly bigger than all the preceding ones. But thats not all, the union of all the sets in the sequence is strictly bigger than each set in the sequence. In this way, you can keep going, building still bigger infinities.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 386  #392\n",
      "\n",
      "386\n",
      "\t\n",
      "Chapter 13\n",
      "\t\n",
      "Infinite Sets\n",
      "13.3.3\n",
      "\t\n",
      "The Continuum Hypothesis\n",
      "Georg Cantor was the mathematician who first developed the theory of infinite sizes (because he thought he needed it in his study of Fourier series). Cantor raised the question whether there is a set whose size is strictly between the smallest infinite set, N, and P.N/. He guessed not:\n",
      "Cantors Continuum Hypothesis. There is no set A such that P.N/ is strictly bigger than A and A is strictly bigger than N.\n",
      "The Continuum Hypothesis remains an open problem a century later. Its diffi-culty arises from one of the deepest results in modern Set Theorydiscovered in part by Godel in the 1930s and Paul Cohen in the 1960snamely, the ZFC axioms are not sufficient to settle the Continuum Hypothesis: there are two collections of sets, each obeying the laws of ZFC, and in one collection, the Continuum Hy-pothesis is true, and in the other, it is false. So settling the Continuum Hypothesis requires a new understanding of what sets should be to arrive at persuasive new axioms that extend ZFC and are strong enough to determine the truth of the Con-tinuum Hypothesis one way or the other.\n",
      "\n",
      "13.4\n",
      "\t\n",
      "Infinities in Computer Science\n",
      "If the romance of different size infinities and continuum hypotheses doesnt appeal to you, not knowing about them is not going to lower your professional abilities as a computer scientist. These abstract issues about infinite sets rarely come up in mainstream mathematics, and they dont come up at all in computer science, where the focus is generally on countable, and often just finite, sets. In practice, only logicians and set theorists have to worry about collections that are too big to be sets. In fact, at the end of the 19th century, even the general mathematical community doubted the relevance of what they called Cantors paradise of unfamiliar sets of arbitrary infinite size.\n",
      "That said, it is worth noting that the proof of Theorem \n",
      "gives the simplest form of what is known as a diagonal argument. Diagonal arguments are used to prove many fundamental results about the limitations of computation, such as the undecidability of the Halting Problem for programs and the inherent, unavoid-able inefficiency (exponential time or worse) of procedures for other computational problems. So computer scientists do need to study diagonal arguments in order to understand the logical limits of computation. Ad a well-educated computer scien-tist will be comfortable dealing with countable sets, finite as well as infinite.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 387  #393\n",
      "\n",
      "IV\n",
      "\t\n",
      "Probability\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 388  #394\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 389  #395\n",
      "\n",
      "Introduction\n",
      "Probability is one of the most important disciplines in all of the sciences. It is also one of the least well understood.\n",
      "Probability is especially important in computer scienceit arises in virtually every branch of the field. In algorithm design and game theory, for example, ran-domized algorithms and strategies (those that use a random number generator as a key input for decision making) frequently outperform deterministic algorithms and strategies. In information theory and signal processing, an understanding of ran-domness is critical for filtering out noise and compressing data. In cryptography and digital rights management, probability is crucial for achieving security. The list of examples is long.\n",
      "Given the impact that probability has on computer science, it seems strange that probability should be so misunderstood by so many. Perhaps the trouble is that basic human intuition is wrong as often as it is right when it comes to problems involving random events. As a consequence, many students develop a fear of prob-ability. Indeed, we have witnessed many graduate oral exams where a student will solve the most horrendous calculation, only to then be tripped up by the simplest probability question. Indeed, even some faculty will start squirming if you ask them a question that starts What is the probability that. . . ?\n",
      "Our goal in the remaining chapters is to equip you with the tools that will enable you to easily and confidently solve problems involving probability.\n",
      "We begin in Chapter \n",
      "with the basic definitions and an elementary 4-step pro-cess that can be used to determine the probability that a specified event occurs. We illustrate the method on two famous problems where your intuition will probably fail you.\n",
      "In Chapter \n",
      ", we describe conditional probability and the notion of indepen-dence. Both notions are important, and sometimes misused, in practice. We will\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 390  #396\n",
      "\n",
      "390\n",
      "\t\n",
      "Part IV\n",
      "\t\n",
      "Probability\n",
      "consider the probability of having a disease given that you tested positive, and the probability that a suspect is guilty given that his blood type matches the blood found at the scene of the crime.\n",
      "We study random variables and distributions in Chapter \n",
      ". Random variables provide a more quantitative way to measure random events. For example, instead of determining the probability that it will rain, we may want to determine how much or how long it is likely to rain. This is closely related to the notion of the expected value of a random variables, which we will consider in Chapter \n",
      ".\n",
      "In Chapter \n",
      ", we examine the probability that a random variable deviates sig-nificantly from its expected value. This is especially important in practice, where things are generally fine if they are going according to expectation, and you would like to be assured that the probability of deviating from the expectation is very low.\n",
      "We conclude in Chapter \n",
      "by combining the tools we have acquired to solve problems involving more complex random processes. We will see why you will probably never get very far ahead at the casino, and how two Stanford graduate students became gazillionaires by combining graph theory and probability theory to design a better search engine for the web.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 391  #397\n",
      "\n",
      "14\n",
      "\t\n",
      "Events and Probability Spaces\n",
      "\n",
      "14.1\n",
      "\t\n",
      "Lets Make a Deal\n",
      "In the September 9, 1990 issue of Parade magazine, columnist Marilyn vos Savant responded to this letter:\n",
      "Suppose youre on a game show, and youre given the choice of three doors. Behind one door is a car, behind the others, goats. You pick a door, say number 1, and the host, who knows whats behind the doors, opens another door, say number 3, which has a goat. He says to you, Do you want to pick door number 2? Is it to your advantage to switch your choice of doors?\n",
      "Craig. F. Whitaker\n",
      "Columbia, MD\n",
      "The letter describes a situation like one faced by contestants in the 1970s game show Lets Make a Deal, hosted by Monty Hall and Carol Merrill. Marilyn replied that the contestant should indeed switch. She explained that if the car was behind either of the two unpicked doorswhich is twice as likely as the the car being behind the picked doorthe contestant wins by switching. But she soon received a torrent of letters, many from mathematicians, telling her that she was wrong. The problem became known as the Monty Hall Problem and it generated thousands of hours of heated debate.\n",
      "This incident highlights a fact about probability: the subject uncovers lots of examples where ordinary intuition leads to completely wrong conclusions. So until youve studied probabilities enough to have refined your intuition, a way to avoid errors is to fall back on a rigorous, systematic approach such as the Four Step Method that we will describe shortly. First, lets make sure we really understand the setup for this problem. This is always a good thing to do when you are dealing with probability.\n",
      "14.1.1\n",
      "\t\n",
      "Clarifying the Problem\n",
      "Craigs original letter to Marilyn vos Savant is a bit vague, so we must make some assumptions in order to have any hope of modeling the game formally. For exam-ple, we will assume that:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 392  #398\n",
      "\n",
      "Chapter 14  Events and Probability Spaces\n",
      "The car is equally likely to be hidden behind each of the three doors.\n",
      "The player is equally likely to pick each of the three doors, regardless of the cars location.\n",
      "After the player picks a door, the host must open a different door with a goat behind it and offer the player the choice of staying with the original door or switching.\n",
      "If the host has a choice of which door to open, then he is equally likely to select each of them.\n",
      "In making these assumptions, were reading a lot into Craig Whitakers letter. Other interpretations are at least as defensible, and some actually lead to different an-swers. But lets accept these assumptions for now and address the question, What is the probability that a player who switches wins the car?\n",
      "\n",
      "14.2\n",
      "\t\n",
      "The Four Step Method\n",
      "Every probability problem involves some sort of randomized experiment, process, or game. And each such problem involves two distinct challenges:\n",
      "How do we model the situation mathematically?\n",
      "How do we solve the resulting mathematical problem?\n",
      "In this section, we introduce a four step approach to questions of the form, What is the probability that. . . ? In this approach, we build a probabilistic model step-by-step, formalizing the original question in terms of that model. Remarkably, the structured thinking that this approach imposes provides simple solutions to many famously-confusing problems. For example, as youll see, the four step method cuts through the confusion surrounding the Monty Hall problem like a Ginsu knife.\n",
      "14.2.1\n",
      "\t\n",
      "Step 1: Find the Sample Space\n",
      "Our first objective is to identify all the possible outcomes of the experiment. A typical experiment involves several randomly-determined quantities. For example, the Monty Hall game involves three such quantities:\n",
      "The door concealing the car.\n",
      "The door initially chosen by the player.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 393  #399\n",
      "\n",
      "car location\n",
      "\n",
      "A\n",
      "B\n",
      "C\n",
      "Figure 14.1 The first level in a tree diagram for the Monty Hall Problem. The branches correspond to the door behind which the car is located.\n",
      "3. The door that the host opens to reveal a goat.\n",
      "Every possible combination of these randomly-determined quantities is called an outcome. The set of all possible outcomes is called the sample space for the exper-iment.\n",
      "A tree diagram is a graphical tool that can help us work through the four step approach when the number of outcomes is not too large or the problem is nicely structured. In particular, we can use a tree diagram to help understand the sample space of an experiment. The first randomly-determined quantity in our experiment is the door concealing the prize. We represent this as a tree with three branches, as shown in Figure \n",
      ". In this diagram, the doors are called A, B, and C instead of 1, 2, and 3, because well be adding a lot of other numbers to the picture later.\n",
      "For each possible location of the prize, the player could initially choose any of the three doors. We represent this in a second layer added to the tree. Then a third layer represents the possibilities of the final step when the host opens a door to reveal a goat, as shown in Figure \n",
      ".\n",
      "Notice that the third layer reflects the fact that the host has either one choice or two, depending on the position of the car and the door initially selected by the player. For example, if the prize is behind door A and the player picks door B, then\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 394  #400\n",
      "\n",
      "394\n",
      "\t\n",
      "Chapter 14\n",
      "\t\n",
      "Events and Probability Spaces\n",
      "car location\n",
      "A\n",
      "B\n",
      "C\n",
      "\n",
      "\n",
      "players\n",
      "intial\n",
      "guess\n",
      "\n",
      "A\n",
      "B\n",
      "C\n",
      "A\n",
      "B\n",
      "C\n",
      "A\n",
      "B\n",
      "C\n",
      "\n",
      "\n",
      "door\n",
      "revealed\n",
      "B\n",
      "C\n",
      "C\n",
      "B\n",
      "C\n",
      "A\n",
      "C\n",
      "A\n",
      "B\n",
      "A\n",
      "A\n",
      "B\n",
      "Figure 14.2 The full tree diagram for the Monty Hall Problem. The second level indicates the door initially chosen by the player. The third level indicates the door revealed by Monty Hall.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 395  #401\n",
      "\n",
      "the host must open door C. However, if the prize is behind door A and the player picks door A, then the host could open either door B or door C.\n",
      "Now lets relate this picture to the terms we introduced earlier: the leaves of the tree represent outcomes of the experiment, and the set of all leaves represents the sample space. Thus, for this experiment, the sample space consists of 12 outcomes. For reference, weve labeled each outcome in Figure \n",
      "with a triple of doors indicating:\n",
      ".door concealing prize; door initially chosen; door opened to reveal a goat/:\n",
      "The tree diagram has a broader interpretation as well: we can regard the whole experiment as following a path from the root to a leaf, where the branch taken at each stage is randomly determined. Keep this interpretation in mind; well use it again later.\n",
      "14.2.2\n",
      "\t\n",
      "Step 2: Define Events of Interest\n",
      "Our objective is to answer questions of the form What is the probability that . . . ?, where, for example, the missing phrase might be the player wins by switching, the player initially picked the door concealing the prize, or the prize is behind door C. Each of these phrases characterizes a set of outcomes. For example, the outcomes specified by the prize is behind door C  is:\n",
      "f.C; A; B/; .C; B; A/; .C; C; A/; .C; C; B/g:\n",
      "A set of outcomes is called an event and it is a subset of the sample space. So the event that the player initially picked the door concealing the prize is the set:\n",
      "f.A; A; B/; .A; A; C /; .B; B; A/; .B; B; C /; .C; C; A/; .C; C; B/g:\n",
      "And what were really after, the event that the player wins by switching, is the set of outcomes:\n",
      "f.A; B; C /; .A; C; B/; .B; A; C /; .B; C; A/; .C; A; B/; .C; B; A/g:\n",
      "These outcomes are denoted with a check mark in Figure \n",
      ".\n",
      "Notice that exactly half of the outcomes are checked, meaning that the player wins by switching in half of all outcomes. You might be tempted to conclude that a player who switches wins with probability 1=2. This is wrong. The reason is that these outcomes are not all equally likely, as well see shortly.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 396  #402\n",
      "\n",
      "396\n",
      "\t\n",
      "Chapter 14\n",
      "\t\n",
      "Events and Probability Spaces\n",
      "car location\n",
      "A\n",
      "B\n",
      "C\n",
      "\n",
      "\n",
      "players\n",
      "intial\n",
      "guess\n",
      "\n",
      "A\n",
      "B\n",
      "C\n",
      "A\n",
      "B\n",
      "C\n",
      "A\n",
      "B\n",
      "C\n",
      "\n",
      "\n",
      "door\n",
      "revealed\n",
      "B\n",
      "C\n",
      "C\n",
      "B\n",
      "C\n",
      "A\n",
      "C\n",
      "A\n",
      "B\n",
      "A\n",
      "A\n",
      "B\n",
      "\n",
      "\n",
      "outcome\n",
      ".A;A;B/\n",
      ".A;A;C/\n",
      ".A;B;C/\n",
      ".A;C;B/\n",
      ".B;A;C/\n",
      ".B;B;A/\n",
      ".B;B;C/\n",
      ".B;C;A/\n",
      ".C;A;B/\n",
      ".C;B;A/\n",
      ".C;C;A/\n",
      ".C;C;B/\n",
      "Figure 14.3 The tree diagram for the Monty Hal Problem with the outcomes la-beled for each path from root to leaf. For example, outcome .A; A; B/ corresponds to the car being behind door A, the player initially choosing door A, and Monty Hall revealing the goat behind door B.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 397  #403\n",
      "\n",
      "car location\n",
      "A\n",
      "B\n",
      "C\n",
      "\n",
      "\n",
      "players\n",
      "intial\n",
      "guess\n",
      "\n",
      "A\n",
      "B\n",
      "C\n",
      "A\n",
      "B\n",
      "C\n",
      "A\n",
      "B\n",
      "C\n",
      "\n",
      "\n",
      "door\n",
      "revealed\n",
      "B\n",
      "C\n",
      "C\n",
      "B\n",
      "C\n",
      "A\n",
      "C\n",
      "A\n",
      "B\n",
      "A\n",
      "A\n",
      "B\n",
      "\n",
      "\n",
      "outcome\n",
      "\t\n",
      "switch wins\n",
      ".A;A;B/\n",
      ".A;A;C/\n",
      ".A;B;C/\n",
      ".A;C;B/\n",
      ".B;A;C/\n",
      ".B;B;A/\n",
      ".B;B;C/\n",
      ".B;C;A/\n",
      ".C;A;B/\n",
      ".C;B;A/\n",
      ".C;C;A/\n",
      ".C;C;B/\n",
      "Figure 14.4 The tree diagram for the Monty Hall Problem where the outcomes in the event where the player wins by switching are denoted with a check mark.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 398  #404\n",
      "\n",
      "398\n",
      "\t\n",
      "Chapter 14\n",
      "\t\n",
      "Events and Probability Spaces\n",
      "14.2.3\n",
      "\t\n",
      "Step 3: Determine Outcome Probabilities\n",
      "So far weve enumerated all the possible outcomes of the experiment. Now we must start assessing the likelihood of those outcomes. In particular, the goal of this step is to assign each outcome a probability, indicating the fraction of the time this outcome is expected to occur. The sum of all outcome probabilities must be one, reflecting the fact that there always is an outcome.\n",
      "Ultimately, outcome probabilities are determined by the phenomenon were mod-eling and thus are not quantities that we can derive mathematically. However, math-ematics can help us compute the probability of every outcome based on fewer and more elementary modeling decisions. In particular, well break the task of deter-mining outcome probabilities into two stages.\n",
      "Step 3a: Assign Edge Probabilities\n",
      "First, we record a probability on each edge of the tree diagram. These edge-probabilities are determined by the assumptions we made at the outset: that the prize is equally likely to be behind each door, that the player is equally likely to pick each door, and that the host is equally likely to reveal each goat, if he has a choice. Notice that when the host has no choice regarding which door to open, the single branch is assigned probability 1. For example, see Figure \n",
      ".\n",
      "Step 3b: Compute Outcome Probabilities\n",
      "Our next job is to convert edge probabilities into outcome probabilities. This is a purely mechanical process: the probability of an outcome is equal to the product of the edge-probabilities on the path from the root to that outcome. For example, the probability of the topmost outcome in Figure \n",
      ", .A; A; B/, is\n",
      "1\n",
      "3\n",
      " \n",
      "1\n",
      "3\n",
      " \n",
      "1\n",
      "2\n",
      "D\n",
      "18\n",
      "1\n",
      ":\n",
      "\n",
      "Theres an easy, intuitive justification for this rule. As the steps in an experiment progress randomly along a path from the root of the tree to a leaf, the probabilities on the edges indicate how likely the path is to proceed along each branch. For example, a path starting at the root in our example is equally likely to go down each of the three top-level branches.\n",
      "How likely is such a path to arrive at the topmost outcome, .A; A; B/? Well, there is a 1-in-3 chance that a path would follow the A-branch at the top level, a 1-in-3 chance it would continue along the A-branch at the second level, and 1-in-2 chance it would follow the B-branch at the third level. Thus, it seems that 1 path in 18 should arrive at the .A; A; B/ leaf, which is precisely the probability we assign it.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 399  #405\n",
      "\n",
      "car location\n",
      "1=3\n",
      "B 1=3\n",
      "C 1=3\n",
      "\n",
      "\n",
      "players\n",
      "intial\n",
      "guess\n",
      "\n",
      "1=3 B 1=3\n",
      "C 1=3\n",
      "1=3 B 1=3\n",
      "C 1=3\n",
      "A 1=3\n",
      "1=3 C 1=3\n",
      "\n",
      "\n",
      "door\n",
      "revealed\n",
      "B 1=2\n",
      "1=2\n",
      "1\n",
      "1 C  1\n",
      "A 1=2\n",
      "1=2 A 1\n",
      "1 A  1\n",
      "1=2 B 1=2\n",
      "\n",
      "\n",
      "outcome\n",
      "\t\n",
      "switch wins\n",
      ".A;A;B/\n",
      ".A;A;C/\n",
      ".A;B;C/\n",
      ".A;C;B/\n",
      ".B;A;C/\n",
      ".B;B;A/\n",
      ".B;B;C/\n",
      ".B;C;A/\n",
      ".C;A;B/\n",
      ".C;B;A/\n",
      ".C;C;A/\n",
      ".C;C;B/\n",
      "Figure 14.5 The tree diagram for the Monty Hall Problem where edge weights denote the probability of that branch being taken given that we are at the parent of that branch. For example, if the car is behind door A, then there is a 1/3 chance that the players initial selection is door B.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 400  #406\n",
      "\n",
      "400\n",
      "\t\n",
      "Chapter 14\n",
      "\t\n",
      "Events and Probability Spaces\n",
      "We have illustrated all of the outcome probabilities in Figure \n",
      ".\n",
      "Specifying the probability of each outcome amounts to defining a function that maps each outcome to a probability. This function is usually called Pr. In these terms, weve just determined that:\n",
      "Pr \n",
      ".A; A; B/\n",
      " D \n",
      "18\n",
      "1\n",
      ";\n",
      "\n",
      "Pr \n",
      ".A; A; C /\n",
      " D \n",
      "18\n",
      "1\n",
      ";\n",
      "\n",
      "Pr \n",
      ".A; B; C /\n",
      " D \n",
      "1\n",
      "9\n",
      ";\n",
      "\n",
      "etc.\n",
      "14.2.4\n",
      "\t\n",
      "Step 4: Compute Event Probabilities\n",
      "We now have a probability for each outcome, but we want to determine the proba-bility of an event. The probability of an event \n",
      "E\n",
      " is denoted by Pr \n",
      "E\n",
      " and it is the sum of the probabilities of the outcomes in \n",
      "E\n",
      ". For example, the probability of the event that the player wins by switching is:\n",
      "Pr switching wins D Pr \n",
      ".A; B; C /\n",
      " C Pr \n",
      ".A; C; B/\n",
      " C Pr \n",
      ".B; A; C /\n",
      " C Pr \n",
      ".B; C; A/\n",
      " C Pr \n",
      ".C; A; B/\n",
      " C Pr \n",
      ".C; B; A/\n",
      "D\n",
      "1\n",
      "9\n",
      "C\n",
      "1\n",
      "9\n",
      "C\n",
      "1\n",
      "9\n",
      "C\n",
      "1\n",
      "9\n",
      "C\n",
      "1\n",
      "9\n",
      "C\n",
      "1\n",
      "9\n",
      "\n",
      "2\n",
      "3\n",
      ":\n",
      "\n",
      "It seems Marilyns answer is correct! A player who switches doors wins the car with probability \n",
      "2=3\n",
      ". In contrast, a player who stays with his or her original door wins with probability \n",
      "1=3\n",
      ", since staying wins if and only if switching loses.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Were done with the problem! We didnt need any appeals to intuition or inge-nious analogies. In fact, no mathematics more difficult than adding and multiplying fractions was required. The only hard part was resisting the temptation to leap to an intuitively obvious answer.\n",
      "14.2.5\tAn Alternative Interpretation of the Monty Hall Problem\n",
      "Was Marilyn really right? Our analysis indicates that she was. But a more accurate\n",
      "conclusion is that her answer is correct provided we accept her interpretation of the\n",
      "\n",
      "Switching wins is shorthand for the set of outcomes where switching wins; namely, f.A; B; C /; .A; C; B/; .B; A; C /; .B; C; A/; .C; A; B/; .C; B; A/g. We will frequently use such shorthand to denote events.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 401  #407\n",
      "\n",
      "car location\n",
      "1=3\n",
      "B 1=3\n",
      "C 1=3\n",
      "\n",
      "\n",
      "players\n",
      "intial\n",
      "guess\n",
      "\n",
      "1=3 B 1=3\n",
      "C 1=3\n",
      "1=3 B 1=3\n",
      "C 1=3\n",
      "A 1=3\n",
      "1=3 C 1=3\n",
      "\n",
      "\n",
      "door\n",
      "revealed\n",
      "B 1=2\n",
      "C 1=2\n",
      "1 B  1\n",
      "1\n",
      "A 1=2\n",
      "C 1=2\n",
      "1 B  1\n",
      "1\n",
      "1=2 B 1=2\n",
      "\n",
      "\n",
      "Figure 14.6 The rightmost column shows the outcome probabilities for the Monty Hall Problem. Each outcome probability is simply the product of the prob-abilities on the branches on the path from the root to the leaf for that outcome.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 402  #408\n",
      "\n",
      "402\n",
      "\t\n",
      "Chapter 14\n",
      "\t\n",
      "Events and Probability Spaces\n",
      "\n",
      "a\n",
      "\t\n",
      "b\n",
      "\t\n",
      "c\n",
      "Figure 14.7 The strange dice. The number of pips on each concealed face is the same as the number on the opposite face. For example, when you roll die A, the probabilities of getting a 2, 6, or 7 are each 1=3.\n",
      "question. There is an equally plausible interpretation in which Marilyns answer is wrong. Notice that Craig Whitakers original letter does not say that the host is required to reveal a goat and offer the player the option to switch, merely that he did these things. In fact, on the Lets Make a Deal show, Monty Hall sometimes simply opened the door that the contestant picked initially. Therefore, if he wanted to, Monty could give the option of switching only to contestants who picked the correct door initially. In this case, switching never works!\n",
      "\n",
      "14.3\n",
      "\t\n",
      "Strange Dice\n",
      "The four-step method is surprisingly powerful. Lets get some more practice with it. Imagine, if you will, the following scenario.\n",
      "Its a typical Saturday night. Youre at your favorite pub, contemplating the true meaning of infinite cardinalities, when a burly-looking biker plops down on the stool next to you. Just as you are about to get your mind around P.P.R//, biker dude slaps three strange-looking dice on the bar and challenges you to a $100 wager.\n",
      "The rules are simple. Each player selects one die and rolls it once. The player with the lower value pays the other player $100.\n",
      "Naturally, you are skeptical. A quick inspection reveals that these are not ordi-nary dice. They each have six sides, but the numbers on the dice are different, as shown in Figure \n",
      ".\n",
      "Biker dude notices your hesitation and so he offers to let you pick a die first, and\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 403  #409\n",
      "\n",
      "then he will choose his die from the two that are left. That seals the deal since you figure that you now have an advantage.\n",
      "But which of the dice should you choose? Die B is appealing because it has a 9, which is a sure winner if it comes up. Then again, die A has two fairly large numbers and die B has an 8 and no really small values.\n",
      "In the end, you choose die B because it has a 9, and then biker dude selects die A. Lets see what the probability is that you will win.\n",
      "Not surprisingly, we will use the four-step method to compute this probability.\n",
      "14.3.1\n",
      "\t\n",
      "Die A versus Die B\n",
      "Step 1: Find the sample space.\n",
      "The sample space for this experiment is worked out in the tree diagram shown in Figure \n",
      ".\n",
      "For this experiment, the sample space is a set of nine outcomes:\n",
      "D f .2; 1/; .2; 5/; .2; 9/; .6; 1/; .6; 5/; .6; 9/; .7; 1/; .7; 5/; .7; 9/ g:\n",
      "Step 2: Define events of interest.\n",
      "We are interested in the event that the number on die A is greater than the number on die B. This event is a set of five outcomes:\n",
      "f .2; 1/; .6; 1/; .6; 5/; .7; 1/; .7; 5/ g:\n",
      "These outcomes are marked A in the tree diagram in Figure \n",
      ".\n",
      "Step 3: Determine outcome probabilities.\n",
      "To find outcome probabilities, we first assign probabilities to edges in the tree di-agram. Each number on each die comes up with probability 1=3, regardless of the value of the other die. Therefore, we assign all edges probability 1=3. The probability of an outcome is the product of the probabilities on the correspond-ing root-to-leaf path, which means that every outcome has probability 1=9. These probabilities are recorded on the right side of the tree diagram in Figure \n",
      ".\n",
      "Step 4: Compute event probabilities.\n",
      "The probability of an event is the sum of the probabilities of the outcomes in that event. In this case, all the outcome probabilities are the same. In general, when the probability of every outcome is the same, we say that the sample space is uniform. Computing event probabilities for uniform sample spaces is particularly easy since\n",
      "\n",
      "Of course, you probably should have done this before picking die B in the first place.\n",
      "Actually, the whole probability space is worked out in this one picture. But pretend that each component sort of fades innyyrrroom!as you read about the corresponding step below.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 404  #410\n",
      "\n",
      "404\n",
      "\t\n",
      "Chapter 14\n",
      "\t\n",
      "Events and Probability Spaces\n",
      "\n",
      "Figure 14.8 The tree diagram for one roll of die A versus die B. Die A wins with probability 5=9.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 405  #411\n",
      "\n",
      "you just have to compute the number of outcomes in the event. In particular, for any event \n",
      "E\n",
      " in a uniform sample space S,\n",
      "In this case, \n",
      "E\n",
      " is the event that die \n",
      "A\n",
      " beats die \n",
      "B\n",
      ", so j\n",
      "E\n",
      "j D \n",
      "5\n",
      ", jSj D \n",
      "9\n",
      ", and\n",
      "Pr \n",
      "E\n",
      " D \n",
      "5=9:\n",
      "This is bad news for you. Die \n",
      "A\n",
      " beats die \n",
      "B\n",
      " more than half the time and, not surprisingly, you just lost $100.\n",
      "Biker dude consoles you on your bad luck and, given that hes a sensitive guy beneath all that leather, he offers to go double or nothing.\n",
      "Given that your wallet only has $25 in it, this sounds like a good plan. Plus, you figure that choosing die \n",
      "A\n",
      " will give you the advantage.\n",
      "So you choose \n",
      "A\n",
      ", and then biker dude chooses \n",
      "C\n",
      " . Can you guess who is more likely to win? (Hint: it is generally not a good idea to gamble with someone you dont know in a bar, especially when you are gambling with strange dice.)\n",
      "14.3.2\n",
      "\t\n",
      "Die A versus Die C\n",
      "We can construct the three diagram and outcome probabilities as before. The result is shown in Figure \n",
      "and there is bad news again. Die \n",
      "C\n",
      " will beat die \n",
      "A\n",
      " with probability \n",
      "5=9\n",
      ", and you lose once again.\n",
      "You now owe the biker dude $200 and he asks for his money. You reply that you need to go to the bathroom.\n",
      "Being a sensitive guy, biker dude nods understandingly and offers yet another wager. This time, hell let you have die \n",
      "C\n",
      " . Hell even let you raise the wager to $200 so you can win your money back.\n",
      "This is too good a deal to pass up. You know that die \n",
      "C\n",
      " is likely to beat die \n",
      "A\n",
      " and that die \n",
      "A\n",
      " is likely to beat die \n",
      "B\n",
      ", and so die \n",
      "C\n",
      " is surely the best. Whether biker dude picks \n",
      "A\n",
      " or \n",
      "B\n",
      ", the odds are surely in your favor this time. Biker dude must really be a nice guy.\n",
      "So you pick \n",
      "C\n",
      " , and then biker dude picks \n",
      "B\n",
      ". Lets use the tree method to figure out the probability that you win.\n",
      "\n",
      "Double or nothing is slang for doing another wager after you have lost the first. If you lose again, you will owe biker dude double what you owed him before. If you win, you will now be even and you will owe him nothing.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 406  #412\n",
      "\n",
      "406\n",
      "\t\n",
      "Chapter 14\n",
      "\t\n",
      "Events and Probability Spaces\n",
      "\n",
      "Figure 14.9 The tree diagram for one roll of die C versus die A. Die C wins with probability 5=9.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 407  #413\n",
      "\n",
      "\n",
      "Figure 14.10 The tree diagram for one roll of die B versus die C . Die B wins with probability 5=9.\n",
      "14.3.3\n",
      "\t\n",
      "Die B versus Die C\n",
      "The tree diagram and outcome probabilities for B versus C are shown in Fig-ure \n",
      ". But surely there is a mistake! The data in Figure \n",
      "shows that die B wins with probability 5=9. How is it possible that\n",
      "beats A with probability 5=9,\n",
      "A beats B with probability 5=9, and\n",
      "B beats C with probability 5=9?\n",
      "The problem is not with the math, but with your intuition. It seems that the likely-to-beat relation should be transitive. But it is not, and whatever die you pick, biker dude can pick one of the others and be likely to win. So picking first is a big disadvantage and you now owe biker dude $400.\n",
      "Just when you think matters cant get worse, biker dude offers you one final wager for $1,000. This time, you demand to choose second. Biker dude agrees,\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 408  #414\n",
      "\n",
      "\n",
      "Figure 14.11 Parts of the tree diagram for die B versus die A where each die is rolled twice. The first two levels are shown in (a). The last two levels consist of nine copies of the tree in (b).\n",
      "but with the condition that instead of rolling each die once, you each roll your die twice and your score is the sum of your rolls.\n",
      "Believing that you finally have a winning wager, you agree.\n",
      "Biker dude chooses die B and, of course, you grab die A. Thats because you know that die A will beat die B with probability 5=9 on one roll and so surely two rolls of die A are likely to beat two rolls of die B, right?\n",
      "Wrong!\n",
      "14.3.4\n",
      "\t\n",
      "Rolling Twice\n",
      "If each player rolls twice, the tree diagram will have four levels and 3\n",
      "4\n",
      " D 81 out-comes. This means that it will take a while to write down the entire tree diagram. We can, however, easily write down the first two levels (as we have done in Fig-ure \n",
      "(a)) and then notice that the remaining two levels consist of nine identical copies of the tree in Figure \n",
      "(b).\n",
      "The probability of each outcome is .1=3/\n",
      "4\n",
      " D 1=81 and so, once again, we have a uniform probability space. By Equation \n",
      ", this means that the probability that A wins is the number of outcomes where A beats B divided by 81.\n",
      "To compute the number of outcomes where A beats B, we observe that the sum\n",
      "\n",
      "Did we mention that playing strange gambling games with strangers in a bar is a bad idea?\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 409  #415\n",
      "\n",
      "of the two rolls of die A is equally likely to be any element of the following multiset:\n",
      "S\n",
      "A\n",
      " D f4; 8; 8; 9; 9; 12; 13; 13; 14g:\n",
      "The sum of two rolls of die B is equally likely to be any element of the following multiset:\n",
      "S\n",
      "B\n",
      " D f2; 6; 6; 10; 10; 10; 14; 14; 18g:\n",
      "We can treat each outcome as a pair .x; y/ 2 S\n",
      "A\n",
      " S\n",
      "B\n",
      " , where A wins iff x > y. If x D 4, there is only one y (namely y D 2) for which x > y. If x D 8, there are three values of y for which x > y. Continuing the count in this way, the number of pairs for which x > y is\n",
      "1C3C3C3C3C6C6C6C6D37:\n",
      "A similar count shows that there are 42 pairs for which x > y, and there are two pairs (.14; 14/, .14; 14/) which result in ties. This means that A loses to B with probability 42=81 > 1=2 and ties with probability 2=81. Die A wins with probability only 37=81.\n",
      "How can it be that A is more likely than B to win with 1 roll, but B is more likely to win with 2 rolls?!? Well, why not? The only reason wed think otherwise is our (faulty) intuition. In fact, the die strength reverses no matter which two die we picked. So for 1 roll,\n",
      "A\tB\tC\tA;\n",
      "but for two rolls,\n",
      "A\tB\tC\tA;\n",
      "where we have used the symbols and to denote which die is more likely to result in the larger value. This is surprising even to us, but at least we dont owe biker dude $1400.\n",
      "14.3.5\n",
      "\t\n",
      "Even Stranger Dice\n",
      "Now that we know that strange things can happen with strange dice, it is natural, at least for mathematicians, to ask how strange things can get. It turns out that things can get very strange. In fact, mathematicians\n",
      "recently made the following discovery:\n",
      "Theorem 14.3.1. For any n 2, there is a set of n dice D\n",
      "1\n",
      ", D\n",
      "2\n",
      ", . . . , D\n",
      "n\n",
      " such that for any n-node tournament graph\n",
      "G, there is a number of rolls k such that if each\n",
      "\n",
      "Reference Ron Graham paper.\n",
      "Recall that a tournament graph is a directed graph for which there is precisely one directed edge between any two distinct nodes. In other words, for every pair of distinct nodes u and v, either u beats v or v beats u, but not both.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 410  #416\n",
      "\n",
      "\n",
      "\n",
      "Figure 14.12 All possible relative strengths for three dice D\n",
      "1\n",
      ", D\n",
      "2\n",
      ", and D\n",
      "3\n",
      ". The edge D\n",
      "i\n",
      " ! D\n",
      "j\n",
      " denotes that the sum of rolls for D\n",
      "i\n",
      " is likely to be greater than the sum of rolls for D\n",
      "j\n",
      " .\n",
      "die is rolled k times, then for all i  j , the sum of the k rolls for D\n",
      "i\n",
      " will exceed the sum for D\n",
      "j\n",
      " with probability greater than 1=2 iff D\n",
      "i\n",
      " ! D\n",
      "j\n",
      " is in G.\n",
      "It will probably take a few attempts at reading Theorem \n",
      "to understand what it is saying. The idea is that for some sets of dice, by rolling them different numbers of times, the dice have varying strengths relative to each other. (This is what we observed for the dice in Figure \n",
      ".) Theorem \n",
      "says that there is a set of (very) strange dice where every possible collection of relative strengths can be observed by varying the number of rolls. For example, the eight possible relative strengths for n D 3 dice are shown in Figure \n",
      ".\n",
      "Our analysis for the dice in Figure \n",
      "showed that for 1 roll, we have the relative strengths shown in Figure \n",
      "(a), and for two rolls, we have the (reverse) relative strengths shown in Figure \n",
      "(b). Can you figure out what other relative strengths are possible for the dice in Figure \n",
      "by using more rolls? This might be worth doing if you are prone to gambling with strangers in bars.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 411  #417\n",
      "\n",
      "\n",
      "14.4\n",
      "\t\n",
      "Set Theory and Probability\n",
      "The study of probability is very closely tied to set theory. That is because any set can be a sample space and any subset can be an event. This means that most of the rules and identities that we have developed for sets extend very naturally to probability. Well cover several examples in this section, but first lets review some definitions that should already be familiar.\n",
      "14.4.1\n",
      "\t\n",
      "Probability Spaces\n",
      "Definition 14.4.1. A countable\n",
      "sample space S is a nonempty countable set. An element \n",
      "w\n",
      " 2 S is called an outcome. A subset of S is called an event.\n",
      "Definition 14.4.2. A probability function on a sample space S is a total function Pr W S ! R such that\n",
      "Pr \n",
      "w   0\n",
      " for all \n",
      "w\n",
      " 2 S, and\n",
      "P\n",
      "w2S\n",
      " Pr \n",
      "w\n",
      " D \n",
      "1\n",
      ".\n",
      "A sample space together with a probability function is called a probability space. For any event \n",
      "E\n",
      " S, the probability of \n",
      "E\n",
      " is defined to be the sum of the probabil-ities of the outcomes in \n",
      "E\n",
      ":\n",
      "14.4.2\n",
      "\t\n",
      "Probability Rules from Set Theory\n",
      "An immediate consequence of the definition of event probability is that for disjoint events \n",
      "E\n",
      " and \n",
      "F\n",
      " ,\n",
      "Pr \n",
      "E\n",
      " [ \n",
      "F\n",
      " D Pr \n",
      "E\n",
      " C Pr \n",
      "F :\n",
      "This generalizes to a countable number of events, as follows.\n",
      "Rule 14.4.3 (Sum Rule). If f\n",
      "E\n",
      "0\n",
      "; E\n",
      "1\n",
      "; : : :\n",
      " g is collection of disjoint events, then\n",
      "#\n",
      "[\n",
      "\t\n",
      "X\n",
      "Pr\n",
      "\t\n",
      "E\n",
      "n\n",
      "\t\n",
      "D\n",
      "\t\n",
      "Pr \n",
      "E\n",
      "n\n",
      " \n",
      ":\n",
      "n2N\n",
      "\t\n",
      "n2N\n",
      "\n",
      "Yes, sample spaces can be infinite. Well see some examples shortly. If you did not read Chap-ter \n",
      ", dont worrycountable means that you can list the elements of the sample space as w\n",
      "1\n",
      ", w\n",
      "2\n",
      ", w\n",
      "3\n",
      ", . . . .\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 412  #418\n",
      "\n",
      "412\n",
      "\t\n",
      "Chapter 14\n",
      "\t\n",
      "Events and Probability Spaces\n",
      "The Sum Rule lets us analyze a complicated event by breaking it down into simpler cases. For example, if the probability that a randomly chosen MIT student is native to the United States is 60%, to Canada is 5%, and to Mexico is 5%, then the probability that a random MIT student is native to North America is 70%.\n",
      "Another consequence of the Sum Rule is that Pr \n",
      "A\n",
      " C Pr \n",
      "A\n",
      " D \n",
      "1\n",
      ", which follows because Pr S D \n",
      "1\n",
      " and S is the union of the disjoint sets \n",
      "A\n",
      " and \n",
      "A\n",
      ". This equation often comes up in the form:\n",
      "\n",
      "Rule 14.4.4 (Complement Rule).\n",
      "Pr \n",
      "A\n",
      " D \n",
      "1\n",
      "\t\n",
      "Pr \n",
      "A :\n",
      "\n",
      "Sometimes the easiest way to compute the probability of an event is to compute the probability of its complement and then apply this formula.\n",
      "Some further basic facts about probability parallel facts about cardinalities of finite sets. In particular:\n",
      "The Difference Rule follows from the Sum Rule because \n",
      "B\n",
      " is the union of the disjoint sets \n",
      "B A\n",
      " and \n",
      "A\n",
      " \\ \n",
      "B\n",
      ". Inclusion-Exclusion then follows from the Sum and Difference Rules, because \n",
      "A\n",
      " [ \n",
      "B\n",
      " is the union of the disjoint sets \n",
      "A\n",
      " and \n",
      "B\n",
      " \n",
      "A\n",
      ". Booles inequality is an immediate consequence of Inclusion-Exclusion since\n",
      " \n",
      "probabilities are nonnegative. Monotonicity follows from the definition of event probability and the fact that outcome probabilities are nonnegative.\n",
      "The two-event Inclusion-Exclusion equation above generalizes to \n",
      "n\n",
      " events in the same way as the corresponding Inclusion-Exclusion rule for \n",
      "n\n",
      " sets. Booles inequality also generalizes to\n",
      "Pr \n",
      "E\n",
      "1\n",
      " [\n",
      "\t\n",
      "[ \n",
      "E\n",
      "n\n",
      "\t\n",
      "Pr \n",
      "E\n",
      "1\n",
      " C\n",
      "\t\n",
      "C Pr \n",
      "E\n",
      "n\n",
      " \n",
      ":\n",
      "\t\n",
      "(Union Bound)\n",
      "This simple Union Bound is useful in many calculations. For example, suppose that \n",
      "E\n",
      "i\n",
      " is the event that the \n",
      "i\n",
      "-th critical component in a spacecraft fails. Then\n",
      "E\n",
      "1\n",
      " \n",
      "[\n",
      "\t\n",
      "[ \n",
      "E\n",
      "n\n",
      " is the event that some critical component fails.  If \n",
      "P\n",
      "n\n",
      "\t\n",
      "Pr \n",
      "E\n",
      "i\n",
      "iD1\n",
      "is small, then the Union Bound can give an adequate upper bound on this vital probability.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 413  #419\n",
      "\n",
      "14.4.3\n",
      "\t\n",
      "Uniform Probability Spaces\n",
      "Definition 14.4.5. A finite probability space S, Pr is said to be uniform if Pr \n",
      "w\n",
      " is the same for every outcome \n",
      "w\n",
      " 2 S.\n",
      "As we saw in the strange dice problem, uniform sample spaces are particularly easy to work with. Thats because for any event \n",
      "E\n",
      " S,\n",
      "This means that once we know the cardinality of \n",
      "E\n",
      " and S, we can immediately obtain Pr \n",
      "E\n",
      " . Thats great news because we developed lots of tools for computing the cardinality of a set in Part \n",
      ".\n",
      "For example, suppose that you select five cards at random from a standard deck of 52 cards. What is the probability of having a full house? Normally, this question would take some effort to answer. But from the analysis in Section \n",
      ", we know that\n",
      "where \n",
      "E\n",
      " is the event that we have a full house. Since every five-card hand is equally likely, we can apply Equation \n",
      "to find that\n",
      "1312465432\n",
      "52 51 50 49 48\n",
      "12495\n",
      "18\n",
      "\n",
      "694\n",
      "1\n",
      ":\n",
      "\n",
      "14.5\n",
      "\t\n",
      "Infinite Probability Spaces\n",
      "General probability theory deals with uncountable sets like R, but in computer sci-ence, it is usually sufficient to restrict our attention to countable probability spaces.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 414  #420\n",
      "\n",
      "414\n",
      "\t\n",
      "Chapter 14\n",
      "\t\n",
      "Events and Probability Spaces\n",
      "\n",
      "Figure 14.13 The tree diagram for the game where players take turns flipping a fair coin. The first player to flip heads wins.\n",
      "Its also a lot easierinfinite sample spaces are hard enough to work with without having to deal with uncountable spaces.\n",
      "Infinite probability spaces are fairly common. For example, two players take turns flipping a fair coin. Whoever flips heads first is declared the winner. What is the probability that the first player wins? A tree diagram for this problem is shown in Figure \n",
      ".\n",
      "The event that the first player wins contains an infinite number of outcomes, but we can still sum their probabilities:\n",
      "Similarly, we can compute the probability that the second player wins:\n",
      "In this case, the sample space is the infinite set\n",
      "S WWD f T\n",
      "n\n",
      "H j \n",
      "n\n",
      " 2 N g\n",
      ";\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 415  #421\n",
      "\n",
      "where T\n",
      "n\n",
      " stands for a length \n",
      "n\n",
      " string of Ts. The probability function is\n",
      "Pr T\n",
      "n\n",
      "H WWD \n",
      "2\n",
      "n\n",
      "1\n",
      "C1\n",
      " \n",
      ":\n",
      "\n",
      "To verify that this is a probability space, we just have to check that all the probabili-ties are nonnegative and that they sum to 1. Nonnegativity is obvious, and applying the formula for the sum of a geometric series, we find that\n",
      "Notice that this model does not have an outcome corresponding to the possibility that both players keep flipping tails forever.\n",
      "Thats because the probability of flipping forever would be\n",
      "and outcomes with probability zero will have no impact on our calculations.\n",
      "\n",
      "In the diagram, flipping forever corresponds to following the infinite path in the tree without ever reaching a leaf or outcome. Some texts deal with this case by adding a special infinite sample point w\n",
      "forever\n",
      " to the sample space, but we will follow the more traditional approach of excluding such sample points, as long as they collectively have probability 0.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 416  #422\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 417  #423\n",
      "\n",
      "15\n",
      "\t\n",
      "Conditional Probability\n",
      "\n",
      "15.1\tDefinition\n",
      "Suppose that we pick a random person in the world. Everyone has an equal chance of being selected. Let A be the event that the person is an MIT student, and let B be the event that the person lives in Cambridge. What are the probabilities of these events? Intuitively, were picking a random point in the big ellipse shown in Figure \n",
      "and asking how likely that point is to fall into region A or B.\n",
      "\n",
      "\n",
      " set of all people\n",
      "in the world\n",
      "A\n",
      "set of MIT\n",
      "students\n",
      "B\n",
      "\n",
      " set of people\n",
      "who live in\n",
      "Cambridge\n",
      "Figure 15.1 Selecting a random person. A is the event that the person is an MIT student. B is the even that the person lives in Cambridge.\n",
      "The vast majority of people in the world neither live in Cambridge nor are MIT students, so events A and B both have low probability. But what about the prob-ability that a person is an MIT student, given that the person lives in Cambridge? This should be much greaterbut what is it exactly?\n",
      "What were asking for is called a conditional probability; that is, the probability that one event happens, given that some other event definitely happens. Questions about conditional probabilities come up all the time:\n",
      "What is the probability that it will rain this afternoon, given that it is cloudy this morning?\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 418  #424\n",
      "\n",
      "Chapter 15  Conditional Probability\n",
      "What is the probability that two rolled dice sum to 10, given that both are odd?\n",
      "What is the probability that Ill get four-of-a-kind in Texas No Limit Hold Em Poker, given that Im initially dealt two queens?\n",
      " \n",
      "There is a special notation for conditional probabilities. In general, Pr \n",
      "A\n",
      " j \n",
      "B\n",
      " denotes the probability of event \n",
      "A\n",
      ", given that event \n",
      "B\n",
      " happens. So, in our example,\n",
      "Pr \n",
      "A\n",
      " j \n",
      "B\n",
      " is the probability that a random person is an MIT student, given that he or she is a Cambridge resident.\n",
      "How do we compute Pr \n",
      "A\n",
      " j \n",
      "B\n",
      " ? Since we are given that the person lives in Cambridge, we can forget about everyone in the world who does not. Thus, all\n",
      " \n",
      "outcomes outside event \n",
      "B\n",
      " are irrelevant. So, intuitively, Pr \n",
      "A\n",
      " j \n",
      "B\n",
      " should be the fraction of Cambridge residents that are also MIT students; that is, the answer should be the probability that the person is in set \n",
      "A\n",
      " \\ \n",
      "B\n",
      " (the darkly shaded region in Figure \n",
      ") divided by the probability that the person is in set \n",
      "B\n",
      " (the lightly shaded region). This motivates the definition of conditional probability:\n",
      "worse! Conditioning can subtly alter probabilities and produce unexpected results in randomized algorithms and computer systems as well as in betting games. Yet, the mathematical definition of conditional probability given above is very simple and should give you no troubleprovided that you rely on formal reasoning and not intuition. The four-step method will also be very helpful as we will see in the next examples.\n",
      "\n",
      "15.2\tUsing the Four-Step Method to Determine Conditional Probability\n",
      "15.2.1\tThe Halting Problem\n",
      "The Halting Problem was the first example of a property that could not be tested by any program. It was introduced by Alan Turing in his seminal 1936 paper. The problem is to determine whether a Turing machine halts on a given . . . yadda yadda\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 419  #425\n",
      "\n",
      "yadda . . . more importantly, it was the name of the MIT EECS departments famed C-league hockey team.\n",
      "In a best-of-three tournament, the Halting Problem wins the first game with prob-ability 1=2. In subsequent games, their probability of winning is determined by the outcome of the previous game. If the Halting Problem won the previous game, then they are invigorated by victory and win the current game with probability 2=3. If they lost the previous game, then they are demoralized by defeat and win the current game with probability only 1=3. What is the probability that the Halting Problem wins the tournament, given that they win the first game?\n",
      "This is a question about a conditional probability. Let A be the event that the Halting Problem wins the tournament, and let B be the event that they win the first\n",
      " \n",
      "game. Our goal is then to determine the conditional probability Pr A j B .\n",
      "We can tackle conditional probability questions just like ordinary probability problems: using a tree diagram and the four step method. A complete tree diagram is shown in Figure \n",
      ".\n",
      "game 1\n",
      "\t\n",
      "game 2\n",
      "\n",
      "W\n",
      "2=3\n",
      "1=3\n",
      "W\n",
      "1=2\n",
      "\t\n",
      "L\n",
      "1=2\n",
      "L\n",
      "\t\n",
      "W\n",
      "1=3\n",
      "2=3\n",
      "L\n",
      "\n",
      "\n",
      "Figure 15.2 The tree diagram for computing the probability that the Halting Problem wins two out of three games given that they won the first game.\n",
      "Step 1: Find the Sample Space\n",
      "Each internal vertex in the tree diagram has two children, one corresponding to a win for the Halting Problem (labeled W ) and one corresponding to a loss (la-\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 420  #426\n",
      "\n",
      "420\n",
      "\t\n",
      "Chapter 15\n",
      "\t\n",
      "Conditional Probability\n",
      "beled \n",
      "L\n",
      "). The complete sample space is:\n",
      "D f\n",
      "W W; W LW; W LL; LW W; LW L; LL\n",
      "g\n",
      ":\n",
      "Step 2: Define Events of Interest\n",
      "The event that the Halting Problem wins the whole tournament is:\n",
      "T \n",
      "D f\n",
      "W W; W LW; LW W \n",
      "g\n",
      ":\n",
      "And the event that the Halting Problem wins the first game is:\n",
      "F \n",
      "D f\n",
      "W W; W LW; W LL\n",
      "g\n",
      ":\n",
      "The outcomes in these events are indicated with check marks in the tree diagram in Figure \n",
      ".\n",
      "Step 3: Determine Outcome Probabilities\n",
      "Next, we must assign a probability to each outcome. We begin by labeling edges as specified in the problem statement. Specifically, The Halting Problem has a \n",
      "1=2\n",
      " chance of winning the first game, so the two edges leaving the root are each as-signed probability \n",
      "1=2\n",
      ". Other edges are labeled \n",
      "1=3\n",
      " or \n",
      "2=3\n",
      " based on the outcome of the preceding game. We then find the probability of each outcome by multi-plying all probabilities along the corresponding root-to-leaf path. For example, the probability of outcome \n",
      "W LL\n",
      " is:\n",
      "1\n",
      "2\n",
      "  \n",
      "1\n",
      "3\n",
      "  \n",
      "2\n",
      "3\n",
      " D \n",
      "1\n",
      "9\n",
      ":\n",
      "\n",
      "Step 4: Compute Event Probabilities\n",
      "We can now compute the probability that The Halting Problem wins the tourna-ment, given that they win the first game:\n",
      "Pr\n",
      " \n",
      "A\n",
      " \n",
      "j\n",
      " \n",
      "B\n",
      "\t\n",
      "D \n",
      "Pr \n",
      "A\n",
      " \n",
      "\\\n",
      " \n",
      "B\n",
      "\n",
      "Pr \n",
      "B\n",
      "Pr f\n",
      "W W; W LW\n",
      " g\n",
      "D\n",
      " Pr f\n",
      "W W; W LW; W LL\n",
      "g\n",
      "\n",
      "1=3 \n",
      "C\n",
      " 1=18\n",
      "D\n",
      "\n",
      "1=3 \n",
      "C\n",
      " 1=18 \n",
      "C\n",
      " 1=9\n",
      "\n",
      "Were done! If the Halting Problem wins the first game, then they win the whole tournament with probability \n",
      "7=9\n",
      ".\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 421  #427\n",
      "\n",
      "15.2.2\n",
      "\t\n",
      "Why Tree Diagrams Work\n",
      "Weve now settled into a routine of solving probability problems using tree dia-grams. But weve left a big question unaddressed: what is the mathematical justifi-cation behind those funny little pictures? Why do they work?\n",
      "The answer involves conditional probabilities. In fact, the probabilities that weve been recording on the edges of tree diagrams are conditional probabilities. For example, consider the uppermost path in the tree diagram for the Halting Prob-lem, which corresponds to the outcome \n",
      "W W\n",
      " . The first edge is labeled \n",
      "1=2\n",
      ", which is the probability that the Halting Problem wins the first game. The second edge is labeled \n",
      "2=3\n",
      ", which is the probability that the Halting Problem wins the second game, given that they won the firstthats a conditional probability! More gener-ally, on each edge of a tree diagram, we record the probability that the experiment proceeds along that path, given that it reaches the parent vertex.\n",
      "So weve been using conditional probabilities all along. But why can we multiply edge probabilities to get outcome probabilities? For example, we concluded that:\n",
      "Pr \n",
      "W W\n",
      "\t\n",
      "D \n",
      "1\n",
      "2\n",
      "  \n",
      "2\n",
      "3\n",
      " D \n",
      "1\n",
      "3\n",
      ":\n",
      "\n",
      "Why is this correct?\n",
      "The answer goes back to Definition \n",
      "of conditional probability which could be written in a form called the Product Rule for probabilities:\n",
      "Rule (Product Rule for 2 Events). If Pr \n",
      "E\n",
      "1\n",
      "  \n",
      "0\n",
      ", then:\n",
      " \n",
      "Pr \n",
      "E\n",
      "1\n",
      " \\ \n",
      "E\n",
      "2\n",
      " D Pr \n",
      "E\n",
      "1\n",
      "\tPr \n",
      "E\n",
      "2\n",
      " j \n",
      "E\n",
      "1\n",
      " \n",
      ":\n",
      "Multiplying edge probabilities in a tree diagram amounts to evaluating the right side of this equation. For example:\n",
      "Pr win first game \\ win second game\n",
      "D Pr win first game Pr win second game j win first game\n",
      "1\n",
      "2\n",
      "  \n",
      "2\n",
      "3\n",
      ":\n",
      "\n",
      "So the Product Rule is the formal justification for multiplying edge probabilities to get outcome probabilities! Of course to justify multiplying edge probabilities along longer paths, we need a Product Rule for \n",
      "n\n",
      " events.\n",
      "Rule (Product Rule for \n",
      "n\n",
      " Events).\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 422  #428\n",
      "\n",
      "422\n",
      "\t\n",
      "Chapter 15\n",
      "\t\n",
      "Conditional Probability\n",
      "provided that\n",
      "Pr \n",
      "E\n",
      "1\n",
      " \\ \n",
      "E\n",
      "2\n",
      " \\\n",
      "\t\n",
      "\\ \n",
      "E\n",
      "n1\n",
      "\t \n",
      "0:\n",
      "This rule follows from the definition of conditional probability and induction on \n",
      "n\n",
      ".\n",
      "15.2.3\n",
      "\t\n",
      "Medical Testing\n",
      "There is an unpleasant condition called BO suffered by 10% of the population. There are no prior symptoms; victims just suddenly start to stink. Fortunately, there is a test for latent BO before things start to smell. The test is not perfect, however:\n",
      "If you have the condition, there is a 10% chance that the test will say you do not. These are called false negatives.\n",
      "If you do not have the condition, there is a 30% chance that the test will say you do. These are false positives.\n",
      "Suppose a random person is tested for latent BO. If the test is positive, then what is the probability that the person has the condition?\n",
      "Step 1: Find the Sample Space\n",
      "The sample space is found with the tree diagram in Figure \n",
      ".\n",
      "\n",
      "Figure 15.3\n",
      "\t\n",
      "The tree diagram for the BO problem.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 423  #429\n",
      "\n",
      "Step 2: Define Events of Interest\n",
      "Let \n",
      "A\n",
      " be the event that the person has BO. Let \n",
      "B\n",
      " be the event that the test was positive. The outcomes in each event are marked in the tree diagram. We want\n",
      "to find Pr \n",
      "A\n",
      " j \n",
      "B\n",
      " , the probability that a person has BO, given that the test was positive.\n",
      "Step 3: Find Outcome Probabilities\n",
      "First, we assign probabilities to edges. These probabilities are drawn directly from the problem statement. By the Product Rule, the probability of an outcome is the product of the probabilities on the corresponding root-to-leaf path. All probabilities are shown in Figure \n",
      ".\n",
      "Step 4: Compute Event Probabilities\n",
      "From Definition \n",
      ", we have\n",
      "So, if you test positive, then there is only a 25% chance that you have the condition! This answer is initially surprising, but makes sense on reflection. There are two ways you could test positive. First, it could be that you have the condition and the test is correct. Second, it could be that you are healthy and the test is incorrect. The problem is that almost everyone is healthy; therefore, most of the positive results\n",
      "arise from incorrect tests of healthy people!\n",
      "We can also compute the probability that the test is correct for a random person. This event consists of two outcomes. The person could have the condition and test positive (probability \n",
      "0:09\n",
      "), or the person could be healthy and test negative (probability \n",
      "0:63\n",
      "). Therefore, the test is correct with probability \n",
      "0:09\n",
      " C \n",
      "0:63\n",
      " D \n",
      "0:72\n",
      ". This is a relief; the test is correct almost three-quarters of the time.\n",
      "But wait! There is a simple way to make the test correct 90% of the time: always return a negative result! This test gives the right answer for all healthy people and the wrong answer only for the 10% that actually have the condition. So a better strategy by this measure is to completely ignore the test result!\n",
      "There is a similar paradox in weather forecasting. During winter, almost all days in Boston are wet and overcast. Predicting miserable weather every day may be more accurate than really trying to get it right!\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 424  #430\n",
      "\n",
      "424\n",
      "\t\n",
      "Chapter 15\n",
      "\t\n",
      "Conditional Probability\n",
      "\n",
      "15.3\n",
      "\t\n",
      "A Posteriori Probabilities\n",
      "If you think about it too much, the medical testing problem we just considered could start to trouble you. The concern would be that by the time you take the test, you either have the BO condition or you dontyou just dont know which it is. So you may wonder if a statement like If you tested positive, then you have the condition with probability 25% makes sense.\n",
      "In fact, such a statement does make sense. It means that 25% of the people who test positive actually have the condition. It is true that any particular person has it or they dont, but a randomly selected person among those who test positive will have the condition with probability 25%.\n",
      "Anyway, if the medical testing example bothers you, you will definitely be wor-ried by the following examples, which go even further down this path.\n",
      "15.3.1\n",
      "\t\n",
      "The Halting Problem, in Reverse\n",
      "Suppose that we turn the hockey question around: what is the probability that the Halting Problem won their first game, given that they won the series?\n",
      "This seems like an absurd question! After all, if the Halting Problem won the series, then the winner of the first game has already been determined. Therefore, who won the first game is a question of fact, not a question of probability. However, our mathematical theory of probability contains no notion of one event preceding anotherthere is no notion of time at all. Therefore, from a mathematical perspec-tive, this is a perfectly valid question. And this is also a meaningful question from a practical perspective. Suppose that youre told that the Halting Problem won the series, but not told the results of individual games. Then, from your perspective, it makes perfect sense to wonder how likely it is that The Halting Problem won the first game.\n",
      "A conditional probability Pr B j A is called a posteriori if event B precedes event A in time. Here are some other examples of a posteriori probabilities:\n",
      "The probability it was cloudy this morning, given that it rained in the after-noon.\n",
      "The probability that I was initially dealt two queens in Texas No Limit Hold Em poker, given that I eventually got four-of-a-kind.\n",
      "Mathematically, a posteriori probabilities are no different from ordinary probabil-ities; the distinction is only at a higher, philosophical level. Our only reason for drawing attention to them is to say, Dont let them rattle you.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 425  #431\n",
      "\n",
      "Lets return to the original problem. The probability that the Halting Problem\n",
      "This answer is suspicious! In the preceding section, we showed that Pr \n",
      "A\n",
      " j \n",
      "B\n",
      " \n",
      "reflection suggests this is unlikely. For example, the probability that I feel uneasy, given that I was abducted by aliens, is pretty large. But the probability that I was abducted by aliens, given that I feel uneasy, is rather small.\n",
      "This equation, in turn, holds only if the denominators are equal or the numerator is 0; namely if\n",
      "Pr \n",
      "B\n",
      " D Pr \n",
      "A\n",
      "\t\n",
      "or\n",
      "\t\n",
      "Pr \n",
      "A\n",
      " \\ \n",
      "B\n",
      " D \n",
      "0:\n",
      "The former condition holds in the hockey example; the probability that the Halting Problem wins the series (event \n",
      "A\n",
      ") is equal to the probability that it wins the first game (event \n",
      "B\n",
      ") since both probabilities are \n",
      "1=2\n",
      ".\n",
      "In general, such pairs of probabilities are related by Bayes Rule:\n",
      "Theorem 15.3.1 (Bayes Rule). If Pr \n",
      "A\n",
      " and Pr \n",
      "B\n",
      " are nonzero, then:\n",
      " \n",
      "Pr \n",
      "A\n",
      " j \n",
      "B\n",
      "  Pr \n",
      "B\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 426  #432\n",
      "\n",
      "426\n",
      "\t\n",
      "Chapter 15\n",
      "\t\n",
      "Conditional Probability\n",
      "15.3.2\n",
      "\t\n",
      "A Coin Problem\n",
      "Suppose that someone hands you either a fair coin or a trick coin with heads on both sides. You flip the coin 100 times and see heads every time. What can you say about the probability that you flipped the fair coin? Remarkably, nothing!\n",
      "In order to make sense out of this outrageous claim, lets formalize the problem. The sample space is worked out in the tree diagram shown in Figure \n",
      ". We do not know the probability \n",
      "p\n",
      " that you were handed the fair coin initiallyyou were just given one coin or the other. Let \n",
      "A\n",
      " be the event that you were handed the\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "p\n",
      "Figure 15.4\n",
      "\t\n",
      "The tree diagram for the coin-flipping problem.\n",
      "fair coin, and let \n",
      "B\n",
      " be the event that you flipped 100 straight heads. Were look-\n",
      "ing for Pr \n",
      "A\n",
      " j \n",
      "B\n",
      " , the probability that you were handed the fair coin, given that you flipped 100 heads. The outcome probabilities are worked out in Figure \n",
      ". Plugging the results into the definition of conditional probability gives:\n",
      "This expression is very small for moderate values of \n",
      "p\n",
      " because of the \n",
      "2\n",
      "100\n",
      " term in the denominator. For example, if \n",
      "p\n",
      " D \n",
      "1=2\n",
      ", then the probability that you were given the fair coin is essentially zero.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 427  #433\n",
      "\n",
      "But we do not know the probability \n",
      "p\n",
      " that you were given the fair coin. And perhaps the value of \n",
      "p\n",
      " is not moderate; in fact, maybe \n",
      "p\n",
      " D \n",
      "1 2\n",
      "100\n",
      " . Then there is nearly an even chance that you have the fair coin, given that you flipped 100 heads. In fact, maybe you were handed the fair coin with probability \n",
      "p\n",
      " D \n",
      "1\n",
      ". Then the probability that you were given the fair coin is, well, 1!\n",
      "Of course, it is extremely unlikely that you would flip 100 straight heads, but in this case, that is a given from the assumption of the conditional probability. And so if you really did see 100 straight heads, it would be very tempting to also assume that \n",
      "p\n",
      " is not close to 1 and hence that you are very likely to have flipped the trick coin.\n",
      "We will encounter a very similar issue when we look at methods for estimation by sampling in Section \n",
      ".\n",
      "\n",
      "15.4\n",
      "\t\n",
      "Conditional Identities\n",
      "15.4.1\n",
      "\t\n",
      "The Law of Total Probability\n",
      "Breaking a probability calculation into cases simplifies many problems. The idea is to calculate the probability of an event \n",
      "A\n",
      " by splitting into two cases based on whether or not another event \n",
      "E\n",
      " occurs. That is, calculate the probability of \n",
      "A\n",
      " \\ \n",
      "E\n",
      " and \n",
      "A\n",
      " \\\n",
      "E\n",
      ". By the Sum Rule, the sum of these probabilities equals Pr \n",
      "A\n",
      " . Express-ing the intersection probabilities as conditional probabilities yields:\n",
      "\n",
      "Rule 15.4.1 (Law of Total Probability, single event). If Pr \n",
      "E\n",
      " and Pr \n",
      "E\n",
      " are nonzero, then\n",
      "\n",
      "coin. If heads comes up, then we roll one die and take the result. If tails comes up, then we roll two dice and take the sum of the two results. What is the probability that this process yields a 2? Let \n",
      "E\n",
      " be the event that the coin comes up heads, and let \n",
      "A\n",
      " be the event that we get a 2 overall. Assuming that the coin is fair, Pr \n",
      "E\n",
      " D Pr \n",
      "E\n",
      " D \n",
      "1=2\n",
      ". There are now two cases. If we flip heads, then we roll\n",
      "\n",
      "There is also a form of the rule to handle more than two cases.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 428  #434\n",
      "\n",
      "428\n",
      "\t\n",
      "Chapter 15\n",
      "\t\n",
      "Conditional Probability\n",
      "Rule 15.4.2 (Law of Total Probability). If \n",
      "E\n",
      "1\n",
      "; : : : ; E\n",
      "n\n",
      " are disjoint events whose union is the whole sample space, then:\n",
      "iD1\n",
      "15.4.2\n",
      "\t\n",
      "Conditioning on a Single Event\n",
      "The probability rules that we derived in Chapter \n",
      "extend to probabilities condi-tioned on the same event. For example, the Inclusion-Exclusion formula for two sets holds when all probabilities are conditioned on an event \n",
      "C\n",
      " :\n",
      "It is important not to mix up events before and after the conditioning bar. For\n",
      "So youre convinced that this equation is false in general, right? Lets see if you really believe that.\n",
      "15.4.3\tDiscrimination Lawsuit\n",
      "Several years ago there was a sex discrimination lawsuit against a famous uni-versity. A female math professor was denied tenure, allegedly because she was\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 429  #435\n",
      "\n",
      "\n",
      "A\n",
      "\n",
      "\n",
      "\n",
      "B\n",
      "C\n",
      "sample space\n",
      "Figure 15.5 A counterexample to Equation \n",
      ". Event A is the gray rectangle, event B is the rectangle with vertical stripes, and event C is the rectangle with horizontal stripes. B \\C lies entirely within A while B C and C B are entirely outside of A.\n",
      "a woman. She argued that in every one of the universitys 22 departments, the percentage of male applicants accepted was greater than the percentage of female applicants accepted. This sounds very suspicious!\n",
      "However, the universitys lawyers argued that across the university as a whole, the percentage of male applicants accepted was actually lower than the percentage of female applicants accepted. This suggests that if there was any sex discrimi-nation, then it was against men! Surely, at least one party in the dispute must be lying.\n",
      "Lets simplify the problem and express both arguments in terms of conditional probabilities. To simplify matters, suppose that there are only two departments, EE and CS, and consider the experiment where we pick a random applicant. Define the following events:\n",
      "Let A be the event that the applicant is accepted.\n",
      "Let F\n",
      "EE\n",
      " the event that the applicant is a female applying to EE. Let F\n",
      "CS\n",
      " the event that the applicant is a female applying to CS. Let M\n",
      "EE\n",
      " the event that the applicant is a male applying to EE. Let M\n",
      "CS\n",
      " the event that the applicant is a male applying to CS.\n",
      "Assume that all applicants are either male or female, and that no applicant applied to both departments. That is, the events F\n",
      "EE\n",
      " , F\n",
      "CS\n",
      " , M\n",
      "EE\n",
      " , and M\n",
      "CS\n",
      " are all dis-joint.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 430  #436\n",
      "\n",
      "Table 15.1 A scenario where females are less likely to be admitted than males in each department, but more likely to be admitted overall.\n",
      "In these terms, the plaintiff is making the following argument:\n",
      " \n",
      "Pr A j F\n",
      "EE\n",
      "\t\n",
      "< Pr A j M\n",
      "EE\n",
      "\t\n",
      "and\n",
      " \n",
      "Pr A j F\n",
      "CS\n",
      "\t\n",
      "< Pr A j M\n",
      "CS\n",
      "  :\n",
      "That is, in both departments, the probability that a woman is accepted for tenure is less than the probability that a man is accepted. The university retorts that overall, a woman applicant is more likely to be accepted than a man; namely that\n",
      " \n",
      "Pr A j F\n",
      "EE\n",
      " [ F\n",
      "CS\n",
      "\t\n",
      "> Pr A j M\n",
      "EE\n",
      " [ M\n",
      "CS\n",
      "  :\n",
      "It is easy to believe that these two positions are contradictory. In fact, we might even try to prove this by adding the plaintiffs two inequalities and then arguing as follows:\n",
      "Pr A j F\n",
      "EE\n",
      " C Pr A j F\n",
      "CS\n",
      " < Pr A j M\n",
      "EE\n",
      " C Pr A j M\n",
      "CS\n",
      " \n",
      "Pr A j F\n",
      "EE\n",
      " [ F\n",
      "CS\n",
      "  < Pr A j M\n",
      "EE\n",
      " [ M\n",
      "CS\n",
      "  :\n",
      "The second line exactly contradicts the universitys position! But there is a big problem with this argument; the second inequality follows from the first only if we accept the false identity (\n",
      "). This argument is bogus! Maybe the two parties do not hold contradictory positions after all!\n",
      "In fact, Table \n",
      "shows a set of application statistics for which the assertions of both the plaintiff and the university hold. In this case, a higher percentage of males were accepted in both departments, but overall a higher percentage of females were accepted! Bizarre!\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 431  #437\n",
      "\n",
      "16\n",
      "\t\n",
      "Independence\n",
      "\n",
      "16.1\n",
      "\t\n",
      "Definitions\n",
      "Suppose that we flip two fair coins simultaneously on opposite sides of a room.\n",
      "Intuitively, the way one coin lands does not affect the way the other coin lands.\n",
      "The mathematical concept that captures this intuition is called independence:\n",
      "Definition 16.1.1. Events \n",
      "A\n",
      " and \n",
      "B\n",
      " are independent if Pr \n",
      "B\n",
      " D \n",
      "0\n",
      " or if\n",
      "In other words, \n",
      "A\n",
      " and \n",
      "B\n",
      " are independent if knowing that \n",
      "B\n",
      " happens does not al-ter the probability that \n",
      "A\n",
      " happens, as is the case with flipping two coins on opposite sides of a room.\n",
      "16.1.1\tPotential Pitfall\n",
      "Students sometimes get the idea that disjoint events are independent. The opposite is true: if \n",
      "A\n",
      " \\ \n",
      "B\n",
      " D ;, then knowing that \n",
      "A\n",
      " happens means you know that \n",
      "B\n",
      " does not happen. So disjoint events are never independentunless one of them has probability zero.\n",
      "16.1.2\tAlternative Formulation\n",
      "Sometimes it is useful to express independence in an alternate form:\n",
      "Theorem 16.1.2. \n",
      "A\n",
      " and \n",
      "B\n",
      " are independent if and only if\n",
      "Proof. There are two cases to consider depending on whether or not Pr \n",
      "B\n",
      " D \n",
      "0\n",
      ".\n",
      "Case 1 \n",
      ".\n",
      "Pr \n",
      "B\n",
      " D \n",
      "0/\n",
      ": If Pr \n",
      "B\n",
      " D \n",
      "0\n",
      ", \n",
      "A\n",
      " and \n",
      "B\n",
      " are independent by Definition \n",
      ". In addition, Equation \n",
      "holds since both sides are 0. Hence, the theorem is true in this case.\n",
      "Case 2 \n",
      ".\n",
      "Pr \n",
      "B > 0/\n",
      ": By Definition \n",
      ",\n",
      " \n",
      "Pr \n",
      "A\n",
      " \\ \n",
      "B\n",
      " D Pr \n",
      "A\n",
      " j \n",
      "B\n",
      " Pr \n",
      "B :\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 432  #438\n",
      "\n",
      "432\n",
      "\t\n",
      "Chapter 16\n",
      "\t\n",
      "Independence\n",
      "So Equation \n",
      "holds if\n",
      " \n",
      "Pr \n",
      "A\n",
      " j \n",
      "B\n",
      "\t\n",
      "D Pr \n",
      "A ;\n",
      "which, by Definition \n",
      ", is true iff \n",
      "A\n",
      " and \n",
      "B\n",
      " are independent. Hence, the\n",
      "theorem is true in this case as well.\n",
      "\n",
      "16.2\n",
      "\t\n",
      "Independence Is an Assumption\n",
      "Generally, independence is something that you assume in modeling a phenomenon. For example, consider the experiment of flipping two fair coins. Let \n",
      "A\n",
      " be the event that the first coin comes up heads, and let \n",
      "B\n",
      " be the event that the second coin is heads. If we assume that \n",
      "A\n",
      " and \n",
      "B\n",
      " are independent, then the probability that both coins come up heads is:\n",
      "Pr \n",
      "A\n",
      " \\ \n",
      "B\n",
      " D Pr \n",
      "A\n",
      "\tPr \n",
      "B\n",
      " D \n",
      "1\n",
      "2\n",
      "\t\n",
      "1\n",
      "2\n",
      " \n",
      "D\n",
      " \n",
      "1\n",
      "4\n",
      ":\n",
      "\n",
      "In this example, the assumption of independence is reasonable. The result of one coin toss should have negligible impact on the outcome of the other coin toss. And if we were to repeat the experiment many times, we would be likely to have \n",
      "A\n",
      " \\ \n",
      "B\n",
      " about 1/4 of the time.\n",
      "There are, of course, many examples of events where assuming independence is not justified, For example, let \n",
      "C\n",
      " be the event that tomorrow is cloudy and \n",
      "R\n",
      " be the event that tomorrow is rainy. Perhaps Pr \n",
      "C\n",
      " D \n",
      "1=5\n",
      " and Pr \n",
      "R\n",
      " D \n",
      "1=10\n",
      " in Boston. If these events were independent, then we could conclude that the probability of a rainy, cloudy day was quite small:\n",
      "Pr \n",
      "R\n",
      " \\ \n",
      "C\n",
      " D Pr \n",
      "R\n",
      "\tPr \n",
      "C\n",
      " D \n",
      "1\n",
      "5\n",
      "\t\n",
      "10\n",
      "1\n",
      " \n",
      "D\n",
      " \n",
      "50\n",
      "1\n",
      ":\n",
      "\n",
      "Unfortunately, these events are definitely not independent; in particular, every rainy day is cloudy. Thus, the probability of a rainy, cloudy day is actually \n",
      "1=10\n",
      ".\n",
      "Deciding when to assume that events are independent is a tricky business. In practice, there are strong motivations to assume independence since many useful formulas (such as Equation \n",
      ") only hold if the events are independent. But you need to be careful lest you end up deriving false conclusions. Well see several famous examples where (false) assumptions of independence led to trouble over the next several chapters. This problem gets even trickier when there are more than two events in play.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 433  #439\n",
      "\n",
      "\n",
      "16.3\n",
      "\t\n",
      "Mutual Independence\n",
      "16.3.1\n",
      "\t\n",
      "Definition\n",
      "We have defined what it means for two events to be independent. What if there are more than two events? For example, how can we say that the flips of \n",
      "n\n",
      " coins are all independent of one another?\n",
      "Events \n",
      "E\n",
      "1\n",
      "; : : : ; E\n",
      "n\n",
      " are said to be mutually independent if and only if the prob-ability of any event \n",
      "E\n",
      "i\n",
      " is unaffected by knowledge of the other events. More for-mally:\n",
      "Definition 16.3.1. A set of events \n",
      "E\n",
      "1\n",
      "; E\n",
      "2\n",
      "; : : : ; E\n",
      "n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", is mutually independent if 8\n",
      "i\n",
      " 2\n",
      "In other words, no matter which other events are known to occur, the probability that \n",
      "E\n",
      "i\n",
      " occurs is unchanged for any \n",
      "i\n",
      ".\n",
      "For example, if we toss 100 fair coins at different times, we might reasonably assume that the tosses are mutually independent since the probability that the \n",
      "i\n",
      "th coin is heads should be \n",
      "1=2\n",
      ", no matter which other coin tosses came out heads.\n",
      "16.3.2\tAlternative Formulation\n",
      "Just as Theorem \n",
      "provided an alternative definition of independence for two events, there is an alternative definition for mutual independence.\n",
      "Theorem 16.3.2. A set of events \n",
      "E\n",
      "1\n",
      "; E\n",
      "2\n",
      "; : : : ; E\n",
      "n\n",
      " is mutually independent iff 8\n",
      "S\n",
      " \n",
      "1; n \n",
      ",\n",
      "3\n",
      "The proof of Theorem \n",
      "uses induction and reasoning similar to the proof of Theorem \n",
      ". We will not include the details here.\n",
      "Theorem \n",
      "says that \n",
      "E\n",
      "1\n",
      "; E\n",
      "2\n",
      "; : : : ; E\n",
      "n\n",
      " are mutually independent if and only\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 434  #440\n",
      "\n",
      "434\n",
      "\t\n",
      "Chapter 16\n",
      "\t\n",
      "Independence\n",
      "if all of the following equations hold for all distinct \n",
      "i\n",
      ", \n",
      "j\n",
      " , \n",
      "k\n",
      ", and \n",
      "l\n",
      ":\n",
      "Pr \n",
      "E\n",
      "i\n",
      " \\ \n",
      "E\n",
      "j\n",
      "  D Pr \n",
      "E\n",
      "i\n",
      "\tPr \n",
      "E\n",
      "j\n",
      "Pr \n",
      "E\n",
      "i\n",
      " \\ \n",
      "E\n",
      "j\n",
      " \\ \n",
      "E\n",
      "k\n",
      "  D Pr \n",
      "E\n",
      "i\n",
      "\tPr \n",
      "E\n",
      "j\n",
      "\tPr \n",
      "E\n",
      "k\n",
      "Pr \n",
      "E\n",
      "i\n",
      " \\ \n",
      "E\n",
      "j\n",
      " \\ \n",
      "E\n",
      "k\n",
      " \\ \n",
      "E\n",
      "l\n",
      "  D Pr \n",
      "E\n",
      "i\n",
      "\t\n",
      "Pr \n",
      "E\n",
      "j\n",
      "\t\n",
      "Pr \n",
      "E\n",
      "k\n",
      "\tPr \n",
      "E\n",
      "l\n",
      ":\n",
      ":\n",
      ":\n",
      "Pr \n",
      "E\n",
      "1\n",
      " \\\n",
      "\t\n",
      "\\ \n",
      "E\n",
      "n\n",
      " D Pr \n",
      "E\n",
      "1\n",
      "\t\n",
      "Pr \n",
      "E\n",
      "n\n",
      " \n",
      ":\n",
      "For example, if we toss \n",
      "n\n",
      " fair coins, the tosses are mutually independent iff for all \n",
      "m\n",
      " 2 \n",
      "1; n\n",
      " and every subset of \n",
      "m\n",
      " coins, the probability that every coin in the subset comes up heads is \n",
      "2\n",
      "m\n",
      " .\n",
      "16.3.3\n",
      "\t\n",
      "DNA Testing\n",
      "Assumptions about independence are routinely made in practice. Frequently, such assumptions are quite reasonable. Sometimes, however, the reasonableness of an independence assumption is not so clear, and the consequences of a faulty assump-tion can be severe.\n",
      "For example, consider the following testimony from the O. J. Simpson murder trial on May 15, 1995:\n",
      "Mr. Clarke: When you make these estimations of frequencyand I believe you touched a little bit on a concept called independence?\n",
      "Dr. Cotton: Yes, I did.\n",
      "Mr. Clarke: And what is that again?\n",
      "Dr. Cotton: It means whether or not you inherit one allele that you have is not does not affect the second allele that you might get. That is, if you inherit a band at 5,000 base pairs, that doesnt mean youll automatically or with some probability inherit one at 6,000. What you inherit from one parent is what you inherit from the other.\n",
      "Mr. Clarke: Why is that important?\n",
      "Dr. Cotton: Mathematically thats important because if that were not the case, it would be improper to multiply the frequencies between the different genetic locations.\n",
      "Mr. Clarke: How do youwell, first of all, are these markers independent that youve described in your testing in this case?\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 435  #441\n",
      "\n",
      "Presumably, this dialogue was as confusing to you as it was for the jury. Es-sentially, the jury was told that genetic markers in blood found at the crime scene matched Simpsons. Furthermore, they were told that the probability that the mark-ers would be found in a randomly-selected person was at most 1 in 170 million. This astronomical figure was derived from statistics such as:\n",
      "1 person in 100 has marker \n",
      "A\n",
      ". 1 person in 50 marker \n",
      "B\n",
      ".\n",
      "1 person in 40 has marker \n",
      "C\n",
      " . 1 person in 5 has marker \n",
      "D\n",
      ". 1 person in 170 has marker \n",
      "E\n",
      ".\n",
      "Then these numbers were multiplied to give the probability that a randomly-selected person would have all five markers:\n",
      "Pr \n",
      "A\n",
      " \\ \n",
      "B\n",
      " \\ \n",
      "C\n",
      " \\ \n",
      "D\n",
      " \\ \n",
      "E\n",
      " D Pr \n",
      "A\n",
      "\tPr \n",
      "B\n",
      "\tPr \n",
      "C\n",
      "\tPr \n",
      "D\n",
      "\tPr \n",
      "E\n",
      "11111 \n",
      "D\n",
      "\n",
      "D\n",
      " 170;000;000\n",
      ":\n",
      "\n",
      "The defense pointed out that this assumes that the markers appear mutually inde-pendently. Furthermore, all the statistics were based on just a few hundred blood samples.\n",
      "After the trial, the jury was widely mocked for failing to understand the DNA evidence. If you were a juror, would you accept the 1 in 170 million calculation?\n",
      "\n",
      "16.4\n",
      "\t\n",
      "Pairwise Independence\n",
      "The definition of mutual independence seems awfully complicatedthere are so many subsets of events to consider! Heres an example that illustrates the subtlety of independence when more than two events are involved. Suppose that we flip three fair, mutually-independent coins. Define the following events:\n",
      "A\n",
      "1\n",
      " \n",
      "is the event that coin 1 matches coin 2.\n",
      " A\n",
      "2\n",
      " \n",
      "is the event that coin 2 matches coin 3.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 436  #442\n",
      "\n",
      "436\n",
      "\t\n",
      "Chapter 16\n",
      "\t\n",
      "Independence\n",
      "A\n",
      "3\n",
      " \n",
      "is the event that coin 3 matches coin 1.\n",
      "Are \n",
      "A\n",
      "1\n",
      ", \n",
      "A\n",
      "2\n",
      ", \n",
      "A\n",
      "3\n",
      " mutually independent?\n",
      "The sample space for this experiment is:\n",
      "f\n",
      "HHH; HH T; H TH; H T T; THH; TH T; T TH; T T T\n",
      " g\n",
      ":\n",
      "Every outcome has probability \n",
      ".1=2/\n",
      "3\n",
      " D \n",
      "1=8\n",
      " by our assumption that the coins are mutually independent.\n",
      "To see if events \n",
      "A\n",
      "1\n",
      ", \n",
      "A\n",
      "2\n",
      ", and \n",
      "A\n",
      "3\n",
      " are mutually independent, we must check a sequence of equalities. It will be helpful first to compute the probability of each event \n",
      "A\n",
      "i\n",
      " :\n",
      "Pr \n",
      "A\n",
      "1\n",
      " D Pr \n",
      "HHH\n",
      " C Pr \n",
      "HH T\n",
      " C Pr \n",
      "T TH\n",
      " C Pr \n",
      "T T T\n",
      "D\n",
      "1\n",
      "8\n",
      "C\n",
      "1\n",
      "8\n",
      "C\n",
      "1\n",
      "8\n",
      "C\n",
      "1\n",
      "8\n",
      "\n",
      "1\n",
      "2\n",
      ":\n",
      "\n",
      "By symmetry, Pr \n",
      "A\n",
      "2\n",
      " D Pr \n",
      "A\n",
      "3\n",
      " D \n",
      "1=2\n",
      " as well. Now we can begin checking all the equalities required for mutual independence in Theorem \n",
      ":\n",
      "Pr \n",
      "A\n",
      "1\n",
      " \\ \n",
      "A\n",
      "2\n",
      " D Pr \n",
      "HHH\n",
      " C Pr \n",
      "T T T\n",
      "D\n",
      "1\n",
      "8\n",
      "C\n",
      "1\n",
      "8\n",
      "\n",
      "D \n",
      "1\n",
      "4\n",
      "\n",
      "D\n",
      "1\n",
      "2\n",
      " \n",
      "1\n",
      "2\n",
      "\n",
      "D Pr \n",
      "A\n",
      "1\n",
      " Pr \n",
      "A\n",
      "2\n",
      " \n",
      ":\n",
      "By symmetry, Pr \n",
      "A\n",
      "1\n",
      " \\ \n",
      "A\n",
      "3\n",
      " D Pr \n",
      "A\n",
      "1\n",
      " Pr \n",
      "A\n",
      "3\n",
      " and Pr \n",
      "A\n",
      "2\n",
      " \\ \n",
      "A\n",
      "3\n",
      " D Pr \n",
      "A\n",
      "2\n",
      " Pr \n",
      "A\n",
      "3\n",
      " must hold also. Finally, we must check one last condition:\n",
      "Pr \n",
      "A\n",
      "1\n",
      " \\ \n",
      "A\n",
      "2\n",
      " \\ \n",
      "A\n",
      "3\n",
      " D Pr \n",
      "HHH\n",
      " C Pr \n",
      "T T T\n",
      "1\n",
      "\t\n",
      "1\n",
      "D\n",
      "8\n",
      "C\n",
      "8\n",
      "\n",
      "1\n",
      " Pr \n",
      "A\n",
      "1\n",
      " Pr \n",
      "A\n",
      "2\n",
      " Pr \n",
      "A\n",
      "3\n",
      " D \n",
      "8\n",
      ":\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 437  #443\n",
      "\n",
      "The three events \n",
      "A\n",
      "1\n",
      ", \n",
      "A\n",
      "2\n",
      ", and \n",
      "A\n",
      "3\n",
      " are not mutually independent even though any two of them are independent! This not-quite mutual independence seems weird at first, but it happens. It even generalizes:\n",
      "Definition 16.4.1. A set \n",
      "A\n",
      "1\n",
      ", \n",
      "A\n",
      "2\n",
      ", . . . , of events is \n",
      "k\n",
      "-way independent iff every set of \n",
      "k\n",
      " of these events is mutually independent. The set is pairwise independent iff it is 2-way independent.\n",
      "So the sets \n",
      "A\n",
      "1\n",
      ", \n",
      "A\n",
      "2\n",
      ", \n",
      "A\n",
      "3\n",
      " above are pairwise independent, but not mutually inde-pendent. Pairwise independence is a much weaker property than mutual indepen-dence.\n",
      "For example, suppose that the prosecutors in the O. J. Simpson trial were wrong and markers \n",
      "A\n",
      ", \n",
      "B\n",
      ", \n",
      "C\n",
      " , \n",
      "D\n",
      ", and \n",
      "E\n",
      " appear only pairwise independently. Then the probability that a randomly-selected person has all five markers is no more than:\n",
      "Pr \n",
      "A\n",
      " \\ \n",
      "B\n",
      " \\ \n",
      "C\n",
      " \\ \n",
      "D\n",
      " \\ \n",
      "E\n",
      "\t\n",
      "Pr \n",
      "A\n",
      " \\ \n",
      "E\n",
      "D Pr \n",
      "A\n",
      "  Pr \n",
      "E\n",
      "1\n",
      "\t\n",
      "1\n",
      "D\n",
      "\n",
      "1\n",
      "D\n",
      " 17;000\n",
      ":\n",
      "\n",
      "The first line uses the fact that \n",
      "A\n",
      "\\\n",
      "B\n",
      " \\\n",
      "C\n",
      " \\\n",
      "D\n",
      " \\\n",
      "E\n",
      " is a subset of \n",
      "A\n",
      "\\\n",
      "E\n",
      ". (We picked out the \n",
      "A\n",
      " and \n",
      "E\n",
      " markers because theyre the rarest.) We use pairwise independence on the second line. Now the probability of a random match is 1 in 17,000a far cry from 1 in 170 million! And this is the strongest conclusion we can reach assuming only pairwise independence.\n",
      "On the other hand, the 1 in 17,000 bound that we get by assuming pairwise independence is a lot better than the bound that we would have if there were no independence at all. For example, if the markers are dependent, then it is possible that\n",
      "everyone with marker \n",
      "E\n",
      " has marker \n",
      "A\n",
      ",\n",
      "everyone with marker \n",
      "A\n",
      " has marker \n",
      "B\n",
      ",\n",
      "everyone with marker \n",
      "B\n",
      " has marker \n",
      "C\n",
      " , and\n",
      "everyone with marker \n",
      "C\n",
      " has marker \n",
      "D\n",
      ".\n",
      "In such a scenario, the probability of a match is\n",
      "Pr \n",
      "E\n",
      " D \n",
      "1=170:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 438  #444\n",
      "\n",
      "438\n",
      "\t\n",
      "Chapter 16\n",
      "\t\n",
      "Independence\n",
      "So a stronger independence assumption leads to a smaller bound on the prob-ability of a match. The trick is to figure out what independence assumption is reasonable. Assuming that the markers are mutually independent may well not be reasonable unless you have examined hundreds of millions of blood samples. Oth-erwise, how would you know that marker D does not show up more frequently whenever the other four markers are simultaneously present?\n",
      "We will conclude our discussion of independence with a useful, and somewhat famous, example known as the Birthday Paradox.\n",
      "\n",
      "16.5\n",
      "\t\n",
      "The Birthday Paradox\n",
      "Suppose that there are 100 students in a class. What is the probability that some birthday is shared by two people? Comparing 100 students to the 365 possible birthdays, you might guess the probability lies somewhere around 1=3but youd be wrong: the probability that there will be two people in the class with matching birthdays is actually 0:999999692 : : : . In other words, the probability that all 100 birthdays are different is less than 1 in 3,000,000.\n",
      "Why is this probability so small? The answer involves a phenomenon known as the Birthday Paradox (or the Birthday Principle), which is surprisingly important in computer science, as well see later.\n",
      "Before delving into the analysis, well need to make some modeling assump-tions:\n",
      "For each student, all possible birthdays are equally likely. The idea under-lying this assumption is that each students birthday is determined by a ran-dom process involving parents, fate, and, um, some issues that we discussed earlier in the context of graph theory. The assumption is not completely ac-curate, however; a disproportionate number of babies are born in August and September, for example.\n",
      "Birthdays are mutually independent. This isnt perfectly accurate either. For example, if there are twins in the class, then their birthdays are surely not independent.\n",
      "Well stick with these assumptions, despite their limitations. Part of the reason is to simplify the analysis. But the bigger reason is that our conclusions will apply to many situations in computer science where twins, leap days, and romantic holidays are not considerations. After all, whether or not two items collide in a hash table really has nothing to do with human reproductive preferences. Also, in pursuit of\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 439  #445\n",
      "\n",
      "generality, lets switch from specific numbers to variables. Let \n",
      "m\n",
      " be the number of people in the room, and let \n",
      "N\n",
      " be the number of days in a year.\n",
      "We can solve this problem using the standard four-step method. However, a tree diagram will be of little value because the sample space is so enormous. This time well have to proceed without the visual aid!\n",
      "Step 1: Find the Sample Space\n",
      "Lets number the people in the room from 1 to \n",
      "m\n",
      ". An outcome of the experiment is a sequence \n",
      ".b\n",
      "1\n",
      "; : : : ; b\n",
      "m\n",
      "/\n",
      " where \n",
      "b\n",
      "i\n",
      " is the birthday of the \n",
      "i\n",
      "th person. The sample space is the set of all such sequences:\n",
      "D f \n",
      ".b\n",
      "1\n",
      "; : : : ; b\n",
      "m\n",
      "/\n",
      " j \n",
      "b\n",
      "i\n",
      " 2 f\n",
      "1; : : : N\n",
      " g g\n",
      ":\n",
      "Step 2: Define Events of Interest\n",
      "Our goal is to determine the probability of the event \n",
      "A\n",
      " in which some pair of people have the same birthday. This event is a little awkward to study directly, however. So well use a common trick, which is to analyze the complementary event \n",
      "A\n",
      ", in which all \n",
      "m\n",
      " people have different birthdays:\n",
      "\n",
      "D f \n",
      ".b\n",
      "1\n",
      "; : : : ; b\n",
      "m\n",
      "/\n",
      " 2 S j all \n",
      "b\n",
      "i\n",
      " are distinct g\n",
      ":\n",
      "\n",
      "If we can compute Pr \n",
      "A\n",
      " , then we can compute what really want, Pr \n",
      "A\n",
      " , using the identity\n",
      "\n",
      "Pr \n",
      "A\n",
      " C Pr \n",
      "A\n",
      " D \n",
      "1:\n",
      "\n",
      "Step 3: Assign Outcome Probabilities\n",
      "We need to compute the probability that \n",
      "m\n",
      " people have a particular combination of birthdays \n",
      ".b\n",
      "1\n",
      "; : : : ; b\n",
      "m\n",
      "/\n",
      ". There are \n",
      "N\n",
      " possible birthdays and all of them are equally likely for each student. Therefore, the probability that the \n",
      "i\n",
      "th person was born on day \n",
      "b\n",
      "i\n",
      " is \n",
      "1=N\n",
      " . Since were assuming that birthdays are mutually independent, we can multiply probabilities. Therefore, the probability that the first person was born on day \n",
      "b\n",
      "1\n",
      ", the second on \n",
      "b\n",
      "2\n",
      ", and so forth is \n",
      ".1=N /\n",
      "m\n",
      ". This is the probability of every outcome in the sample space, which means that the sample space is uniform. Thats good news, because, as we have seen, it means that the analysis will be simpler.\n",
      "Step 4: Compute Event Probabilities\n",
      "Were interested in the probability of the event \n",
      "A\n",
      " in which everyone has a different birthday:\n",
      "\n",
      "A \n",
      "D f\n",
      " .b\n",
      "1\n",
      "; : : : ; b\n",
      "n\n",
      "/ \n",
      "j\n",
      " \n",
      "all\n",
      " b\n",
      "i\n",
      " \n",
      "are distinct\n",
      " \n",
      "g\n",
      ":\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 440  #446\n",
      "\n",
      "Were done!\n",
      "Or are we? While correct, it would certainly be nicer to have a closed-form ex-pression for Equation \n",
      ". That means finding an approximation for \n",
      "N\n",
      " and \n",
      ".N\n",
      " \n",
      "m/ \n",
      ". But this is what we learned how to do in Section\n",
      " \n",
      ".\n",
      " \n",
      "In fact, since\n",
      " N \n",
      "and \n",
      "N m\n",
      " are each at least 100, we know from Corollary \n",
      "that\n",
      "are excellent approximations (accurate to within .09%) of \n",
      "N\n",
      " and \n",
      ".N m/\n",
      " , re-spectively. Plugging these values into Equation \n",
      "means that (to within .2%)\n",
      "\n",
      "If there are two terms that can be off by .09%, then the ratio can be off by at most a factor of .1:0009/\n",
      "2\n",
      " < 1:002.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 441  #447\n",
      "\n",
      "We can now evaluate Equation \n",
      "for \n",
      "m\n",
      " D \n",
      "100\n",
      " and \n",
      "N\n",
      " D \n",
      "365\n",
      " to find that the probability that all 100 birthdays are different is\n",
      "3:07::: 10\n",
      "7\n",
      " :\n",
      "We can also plug in other values of \n",
      "m\n",
      " to find the number of people so that the probability of a matching birthday will be about \n",
      "1=2\n",
      ". In particular, for \n",
      "m\n",
      " D \n",
      "23\n",
      " and\n",
      "D \n",
      "365\n",
      ", Equation \n",
      "reveals that the probability that all the birthdays differ is 0.49. . . . So if you are in a room with 23 other people, the probability that some pair of people share a birthday will be a little better than \n",
      "1=2\n",
      ". It is because 23 seems like such a small number of people for a match that the phenomenon is called the Birthday Paradox.\n",
      "16.5.1\n",
      "\t\n",
      "Applications to Hashing\n",
      "Hashing is frequently used in computer science to map large strings of data into short strings of data. In a typical scenario, you have a set of \n",
      "m\n",
      " items and you would like to assign each item to a number from 1 to \n",
      "N\n",
      " where no pair of items is assigned to the same number and \n",
      "N\n",
      " is as small as possible. For example, the items might be messages, addresses, or variables. The numbers might represent storage locations, devices, indices, or digital signatures.\n",
      "If two items are assigned to the same number, then a collision is said to occur. Collisions are generally bad. For example, collisions can correspond to two vari-ables being stored in the same place or two messages being assigned the same dig-ital signature. Just imagine if you were doing electronic banking and your digital signature for a $10 check were the same as your signature for a $10 million dollar check. In fact, finding collisions is a common technique in breaking cryptographic codes.\n",
      "In practice, the assignment of a number to an item is done using a hash function\n",
      "h \n",
      "W\n",
      " S \n",
      "!\n",
      " 1; N ;\n",
      "where \n",
      "S\n",
      " is the set of items and \n",
      "m\n",
      " D j\n",
      "S\n",
      "j. Typically, the values of \n",
      "h.S/\n",
      " are assigned randomly and are assumed to be equally likely in \n",
      "1; N\n",
      " and mutually independent.\n",
      "For efficiency purposes, it is generally desirable to make \n",
      "N\n",
      " as small as necessary to accommodate the hashing of \n",
      "m\n",
      " items without collisions. Ideally, \n",
      "N\n",
      " would be only a little larger than \n",
      "m\n",
      ". Unfortunately, this is not possible for random hash functions. To see why, lets take a closer look at Equation \n",
      ".\n",
      "\n",
      "The possible .2% error is so small that it is lost in the . . . after 3.07.\n",
      "Such techniques are often referred to as birthday attacks because of the association of such attacks with the Birthday Paradox.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 442  #448\n",
      "\n",
      "442\n",
      "\t\n",
      "Chapter 16\n",
      "\t\n",
      "Independence\n",
      "By Theorem \n",
      "and the derivation of Equation \n",
      ", we know that the proba-bility that there are no collisions for a random hash function is\n",
      "For any m, we now need to find a value of N for which this expression is at least 1/2. That will tell us how big the hash table needs to be in order to have at least a 50% chance of avoiding collisions. This means that we need to find a value of N for which\n",
      "\n",
      "\n",
      "(16.6)\n",
      "term. We can do\n",
      "\n",
      "This may not look like a simplification, but stick with us here.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 443  #449\n",
      "\n",
      "If N grows faster than m\n",
      "2\n",
      ", then the value in Equation \n",
      "tends to 0 and Equa-tion \n",
      "cannot be satisfied. If N grows more slowly than m\n",
      "2\n",
      ", then the value in Equation \n",
      "diverges to negative infinity, and, once again, Equation \n",
      "cannot be satisfied. This suggests that we should focus on the case where N D .m\n",
      "2\n",
      "/, when Equation \n",
      "simplifies to\n",
      "In other words, N needs to grow quadratically with m in order to avoid collisions. This unfortunate fact is known as the Birthday Principle and it limits the efficiency of hashing in practiceeither N is quadratic in the number of items being hashed or you need to be able to deal with collisions.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 444  #450\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 445  #451\n",
      "\n",
      "17\n",
      "\t\n",
      "Random Variables and Distributions\n",
      "Thus far, we have focused on probabilities of events. For example, we computed the probability that you win the Monty Hall game, or that you have a rare medical condition given that you tested positive. But, in many cases we would like to more more. For example, how many contestants must play the Monty Hall game until one of them finally wins? How long will this condition last? How much will I lose gambling with strange dice all night? To answer such questions, we need to work with random variables.\n",
      "\n",
      "17.1\n",
      "\t\n",
      "Definitions and Examples\n",
      "Definition 17.1.1. A random variable R on a probability space is a total function whose domain is the sample space.\n",
      "The codomain of R can be anything, but will usually be a subset of the real numbers. Notice that the name random variable is a misnomer; random variables are actually functions!\n",
      "For example, suppose we toss three independent\n",
      ", unbiased coins. Let C be the number of heads that appear. Let M D 1 if the three coins come up all heads or all tails, and let M D 0 otherwise. Every outcome of the three coin flips uniquely determines the values of C and M . For example, if we flip heads, tails, heads, then\n",
      "D 2 and M D 0. If we flip tails, tails, tails, then C D 0 and M D 1. In effect,\n",
      "counts the number of heads, and M indicates whether all the coins match. Since each outcome uniquely determines C and M , we can regard them as func-\n",
      "tions mapping outcomes to numbers. For this experiment, the sample space is\n",
      "D fHHH; HH T; H TH; H T T; THH; TH T; T TH; T T T g\n",
      "and C is a function that maps each outcome in the sample space to a number as\n",
      "\n",
      "Going forward, when we talk about flipping independent coins, we will assume that they are mutually independent.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 446  #452\n",
      "\n",
      "So C and M are random variables.\n",
      "17.1.1\n",
      "\t\n",
      "Indicator Random Variables\n",
      "An indicator random variable is a random variable that maps every outcome to either 0 or 1. Indicator random variables are also called Bernoulli variables. The random variable M is an example. If all three coins match, then M D 1; otherwise,\n",
      "D 0.\n",
      "Indicator random variables are closely related to events. In particular, an in-dicator random variable partitions the sample space into those outcomes mapped to 1 and those outcomes mapped to 0. For example, the indicator M partitions the sample space into two blocks as follows:\n",
      "In the same way, an event E partitions the sample space into those outcomes in E and those not in E. So E is naturally associated with an indicator random variable, I\n",
      "E\n",
      " , where I\n",
      "E\n",
      " .w/ D 1 for outcomes w 2 E and I\n",
      "E\n",
      " .w/ D 0 for outcomes w E. Thus, M D I\n",
      "E\n",
      " where E is the event that all three coins match.\n",
      "17.1.2\n",
      "\t\n",
      "Random Variables and Events\n",
      "There is a strong relationship between events and more general random variables as well. A random variable that takes on several values partitions the sample space into several blocks. For example, C partitions the sample space as follows:\n",
      "\n",
      "CD0\n",
      "\t\n",
      "CD1\n",
      "\t\n",
      "CD2\n",
      "\t\n",
      "CD3\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 447  #453\n",
      "\n",
      "Each block is a subset of the sample space and is therefore an event. Thus, we can regard an equation or inequality involving a random variable as an event. For example, the event that \n",
      "C\n",
      " D \n",
      "2\n",
      " consists of the outcomes \n",
      "THH\n",
      " , \n",
      "H TH\n",
      " , and \n",
      "HH T\n",
      " . The event \n",
      "C 1\n",
      " consists of the outcomes \n",
      "T T T\n",
      " , \n",
      "T TH\n",
      " , \n",
      "TH T\n",
      " , and \n",
      "H T T\n",
      " .\n",
      "Naturally enough, we can talk about the probability of events defined by proper-ties of random variables. For example,\n",
      "Pr \n",
      "C\n",
      " D \n",
      "2\n",
      " D Pr \n",
      "THH\n",
      " C Pr \n",
      "H TH\n",
      " C Pr \n",
      "HH T\n",
      "1\n",
      "\t\n",
      "1\n",
      "\t\n",
      "1\n",
      "D\n",
      "8\n",
      "C\n",
      "8\n",
      "C\n",
      "8\n",
      "\n",
      "3\n",
      "8\n",
      ":\n",
      "\n",
      "As another example:\n",
      "Pr \n",
      "M\n",
      " D \n",
      "1\n",
      " D Pr \n",
      "T T T\n",
      " C Pr \n",
      "HHH\n",
      "D\n",
      "1\n",
      "8\n",
      "C\n",
      "1\n",
      "8\n",
      "\n",
      "1\n",
      "4\n",
      ":\n",
      "\n",
      "17.1.3\n",
      "\t\n",
      "Functions of Random Variables\n",
      "Random variables can be combined to form other random variables. For exam-ple, suppose that you roll two unbiased, independent 6-sided dice. Let \n",
      "D\n",
      "i\n",
      " be the random variable denoting the outcome of the \n",
      "i\n",
      "th die for \n",
      "i\n",
      " D \n",
      "1\n",
      ", \n",
      "2\n",
      ". For example,\n",
      "Pr \n",
      "D\n",
      "1\n",
      " D \n",
      "3\n",
      " D \n",
      "1=6:\n",
      "Then let \n",
      "T\n",
      " D \n",
      "D\n",
      "1\n",
      " C \n",
      "D\n",
      "2\n",
      ". \n",
      "T\n",
      " is also a random variable and it denotes the sum of the two dice. For example,\n",
      "Pr \n",
      "T\n",
      " D \n",
      "2\n",
      " D \n",
      "1=36\n",
      "and\n",
      "Pr \n",
      "T\n",
      " D \n",
      "7\n",
      " D \n",
      "1=6:\n",
      "Random variables can be combined in complicated ways, as we will see in Chap-ter \n",
      ". For example,\n",
      "D \n",
      "e\n",
      "T\n",
      "is also a random variable. In this case,\n",
      "Pr \n",
      "Y\n",
      " D \n",
      "e\n",
      "2\n",
      " D \n",
      "1=36\n",
      "and\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 448  #454\n",
      "\n",
      "Pr f\n",
      "THH; H TH; HH T\n",
      " g\n",
      "Pr f\n",
      "THH; H TH; HH T; H T T; TH T; T TH\n",
      " g\n",
      "3=8\n",
      "6=8\n",
      "1\n",
      "2\n",
      ":\n",
      "\n",
      "The expression \n",
      "C 2\n",
      " \\ \n",
      "M\n",
      " D \n",
      "0\n",
      " on the first line may look odd; what is the set operation \\ doing between an inequality and an equality? But recall that, in this context, \n",
      "C 2\n",
      " and \n",
      "M\n",
      " D \n",
      "0\n",
      " are events, and so they are sets of outcomes.\n",
      "17.1.5\n",
      "\t\n",
      "Independence\n",
      "The notion of independence carries over from events to random variables as well. Random variables \n",
      "R\n",
      "1\n",
      " and \n",
      "R\n",
      "2\n",
      " are independent iff for all \n",
      "x\n",
      "1\n",
      " in the codomain of \n",
      "R\n",
      "1\n",
      ", and \n",
      "x\n",
      "2\n",
      " in the codomain of \n",
      "R\n",
      "2\n",
      " for which Pr \n",
      "R\n",
      "2\n",
      " D \n",
      "X\n",
      "2\n",
      " \n",
      "> 0\n",
      ", we have:\n",
      "Pr \n",
      "R\n",
      "1\n",
      " D \n",
      "x\n",
      "1\n",
      " j \n",
      "R\n",
      "2\n",
      " D \n",
      "x\n",
      "2\n",
      "  D Pr \n",
      "R\n",
      "1\n",
      " D \n",
      "x\n",
      "1\n",
      " \n",
      ":\n",
      "As with events, we can formulate independence for random variables in an equiva-lent and perhaps more useful way: random variables \n",
      "R\n",
      "1\n",
      " and \n",
      "R\n",
      "2\n",
      " are independent if for all \n",
      "x\n",
      "1\n",
      " and \n",
      "x\n",
      "2\n",
      "Pr \n",
      "R\n",
      "1\n",
      " D \n",
      "x\n",
      "1\n",
      " \\ \n",
      "R\n",
      "2\n",
      " D \n",
      "x\n",
      "2\n",
      " D Pr \n",
      "R\n",
      "1\n",
      " D \n",
      "x\n",
      "1\n",
      "\t\n",
      "Pr \n",
      "R\n",
      "2\n",
      " D \n",
      "x\n",
      "2\n",
      " \n",
      ":\n",
      "For example, are \n",
      "C\n",
      " and \n",
      "M\n",
      " independent? Intuitively, the answer should be no. The number of heads, \n",
      "C\n",
      " , completely determines whether all three coins match; that is, whether \n",
      "M\n",
      " D \n",
      "1\n",
      ". But, to verify this intuition, we must find some \n",
      "x\n",
      "1\n",
      "; x\n",
      "2\n",
      " 2 R such that:\n",
      "Pr \n",
      "C\n",
      " D \n",
      "x\n",
      "1\n",
      " \\ \n",
      "M\n",
      " D \n",
      "x\n",
      "2\n",
      "  Pr \n",
      "C\n",
      " D \n",
      "x\n",
      "1\n",
      "\tPr \n",
      "M\n",
      " D \n",
      "x\n",
      "2\n",
      " \n",
      ":\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 449  #455\n",
      "\n",
      "One appropriate choice of values is \n",
      "x\n",
      "1\n",
      " D \n",
      "2\n",
      " and \n",
      "x\n",
      "2\n",
      " D \n",
      "1\n",
      ". In this case, we have:\n",
      "Pr \n",
      "C\n",
      " D \n",
      "2\n",
      " \\ \n",
      "M\n",
      " D \n",
      "1\n",
      " D \n",
      "0\n",
      "and\n",
      "Pr \n",
      "M\n",
      " D \n",
      "1\n",
      "\tPr \n",
      "C\n",
      " D \n",
      "2\n",
      " D \n",
      "1\n",
      "4\n",
      "\t\n",
      "3\n",
      "8\n",
      " \n",
      "\n",
      " \n",
      "0:\n",
      "\n",
      "The first probability is zero because we never have exactly two heads (\n",
      "C\n",
      " D \n",
      "2\n",
      ") when all three coins match (\n",
      "M\n",
      " D \n",
      "1\n",
      "). The other two probabilities were computed earlier.\n",
      "On the other hand, let \n",
      "F\n",
      " be the indicator variable for the event that the first flip is a Head, so\n",
      "Pr \n",
      "M\n",
      " D \n",
      "0\n",
      " D \n",
      "3=4\n",
      " D Pr \n",
      "M\n",
      " D \n",
      "0\n",
      " j \n",
      "F\n",
      " D \n",
      "1\n",
      " D Pr \n",
      "M\n",
      " D \n",
      "0\n",
      " j \n",
      "F\n",
      " D \n",
      "0 :\n",
      "This example is an instance of a simple lemma:\n",
      "Lemma 17.1.2. Two events are independent iff their indicator variables are inde-pendent.\n",
      "As with events, the notion of independence generalizes to more than two random variables.\n",
      "Definition 17.1.3. Random variables \n",
      "R\n",
      "1\n",
      "; R\n",
      "2\n",
      "; : : : ; R\n",
      "n\n",
      " are mutually independent iff Pr \n",
      "R\n",
      "1\n",
      " D \n",
      "x\n",
      "1\n",
      " \\ \n",
      "R\n",
      "2\n",
      " D \n",
      "x\n",
      "2\n",
      " \\ \\ \n",
      "R\n",
      "n\n",
      " D \n",
      "x\n",
      "n\n",
      "Pr \n",
      "R\n",
      "1\n",
      " D \n",
      "x\n",
      "1\n",
      "  Pr \n",
      "R\n",
      "2\n",
      " D \n",
      "x\n",
      "2\n",
      "    Pr \n",
      "R\n",
      "n\n",
      " D \n",
      "x\n",
      "n\n",
      " \n",
      ":\n",
      "for all \n",
      "x\n",
      "1\n",
      "; x\n",
      "2\n",
      "; : : : ; x\n",
      "n\n",
      ".\n",
      "A consequence of Definition \n",
      "is that the probability that any subset of the variables takes a particular set of values is equal to the product of the probabilities that the individual variables take their values. Thus, for example, if \n",
      "R\n",
      "1\n",
      "; R\n",
      "2\n",
      "; : : : ; R\n",
      "100\n",
      " are mutually independent random variables, then it follows that:\n",
      "Pr \n",
      "R\n",
      "1\n",
      " D \n",
      "7\n",
      " \\ \n",
      "R\n",
      "7\n",
      " D \n",
      "9:1\n",
      " \\ \n",
      "R\n",
      "23\n",
      " D\n",
      "D Pr \n",
      "R\n",
      "1\n",
      " D \n",
      "7\n",
      "  Pr \n",
      "R\n",
      "7\n",
      " D \n",
      "9:1\n",
      "  Pr \n",
      "R\n",
      "23\n",
      " D\n",
      "\t\n",
      ":\n",
      "The proof is based on summing over all possible values for all of the other random variables.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 450  #456\n",
      "\n",
      "450\n",
      "\t\n",
      "Chapter 17\n",
      "\t\n",
      "Random Variables and Distributions\n",
      "\n",
      "17.2\n",
      "\t\n",
      "Distribution Functions\n",
      "A random variable maps outcomes to values. Often, random variables that show up for different spaces of outcomes wind up behaving in much the same way because they have the same probability of having any given value. Hence, random variables on different probability spaces may wind up having the same probability density function.\n",
      "Definition 17.2.1. Let \n",
      "R\n",
      " be a random variable with codomain \n",
      "V\n",
      " . The probability density function (pdf) of \n",
      "R\n",
      " is a function PDF\n",
      "R\n",
      " W \n",
      "V\n",
      " ! \n",
      "0; 1\n",
      " defined by:\n",
      "This is because \n",
      "R\n",
      " has a value for each outcome, so summing the probabilities over all outcomes is the same as summing over the probabilities of each value in the range of \n",
      "R\n",
      ".\n",
      "As an example, suppose that you roll two unbiased, independent, 6-sided dice. Let \n",
      "T\n",
      " be the random variable that equals the sum of the two rolls. This random variable takes on values in the set \n",
      "V\n",
      " D f\n",
      "2; 3; : : : ; 12\n",
      "g. A plot of the probability density function for \n",
      "T\n",
      " is shown in Figure \n",
      ": The lump in the middle indicates that sums close to 7 are the most likely. The total area of all the rectangles is 1 since the dice must take on exactly one of the sums in \n",
      "V\n",
      " D f\n",
      "2; 3; : : : ; 12\n",
      "g.\n",
      "A closely-related concept to a PDF is the cumulative distribution function (cdf) for a random variable whose codomain is the real numbers. This is a function CDF\n",
      "R\n",
      " W R ! \n",
      "0; 1\n",
      " defined by:\n",
      "CDF\n",
      "R\n",
      ".x/\n",
      " D Pr \n",
      "R\n",
      "\t\n",
      "x :\n",
      "As an example, the cumulative distribution function for the random variable \n",
      "T\n",
      " is shown in Figure \n",
      ": The height of the \n",
      "i\n",
      "th bar in the cumulative distribution function is equal to the sum of the heights of the leftmost \n",
      "i\n",
      " bars in the probability\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 451  #457\n",
      "\n",
      "\n",
      "6=36\n",
      "\n",
      "PDF\n",
      "T\n",
      ".x/\n",
      "3=36\n",
      "\n",
      "Figure 17.1\n",
      "\t\n",
      "The probability density function for the sum of two 6-sided dice.\n",
      "\n",
      "\n",
      "CDF\n",
      "T\n",
      ".x/\n",
      "1=2\n",
      "\n",
      "0\n",
      "\n",
      "Figure 17.2\n",
      "\t\n",
      "The cumulative distribution function for the sum of two 6-sided dice.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 452  #458\n",
      "\n",
      "452\n",
      "\t\n",
      "Chapter 17\n",
      "\t\n",
      "Random Variables and Distributions\n",
      "density function. This follows from the definitions of pdf and cdf:\n",
      "CDF\n",
      "R\n",
      ".x/\n",
      " D Pr \n",
      "R\n",
      "\t\n",
      "x\n",
      "X\n",
      "D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\n",
      "Pr \n",
      "R\n",
      " D \n",
      "y\n",
      "y  x\n",
      "X\n",
      "D\n",
      "\t\n",
      "PDF\n",
      "R\n",
      ".y/:\n",
      "y  x\n",
      "In summary, PDF\n",
      "R\n",
      ".x/\n",
      " measures the probability that \n",
      "R\n",
      " D \n",
      "x\n",
      " and CDF\n",
      "R\n",
      ".x/\n",
      " measures the probability that \n",
      "R x\n",
      ". Both PDF\n",
      "R\n",
      " and CDF\n",
      "R\n",
      " capture the same information about the random variable \n",
      "R\n",
      "you can derive one from the otherbut sometimes one is more convenient.\n",
      "One of the really interesting things about density functions and distribution func-tions is that many random variables turn out to have the same pdf and cdf. In other words, even though \n",
      "R\n",
      " and \n",
      "S\n",
      " are different random variables on different probability spaces, it is often the case that\n",
      "PDF\n",
      "R\n",
      " D PDF\n",
      "s\n",
      ":\n",
      "In fact, some pdfs are so common that they are given special names. For exam-ple, the three most important distributions in computer science are the Bernoulli distribution, the uniform distribution, and the binomial distribution. We look more closely at these common distributions in the next several sections.\n",
      "\n",
      "17.3\tBernoulli Distributions\n",
      "The Bernoulli distribution is the simplest and most common distribution func-tion. Thats because it is the distribution function for an indicator random vari-able. Specifically, the Bernoulli distribution has a probability density function of the form \n",
      "f\n",
      "p\n",
      " W f\n",
      "0; 1\n",
      "g ! \n",
      "0; 1\n",
      " where\n",
      "f\n",
      "p\n",
      ".0/ \n",
      "D\n",
      " p;\n",
      "\t\n",
      "and\n",
      "f\n",
      "p\n",
      ".1/ \n",
      "D\n",
      " 1\tp;\n",
      "for some \n",
      "p\n",
      " 2 \n",
      "0; 1\n",
      " . The corresponding cumulative distribution function is \n",
      "F\n",
      "p\n",
      " W R ! \n",
      "0; 1\n",
      " where:\n",
      "8\n",
      "0\n",
      "\t\n",
      "if \n",
      "x < 0\n",
      "<\n",
      "F\n",
      "p\n",
      ".x/ \n",
      "D\n",
      "\tp\n",
      "\t\n",
      "if \n",
      "0\n",
      "\t\n",
      "x < 1\n",
      ":\n",
      "1\n",
      "\t\n",
      "if \n",
      "1\n",
      "\t\n",
      "x:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 453  #459\n",
      "\n",
      "\n",
      "17.4\tUniform Distributions\n",
      "17.4.1\n",
      "\t\n",
      "Definition\n",
      "A random variable that takes on each possible value with the same probability is said to be uniform. If the sample space is f\n",
      "1; 2; : : : ; n\n",
      "g, then the uniform distribu-tion has a pdf of the form\n",
      "f\n",
      "n\n",
      " \n",
      "W f\n",
      "1; 2; : : : ; n\n",
      "g !\n",
      " 0; 1\n",
      "where\n",
      "1\n",
      "f\n",
      "n\n",
      ".k/\n",
      " \n",
      "D\n",
      "\n",
      "n\n",
      "for some \n",
      "n\n",
      " 2 N\n",
      "C\n",
      ". The cumulative distribution function is then \n",
      "F\n",
      "n\n",
      " W R ! \n",
      "0; 1\n",
      " where\n",
      "8\n",
      "0\n",
      "\t\n",
      "if \n",
      "x < 1\n",
      "<\n",
      "F\n",
      "n\n",
      ".x/ \n",
      "D\n",
      "\tk=n\n",
      "\t\n",
      "if \n",
      "k\n",
      "\t\n",
      "x < k \n",
      "C\n",
      " 1 \n",
      "for\n",
      " 1\tk < n\n",
      ":\n",
      "1\n",
      "\t\n",
      "if \n",
      "n\n",
      "\t\n",
      "x:\n",
      "Uniform distributions arise frequently in practice. For example, the number rolled on a fair die is uniform on the set f\n",
      "1; 2; : : : ; 6\n",
      "g. If \n",
      "p\n",
      " D \n",
      "1=2\n",
      ", then an indicator random variable is uniform on the set f\n",
      "0; 1\n",
      "g.\n",
      "17.4.2\n",
      "\t\n",
      "The Numbers Game\n",
      "Enough definitionslets play a game! I have two envelopes. Each contains an in-teger in the range \n",
      "0; 1; : : : ; 100\n",
      ", and the numbers are distinct. To win the game, you must determine which envelope contains the larger number. To give you a fighting chance, well let you peek at the number in one envelope selected at random. Can you devise a strategy that gives you a better than 50% chance of winning?\n",
      "For example, you could just pick an envelope at random and guess that it contains the larger number. But this strategy wins only 50% of the time. Your challenge is to do better.\n",
      "So you might try to be more clever. Suppose you peek in one envelope and see the number 12. Since 12 is a small number, you might guess that that the number in the other envelope is larger. But perhaps weve been tricky and put small numbers in both envelopes. Then your guess might not be so good!\n",
      "An important point here is that the numbers in the envelopes may not be random. Were picking the numbers and were choosing them in a way that we think will defeat your guessing strategy. Well only use randomization to choose the numbers if that serves our purpose, which is to make you lose!\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 454  #460\n",
      "\n",
      "454\n",
      "\t\n",
      "Chapter 17\n",
      "\t\n",
      "Random Variables and Distributions\n",
      "Intuition Behind the Winning Strategy\n",
      "Amazingly, there is a strategy that wins more than 50% of the time, regardless of what numbers we put in the envelopes!\n",
      "Suppose that you somehow knew a number x that was in between the numbers in the envelopes. Now you peek in one envelope and see a number. If it is bigger than x, then you know youre peeking at the higher number. If it is smaller than x, then youre peeking at the lower number. In other words, if you know a number x between the numbers in the envelopes, then you are certain to win the game.\n",
      "The only flaw with this brilliant strategy is that you do not know such an x. Oh well.\n",
      "But what if you try to guess x? There is some probability that you guess cor-rectly. In this case, you win 100% of the time. On the other hand, if you guess incorrectly, then youre no worse off than before; your chance of winning is still 50%. Combining these two cases, your overall chance of winning is better than 50%!\n",
      "Informal arguments about probability, like this one, often sound plausible, but do not hold up under close scrutiny. In contrast, this argument sounds completely implausiblebut is actually correct!\n",
      "Analysis of the Winning Strategy\n",
      "For generality, suppose that we can choose numbers from the set f0; 1; : : : ; ng. Call the lower number L and the higher number H .\n",
      "Your goal is to guess a number x between L and H . To avoid confusing equality cases, you select x at random from among the half-integers:\n",
      "But what probability distribution should you use?\n",
      "The uniform distribution turns out to be your best bet. An informal justification is that if we figured out that you were unlikely to pick some numbersay 50\n",
      "1\n",
      "2\n",
      "  then wed always put 50 and 51 in the envelopes. Then youd be unlikely to pick an x between L and H and would have less chance of winning.\n",
      "After youve selected the number x, you peek into an envelope and see some number T . If T > x, then you guess that youre looking at the larger number. If T < x, then you guess that the other number is larger.\n",
      "All that remains is to determine the probability that this strategy succeeds. We can do this with the usual four step method and a tree diagram.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 455  #461\n",
      "\n",
      "Step 1: Find the sample space.\n",
      "You either choose x too low (< L), too high (> H ), or just right (L < x < H ).\n",
      "Then you either peek at the lower number (T D L) or the higher number (T D H ).\n",
      "This gives a total of six possible outcomes, as show in Figure \n",
      ".\n",
      "\n",
      "Figure 17.3\n",
      "\t\n",
      "The tree diagram for the numbers game.\n",
      "Step 2: Define events of interest.\n",
      "The four outcomes in the event that you win are marked in the tree diagram.\n",
      "Step 3: Assign outcome probabilities.\n",
      "First, we assign edge probabilities. Your guess x is too low with probability L=n, too high with probability .n H /=n, and just right with probability .H L/=n. Next, you peek at either the lower or higher number with equal probability. Multi-plying along root-to-leaf paths gives the outcome probabilities.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 456  #462\n",
      "\n",
      "456\n",
      "\t\n",
      "Chapter 17\n",
      "\t\n",
      "Random Variables and Distributions\n",
      "Step 4: Compute event probabilities.\n",
      "The probability of the event that you win is the sum of the probabilities of the four outcomes in that event:\n",
      "1\n",
      "2\n",
      " C \n",
      "H\n",
      "2n\n",
      " \n",
      "L\n",
      " \n",
      "1\n",
      "2\n",
      " C \n",
      "2n\n",
      "1\n",
      "\n",
      "The final inequality relies on the fact that the higher number \n",
      "H\n",
      " is at least 1 greater than the lower number \n",
      "L\n",
      " since they are required to be distinct.\n",
      "Sure enough, you win with this strategy more than half the time, regardless of the numbers in the envelopes! For example, if I choose numbers in the range\n",
      "0; 1; : : : ; 100\n",
      ", then you win with probability at least\n",
      " \n",
      "1\n",
      "2\n",
      " \n",
      "C\n",
      " \n",
      "200\n",
      "1\n",
      "  \n",
      "D\n",
      " 50:5\n",
      "%.  Even\n",
      "\n",
      "better, if Im allowed only numbers in the range \n",
      "0; : : : ; 10\n",
      ", then your probability of winning rises to 55%! By Las Vegas standards, those are great odds!\n",
      "17.4.3\n",
      "\t\n",
      "Randomized Algorithms\n",
      "The best strategy to win the numbers game is an example of a randomized algo-rithmit uses random numbers to influence decisions. Protocols and algorithms that make use of random numbers are very important in computer science. There are many problems for which the best known solutions are based on a random num-ber generator.\n",
      "For example, the most commonly-used protocol for deciding when to send a broadcast on a shared bus or Ethernet is a randomized algorithm known as expo-nential backoff. One of the most commonly-used sorting algorithms used in prac-tice, called quicksort, uses random numbers. Youll see many more examples if you take an algorithms course. In each case, randomness is used to improve the probability that the algorithm runs quickly or otherwise performs well.\n",
      "\n",
      "17.5\tBinomial Distributions\n",
      "17.5.1\n",
      "\t\n",
      "Definitions\n",
      "The third commonly-used distribution in computer science is the binomial distri-bution. The standard example of a random variable with a binomial distribution is the number of heads that come up in \n",
      "n\n",
      " independent flips of a coin. If the coin is\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 457  #463\n",
      "\n",
      "0:18\n",
      "\n",
      "0:16\n",
      "0:14\n",
      "0:12\n",
      "f\n",
      "20\n",
      ".k/ 0:10\n",
      "0:08\n",
      "0:06\n",
      "0:04\n",
      "0:02\n",
      "0\n",
      "0\n",
      "\t\n",
      "5\n",
      "\t\n",
      "10\n",
      "\t\n",
      "15\n",
      "\t\n",
      "20\n",
      "k\n",
      "Figure 17.4\n",
      "\t\n",
      "The pdf for the unbiased binomial distribution for \n",
      "n\n",
      " D \n",
      "20\n",
      ", \n",
      "f\n",
      "20\n",
      ".k/\n",
      ".\n",
      "fair, then the number of heads has an unbiased binomial distribution, specified by the pdf\n",
      "f\n",
      "n\n",
      " \n",
      "W f\n",
      "1; 2; : : : ; n\n",
      "g !\n",
      " 0; 1\n",
      "where\n",
      "!\n",
      "f\n",
      "n\n",
      ".k/ \n",
      "D\n",
      "\t\n",
      "k\n",
      "n\n",
      " \n",
      "2\n",
      "n\n",
      "for some \n",
      "n\n",
      " 2 N\n",
      "C\n",
      ". This is because there are \n",
      "k\n",
      "n\n",
      " sequences of \n",
      "n\n",
      " coin tosses with exactly \n",
      "k\n",
      " heads, and each such sequence has probability \n",
      "2\n",
      "n\n",
      " .\n",
      "A plot of \n",
      "f\n",
      "20\n",
      ".k/\n",
      " is shown in Figure \n",
      ". The most likely outcome is \n",
      "k\n",
      " D \n",
      "10\n",
      " heads, and the probability falls off rapidly for larger and smaller values of \n",
      "k\n",
      ". The falloff regions to the left and right of the main hump are called the tails of the distribution. Well talk a lot more about these tails shortly.\n",
      "The cumulative distribution function for the unbiased binomial distribution is \n",
      "F\n",
      "n\n",
      " \n",
      "W\n",
      " \n",
      "R\n",
      " \n",
      "!\n",
      " 0; 1 \n",
      "where\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 458  #464\n",
      "\n",
      "458\n",
      "\t\n",
      "Chapter 17\n",
      "\t\n",
      "Random Variables and Distributions\n",
      "0:25\n",
      "\n",
      "0:2\n",
      "0:15\n",
      "f\n",
      "20;:75\n",
      ".k/\n",
      "0:1\n",
      "0:05\n",
      "0\n",
      "0\n",
      "\t\n",
      "5\n",
      "\t\n",
      "10\n",
      "\t\n",
      "15\n",
      "\t\n",
      "20\n",
      "k\n",
      "Figure 17.5 The pdf for the general binomial distribution \n",
      "f\n",
      "n;p\n",
      ".k/\n",
      " for \n",
      "n\n",
      " D \n",
      "20\n",
      " and \n",
      "p\n",
      " D \n",
      ":75\n",
      ".\n",
      "The General Binomial Distribution\n",
      "If the coins are biased so that each coin is heads with probability \n",
      "p\n",
      ", then the number of heads has a general binomial density function specified by the pdf\n",
      "f\n",
      "n;p\n",
      ".k/ \n",
      "corresponding to flipping\n",
      " n \n",
      "D\n",
      " 20 \n",
      "independent coins that are heads with\n",
      " \n",
      "probability \n",
      "p\n",
      " D \n",
      "0:75\n",
      ". The graph shows that we are most likely to get \n",
      "k\n",
      " D \n",
      "15\n",
      " heads, as you might expect. Once again, the probability falls off quickly for larger and smaller values of \n",
      "k\n",
      ".\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 459  #465\n",
      "\n",
      "The cumulative distribution function for the general binomial distribution is \n",
      "F\n",
      "n;p\n",
      " W R ! \n",
      "0; 1\n",
      " where\n",
      "17.5.2\n",
      "\t\n",
      "Approximating the Probability Density Function\n",
      "Computing the general binomial density function is daunting when \n",
      "k\n",
      " and \n",
      "n\n",
      " are large. Fortunately, there is an approximate closed-form formula for this function based on an approximation for the binomial coefficient. In the formula below, \n",
      "k\n",
      " is replaced by \n",
      "n\n",
      " where is a number between 0 and 1.\n",
      "Lemma 17.5.1.\n",
      "!\n",
      "2\n",
      "nH. /\n",
      "n\n",
      "\t\n",
      "p\n",
      "2   .1   /n\n",
      "\t\n",
      "(17.2)\n",
      "\n",
      "and\n",
      "!\n",
      "Moreover, if \n",
      "n > 10\n",
      " and \n",
      ".1 /n > 10\n",
      ", then the left and right sides of Equa-tion \n",
      "differ by at most \n",
      "2\n",
      "%. If \n",
      "n > 100\n",
      " and \n",
      ".1 /n > 100\n",
      ", then the difference is at most \n",
      "0:2\n",
      "%.\n",
      "The graph of \n",
      "H\n",
      " is shown in Figure \n",
      ".\n",
      "Lemma (\n",
      ") provides an excellent approximation for binomial coefficients. Well skip its derivation, which consists of plugging in Theorem \n",
      "for the fac-torials in the binomial coefficient and then simplifying.\n",
      "Now lets plug Equation \n",
      "into the general binomial density function. The probability of flipping \n",
      "n\n",
      " heads in \n",
      "n\n",
      " tosses of a coin that comes up heads with\n",
      "log.x/ means log\n",
      "2\n",
      ".x/.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 460  #466\n",
      "\n",
      "460\n",
      "\t\n",
      "Chapter 17\n",
      "\t\n",
      "Random Variables and Distributions\n",
      "1\n",
      "\n",
      "0:8\n",
      "0:6\n",
      "H./\n",
      "0:4\n",
      "0:2\n",
      "0\n",
      "0\n",
      "\t\n",
      "0:2\n",
      "\t\n",
      "0:4\n",
      "\t\n",
      "0:6\n",
      "\t\n",
      "0:8\n",
      "\t\n",
      "1\n",
      "\n",
      "Figure 17.6\n",
      "\t\n",
      "The Entropy Function\n",
      "probability p is:\n",
      "2\n",
      "nH. /\n",
      "p\n",
      " n\n",
      ".1\n",
      "\t\n",
      "p/\n",
      ".1 /n\n",
      "f\n",
      "n;p\n",
      ". n/\n",
      "\t\n",
      "p\n",
      "\n",
      "2\t.1\n",
      "\t\n",
      "/n\n",
      "where the margin of error in the approximation is the same as in Lemma \n",
      ". From Equation \n",
      ", we also find that\n",
      "The formula in Equations \n",
      "and \n",
      "is as ugly as a bowling shoe, but its useful because its easy to evaluate. For example, suppose we flip a fair coin n times. What is the probability of getting exactly pn heads? Plugging D p\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 461  #467\n",
      "\n",
      "17.5. Binomial Distributions\n",
      "\t\n",
      "461\n",
      "Thus, for example, if we flip a fair coin (where \n",
      "p\n",
      " D \n",
      "1=2\n",
      ") \n",
      "n\n",
      " D \n",
      "100\n",
      " times, the probability of getting exactly 50 heads is within 2% of \n",
      "0:079\n",
      ", which is about 8%.\n",
      "17.5.3\tApproximating the Cumulative Distribution Function\n",
      "In many fields, including computer science, probability analyses come down to get-ting small bounds on the tails of the binomial distribution. In a typical application, you want to bound the tails in order to show that there is very small probability that too many bad things happen. For example, we might like to know that it is very unlikely that too many bits are corrupted in a message, or that too many servers or communication links become overloaded, or that a randomized algorithm runs for too long.\n",
      "So it is usually good news that the binomial distribution has small tails. To get a feel for their size, consider the probability of flipping at most 25 heads in 100 independent tosses of a fair coin.\n",
      "The probability of getting at most \n",
      "n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " heads is given by the binomial cumulative distribution function\n",
      "We can bound this sum by bounding the ratio of successive terms.\n",
      "In particular, for \n",
      "i\n",
      "\t\n",
      "n\n",
      ",\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 462  #468\n",
      "\n",
      "462\n",
      "\t\n",
      "Chapter 17\n",
      "\t\n",
      "Random Variables and Distributions\n",
      "times the probability of exactly\n",
      "\t\n",
      "n heads. For our scenario, where p D 1=2 and\n",
      "D 1=4,\n",
      "D\n",
      "3=4\n",
      "D\n",
      "3\n",
      ":\n",
      " 1 =p 1=2 2\n",
      "\n",
      "Plugging n D 100, D 1=4, and p D 1=2 into Equation \n",
      ", we find that the probability of at most 25 heads in 100 coin flips is\n",
      "This says that flipping 25 or fewer heads is extremely unlikely, which is consis-tent with our earlier claim that the tails of the binomial distribution are very small. In fact, notice that the probability of flipping 25 or fewer heads is only 50% more than the probability of flipping exactly 25 heads. Thus, flipping exactly 25 heads is twice as likely as flipping any number between 0 and 24!\n",
      "Caveat. The upper bound on F\n",
      "n;p\n",
      ". n/ in Equation \n",
      "holds only if < p. If this is not the case in your problem, then try thinking in complementary terms; that is, look at the number of tails flipped instead of the number of heads. In fact, this is precisely what we will do in the next example.\n",
      "17.5.4\n",
      "\t\n",
      "Noisy Channels\n",
      "Suppose you are sending packets of data across a communication channel and that each packet is lost with probability p D :01. Also suppose that packet losses are independent. You need to figure out how much redundancy (or error correction) to\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 463  #469\n",
      "\n",
      "build into your communication protocol. Since redundancy is expensive overheard, you would like to use as little as possible. On the other hand, you never want to be caught short. Would it be safe for you to assume that in any batch of 10,000 packets, only 200 (or 2%) are lost? Lets find out.\n",
      "The noisy channel is analogous to flipping n D 10;000 independent coins, each with probability p D :01 of coming up heads, and asking for the probability that there are at least n heads where D :02. Since > p, we cannot use Equa-tion \n",
      ". So we need to recast the problem by looking at the numbers of tails. In this case, the probability of tails is p D :99 and we are asking for the probability of at most n tails where D :98.\n",
      "Now we can use Equations \n",
      "and \n",
      "to find that the probability of losing 2%\n",
      "This is good news. It says that planning on at most 2% packet loss in a batch of 10,000 packets should be very safe, at least for the next few millennia.\n",
      "17.5.5\n",
      "\t\n",
      "Estimation by Sampling\n",
      "Sampling is a very common technique for estimating the fraction of elements in a set that have a certain property. For example, suppose that you would like to know how many Americans plan to vote for the Republican candidate in the next presidential election. It is infeasible to ask every American how they intend to vote, so pollsters will typically contact n Americans selected at random and then compute the fraction of those Americans that will vote Republican. This value is then used as the estimate of the number of all Americans that will vote Republican. For example, if 45% of the n contacted voters report that they will vote Republican, the pollster reports that 45% of all Americans will vote Republican. In addition, the pollster will usually also provide some sort of qualifying statement such as\n",
      "There is a 95% probability that the poll is accurate to within 4 per-centage points.\n",
      "The qualifying statement is often the source of confusion and misinterpretation. For example, many people interpret the qualifying statement to mean that there is a 95% chance that between 41% and 49% of Americans intend to vote Republican. But this is wrong! The fraction of Americans that intend to vote Republican is a fixed (and unknown) value p that is not a random variable. Since p is not a random variable, we cannot say anything about the probability that :41 p :49.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 464  #470\n",
      "\n",
      "464\n",
      "\t\n",
      "Chapter 17\n",
      "\t\n",
      "Random Variables and Distributions\n",
      "To obtain a correct interpretation of the qualifying statement and the results of the poll, it is helpful to introduce some notation.\n",
      "Define \n",
      "R\n",
      "i\n",
      " to be the indicator random variable for the \n",
      "i\n",
      "th contacted American in the sample. In particular, set \n",
      "R\n",
      "i\n",
      " D \n",
      "1\n",
      " if the \n",
      "i\n",
      "th contacted American intends to vote Republican and \n",
      "R\n",
      "i\n",
      " D \n",
      "0\n",
      " otherwise. For the purposes of the analysis, we will assume that the \n",
      "i\n",
      "th contacted American is selected uniformly at random (with replacement) from the set of all Americans.\n",
      "We will also assume that every contacted person responds honestly about whether or not they intend to vote Republican and that there are only two optionseach American intends to vote Republican or they dont. Thus,\n",
      "where \n",
      "p\n",
      " is the (unknown) fraction of Americans that intend to vote Republican.\n",
      "We next define\n",
      "D \n",
      "R\n",
      "1\n",
      " C \n",
      "R\n",
      "2\n",
      " C  C \n",
      "R\n",
      "n\n",
      "to be the number of contacted Americans who intend to vote Republican. Then \n",
      "T =n \n",
      "is a random variable that is the estimate of the fraction of Americans that\n",
      " \n",
      "intend to vote Republican.\n",
      "We are now ready to provide the correct interpretation of the qualifying state-ment. The poll results mean that\n",
      "In other words, there is a 95% chance that the sample group will produce an esti-mate that is within \n",
      "4\n",
      " percentage points of the correct value for the overall popu-lation. So either we were unlucky in selecting the people to poll or the results of the poll will be correct to within \n",
      "4\n",
      " points.\n",
      "How Many People Do We Need to Contact?\n",
      "There remains an important question: how many people \n",
      "n\n",
      " do we need to contact to make sure that Equation \n",
      "is true? In general, we would like \n",
      "n\n",
      " to be as small as possible in order to minimize the cost of the poll.\n",
      "Surprisingly, the answer depends only on the desired accuracy and confidence of the poll and not on the number of items in the set being sampled. In this case, the desired accuracy is .04, the desired confidence is .95, and the set being sampled is the set of Americans. Its a good thing that \n",
      "n\n",
      " wont depend on the size of the set being sampledthere are over 300 million Americans!\n",
      "\n",
      "This means that someone could be contacted multiple times.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 465  #471\n",
      "\n",
      "The task of finding an \n",
      "n\n",
      " that satisfies Equation \n",
      "is made tractable by observ-ing that \n",
      "T\n",
      " has a general binomial distribution with parameters \n",
      "n\n",
      " and \n",
      "p\n",
      " and then applying Equations \n",
      "and \n",
      ". Lets see how this works.\n",
      "Since we will be using bounds on the tails of the binomial distribution, we first do the standard conversion\n",
      " \n",
      "Pr  j\n",
      "T =n\n",
      "\t\n",
      "p\n",
      "j\n",
      "\t:04  \n",
      "D\n",
      " 1\n",
      "\t\n",
      "Pr  j\n",
      "T =n\n",
      "\t\n",
      "p\n",
      "j\n",
      " > :04 :\n",
      "We then proceed to upper bound\n",
      "We dont know the true value of \n",
      "p\n",
      ", but it turns out that the expression on the righthand side of Equation \n",
      "is maximized when \n",
      "p\n",
      " D \n",
      "1=2\n",
      " and so\n",
      "Pr  j\n",
      "T =n\n",
      "\t\n",
      "p\n",
      "j\n",
      " > :04\n",
      "\t\n",
      "2F\n",
      "n;1=2\n",
      ".:46n/\n",
      "1  :46\n",
      "2\n",
      "  \n",
      "1  .:46=:5/\n",
      "  \n",
      "f\n",
      "n;1=2\n",
      ".:46n/\n",
      "\n",
      "\n",
      "2\t0:46 0:54 n\n",
      "10:81 2\n",
      ":00462n\n",
      "<\n",
      "\t\n",
      "p\n",
      "\t\n",
      ":\n",
      "\t\n",
      "(17.11)\n",
      "\n",
      "n\n",
      "The second line comes from Equation \n",
      "using D \n",
      ":46\n",
      ". The third line comes from Equation \n",
      ".\n",
      "Equation \n",
      "provides bounds on the confidence of the poll for different values of \n",
      "n\n",
      ". For example, if \n",
      "n\n",
      " D \n",
      "665\n",
      ", the bound in Equation \n",
      "evaluates to \n",
      ":04978 : : :\n",
      " . Hence, if the pollster contacts 665 Americans, the poll will be accurate to within \n",
      "4 \n",
      "percentage points with at least 95% probability.\n",
      "Since the bound in Equation \n",
      "is exponential in \n",
      "n\n",
      ", the confidence increases greatly as \n",
      "n\n",
      " increases. For example, if \n",
      "n\n",
      " D \n",
      "6;650\n",
      " Americans are contacted, the poll will be accurate to within \n",
      "4\n",
      " points with probability at least \n",
      "1 10\n",
      "10\n",
      " . Of course, most pollsters are not willing to pay the added cost of polling 10 times as many people when they already have a confidence level of 95% from polling 665 people.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 466  #472\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 467  #473\n",
      "\n",
      "18\n",
      "\t\n",
      "Expectation\n",
      "\n",
      "18.1\n",
      "\t\n",
      "Definitions and Examples\n",
      "The expectation or expected value of a random variable is a single number that tells you a lot about the behavior of the variable. Roughly, the expectation is the average value of the random variable where each value is weighted according to its probability. Formally, the expected value (also known as the average or mean) of a random variable is defined as follows.\n",
      "Definition 18.1.1. If \n",
      "R\n",
      " is a random variable defined on a sample space S, then the expectation of \n",
      "R\n",
      " is\n",
      "w2S\n",
      "For example, suppose S is the set of students in a class, and we select a student uniformly at random. Let \n",
      "R\n",
      " be the selected students exam score. Then Ex \n",
      "R\n",
      " is just the class averagethe first thing everyone wants to know after getting their test back! For similar reasons, the first thing you usually want to know about a random variable is its expected value.\n",
      "Lets work through some examples.\n",
      "18.1.1\n",
      "\t\n",
      "The Expected Value of a Uniform Random Variable\n",
      "Let \n",
      "R\n",
      " be the value that comes up with you roll a fair 6-sided die. The the expected value of \n",
      "R\n",
      " is\n",
      "Ex \n",
      "R\n",
      " D \n",
      "1\n",
      "\t\n",
      "1\n",
      "6\n",
      " \n",
      "C\n",
      " \n",
      "2\n",
      "  \n",
      "1\n",
      "6\n",
      " \n",
      "C\n",
      " \n",
      "3\n",
      "  \n",
      "1\n",
      "6\n",
      " \n",
      "C\n",
      " \n",
      "4\n",
      "  \n",
      "1\n",
      "6\n",
      " \n",
      "C\n",
      " \n",
      "5\n",
      "  \n",
      "1\n",
      "6\n",
      " \n",
      "C\n",
      " \n",
      "6\n",
      "  \n",
      "1\n",
      "6\n",
      " \n",
      "D\n",
      " \n",
      "7\n",
      "2\n",
      ":\n",
      "\n",
      "This calculation shows that the name expected value is a little misleading; the random variable might never actually take on that value. You dont ever expect to roll a \n",
      "3\n",
      "1\n",
      "2\n",
      " on an ordinary die!\n",
      "Also note that the mean of a random variable is not the same as the median. The median is the midpoint of a distribution.\n",
      "Definition 18.1.2. The median\n",
      "of a random variable \n",
      "R\n",
      " is the value \n",
      "x\n",
      " 2 range\n",
      ".R/\n",
      "\n",
      "1\n",
      "Some texts define the median to be the value of \n",
      "x\n",
      " 2 range\n",
      ".R/\n",
      " for which Pr \n",
      "R x < 1=2\n",
      " and Pr \n",
      "R > x 1=2\n",
      ". The difference in definitions is not important.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 468  #474\n",
      "\n",
      "468\n",
      "\t\n",
      "Chapter 18\n",
      "\t\n",
      "Expectation\n",
      "such that\n",
      "In this text, we will not devote much attention to the median. Rather, we will focus on the expected value, which is much more interesting and useful.\n",
      "Rolling a 6-sided die provides an example of a uniform random variable. In general, if \n",
      "R\n",
      "n\n",
      " is a random variable with a uniform distribution on f\n",
      "1; 2; : : : ; n\n",
      "g, then\n",
      "18.1.2\n",
      "\t\n",
      "The Expected Value of an Indicator Random Variable\n",
      "The expected value of an indicator random variable for an event is just the proba-bility of that event.\n",
      "Lemma 18.1.3. If \n",
      "I\n",
      "A\n",
      " is the indicator random variable for event \n",
      "A\n",
      ", then\n",
      "Ex \n",
      "I\n",
      "A\n",
      " D Pr \n",
      "A :\n",
      "Proof.\n",
      "Ex \n",
      "I\n",
      "A\n",
      " D \n",
      "1\n",
      " Pr \n",
      "I\n",
      "A\n",
      " D \n",
      "1\n",
      " C \n",
      "0\n",
      " Pr \n",
      "I\n",
      "A\n",
      " D \n",
      "0\n",
      "D Pr \n",
      "I\n",
      "A\n",
      " D \n",
      "1\n",
      "D Pr \n",
      "A :\n",
      "\t\n",
      "(def of \n",
      "I\n",
      "A\n",
      ")\n",
      "For example, if \n",
      "A\n",
      " is the event that a coin with bias \n",
      "p\n",
      " comes up heads, then Ex \n",
      "I\n",
      "A\n",
      " D Pr \n",
      "I\n",
      "A\n",
      " D \n",
      "1\n",
      " D \n",
      "p\n",
      ".\n",
      "18.1.3\n",
      "\t\n",
      "Alternate Definitions\n",
      "There are several equivalent ways to define expectation.\n",
      "Theorem 18.1.4. If \n",
      "R\n",
      " is a random variable defined on a sample space S then\n",
      "The proof of Theorem \n",
      ", like many of the elementary proofs about expecta-tion in this chapter, follows by judicious regrouping of terms in the Equation \n",
      ":\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 469  #475\n",
      "\n",
      "The first equality follows because the events \n",
      "R\n",
      " D \n",
      "x\n",
      " for \n",
      "x\n",
      " 2 range\n",
      ".R/\n",
      " partition the sample space S, so summing over the outcomes in \n",
      "R\n",
      " D \n",
      "x\n",
      " for \n",
      "x\n",
      " 2 range\n",
      ".R/\n",
      "is the same as summing over S.\n",
      "In general, Equation \n",
      "is more useful than Equation \n",
      "for calculating ex-pected values and has the advantage that it does not depend on the sample space, but only on the density function of the random variable. It is especially useful when the range of the random variable is N, as we will see from the following corollary.\n",
      "Corollary 18.1.5. If the range of a random variable \n",
      "R\n",
      " is N, then\n",
      "Proof. The first equality follows directly from Theorem \n",
      "and the fact that range\n",
      ".R/\n",
      " D N. The second equality is derived by adding the following equations:\n",
      "Pr \n",
      "R > 0\n",
      " D\tPr \n",
      "R\n",
      " D \n",
      "1\n",
      "\t\n",
      "C Pr \n",
      "R\n",
      " D \n",
      "2\n",
      "  C Pr \n",
      "R\n",
      " D \n",
      "3\n",
      "  C\n",
      "D\n",
      "1\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 470  #476\n",
      "\n",
      "470\n",
      "\t\n",
      "Chapter 18\n",
      "\t\n",
      "Expectation\n",
      "18.1.4\n",
      "\t\n",
      "Mean Time to Failure\n",
      "The mean time to failure is a critical parameter in the design of most any system. For example, suppose that a computer program crashes at the end of each hour of use with probability \n",
      "p\n",
      ", if it has not crashed already. What is the expected time until the program crashes?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If we let \n",
      "C\n",
      " be the number of hours until the crash, then the answer to our prob-lem is Ex \n",
      "C\n",
      " . \n",
      "C\n",
      " is a random variable with values in N and so we can use Corol-lary \n",
      "to determine that\n",
      "Pr \n",
      "C > i\n",
      " is easy to evaluate: a crash happens later than the \n",
      "i\n",
      "th hour iff the system did not crash during the first \n",
      "i\n",
      " hours, which happens with probability \n",
      ".1\n",
      " \n",
      "p/\n",
      "i\n",
      " \n",
      ". Plugging this into Equation\n",
      " \n",
      "gives:\n",
      "D0\n",
      "For example, if there is a 1% chance that the program crashes at the end of each hour, then the expected time until the program crashes is \n",
      "1=0:01\n",
      " D \n",
      "100\n",
      " hours.\n",
      "The general principle here is well-worth remembering:\n",
      "If a system fails at each time step with probability \n",
      "p\n",
      ", then the expected number of steps up to (and including) the first failure is \n",
      "1=p\n",
      ".\n",
      "Making Babies\n",
      "As a related example, suppose a couple really wants to have a baby girl. For sim-plicity, assume that there is a 50% chance that each child they have is a girl, and that the genders of their children are mutually independent. If the couple insists on having children until they get a girl, then how many baby boys should they expect first?\n",
      "The question, How many hours until the program crashes? is mathematically the same as the question, How many children must the couple have until they get a girl? In this case, a crash corresponds to having a girl, so we should set\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 471  #477\n",
      "\n",
      "D 1=2. By the preceding analysis, the couple should expect a baby girl after having 1=p D 2 children. Since the last of these will be the girl, they should expect just one boy.\n",
      "18.1.5\tDealing with Infinity\n",
      "The analysis of the mean time to failure was easy enough. But if you think about it further, you might start to wonder about the case when the computer program never fails. For example, what if the program runs forever? How do we handle outcomes with an infinite value?\n",
      "These are good questions and we wonder about them too. Indeed, mathemati-cians have gone to a lot of work to reason about sample spaces with an infinite number of outcomes or outcomes with infinite value.\n",
      "To keep matters simple in this text, we will follow the common convention of ignoring the contribution of outcomes that have probability zero when computing expected values. This means that we can safely ignore the never-fail outcome, because it has probability\n",
      "lim .1\n",
      "\t\n",
      "p/\n",
      "n\n",
      " D 0:\n",
      "n!1\n",
      "In general, when we are computing expectations for infinite sample spaces, we will generally focus our attention on a subset of outcomes that occur with collec-tive probability one. For the most part, this will allow us to ignore the infinite outcomes because they will typically happen with probability zero.\n",
      "This assumption does not mean that the expected value of a random variable is always finite, however. Indeed, there are many examples where the expected value is infinite. And where infinity raises its ugly head, trouble is sure to follow. Lets see an example.\n",
      "18.1.6\n",
      "\t\n",
      "Pitfall: Computing Expectations by Sampling\n",
      "Suppose that you are trying to estimate a parameter such as the average delay across a communication channel. So you set up an experiment to measure how long it takes to send a test packet from one end to the other and you run the experiment 100 times.\n",
      "You record the latency, rounded to the nearest millisecond, for each of the hun-dred experiments, and then compute the average of the 100 measurements. Suppose that this average is 8.3 ms.\n",
      "Because you are careful, you repeat the entire process twice more and get aver-ages of 7.8 ms and 7.9 ms. You conclude that the average latency across the channel\n",
      "\n",
      "If this still bothers you, you might consider taking a course on measure theory.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 472  #478\n",
      "\n",
      "472\n",
      "\t\n",
      "Chapter 18\n",
      "\t\n",
      "Expectation\n",
      "with probability \n",
      "1=2\n",
      ", \n",
      "D\n",
      " D \n",
      "2\n",
      " with probability \n",
      "1=6\n",
      ", and so forth. So if we took 100 samples of \n",
      "D\n",
      ", about 50 would be 1 ms, about 16 would be 2 ms, and very few would be large. In summary, it might well be the case that the average of the 100 measurements would be under 10 ms, just as in our example.\n",
      "This sort of reasoning and the calculation of expected values by averaging ex-perimental values is very common in practice. It can easily lead to incorrect con-clusions, however. For example, using Corollary \n",
      ", we can quickly (and accu-rately) determine that\n",
      "1\n",
      "X\n",
      "Ex \n",
      "D\n",
      " D\n",
      "\t\n",
      "i \n",
      "Pr\n",
      " D \n",
      "D\n",
      " i\n",
      "Uh-oh! The expected time to cross the communication channel is infinite! This result is a far cry from the 10 ms that we calculated. What went wrong?\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 473  #479\n",
      "\n",
      "It is true that most of the time, the value of \n",
      "D\n",
      " will be small. But sometimes \n",
      "D \n",
      "will be very large and this happens with sufficient probability that the expected\n",
      " \n",
      "value of \n",
      "D\n",
      " is unbounded. In fact, if you keep repeating the experiment, you are likely to see some outcomes and averages that are much larger than 10 ms. In practice, such outliers are sometimes discarded, which masks the true behavior of \n",
      "D\n",
      ".\n",
      "In general, the best way to compute an expected value in practice is to first use the experimental data to figure out the distribution as best you can, and then to use Theorem \n",
      "or Corollary \n",
      "to compute its expectation. This method will help you identify cases where the expectation is infinite, and will generally be more accurate than a simple averaging of the data.\n",
      "18.1.7\n",
      "\t\n",
      "Conditional Expectation\n",
      "Just like event probabilities, expectations can be conditioned on some event. Given a random variable \n",
      "R\n",
      ", the expected value of \n",
      "R\n",
      " conditioned on an event \n",
      "A\n",
      " is the (probability-weighted) average value of \n",
      "R\n",
      " over outcomes in \n",
      "A\n",
      ". More formally:\n",
      "Definition 18.1.6. The conditional expectation Ex \n",
      "R\n",
      " j \n",
      "A\n",
      " of a random variable \n",
      "R\n",
      " given event \n",
      "A\n",
      " is:\n",
      "X\n",
      " \n",
      "Ex \n",
      "R\n",
      " j \n",
      "A\n",
      " WWD\n",
      "\t\n",
      "r  \n",
      "Pr\n",
      " R \n",
      "D\n",
      " r \n",
      "j\n",
      " A :\n",
      "\t\n",
      "(18.6)\n",
      "2range.R/\n",
      "For example, we can compute the expected value of a roll of a fair die, given, for example, that the number rolled is at least 4. We do this by letting \n",
      "R\n",
      " be the outcome of a roll of the die. Then by equation (\n",
      "),\n",
      "6\n",
      "X\n",
      "Ex \n",
      "R\n",
      " j \n",
      "R\n",
      "\t\n",
      "4 \n",
      "D\n",
      "\t\n",
      "i \n",
      "Pr\n",
      " R \n",
      "D\n",
      " i \n",
      "j\n",
      " R\n",
      "\t\n",
      "4 \n",
      "D\n",
      " 1 0\n",
      "C\n",
      "2 0\n",
      "C\n",
      "3 0\n",
      "C\n",
      "4 \n",
      "1\n",
      "3\n",
      " \n",
      "C\n",
      "5 \n",
      "1\n",
      "3\n",
      " \n",
      "C\n",
      "6 \n",
      "1\n",
      "3\n",
      " \n",
      "D\n",
      " 5:\n",
      "D1\n",
      "As another example, consider the channel latency problem from Section \n",
      ". The expected latency for this problem was infinite. But what if we look at the\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 474  #480\n",
      "\n",
      "474\n",
      "\t\n",
      "Chapter 18\n",
      "\t\n",
      "Expectation\n",
      "expected latency conditioned on the latency not exceeding \n",
      "n\n",
      ". Then\n",
      "1\n",
      "X\n",
      " \n",
      "Ex \n",
      "D\n",
      " D\n",
      "\t\n",
      "i \n",
      "Pr\n",
      " D \n",
      "D\n",
      " i \n",
      "j\n",
      " D\n",
      "\t\n",
      "n\n",
      "D1\n",
      "1\n",
      "D\n",
      " X \n",
      "i\n",
      " Pr \n",
      "D\n",
      " D \n",
      "i\n",
      " ^ \n",
      "D\n",
      "\t\n",
      "n\n",
      "\n",
      "Pr \n",
      "D\n",
      "\t\n",
      "n\n",
      "D1\n",
      "and \n",
      "0 .n/ 1\n",
      ". The second equality follows from the definition of conditional expectation, the third equality follows from the fact that Pr \n",
      "D\n",
      " D \n",
      "i\n",
      " ^ \n",
      "D n\n",
      " D \n",
      "0\n",
      " for \n",
      "i > n\n",
      ", and the fourth equality follows from the definition of \n",
      "D\n",
      " in Equation \n",
      ".\n",
      "n\n",
      " \n",
      "C\n",
      "n\n",
      " \n",
      "1\n",
      ":\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 475  #481\n",
      "\n",
      "For \n",
      "n\n",
      " D \n",
      "1000\n",
      ", this is about 6.5. This explains why the expected value of \n",
      "D\n",
      " appears to be finite when you try to evaluate it experimentally. If you compute 100 samples of \n",
      "D\n",
      ", it is likely that all of them will be at most 1000 ms. If you condition on not having any outcomes greater than 1000 ms, then the conditional expected value will be about 6.5 ms, which would be a commonly observed result in practice. Yet we know that Ex \n",
      "D\n",
      " is infinite. For this reason, expectations computed in practice are often really just conditional expectations where the condition is that rare outlier sample points are eliminated from the analysis.\n",
      "18.1.8\n",
      "\t\n",
      "The Law of Total Expectation\n",
      "Another useful feature of conditional expectation is that it lets us divide compli-cated expectation calculations into simpler cases. We can then find the desired expectation by calculating the conditional expectation in each simple case and av-eraging them, weighing each case by its probability.\n",
      "For example, suppose that 49.8% of the people in the world are male and the rest femalewhich is more or less true. Also suppose the expected height of a randomly chosen male is \n",
      "5\n",
      "0\n",
      " \n",
      "11\n",
      "00\n",
      ", while the expected height of a randomly chosen female is \n",
      "5\n",
      "0\n",
      " \n",
      "5\n",
      "00\n",
      ". What is the expected height of a randomly chosen individual? We can calculate this by averaging the heights of men and women. Namely, let \n",
      "H\n",
      " be the height (in feet) of a randomly chosen person, and let \n",
      "M\n",
      " be the event that the person is male and \n",
      "F\n",
      " the event that the person is female. Then\n",
      "Ex \n",
      "H\n",
      " D Ex \n",
      "H\n",
      " j \n",
      "M\n",
      " Pr \n",
      "M\n",
      " C Ex \n",
      "H\n",
      " j \n",
      "F\n",
      " Pr \n",
      "F\n",
      "D \n",
      ".5\n",
      " C \n",
      "11=12/ 0:498\n",
      " C \n",
      ".5\n",
      " C \n",
      "5=12/ 0:502\n",
      "5:665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which is a little less than 5 8.\n",
      "This method is justified by the Law of Total Expectation.\n",
      "Theorem 18.1.7 (Law of Total Expectation). Let \n",
      "R\n",
      " be a random variable on a sample space S and suppose that \n",
      "A\n",
      "1\n",
      ", \n",
      "A\n",
      "2\n",
      ", . . . , is a partition of S. Then\n",
      "X\n",
      "Ex \n",
      "R\n",
      " D\n",
      "\t\n",
      "Ex \n",
      "R\n",
      " j \n",
      "A\n",
      "i\n",
      " Pr \n",
      "A\n",
      "i\n",
      " \n",
      ":\n",
      "i\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 476  #482\n",
      "\n",
      "2range.R/\n",
      "X\tX\n",
      " \n",
      "D\n",
      "\t\n",
      "r\n",
      "\t\n",
      "Pr \n",
      "R\n",
      " D \n",
      "r\n",
      " j \n",
      "A\n",
      "i\n",
      "  Pr \n",
      "A\n",
      "i\n",
      "\t\n",
      "(Law of Total Probability)\n",
      "i\n",
      "X X\n",
      "D\n",
      "\t\n",
      "r  \n",
      "Pr\n",
      " R \n",
      "D\n",
      " r \n",
      "j\n",
      " A\n",
      "i\n",
      "  \n",
      "Pr\n",
      " A\n",
      "i\n",
      "\t\n",
      "(distribute constant \n",
      "r\n",
      ")\n",
      "i\n",
      "X X\n",
      "D\n",
      "\t\n",
      "r  \n",
      "Pr\n",
      " R \n",
      "D\n",
      " r \n",
      "j\n",
      " A\n",
      "i\n",
      "  \n",
      "Pr\n",
      " A\n",
      "i\n",
      "\t\n",
      "(exchange order of summation)\n",
      "r\n",
      "X\n",
      "\t\n",
      "X\n",
      "D\n",
      "\t\n",
      "Pr \n",
      "A\n",
      "i\n",
      "\t\n",
      "r  \n",
      "Pr\n",
      " R \n",
      "D\n",
      " r \n",
      "j\n",
      " A\n",
      "i\n",
      "\t\n",
      "(factor constant Pr \n",
      "A\n",
      "i\n",
      " )\n",
      "r\n",
      "X\n",
      "D\n",
      "\t\n",
      "Pr \n",
      "A\n",
      "i\n",
      " Ex \n",
      "R\n",
      " j \n",
      "A\n",
      "i\n",
      " \n",
      ":\n",
      "\t\n",
      "(Def \n",
      "of cond. expectation)\n",
      "i\n",
      "As a more interesting application of the Law of Total Expectation, lets take another look at the mean time to failure of a system that fails with probability \n",
      "p\n",
      " at each step. Well define \n",
      "A\n",
      " to be the event that the system fails on the first step and \n",
      "A \n",
      "to be the complementary event (namely, that the system does not fail on the first\n",
      " \n",
      "step). Then the mean time to failure Ex \n",
      "C\n",
      " is\n",
      "\n",
      "Since \n",
      "A\n",
      " is the condition that the system crashes on the first step, we know that\n",
      "Since \n",
      "A\n",
      " is the condition that the system does not crash on the first step, conditioning on \n",
      "A\n",
      " is equivalent to taking a first step without failure and then starting over without conditioning. Hence,\n",
      "\n",
      "Plugging Equations \n",
      "and \n",
      "into Equation \n",
      ", we find that\n",
      "Ex \n",
      "C\n",
      " D \n",
      "1 p\n",
      " C \n",
      ".1\n",
      " C Ex \n",
      "C /.1\n",
      "\t\n",
      "p/\n",
      "D \n",
      "p\n",
      " C \n",
      "1\n",
      "\t\n",
      "p \n",
      "C\n",
      " .1\tp/ \n",
      "Ex\n",
      " C\n",
      "D \n",
      "1\n",
      " C \n",
      ".1\n",
      "\t\n",
      "p/ \n",
      "Ex\n",
      " C :\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 477  #483\n",
      "\n",
      "Rearranging terms, we find that\n",
      "1 \n",
      "D\n",
      " \n",
      "Ex\n",
      " C\t.1\tp/ \n",
      "Ex\n",
      " C \n",
      "D\n",
      " p \n",
      "Ex\n",
      " C ;\n",
      "and thus that\n",
      "Ex \n",
      "C\n",
      " D \n",
      "p\n",
      "1\n",
      " \n",
      ";\n",
      "\n",
      "as expected.\n",
      "We will use this sort of analysis extensively in Chapter \n",
      "when we examine the expected behavior of random walks.\n",
      "18.1.9\n",
      "\t\n",
      "Expectations of Functions\n",
      "Expectations can also be defined for functions of random variables.\n",
      "Definition 18.1.8. Let \n",
      "R\n",
      " W S ! \n",
      "V\n",
      " be a random variable and \n",
      "f\n",
      " W \n",
      "V\n",
      " ! R be a total function on the range of \n",
      "R\n",
      ". Then\n",
      "For example, suppose that \n",
      "R\n",
      " is the value obtained by rolling a fair 6-sided die. Then\n",
      "\n",
      "18.2\n",
      "\t\n",
      "Expected Returns in Gambling Games\n",
      "Some of the most interesting examples of expectation can be explained in terms of gambling games. For straightforward games where you win $\n",
      "A\n",
      " with probability \n",
      "p\n",
      " and you lose $\n",
      "B\n",
      " with probability \n",
      "1 p\n",
      ", it is easy to compute your expected return or winnings. It is simply\n",
      "pA\t.1\tp/B:\n",
      "For example, if you are flipping a fair coin and you win $1 for heads and you lose $1 for tails, then your expected winnings are\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 478  #484\n",
      "\n",
      "478\n",
      "\t\n",
      "Chapter 18\n",
      "\t\n",
      "Expectation\n",
      "In such cases, the game is said to be fair since your expected return is zero.\n",
      "Some gambling games are more complicated and thus more interesting. For example, consider the following game where the winners split a pot. This sort of game is representative of many poker games, betting pools, and lotteries.\n",
      "18.2.1\n",
      "\t\n",
      "Splitting the Pot\n",
      "After your last encounter with biker dude, one thing lead to another and you have dropped out of school and become a Hells Angel. Its late on a Friday night and, feeling nostalgic for the old days, you drop by your old hangout, where you en-counter two of your former TAs, Eric and Nick. Eric and Nick propose that you join them in a simple wager. Each player will put $2 on the bar and secretly write heads or tails on their napkin. Then one player will flip a fair coin. The $6 on the bar will then be divided equally among the players who correctly predicted the outcome of the coin toss.\n",
      "After your life-altering encounter with strange dice, you are more than a little skeptical. So Eric and Nick agree to let you be the one to flip the coin. This certainly seems fair. How can you lose?\n",
      "But you have learned your lesson and so before agreeing, you go through the four-step method and write out the tree diagram to compute your expected return. The tree diagram is shown in Figure \n",
      ".\n",
      "The payoff values in Figure \n",
      "are computed by dividing the $6 pot\n",
      "among those players who guessed correctly and then subtracting the $2 that you put into the pot at the beginning. For example, if all three players guessed correctly, then you payoff is $0, since you just get back your $2 wager. If you and Nick guess correctly and Eric guessed wrong, then your payoff is\n",
      "6\n",
      "2\n",
      "D\n",
      "1:\n",
      "\n",
      "2\n",
      "In the case that everyone is wrong, you all agree to split the pot and so, again, your payoff is zero.\n",
      "To compute your expected return, you use Equation \n",
      "in the definition of expected value. This yields\n",
      "D \n",
      "0:\n",
      "\n",
      "The money invested in a wager is commonly referred to as the pot.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 479  #485\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Figure 18.1 The tree diagram for the game where three players each wager $2 and then guess the outcome of a fair coin toss. The winners split the pot.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 480  #486\n",
      "\n",
      "480\n",
      "\t\n",
      "Chapter 18\n",
      "\t\n",
      "Expectation\n",
      "This confirms that the game is fair. So, for old times sake, you break your solemn vow to never ever engage in strange gambling games.\n",
      "18.2.2\n",
      "\t\n",
      "The Impact of Collusion\n",
      "Needless to say, things are not turning out well for you. The more times you play the game, the more money you seem to be losing. After 1000 wagers, you have lost over $500. As Nick and Eric are consoling you on your bad luck, you do a back-of-the-napkin calculation using the bounds on the tails of the binomial distribution from Section \n",
      "that suggests that the probability of losing $500 in 1000 wagers is less than the probability of a Vietnamese Monk waltzing in and handing you one of those golden disks. How can this be?\n",
      "It is possible that you are truly very very unlucky. But it is more likely that something is wrong with the tree diagram in Figure \n",
      "and that something just might have something to do with the possibility that Nick and Eric are colluding against you.\n",
      "To be sure, Nick and Eric can only guess the outcome of the coin toss with probability \n",
      "1=2\n",
      ", but what if Nick and Eric always guess differently? In other words, what if Nick always guesses tails when Eric guesses heads, and vice-versa? This would result in a slightly different tree diagram, as shown in Figure \n",
      ".\n",
      "The payoffs for each outcome are the same in Figures \n",
      "and \n",
      ", but the probabilities of the outcomes are different. For example, it is no longer possible for all three players to guess correctly, since Nick and Eric are always guessing differently. More importantly, the outcome where your payoff is $4 is also no longer possible. Since Nick and Eric are always guessing differently, one of them will always get a share of the pot. As you might imagine, this is not good for you!\n",
      "When we use Equation \n",
      "to compute your expected return in the collusion scenario, we find that\n",
      "Ex payoff D \n",
      "0 0\n",
      " C \n",
      "1\n",
      "\t\n",
      "1\n",
      "4\n",
      " \n",
      "C\n",
      " \n",
      "1\n",
      "  \n",
      "1\n",
      "4\n",
      " \n",
      "C\n",
      " \n",
      "4 0\n",
      "\n",
      "This is very bad indeed. By colluding, Nick and Eric have made it so that you expect to lose $.50 every time you play. No wonder you lost $500 over the course of 1000 wagers.\n",
      "Maybe it would be a good idea to go back to schoolyour Hells Angels buds may not be too happy that you just lost their $500.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 481  #487\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Figure 18.2 The revised tree diagram reflecting the scenario where Nick always guesses the opposite of Eric.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 482  #488\n",
      "\n",
      "482\n",
      "\t\n",
      "Chapter 18\n",
      "\t\n",
      "Expectation\n",
      "18.2.3\tHow to Win the Lottery\n",
      "Similar opportunities to collude arise in many betting games. For example, con-sider the typical weekly football betting pool, where each participant wagers $10 and the participants that pick the most games correctly split a large pot. The pool seems fair if you think of it as in Figure \n",
      ". But, in fact, if two or more players collude by guessing differently, they can get an unfair advantage at your expense!\n",
      "In some cases, the collusion is inadvertent and you can profit from it. For ex-ample, many years ago, a former MIT Professor of Mathematics named Herman Chernoff figured out a way to make money by playing the state lottery. This was surprising since state lotteries typically have very poor expected returns. Thats be-cause the state usually takes a large share of the wagers before distributing the rest of the pot among the winners. Hence, anyone who buys a lottery ticket is expected to lose money. So how did Chernoff find a way to make money? It turned out to be easy!\n",
      "In a typical state lottery,\n",
      "all players pay $1 to play and select 4 numbers from 1 to 36, the state draws 4 numbers from 1 to 36 uniformly at random,\n",
      "the states divides 1/2 of the money collected among the people who guessed correctly and spends the other half redecorating the governors residence.\n",
      "This is a lot like the game you played with Nick and Eric, except that there are more players and more choices. Chernoff discovered that a small set of numbers was selected by a large fraction of the population. Apparently many people think the same way; they pick the same numbers not on purpose as in the previous game with Nick and Eric, but based on Mannys batting average or todays date.\n",
      "It was as if the players were colluding to lose! If any one of them guessed correctly, then theyd have to split the pot with many other players. By selecting numbers uniformly at random, Chernoff was unlikely to get one of these favored sequences. So if he won, hed likely get the whole pot! By analyzing actual state lottery data, he determined that he could win an average of 7 cents on the dollar. In other words, his expected return was not $:50 as you might think, but C$:07.\n",
      "Inadvertent collusion often arises in betting pools and is a phenomenon that you can take advantage of. For example, suppose you enter a Super Bowl betting pool where the goal is to get closest to the total number of points scored in the game. Also suppose that the average Super Bowl has a total of 30 point scored and that\n",
      "\n",
      "Most lotteries now offer randomized tickets to help smooth out the distribution of selected se-quences.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 483  #489\n",
      "\n",
      "everyone knows this. Then most people will guess around 30 points. Where should you guess? Well, you should guess just outside of this range because you get to cover a lot more ground and you dont share the pot if you win. Of course, if you are in a pool with math students and they all know this strategy, then maybe you should guess 30 points after all.\n",
      "\n",
      "18.3\n",
      "\t\n",
      "Expectations of Sums\n",
      "18.3.1\tLinearity of Expectation\n",
      "Expected values obey a simple, very helpful rule called Linearity of Expectation. Its simplest form says that the expected value of a sum of random variables is the sum of the expected values of the variables.\n",
      "Theorem 18.3.1. For any random variables \n",
      "R\n",
      "1\n",
      " and \n",
      "R\n",
      "2\n",
      ",\n",
      "Ex \n",
      "R\n",
      "1\n",
      " C \n",
      "R\n",
      "2\n",
      " D Ex \n",
      "R\n",
      "1\n",
      " C Ex \n",
      "R\n",
      "2\n",
      " \n",
      ":\n",
      "Proof. Let \n",
      "T\n",
      " WWD \n",
      "R\n",
      "1\n",
      " C \n",
      "R\n",
      "2\n",
      ". The proof follows straightforwardly by rearranging terms in Equation (\n",
      "):\n",
      "Theorem 18.3.2. For random variables \n",
      "R\n",
      "1\n",
      ", \n",
      "R\n",
      "2\n",
      " and constants \n",
      "a\n",
      "1\n",
      "; a\n",
      "2\n",
      " 2 R,\n",
      "Ex \n",
      "a\n",
      "1\n",
      "R\n",
      "1\n",
      " C \n",
      "a\n",
      "2\n",
      "R\n",
      "2\n",
      " D \n",
      "a\n",
      "1\n",
      " Ex \n",
      "R\n",
      "1\n",
      " C \n",
      "a\n",
      "2\n",
      " Ex \n",
      "R\n",
      "2\n",
      " \n",
      ":\n",
      "In other words, expectation is a linear function. A routine induction extends the result to more than two variables:\n",
      "Corollary 18.3.3 (Linearity of Expectation). For any random variables \n",
      "R\n",
      "1\n",
      "; : : : ; R\n",
      "k\n",
      "and constants \n",
      "a\n",
      "1\n",
      "; : : : ; a\n",
      "k\n",
      " 2 R,\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 484  #490\n",
      "\n",
      "484\n",
      "\t\n",
      "Chapter 18\n",
      "\t\n",
      "Expectation\n",
      "The great thing about linearity of expectation is that no independence is required. This is really useful, because dealing with independence is a pain, and we often need to work with random variables that are not known to be independent.\n",
      "As an example, lets compute the expected value of the sum of two fair dice. Let the random variable \n",
      "R\n",
      "1\n",
      " be the number on the first die, and let \n",
      "R\n",
      "2\n",
      " be the number on the second die. We observed earlier that the expected value of one die is 3.5. We can find the expected value of the sum using linearity of expectation:\n",
      "Ex \n",
      "R\n",
      "1\n",
      " C \n",
      "R\n",
      "2\n",
      " D Ex \n",
      "R\n",
      "1\n",
      " C Ex \n",
      "R\n",
      "2\n",
      " D \n",
      "3:5\n",
      " C \n",
      "3:5\n",
      " D \n",
      "7:\n",
      "Notice that we did not have to assume that the two dice were independent. The expected sum of two dice is 7, even if they are glued together (provided each indi-vidual die remains fair after the gluing). Proving that this expected sum is 7 with a tree diagram would be a bother: there are 36 cases. And if we did not assume that the dice were independent, the job would be really tough!\n",
      "18.3.2\n",
      "\t\n",
      "Sums of Indicator Random Variables\n",
      "Linearity of expectation is especially useful when you have a sum of indicator ran-dom variables. As an example, suppose there is a dinner party where \n",
      "n\n",
      " men check their hats. The hats are mixed up during dinner, so that afterward each man receives a random hat. In particular, each man gets his own hat with probability \n",
      "1=n\n",
      ". What is the expected number of men who get their own hat?\n",
      "Letting \n",
      "G\n",
      " be the number of men that get their own hat, we want to find the expectation of \n",
      "G\n",
      ". But all we know about \n",
      "G\n",
      " is that the probability that a man gets his own hat back is \n",
      "1=n\n",
      ". There are many different probability distributions of hat permutations with this property, so we dont know enough about the distribution of \n",
      "G\n",
      " to calculate its expectation directly. But linearity of expectation makes the problem really easy.\n",
      "The trick\n",
      "is to express \n",
      "G\n",
      " as a sum of indicator variables. In particular, let \n",
      "G\n",
      "i\n",
      " be an indicator for the event that the \n",
      "i\n",
      "th man gets his own hat. That is, \n",
      "G\n",
      "i\n",
      " D \n",
      "1\n",
      " if the \n",
      "i\n",
      "th man gets his own hat, and\n",
      " G\n",
      "i\n",
      " \n",
      "D\n",
      " 0 \n",
      "otherwise. The number of men that get their\n",
      " \n",
      "own hat is then the sum of these indicator random variables:\n",
      "G \n",
      "D\n",
      " G\n",
      "1\n",
      " \n",
      "C\n",
      " G\n",
      "2\n",
      " \n",
      "C\n",
      "\t\n",
      "C \n",
      "G\n",
      "n\n",
      ":\n",
      "\t\n",
      "(18.13)\n",
      "These indicator variables are not mutually independent. For example, if \n",
      "n 1\n",
      " men all get their own hats, then the last man is certain to receive his own hat. But, since we plan to use linearity of expectation, we dont have worry about independence!\n",
      "\n",
      "5\n",
      "We are going to use this trick a lot so it is important to understand it.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 485  #491\n",
      "\n",
      "Ex \n",
      "G\n",
      " D Ex \n",
      "G\n",
      "1\n",
      " C \n",
      "G\n",
      "2\n",
      " C\n",
      "\t\n",
      "C \n",
      "G\n",
      "n\n",
      "Ex \n",
      "G\n",
      "1\n",
      " C Ex \n",
      "G\n",
      "2\n",
      " C  C Ex \n",
      "G\n",
      "n\n",
      "n\n",
      " \n",
      "\n",
      "n\n",
      "1\n",
      " C \n",
      "n\n",
      "1\n",
      " C  C \n",
      "n\n",
      "1\n",
      "1:\n",
      "\n",
      "So even though we dont know much about how hats are scrambled, weve figured out that on average, just one man gets his own hat back!\n",
      "More generally, Linearity of Expectation provides a very good method for com-puting the expected number of events that will happen.\n",
      "Theorem 18.3.4. Given any collection of \n",
      "n\n",
      " events \n",
      "A\n",
      "1\n",
      "; A\n",
      "2\n",
      "; : : : ; A\n",
      "n\n",
      " S, the ex-pected number of events that will occur is\n",
      "n\n",
      "X\n",
      "Pr \n",
      "A\n",
      "i\n",
      " \n",
      ":\n",
      "D1\n",
      "For example, \n",
      "A\n",
      "i\n",
      " could be the event that the \n",
      "i\n",
      "th man gets the right hat back. But in general, it could be any subset of the sample space, and we are asking for the expected number of events that will contain a random sample point.\n",
      "Proof. Define \n",
      "R\n",
      "i\n",
      " to be the indicator random variable for \n",
      "A\n",
      "i\n",
      " , where \n",
      "R\n",
      "i\n",
      " \n",
      ".w/\n",
      " D \n",
      "1\n",
      " if\n",
      "2 \n",
      "A\n",
      "i\n",
      " and \n",
      "R\n",
      "i\n",
      " \n",
      ".w/\n",
      " D \n",
      "0\n",
      " if \n",
      "w  A\n",
      "i\n",
      " . Let \n",
      "R\n",
      " D \n",
      "R\n",
      "1\n",
      " C \n",
      "R\n",
      "2\n",
      " C  C \n",
      "R\n",
      "n\n",
      ". Then\n",
      "iD1\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 486  #492\n",
      "\n",
      "486\n",
      "\t\n",
      "Chapter 18\n",
      "\t\n",
      "Expectation\n",
      "So whenever you are asked for the expected number of events that occur, all you have to do is sum the probabilities that each event occurs. Independence is not needed.\n",
      "18.3.3\n",
      "\t\n",
      "Expectation of a Binomial Distribution\n",
      "Suppose that we independently flip \n",
      "n\n",
      " biased coins, each with probability \n",
      "p\n",
      " of com-ing up heads. What is the expected number of heads?\n",
      "Let \n",
      "J\n",
      " be the random variable denoting the number of heads. Then \n",
      "J\n",
      " has a binomial distribution with parameters \n",
      "n\n",
      ", \n",
      "p\n",
      ", and\n",
      "!\n",
      "Pr \n",
      "J\n",
      " D \n",
      "k\n",
      " D\n",
      "\t\n",
      "k\n",
      "n\n",
      " \n",
      "k\n",
      "p\n",
      ".n  k/\n",
      "1p\n",
      "  \n",
      ":\n",
      "Applying Equation \n",
      ", this means that\n",
      "n\n",
      "X\n",
      "Ex \n",
      "J\n",
      " D\n",
      "\t\n",
      "k \n",
      "Pr\n",
      " J \n",
      "D\n",
      " k\n",
      "kD0\n",
      "Ouch! This is one nasty looking sum. Lets try another approach.\n",
      "Since we have just learned about linearity of expectation for sums of indicator random variables, maybe Theorem \n",
      "will be helpful. But how do we express \n",
      "J\n",
      " as a sum of indicator random variables? It turns out to be easy. Let \n",
      "J\n",
      "i\n",
      " be the indicator random variable for the \n",
      "i\n",
      "th coin. In particular, define\n",
      "Then the number of heads is simply\n",
      "J \n",
      "D\n",
      " J\n",
      "1\n",
      " \n",
      "C\n",
      " J\n",
      "2\n",
      " \n",
      "C\n",
      "\t\n",
      "C \n",
      "J\n",
      "n\n",
      ":\n",
      "By Theorem \n",
      ",\n",
      "n\n",
      "X\n",
      "Ex \n",
      "J\n",
      " D\n",
      "\t\n",
      "Pr \n",
      "J\n",
      "i\n",
      "iD1\n",
      "D \n",
      "np:\n",
      "\t\n",
      "(18.16)\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 487  #493\n",
      "\n",
      "That really was easy. If we flip n mutually independent coins, we expect to get pn heads. Hence the expected value of a binomial distribution with parameters n and p is simply pn.\n",
      "But what if the coins are not mutually independent? It doesnt matterthe an-swer is still pn because Linearity of Expectation and Theorem \n",
      "do not as-sume any independence.\n",
      "If you are not yet convinced that Linearity of Expectation and Theorem \n",
      " are powerful tools, consider this: without even trying, we have used them to prove a very complicated identity, namely\n",
      "If you are still not convinced, then take a look at the next problem.\n",
      "18.3.4\n",
      "\t\n",
      "The Coupon Collector Problem\n",
      "Every time we purchase a kids meal at Taco Bell, we are graciously presented with a miniature Racin Rocket car together with a launching device which enables us to project our new vehicle across any tabletop or smooth floor at high velocity. Truly, our delight knows no bounds.\n",
      "There are n different types of Racin Rocket cars (blue, green, red, gray, etc.). The type of car awarded to us each day by the kind woman at the Taco Bell reg-ister appears to be selected uniformly and independently at random. What is the expected number of kids meals that we must purchase in order to acquire at least one of each type of Racin Rocket car?\n",
      "The same mathematical question shows up in many guises: for example, what is the expected number of people you must poll in order to find at least one person with each possible birthday? Here, instead of collecting Racin Rocket cars, youre collecting birthdays. The general question is commonly called the coupon collector problem after yet another interpretation.\n",
      "A clever application of linearity of expectation leads to a simple solution to the coupon collector problem. Suppose there are five different types of Racin Rocket cars, and we receive this sequence:\n",
      "blue\tgreen\tgreen\tred\tblue\torange\tblue\torange\n",
      "\t\n",
      "gray.\n",
      "Lets partition the sequence into 5 segments:\n",
      "\n",
      "This follows by combining Equations \n",
      "and \n",
      ".\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 488  #494\n",
      "\n",
      "488\n",
      "\t\n",
      "Chapter 18\n",
      "\t\n",
      "Expectation\n",
      "The rule is that a segment ends whenever we get a new kind of car. For example, the middle segment ends when we get a red car for the first time. In this way, we can break the problem of collecting every type of car into stages. Then we can analyze each stage individually and assemble the results using linearity of expectation.\n",
      "Lets return to the general case where were collecting \n",
      "n\n",
      " Racin Rockets. Let \n",
      "X\n",
      "k\n",
      " \n",
      "be the length of the\n",
      " k\n",
      "th segment. The total number of kids meals we must\n",
      " \n",
      "purchase to get all \n",
      "n\n",
      " Racin Rockets is the sum of the lengths of all these segments:\n",
      "D \n",
      "X\n",
      "0\n",
      " C \n",
      "X\n",
      "1\n",
      " C  C \n",
      "X\n",
      "n1\n",
      "Now lets focus our attention on \n",
      "X\n",
      "k\n",
      ", the length of the \n",
      "k\n",
      "th segment. At the beginning of segment \n",
      "k\n",
      ", we have \n",
      "k\n",
      " different types of car, and the segment ends when we acquire a new type. When we own \n",
      "k\n",
      " types, each kids meal contains a type that we already have with probability \n",
      "k=n\n",
      ". Therefore, each meal contains a new type of car with probability \n",
      "1 k=n\n",
      " D \n",
      ".n k/=n\n",
      ". Thus, the expected number\n",
      "of meals until we get a new kind of car is \n",
      "n=.n\n",
      "\t\n",
      "k/ \n",
      "by the mean time to failure\n",
      "formula in Equation \n",
      ". This means that\n",
      "n\n",
      "Ex\n",
      " \n",
      "X\n",
      "k  \n",
      "D\n",
      " \n",
      "n\n",
      "\t\n",
      "k \n",
      ":\n",
      "\n",
      "Linearity of expectation, together with this observation, solves the coupon col-lector problem:\n",
      "Ex \n",
      "T\n",
      "  D Ex \n",
      "X\n",
      "0\n",
      " C \n",
      "X\n",
      "1\n",
      " C\n",
      "\t\n",
      "C \n",
      "X\n",
      "n1\n",
      "D Ex \n",
      "X\n",
      "0\n",
      " C Ex \n",
      "X\n",
      "1\n",
      " C\tC Ex \n",
      "X\n",
      "n1\n",
      "n\n",
      " \n",
      "n\n",
      " \n",
      "0\n",
      " C \n",
      "n\n",
      " \n",
      "n\n",
      " \n",
      "1\n",
      " C  C \n",
      "n\n",
      "3\n",
      " C \n",
      "n\n",
      "2\n",
      " C \n",
      "n\n",
      "1\n",
      "\n",
      "Wow! Its those Harmonic Numbers again!\n",
      "We can use Equation \n",
      "to answer some concrete questions. For example, the expected number of die rolls required to see every number from 1 to 6 is:\n",
      "6H\n",
      "6\n",
      " \n",
      "D\n",
      " 14:7::::\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 489  #495\n",
      "\n",
      "And the expected number of people you must poll to find at least one person with each possible birthday is:\n",
      "365H\n",
      "365\n",
      " \n",
      "D\n",
      " 2364:6 : : : :\n",
      "18.3.5\n",
      "\t\n",
      "Infinite Sums\n",
      "Linearity of expectation also works for an infinite number of random variables provided that the variables satisfy some stringent absolute convergence criteria.\n",
      "Theorem 18.3.5 (Linearity of Expectation). Let \n",
      "R\n",
      "0\n",
      ", \n",
      "R\n",
      "1\n",
      ", . . . , be random variables such that\n",
      "1\n",
      "X\n",
      "Ex j\n",
      "R\n",
      "i\n",
      " j\n",
      "D0\n",
      "all the sums in the following derivation are absolutely convergent, which justifies rearranging them as follows:\n",
      "iD0\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 490  #496\n",
      "\n",
      "490\n",
      "\t\n",
      "Chapter 18\n",
      "\t\n",
      "Expectation\n",
      "\n",
      "18.4\n",
      "\t\n",
      "Expectations of Products\n",
      "While the expectation of a sum is the sum of the expectations, the same is usually not true for products. For example, suppose that we roll a fair 6-sided die and denote the outcome with the random variable \n",
      "R\n",
      ". Does Ex \n",
      "R R\n",
      " D Ex \n",
      "R\n",
      " Ex \n",
      "R\n",
      " ?\n",
      "We know that Ex \n",
      "R\n",
      " D \n",
      "3\n",
      "1\n",
      "2\n",
      " and thus Ex \n",
      "R\n",
      " \n",
      "2\n",
      " D \n",
      "12\n",
      "1\n",
      "4\n",
      " . Lets compute Ex \n",
      "R\n",
      "2\n",
      " to see if we get the same result.\n",
      "Ex \n",
      "R\n",
      "2\n",
      " D \n",
      "X\n",
      " \n",
      "R\n",
      "2\n",
      ".w/\n",
      " Pr \n",
      "w\n",
      "2S\n",
      "6\n",
      "X\n",
      " i\n",
      "2\n",
      "  \n",
      "Pr\n",
      " R\n",
      "i\n",
      " \n",
      "D\n",
      " i\n",
      "iD1\n",
      "1\n",
      "2\n",
      "C\n",
      "2\n",
      "2\n",
      "C\n",
      "3\n",
      "2\n",
      "C\n",
      "4\n",
      "2\n",
      "C\n",
      "5\n",
      "2\n",
      "C\n",
      "6\n",
      "2\n",
      " 666666\n",
      "\n",
      "D \n",
      "15 1=6\n",
      "12 1=4:\n",
      "Hence,\n",
      "Ex \n",
      "R R\n",
      "  Ex \n",
      "R\n",
      "\tEx \n",
      "R\n",
      "and so the expectation of a product is not always equal to the product of the expec-tations.\n",
      "There is a special case when such a relationship does hold however; namely, when the random variables in the product are independent.\n",
      "Theorem 18.4.1. For any two independent random variables \n",
      "R\n",
      "1\n",
      ", \n",
      "R\n",
      "2\n",
      ",\n",
      "Ex \n",
      "R\n",
      "1\n",
      "  \n",
      "R\n",
      "2\n",
      " D Ex \n",
      "R\n",
      "1\n",
      "\t\n",
      "Ex \n",
      "R\n",
      "2\n",
      " \n",
      ":\n",
      "Proof. The event  \n",
      "R\n",
      "1\n",
      "\t\n",
      "R\n",
      "2\n",
      " \n",
      "D\n",
      " r \n",
      "can be split up into events of the form\n",
      "  R\n",
      "1\n",
      " \n",
      "D\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 491  #497\n",
      "\n",
      "r\n",
      "1\n",
      " \n",
      "and\n",
      " R\n",
      "2\n",
      " \n",
      "D\n",
      " r\n",
      "2\n",
      " \n",
      "where\n",
      " r\n",
      "1\n",
      "  r\n",
      "2\n",
      " \n",
      "D\n",
      " r\n",
      ". So\n",
      "For example, let \n",
      "R\n",
      "1\n",
      " and \n",
      "R\n",
      "2\n",
      " be random variables denoting the result of rolling two independent and fair 6-sided dice. Then\n",
      "1\t1\n",
      "\t\n",
      "1\n",
      "Ex\n",
      " \n",
      "R\n",
      "1  \n",
      "R\n",
      "2 \n",
      "D\n",
      " \n",
      "Ex\n",
      " \n",
      "R\n",
      "1 \n",
      "Ex\n",
      " \n",
      "R\n",
      "2 \n",
      "D\n",
      " \n",
      "3\n",
      "\t\n",
      "3\n",
      "\t\n",
      "D \n",
      "12 :\n",
      "\n",
      "2\n",
      "\t\n",
      "2\n",
      "\t\n",
      "4\n",
      "Theorem \n",
      "extends by induction to a collection of mutually independent random variables.\n",
      "Corollary 18.4.2. If random variables \n",
      "R\n",
      "1\n",
      "; R\n",
      "2\n",
      "; : : : ; R\n",
      "k\n",
      " are mutually independent, then\n",
      "3\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 492  #498\n",
      "\n",
      "492\n",
      "\t\n",
      "Chapter 18\n",
      "\t\n",
      "Expectation\n",
      "\n",
      "18.5\n",
      "\t\n",
      "Expectations of Quotients\n",
      "If \n",
      "S\n",
      " and \n",
      "T\n",
      " are random variables, we know from Linearity of Expectation that\n",
      "Of course, we have to worry about the situation when Ex \n",
      "T\n",
      " D \n",
      "0\n",
      ", but what if we assume that \n",
      "T\n",
      " is always positive? As we will soon see, Equation \n",
      "is usually not true, but lets see if we can prove it anyway.\n",
      "False Claim 18.5.1. If \n",
      "S\n",
      " and \n",
      "T\n",
      " are independent random variables with \n",
      "T > 0\n",
      ", then\n",
      "Note that line \n",
      "uses the fact that if \n",
      "S\n",
      " and \n",
      "T\n",
      " are independent, then so are \n",
      "S \n",
      "and\n",
      " 1=T \n",
      ". This holds because functions of independent random variables are\n",
      " \n",
      "independent. It is a fact that needs proof, which we will leave to the reader, but it is not the bug. The bug is in line (\n",
      "), which assumes\n",
      "False Claim 18.5.2.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 493  #499\n",
      "\n",
      "Table 18.1 Sample program lengths for benchmark problems using RISC and CISC compilers.\n",
      "This means that Claim \n",
      "is also false since we could define \n",
      "S\n",
      " D \n",
      "1\n",
      " with prob-ability 1. In fact, both Claims \n",
      "and \n",
      "are untrue for most all choices of\n",
      "and \n",
      "T\n",
      " . Unfortunately, the fact that they are false does not keep them from being widely used in practice! Lets see an example.\n",
      "18.5.1\n",
      "\t\n",
      "A RISC Paradox\n",
      "The data in Table \n",
      "is representative of data in a paper by some famous pro-fessors. They wanted to show that programs on a RISC processor are generally shorter than programs on a CISC processor. For this purpose, they applied a RISC compiler and then a CISC compiler to some benchmark source programs and made a table of compiled program lengths.\n",
      "Each row in Table \n",
      "contains the data for one benchmark. The numbers in the second and third columns are program lengths for each type of compiler. The fourth column contains the ratio of the CISC program length to the RISC program length. Averaging this ratio over all benchmarks gives the value 1.2 in the lower right. The conclusion is that CISC programs are 20% longer on average.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 494  #500\n",
      "\n",
      "Table 18.2 The same data as in Table \n",
      ", but with the opposite ratio in the last column.\n",
      "However, some critics of their paper took the same data and argued this way: redo the final column, taking the other ratio, RISC/CISC instead of CISC/RISC, as shown in Table \n",
      ".\n",
      "From Table \n",
      ", we would conclude that RISC programs are 10% longer than CISC programs on average! We are using the same reasoning as in the paper, so this conclusion is equally justifiableyet the result is opposite. What is going on?\n",
      "A Probabilistic Interpretation\n",
      "To resolve these contradictory conclusions, we can model the RISC vs. CISC de-bate with the machinery of probability theory.\n",
      "Let the sample space be the set of benchmark programs. Let the random variable \n",
      "R \n",
      "be the length of the compiled RISC program, and let the random variable\n",
      " C \n",
      "be\n",
      " \n",
      "the length of the compiled CISC program. We would like to compare the average length Ex \n",
      "R\n",
      " of a RISC program to the average length Ex \n",
      "C\n",
      " of a CISC program.\n",
      "To compare average program lengths, we must assign a probability to each sam-ple point; in effect, this assigns a weight to each benchmark. One might like to weigh benchmarks based on how frequently similar programs arise in practice. Lacking such data, however, we will assign all benchmarks equal weight; that is, our sample space is uniform.\n",
      "In terms of our probability model, the paper computes \n",
      "C=R\n",
      " for each sample point, and then averages to obtain Ex \n",
      "C=R\n",
      " D \n",
      "1:2\n",
      ". This much is correct. The authors then conclude that CISC programs are 20% longer on average; that is, they conclude that Ex \n",
      "C\n",
      " D \n",
      "1:2\n",
      " Ex \n",
      "R\n",
      " . Therein lies the problem. The authors have implicitly used False Claim \n",
      "to assume that Ex \n",
      "C=R\n",
      " D Ex \n",
      "C =\n",
      " Ex \n",
      "R\n",
      " . By using the same false logic, the critics can arrive at the opposite conclusion; namely, that RISC programs are 10% longer on average.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 495  #501\n",
      "\n",
      "The Proper Quotient\n",
      "We can compute Ex \n",
      "R\n",
      " and Ex \n",
      "C\n",
      " as follows:\n",
      "X\n",
      "Ex \n",
      "R\n",
      " D\n",
      "\t\n",
      "i  \n",
      "Pr\n",
      " R \n",
      "D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " i\n",
      "2Range(R)\n",
      "D \n",
      "150\n",
      "4\n",
      " C \n",
      "120\n",
      "4\n",
      " C \n",
      "150\n",
      "4\n",
      " C \n",
      "2800\n",
      "4\n",
      "\n",
      "805;\n",
      "X\n",
      "Ex \n",
      "C\n",
      " D\n",
      "\t\n",
      "i  \n",
      "Pr\n",
      " C \n",
      "D\n",
      " i\n",
      "2Range(C)\n",
      "D \n",
      "120\n",
      "4\n",
      " C \n",
      "180\n",
      "4\n",
      " C \n",
      "300\n",
      "4\n",
      " C \n",
      "1400\n",
      "4\n",
      "\n",
      "500\n",
      "Now since Ex \n",
      "R =\n",
      " Ex \n",
      "C\n",
      " D \n",
      "1:61\n",
      ", we conclude that the average RISC program is 61% longer than the average CISC program. This is a third answer, completely different from the other two! Furthermore, this answer makes RISC look really bad in terms of code length. This one is the correct conclusion, under our assump-tion that the benchmarks deserve equal weight. Neither of the earlier results were correctnot surprising since both were based on the same False Claim.\n",
      "A Simpler Example\n",
      "The source of the problem is clearer in the following, simpler example. Suppose the data were as follows.\n",
      "Now the data for the processors \n",
      "A\n",
      " and \n",
      "B\n",
      " is exactly symmetric; the two proces-sors are equivalent. Yet, from the third column we would conclude that Processor \n",
      "B\n",
      " programs are 25% longer on average, and from the fourth column we would con-clude that Processor \n",
      "A\n",
      " programs are 25% longer on average. Both conclusions are obviously wrong.\n",
      "The moral is that one must be very careful in summarizing data, we must not take an average of ratios blindly!\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 496  #502\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 497  #503\n",
      "\n",
      "19\n",
      "\t\n",
      "Deviations\n",
      "In some cases, a random variable is likely to be very close to its expected value. For example, if we flip 100 fair, mutually-independent coins, it is very likely that we will get about 50 heads. In fact, we proved in Section \n",
      "that the probability of getting fewer than 25 or more than 75 heads are each less than 3 10\n",
      "7\n",
      " . In such cases, the mean provides a lot of information about the random variable.\n",
      "In other cases, a random variable is likely to be far from its expected value. For example, suppose we flipped 100 fair coins that are glued together so that they all come out heads or they call all come out tails. In this case, the expected value of the number of heads is still 50, but the actual number of heads is guaranteed to be far from this valueit will be 0 or 100, each with probability 1=2.\n",
      "Mathematicians have developed a variety of measures and methods to help us understand how a random variable performs in comparison to its mean. The sim-plest and most widely used measure is called the variance of the random variable. The variance is a single value associated with the random variable that is large for random variables that are likely to deviate significantly from the mean and that is small otherwise.\n",
      "\n",
      "19.1\n",
      "\t\n",
      "Variance\n",
      "19.1.1\n",
      "\t\n",
      "Definition and Examples\n",
      "Consider the following two gambling games:\n",
      "Game A: You win $2 with probability 2=3 and lose $1 with probability 1=3.\n",
      "Game B: You win $1002 with probability 2=3 and lose $2001 with probabil-ity 1=3.\n",
      "Which game would you rather play? Which game is better financially? We have the same probability, 2/3, of winning each game, but that does not tell the whole story. What about the expected return for each game? Let random variables A and B be the payoffs for the two games. For example, A is 2 with probability 2/3 and -1 with\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 498  #504\n",
      "\n",
      "498\n",
      "\t\n",
      "Chapter 19\n",
      "\t\n",
      "Deviations\n",
      "probability 1/3. We can compute the expected payoff for each game as follows:\n",
      "The expected payoff is the same for both games, but they are obviously very different! The stakes are a lot higher for Game B and so it is likely to deviate much farther from its mean than is Game A. This fact is captured by the notion of variance.\n",
      "Definition 19.1.1. The variance Var \n",
      "R\n",
      " of a random variable \n",
      "R\n",
      " is\n",
      "Var \n",
      "R\n",
      " WWD Ex \n",
      ".R\n",
      "\tEx \n",
      "R /\n",
      "2\n",
      " \n",
      ":\n",
      "In words, the variance of a random variable \n",
      "R\n",
      " is the expectation of the square of the amount by which \n",
      "R\n",
      " differs from its expectation.\n",
      "Yikes! Thats a mouthful. Try saying that 10 times in a row!\n",
      "Lets look at this definition more carefully. Well start with \n",
      "R\n",
      " Ex \n",
      "R\n",
      " . Thats the amount by which \n",
      "R\n",
      " differs from its expectation and it is obviously an important measure. Next, we square this value. More on why we do that in a moment. Finally, we take the the expected value of the square. If the square is likely to be large, then the variance will be large. If it is likely to be small, then the variance will be small. Thats just the kind of statistic we are looking for. Lets see how it works out for our two gambling games.\n",
      "Well start with Game A:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 499  #505\n",
      "\n",
      "The variance of Game A is 2 and the variance of Game B is more than two million! Intuitively, this means that the payoff in Game A is usually close to the expected value of $1, but the payoff in Game B can deviate very far from this expected value.\n",
      "High variance is often associated with high risk. For example, in ten rounds of Game A, we expect to make $10, but could conceivably lose $10 instead. On the other hand, in ten rounds of Game B, we also expect to make $10, but could actually lose more than $20,000!\n",
      "Why Bother Squaring?\n",
      "The variance is the average of the square of the deviation from the mean. For this reason, variance is sometimes called the mean squared deviation. But why bother squaring? Why not simply compute the average deviation from the mean? That is, why not define variance to be Ex \n",
      "R\n",
      " Ex \n",
      "R\n",
      " ?\n",
      "The problem with this definition is that the positive and negative deviations from the mean exactly cancel. By linearity of expectation, we have:\n",
      " \n",
      "Ex \n",
      "R\n",
      "\tEx \n",
      "R\n",
      "\t\n",
      "D Ex \n",
      "R\n",
      "\t\n",
      "Ex  Ex \n",
      "R\n",
      "\t\n",
      ":\n",
      "Since Ex \n",
      "R\n",
      " is a constant, its expected value is itself. Therefore\n",
      "Ex \n",
      "R\n",
      "\tEx \n",
      "R\n",
      "\t\n",
      "D Ex \n",
      "R\n",
      "\t\n",
      "Ex \n",
      "R\n",
      " D \n",
      "0:\n",
      "By this definition, every random variable would have zero variance, which would not be very useful! Because of the square in the conventional definition, both pos-itive and negative deviations from the mean increase the variance, and they do not cancel.\n",
      "Of course, we could also prevent positive and negative deviations from canceling by taking an absolute value. In other words, we could compute Ex j\n",
      "R\n",
      " Ex \n",
      "R\n",
      " j . But this measure doesnt have the many useful properties that variance has, and so mathematicians went with squaring.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 500  #506\n",
      "\n",
      "500\n",
      "\t\n",
      "Chapter 19\n",
      "\t\n",
      "Deviations\n",
      "19.1.2\n",
      "\t\n",
      "Standard Deviation\n",
      "Because of its definition in terms of the square of a random variable, the variance of a random variable may be very far from a typical deviation from the mean. For example, in Game B above, the deviation from the mean is 1001 in one outcome and -2002 in the other. But the variance is a whopping 2,004,002.\n",
      "From a dimensional analysis viewpoint, the units of variance are wrong: if the random variable is in dollars, then the expectation is also in dollars, but the variance is in square dollars.\n",
      "For these reasons, people often describe the deviation of a random variable using standard deviation instead of variance.\n",
      "Definition 19.1.2. The standard deviation \n",
      "R\n",
      " of a random variable \n",
      "R\n",
      " is the square root of the variance:\n",
      "q\n",
      "\n",
      "p\n",
      "R\n",
      " WWD\n",
      "\t\n",
      "Var \n",
      "R\n",
      " D\tEx \n",
      ".R\n",
      "\tEx \n",
      "R /\n",
      "2\n",
      " \n",
      ":\n",
      "So the standard deviation is the square root of the mean of the square of the deviation, or the root mean square for short. It has the same unitsdollars in our exampleas the original random variable and as the mean. Intuitively, it measures the average deviation from the mean, since we can think of the square root on the outside as roughly canceling the square on the inside.\n",
      "For example, the standard deviations for \n",
      "A\n",
      " and \n",
      "B\n",
      " are\n",
      "p\n",
      "\t\n",
      "p\n",
      "\n",
      "The random variable \n",
      "B\n",
      " actually deviates from the mean by either positive 1001 or negative 2002; therefore, the standard deviation of 1416 describes this situation reasonably well.\n",
      "19.1.3\tAn Alternative Formulation\n",
      "Applying linearity of expectation to the formula for variance yields a convenient alternative formula.\n",
      "Lemma 19.1.3. For any random variable \n",
      "R\n",
      ",\n",
      "Var \n",
      "R\n",
      " D Ex \n",
      "R\n",
      "2\n",
      "\t\n",
      "Ex\n",
      "2\n",
      " \n",
      "R :\n",
      "Here we use the notation Ex\n",
      "2\n",
      " \n",
      "R\n",
      " as shorthand for \n",
      ".\n",
      "Ex \n",
      "R /\n",
      "2\n",
      ". Remember that Ex \n",
      "R\n",
      "2\n",
      " is generally not equal to Ex\n",
      "2\n",
      " \n",
      "R\n",
      " . We know the expected value of a product is the product of the expected values for independent variables, but not in general. And \n",
      "R\n",
      " is not independent of itself unless it is constant.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 501  #507\n",
      "\n",
      "For example, lets take another look at Game A from Section \n",
      "where you win $2 with probability 2=3 and lose $1 with probability 1=3. Then\n",
      "and\n",
      "Ex A\n",
      "2\n",
      " D 4\n",
      "\t\n",
      "2\n",
      "3\n",
      " \n",
      "C\n",
      " \n",
      "1\n",
      "  \n",
      "1\n",
      "3\n",
      " \n",
      "D\n",
      " \n",
      "3:\n",
      "\n",
      "By Lemma \n",
      ", this means that\n",
      "Var A  D Ex A\n",
      "2\n",
      "\t\n",
      "Ex\n",
      "2\n",
      " A  D 3\n",
      "\t\n",
      "1\n",
      "2\n",
      " D 2;\n",
      "confirming the result in Equation \n",
      ".\n",
      "The alternate formulation of variance given in Lemma \n",
      "has a cute implica-tion:\n",
      "Corollary 19.1.4. If R is a random variable, then Ex R\n",
      "2\n",
      "\t\n",
      "Ex\n",
      "2\n",
      " R .\n",
      "Proof. We defined Var R  as an average of a squared expression, so Var R  is non-\n",
      "In words, the expectation of a square is at least the square of the expectation.\n",
      "The two are equal exactly when the variance is zero:\n",
      "Ex R\n",
      "2\n",
      " D Ex\n",
      "2\n",
      " R \tiff\tEx R\n",
      "2\n",
      "\tEx\n",
      "2\n",
      " R  D 0\tiff\n",
      "\t\n",
      "Var R  D 0:\n",
      "This happens precisely when\n",
      "Pr R D Ex R  D 1I\n",
      "namely, when R is a constant.\n",
      "\n",
      "Technically, R could deviate from its mean on some sample points with probability 0, but we are ignoring events of probability 0 when computing expectations and variances.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 502  #508\n",
      "\n",
      "502\n",
      "\t\n",
      "Chapter 19\n",
      "\t\n",
      "Deviations\n",
      "19.1.4\n",
      "\t\n",
      "Indicator Random Variables\n",
      "Computing the variance of an indicator random variable is straightforward given Lemma \n",
      ".\n",
      "Lemma 19.1.5. Let \n",
      "B\n",
      " be an indicator random variable for which Pr \n",
      "B\n",
      " D \n",
      "1\n",
      " D \n",
      "p\n",
      ". Then\n",
      "19.1.5\n",
      "\t\n",
      "Mean Time to Failure\n",
      "As another example, consider the mean time to failure problem, described in Sec-tion \n",
      ". If the system crashes at each step with probability \n",
      "p\n",
      ", then we already know that the mean time to failure is \n",
      "1=p\n",
      ". In other words, if \n",
      "C\n",
      " is the number of steps up to and including the step when the first crash occurs, then\n",
      "Ex \n",
      "C\n",
      " D \n",
      "p\n",
      "1\n",
      " \n",
      ":\n",
      "\n",
      "What about the variance of \n",
      "C\n",
      " ? To use Lemma \n",
      ", we need to compute Ex \n",
      "C\n",
      " \n",
      "2\n",
      " . As in Section \n",
      ", we can do this by summing over all the sample points or we can use the Law of Total Expectation. The latter approach is simpler, so well do that. The analysis breaks into two cases: the system crashes in the first step or it doesnt. Hence,\n",
      "Ex \n",
      "C\n",
      " \n",
      "2\n",
      " D \n",
      "1\n",
      "2\n",
      "  \n",
      "p\n",
      " C Ex \n",
      ".C\n",
      " C \n",
      "1/\n",
      "2\n",
      " \n",
      ".1\n",
      "\t\n",
      "p/\n",
      "D \n",
      "p\n",
      " C Ex \n",
      "C\n",
      " \n",
      "2\n",
      " \n",
      ".1\n",
      "\t\n",
      "p/ \n",
      "C\n",
      " 2 \n",
      "Ex\n",
      " C .1\tp/ \n",
      "C\n",
      " .1\tp/\n",
      " \n",
      "D\n",
      " \n",
      "1\n",
      " \n",
      "C\n",
      " \n",
      "Ex\n",
      " \n",
      "C\n",
      " 2 \n",
      ".1\n",
      "\t\n",
      "p/ \n",
      "C\n",
      " 2\n",
      "\t\n",
      "1\n",
      "\t\n",
      "p\n",
      "\t\n",
      ":\n",
      "\n",
      "p\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 503  #509\n",
      "\n",
      "and that\n",
      "Ex \n",
      "C\n",
      " \n",
      "2\n",
      " D \n",
      "2\n",
      "p\n",
      "2\n",
      "p\n",
      " \n",
      ":\n",
      "\n",
      "Using Lemma \n",
      ", we conclude that\n",
      "p \n",
      "D\n",
      "  \n",
      "p\n",
      "2  \n",
      ":\n",
      "\n",
      "19.1.6\n",
      "\t\n",
      "Uniform Random Variables\n",
      "Computing the variance of a uniform random variable is also straightforward given Lemma \n",
      ". For example, we can compute the variance of the outcome of a fair die \n",
      "R\n",
      " as follows:\n",
      "Ex \n",
      "R\n",
      "2\n",
      " D \n",
      "1\n",
      "6\n",
      ".1\n",
      "2\n",
      " C \n",
      "2\n",
      "2\n",
      " C \n",
      "3\n",
      "2\n",
      " C \n",
      "4\n",
      "2\n",
      " C \n",
      "5\n",
      "2\n",
      " C \n",
      "6\n",
      "2\n",
      "/\n",
      " D \n",
      "91\n",
      "6\n",
      ";\n",
      "\n",
      "Ex\n",
      "2 \n",
      "R\n",
      " \n",
      "D\n",
      "\t\n",
      "3\n",
      "1\n",
      "2\n",
      "  \n",
      "2\n",
      " \n",
      "D\n",
      " \n",
      "49\n",
      "4;\n",
      "\n",
      "For a general uniform random variable \n",
      "R\n",
      " on f\n",
      "1; 2; 3; : : : n\n",
      "g, the variance can be\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 504  #510\n",
      "\n",
      "504\n",
      "\t\n",
      "Chapter 19\n",
      "\t\n",
      "Deviations\n",
      "computed as follows:\n",
      "Ex \n",
      "R\n",
      " D \n",
      "n\n",
      "1\n",
      ".1\n",
      " C \n",
      "2\n",
      " C\n",
      "\t\n",
      "C \n",
      "n/\n",
      "\n",
      "1  n.n \n",
      "C\n",
      " 1/\n",
      "n\n",
      "2\n",
      "\n",
      "n\n",
      " \n",
      "C\n",
      "2\n",
      " \n",
      "1\n",
      ":\n",
      "\n",
      "Ex \n",
      "R\n",
      "2\n",
      " D \n",
      "n\n",
      "1\n",
      ".1\n",
      "2\n",
      " C \n",
      "2\n",
      "2\n",
      " C\n",
      "\t\n",
      "C \n",
      "n\n",
      "2\n",
      "/\n",
      "\n",
      "1  .2n \n",
      "C\n",
      " 1/n.n \n",
      "C\n",
      " 1/\n",
      "n\n",
      "6\n",
      "\n",
      ".2n \n",
      "C\n",
      " 1/.n \n",
      "C\n",
      " 1/\n",
      ":\n",
      "6\n",
      "\n",
      "19.1.7\n",
      "\t\n",
      "Dealing with Constants\n",
      "It helps to know how to calculate the variance of \n",
      "aR\n",
      " C \n",
      "b\n",
      ":\n",
      "Theorem 19.1.6. Let \n",
      "R\n",
      " be a random variable, and let \n",
      "a\n",
      " and \n",
      "b\n",
      " be constants. Then\n",
      "Proof. Beginning with Lemma \n",
      "and repeatedly applying linearity of expec-tation, we have:\n",
      "Corollary 19.1.7.\n",
      "aRCb\n",
      " D j\n",
      "a\n",
      "j \n",
      "R\n",
      ":\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 505  #511\n",
      "\n",
      "19.1.8\n",
      "\t\n",
      "Variance of a Sum\n",
      "In general, the variance of a sum is not equal to the sum of the variances, but variances do add for independent random variables. In fact, mutual independence is not necessary: pairwise independence will do.\n",
      "Theorem 19.1.8. If \n",
      "R\n",
      "1\n",
      " and \n",
      "R\n",
      "2\n",
      " are independent random variables, then\n",
      "Proof. As with the proof of Theorem \n",
      ", this proof uses repeated applications of Lemma \n",
      "and Linearity of Expectation.\n",
      "Var \n",
      "R\n",
      "1\n",
      " C \n",
      "R\n",
      "2\n",
      " D Ex \n",
      ".R\n",
      "1\n",
      " C \n",
      "R\n",
      "2\n",
      "/\n",
      "2\n",
      "\t\n",
      "Ex\n",
      "2\n",
      " \n",
      "R\n",
      "1\n",
      " C \n",
      "R\n",
      "2\n",
      "D Ex \n",
      "R\n",
      "1\n",
      "2\n",
      " C \n",
      "2R\n",
      "1\n",
      "R\n",
      "2\n",
      " C \n",
      "R\n",
      "2\n",
      "\t\n",
      ".\n",
      "Ex\n",
      " R\n",
      "1\n",
      " \n",
      "C\n",
      " \n",
      "Ex\n",
      " R\n",
      "2\n",
      " /\n",
      "2\n",
      "Note that Theorem \n",
      "does not necessarily hold if \n",
      "R\n",
      "1\n",
      " and \n",
      "R\n",
      "2\n",
      " are dependent since then it would generally not be true that\n",
      "Ex \n",
      "R\n",
      "1\n",
      "R\n",
      "2\n",
      " D Ex \n",
      "R\n",
      "1\n",
      " Ex \n",
      "R\n",
      "2\n",
      "\t\n",
      "(19.6)\n",
      "in the last step of the proof. For example, suppose that \n",
      "R\n",
      "1\n",
      " D \n",
      "R\n",
      "2\n",
      " D \n",
      "R\n",
      ". Then Equation \n",
      "holds only if \n",
      "R\n",
      " is essentially constant.\n",
      "The proof of Theorem \n",
      "carries over straightforwardly to the sum of any finite number of variables.\n",
      "Theorem 19.1.9 (Pairwise Independent Additivity of Variance). If \n",
      "R\n",
      "1\n",
      ", \n",
      "R\n",
      "2\n",
      ", . . . , \n",
      "R\n",
      "n\n",
      " are pairwise independent random variables, then\n",
      "Var \n",
      "R\n",
      "1\n",
      " C \n",
      "R\n",
      "2\n",
      " C\n",
      "\t\n",
      "C \n",
      "R\n",
      "n\n",
      " D Var \n",
      "R\n",
      "1\n",
      " C Var \n",
      "R\n",
      "2\n",
      " C\tC Var \n",
      "R\n",
      "n\n",
      " \n",
      ":\n",
      "\t\n",
      "(19.7)\n",
      "Unfortunately, there is no product rule for computing variances, even if the ran-dom variables are mutually independent. However, we can use Theorem \n",
      "to quickly compute the variance of a random variable with a general binomial distri-bution.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 506  #512\n",
      "\n",
      "506\n",
      "\t\n",
      "Chapter 19\n",
      "\t\n",
      "Deviations\n",
      "19.1.9\tBinomial Distributions\n",
      "Lemma 19.1.10 (Variance of the Binomial Distribution). If \n",
      "J\n",
      " has a binomial dis-tribution with parameters \n",
      "n\n",
      " and \n",
      "p\n",
      ", then\n",
      "Proof. From the definition of the binomial distribution, we can think of \n",
      "J\n",
      " as being the number of heads when you flip \n",
      "n\n",
      " mutually independent coins, each of which is heads with probability \n",
      "p\n",
      ". Thus \n",
      "J\n",
      " can be expressed as the sum of \n",
      "n\n",
      " mutually independent indicator variables \n",
      "J\n",
      "i\n",
      " where\n",
      "Pr \n",
      "J\n",
      "i\n",
      " D \n",
      "1\n",
      " D \n",
      "p\n",
      "for \n",
      "1\n",
      "\t\n",
      "i\n",
      "\t\n",
      "n\n",
      ". From Lemma\n",
      " \n",
      ",\n",
      " \n",
      "we know that\n",
      "Var \n",
      "J\n",
      "i\n",
      "  D \n",
      "p.1\n",
      "\t\n",
      "p/:\n",
      "By Theorem \n",
      ", this means that\n",
      "For example, suppose we flip \n",
      "n\n",
      " mutually independent\n",
      "fair coins. Let \n",
      "R\n",
      " be the number of heads. Then Theorem \n",
      "tells us that\n",
      "which should not be surprising since we already knew from Section \n",
      "that \n",
      "R\n",
      " is unlikely to stray very far from its mean.\n",
      "\n",
      "Actually, we only need to assume pairwise independence for this to be true using Theorem \n",
      ".\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 507  #513\n",
      "\n",
      "\n",
      "19.2\n",
      "\t\n",
      "Markovs Theorem\n",
      "The variance of a random variable gives us a rough idea of the amount by which a random variable is likely to deviate from its mean. But it does not directly give us specific bounds on the probability that the deviation exceeds a specified threshold. To obtain such specific bounds, well need to work a little harder.\n",
      "In this section, we derive a famous result known as Markovs Theorem that gives an upper bound on the probability that a random variable exceeds a specified thresh-old. In the next section, we give a similar but stronger result known as Chebyshevs Theorem. The difference between these results is that Markovs Theorem depends only on the mean of the random variable, whereas Chebyshevs Theorem makes use of the mean and the variance. Basically, the more you know about a random variable, the better bounds you can derive on the probability that it deviates from its mean.\n",
      "19.2.1\n",
      "\t\n",
      "A Motivating Example\n",
      "The idea behind Markovs Theorem can be explained with a simple example involv-ing intelligence quotients, or IQs. This quantity was devised so that the average IQ measurement would be 100. From this fact alone we can conclude that at most 1/3 the population can have an IQ of 300 or more, because if more than a third had an IQ of at least 300, then the average IQ would have to be more than .1=3/300 D 100, contradicting the fact that the average is 100. So the probability that a randomly chosen person has an IQ of 300 or more is at most 1/3. Of course this is not a very strong conclusion since no IQ over 200 has ever been recorded.\n",
      "By the same logic, we can also conclude that at most 2/3 of the population can have an IQ of 150 or more. IQs over 150 have certainly been recorded, although a much smaller fraction than 2/3 of the population actually has an IQ that high.\n",
      "Although these conclusions about IQ are weak, they are actually the strongest general conclusions that can be reached about a random variable using only the fact that it is nonnegative and its mean is 100. For example, if we choose a random variable equal to 300 with probability 1/3, and 0 with probability 2/3, then its mean is 100, and the probability of a value of 300 or more really is 1/3. So we cant hope to get a better upper bound based solely on this limited amount of information.\n",
      "Markovs Theorem characterizes the bounds that can be achieved with this kind of analysis\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 508  #514\n",
      "\n",
      "508\n",
      "\t\n",
      "Chapter 19\n",
      "\t\n",
      "Deviations\n",
      "19.2.2\n",
      "\t\n",
      "The Theorem\n",
      "Theorem 19.2.1 (Markovs Theorem). If \n",
      "R\n",
      " is a nonnegative random variable, then for all \n",
      "x > 0\n",
      ",\n",
      "y  x;\n",
      "y2range.R/\n",
      "X\n",
      "x \n",
      "Pr\n",
      " R \n",
      "D\n",
      " y\n",
      "y  x;\n",
      "y2range.R/\n",
      "As an example, suppose we flip 100 fair coins and use Markovs Theorem to compute the probability of getting all heads:\n",
      "Pr heads\n",
      "\t\n",
      "100\n",
      "\t\n",
      "Ex heads  \n",
      "D \n",
      "50\n",
      " \n",
      "D\n",
      " \n",
      "1\n",
      ":\n",
      "\n",
      "100\n",
      "\t\n",
      "100\n",
      "\t\n",
      "2\n",
      "If the coins are mutually independent, then the actual probability of getting all heads is a minuscule 1 in \n",
      "2\n",
      "100\n",
      ". In this case, Markovs Theorem looks very weak. However, in applying Markovs Theorem, we made no independence assumptions. In fact, if all the coins are glued together, then probability of throwing all heads is exactly \n",
      "1=2\n",
      ". In this nasty case, Markovs Theorem is actually tight!\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 509  #515\n",
      "\n",
      "The Chinese Appetizer Problem\n",
      "Suppose that \n",
      "n\n",
      " people are seated at a circular table and that each person has an appetizer in front of them on a rotating Chinese banquet tray. Just as everyone is about to dig in, some joker spins the tray so that each person receives a random appetizer. We are interested in the number of people \n",
      "R\n",
      " that get their same appetizer as before, assuming that the \n",
      "n\n",
      " appetizers are all different.\n",
      "Each person gets their original appetizer with probability \n",
      "1=n\n",
      ". Hence, by Lin-earity of Expectation,\n",
      "Ex \n",
      "R\n",
      " D \n",
      "n\n",
      "\t\n",
      "n\n",
      "1\n",
      " \n",
      "D\n",
      " \n",
      "1:\n",
      "\n",
      "What is the probability that all \n",
      "n\n",
      " people get their original appetizer back? Markovs Theorem tells us that\n",
      "Pr \n",
      "R\n",
      " D \n",
      "n\n",
      " D Pr \n",
      "R\n",
      "\t\n",
      "n\n",
      "\t\n",
      "Ex\n",
      "n\n",
      "R\n",
      " \n",
      "D\n",
      " \n",
      "n\n",
      "1\n",
      ":\n",
      "\n",
      "In fact, this bound is tight sine everyone gets their original appetizers back if and only if the rotating tray returns to its original configuration, which happens with probability \n",
      "1=n\n",
      ".\n",
      "The Chinese Appetizer problem is similar to the Hat Check problem that we studied in Section \n",
      ", except that no distribution was specified in the Hat Check problemwe were told only that each person gets their correct hat back with prob-ability \n",
      "1=n\n",
      ". If the hats are scrambled according to uniformly random permutations, then the probability that everyone gets the right hat back is \n",
      "1=n\n",
      " , which is much less than the \n",
      "1=n\n",
      " upper bound given by Markovs Theorem. So, in this case, the bound given by Markovs Theorem is not close to the actual probability.\n",
      "What is the probability that at least two people get their right hats back? Markovs Theorem tells us that\n",
      "Pr \n",
      "R\n",
      "\t\n",
      "2\n",
      "\t\n",
      "Ex\n",
      "2\n",
      "R\n",
      " \n",
      "D\n",
      " \n",
      "1\n",
      "2\n",
      ":\n",
      "\n",
      "In this case, Markovs Theorem is not too far off from the right answer if the hats are distributed according to a random permutation\n",
      "but it is not very close to the correct answer \n",
      "1=n\n",
      " for the case when the hats are distributed as in the Chinese Appetizer problem.\n",
      "Why R Must be Nonnegative\n",
      "Remember that Markovs Theorem applies only to nonnegative random variables! Indeed, the theorem is false if this restriction is removed. For example, let \n",
      "R\n",
      " be -10\n",
      "\n",
      "Proving this requires some effort.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 510  #516\n",
      "\n",
      "This is the wrong answer! Obviously, \n",
      "R\n",
      " is at least 5 with probability \n",
      "1=2\n",
      ".\n",
      "On the other hand, we can still apply Markovs Theorem indirectly to derive a bound on the probability that an arbitrary variable like \n",
      "R\n",
      " is 5 or more. For example, given any random variable, \n",
      "R\n",
      " with expectation 0 and values \n",
      "10\n",
      ", we can con-clude that Pr \n",
      "R 5 2=3\n",
      ". To prove this fact, we define \n",
      "T\n",
      " WWD \n",
      "R\n",
      " C \n",
      "10\n",
      ". Then \n",
      "T\n",
      " is a nonnegative random variable with expectation Ex \n",
      "R\n",
      " C \n",
      "10\n",
      " D Ex \n",
      "R\n",
      " C \n",
      "10\n",
      " D \n",
      "10\n",
      ", so Markovs Theorem applies and tells us that Pr \n",
      "T 15 10=15\n",
      " D \n",
      "2=3\n",
      ". But\n",
      "15 \n",
      "iff\n",
      " R  5\n",
      ", so Pr\n",
      " R  5   2=3\n",
      ", as claimed.\n",
      "19.2.3\n",
      "\t\n",
      "Markovs Theorem for Bounded Variables\n",
      "Suppose we learn that the average IQ among MIT students is 150 (which is not true, by the way). What can we say about the probability that an MIT student has an IQ of more than 200? Markovs Theorem immediately tells us that no more than \n",
      "150=200 \n",
      "or\n",
      " 3=4 \n",
      "of the students can have such a high IQ. Thats because if\n",
      " R \n",
      "is the\n",
      " \n",
      "IQ of a random MIT student, then\n",
      "Pr \n",
      "R > 200\n",
      "\t\n",
      "Ex\n",
      "200\n",
      "R\n",
      " \n",
      "D\n",
      " \n",
      "150\n",
      "200\n",
      " \n",
      "D\n",
      " \n",
      "3\n",
      "4\n",
      ":\n",
      "\n",
      "But lets also suppose that no MIT student has an IQ less than 100 (which may\n",
      "So only half, not 3/4, of the students can be as amazing as they think they are. A bit of a relief!\n",
      "More generally, we can get better bounds applying Markovs Theorem to \n",
      "R l\n",
      " instead of \n",
      "R\n",
      " for any lower bound \n",
      "l\n",
      " on \n",
      "R\n",
      ", even when \n",
      "l\n",
      " is negative.\n",
      "Theorem 19.2.3. Let \n",
      "R\n",
      " be a random variable for which \n",
      "R\n",
      "\t\n",
      "l \n",
      "for some\n",
      " l \n",
      "2\n",
      " \n",
      "R.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 511  #517\n",
      "\n",
      "19.2.4\n",
      "\t\n",
      "Deviations Below the Mean\n",
      "Markovs Theorem says that a random variable is unlikely to greatly exceed the mean. Correspondingly, there is a variation of Markovs Theorem that says a ran-dom variable is unlikely to be much smaller than its mean.\n",
      "Theorem 19.2.4. Let \n",
      "u\n",
      " 2 R and let \n",
      "R\n",
      " be a random variable such that \n",
      "R u\n",
      ". Then for all \n",
      "x < u\n",
      ",\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 512  #518\n",
      "\n",
      "512\n",
      "\t\n",
      "Chapter 19\n",
      "\t\n",
      "Deviations\n",
      "For example, suppose that the class average on a midterm was 75/100. What fraction of the class scored below 50?\n",
      "There is not enough information here to answer the question exactly, but Theo-rem \n",
      "gives an upper bound. Let \n",
      "R\n",
      " be the score of a random student. Since 100 is the highest possible score, we can set \n",
      "u\n",
      " D \n",
      "100\n",
      " to meet the condition in the theorem that \n",
      "R u\n",
      ". Applying Theorem \n",
      ", we find:\n",
      "That is, at most half of the class scored 50 or worse. This makes sense; if more than half of the class scored 50 or worse, then the class average could not be 75, even if everyone else scored 100. As with Markovs Theorem, Theorem \n",
      " often gives weak results. In fact, based on the data given, the entire class could have scored above 50.\n",
      "19.2.5\n",
      "\t\n",
      "Using Markovs Theorem to Analyze Non-Random Events\n",
      "In the previous example, we used a theorem about a random variable to conclude facts about non-random data. For example, we concluded that if the average score on a test is 75, then at most \n",
      "1=2\n",
      " the class scored 50 or worse. There is no random-ness in this problem, so how can we apply Theorem \n",
      "to reach this conclusion?\n",
      "The explanation is not difficult. For any set of scores \n",
      "S\n",
      " D f\n",
      "s\n",
      "1\n",
      "; s\n",
      "2\n",
      "; : : : ; s\n",
      "n\n",
      "g, we introduce a random variable \n",
      "R\n",
      " such that\n",
      "Pr\n",
      " \n",
      "R\n",
      " \n",
      "D\n",
      " \n",
      "s\n",
      "i\n",
      "  \n",
      "D\n",
      " \n",
      "(# of students with score\n",
      " \n",
      "s\n",
      "i \n",
      ")\n",
      " \n",
      ":\n",
      "\n",
      "n\n",
      "We then use Theorem \n",
      "to conclude that Pr \n",
      "R 50 1=2\n",
      ". To see why this means (with certainty) that at most \n",
      "1=2\n",
      " of the students scored 50 or less, we observe that\n",
      "1\n",
      "n\n",
      "(# of students with score 50 or less)\n",
      ":\n",
      "\n",
      "So, if Pr \n",
      "R 50 1=2\n",
      ", then the number of students with score 50 or less is at most \n",
      "n=2\n",
      ".\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 513  #519\n",
      "\n",
      "\n",
      "19.3\n",
      "\t\n",
      "Chebyshevs Theorem\n",
      "As we have just seen, Markovs Theorem can be extended by applying it to func-\n",
      "The restatement of Equation \n",
      "for\t\n",
      "D \n",
      "2\n",
      " is known as Chebyshevs Theorem.\n",
      "Theorem 19.3.2 (Chebyshev). Let \n",
      "R\n",
      " be a random variable and \n",
      "x\n",
      " 2 R\n",
      "C\n",
      ". Then\n",
      "Proof. Define\n",
      "T \n",
      "WWD\n",
      " R\n",
      "\t\n",
      "Ex \n",
      "R :\n",
      "Then\n",
      "Pr  j\n",
      "R\n",
      "\tEx \n",
      "R\n",
      " j\n",
      "\t\n",
      "x \n",
      "D\n",
      " \n",
      "Pr\n",
      " \n",
      "j\n",
      "T \n",
      "j\n",
      "\tx\n",
      "Pr \n",
      "T\n",
      " \n",
      "2\n",
      "   \n",
      "x\n",
      "2\n",
      "Corollary 19.3.3. Let \n",
      "R\n",
      " be a random variable, and let \n",
      "c\n",
      " be a positive real number.\n",
      "1\n",
      "Pr j\n",
      "R\n",
      "\tEx \n",
      "R\n",
      " j\n",
      "\t\n",
      "c \n",
      "R\n",
      "\t\n",
      "c\n",
      "2\n",
      " \n",
      ":\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 514  #520\n",
      "\n",
      "514\n",
      "\t\n",
      "Chapter 19\n",
      "\t\n",
      "Deviations\n",
      "Proof. Substituting \n",
      "x\n",
      " D \n",
      "c\n",
      " \n",
      "R\n",
      " in Chebyshevs Theorem gives:\n",
      "As an example, suppose that, in addition to the national average IQ being 100, we also know the standard deviation of IQs is 10. How rare is an IQ of 300 or more?\n",
      "Let the random variable \n",
      "R\n",
      " be the IQ of a random person. So we are supposing that Ex \n",
      "R\n",
      " D \n",
      "100\n",
      ", \n",
      "R\n",
      " D \n",
      "10\n",
      ", and \n",
      "R\n",
      " is nonnegative. We want to compute Pr \n",
      "R\n",
      " \n",
      "300 \n",
      ".\n",
      "We have already seen that Markovs Theorem \n",
      "gives a coarse bound, namely,\n",
      "Pr \n",
      "R\n",
      "\t\n",
      "300\n",
      "\t\n",
      "1\n",
      "3\n",
      ":\n",
      "\n",
      "Now we apply Corollary \n",
      "to the same problem:\n",
      "So Chebyshevs Theorem implies that at most one person in four hundred has an IQ of 300 or more. We have gotten a much tighter bound using the additional information, namely the standard deviation of \n",
      "R\n",
      ", than we could get knowing only the expectation.\n",
      "More generally, Corollary \n",
      "tells us that a random variable is never likely to stray by more than a few standard deviations from its mean. For example, plug-ging \n",
      "c\n",
      " D \n",
      "3\n",
      " into Corollary \n",
      ", we find that the probability that a random variable strays from the mean by more than \n",
      "3\n",
      " is at most \n",
      "1=9\n",
      ".\n",
      "This fact has a nice pictorial characterization for pdfs with a bell-curve shape; namely, the width of the bell is \n",
      "O. /\n",
      ", as shown in Figure \n",
      ".\n",
      "19.3.1\n",
      "\t\n",
      "Bounds on One-Sided Errors\n",
      "Corollary \n",
      "gives bounds on the probability of deviating from the mean in either direction. If you only care about deviations in one direction, as was the case in the IQ example, then slightly better bounds can be obtained.\n",
      "Theorem 19.3.4. For any random variable \n",
      "R\n",
      " and any \n",
      "c > 0\n",
      ",\n",
      "1\n",
      "Pr\n",
      " \n",
      "R\n",
      "\t\n",
      "Ex \n",
      "R\n",
      "\t\n",
      "c \n",
      "R\n",
      "    \n",
      "c\n",
      "2\n",
      " \n",
      "C\n",
      " \n",
      "1\n",
      "\n",
      "and\n",
      "1\n",
      "Pr\n",
      " \n",
      "R\n",
      "\t\n",
      "Ex \n",
      "R\n",
      "\t\n",
      "c\n",
      "\t\n",
      "R\n",
      "\t\n",
      "c\n",
      "2\n",
      " \n",
      "C\n",
      " 1\n",
      ":\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 515  #521\n",
      "\n",
      "\n",
      "mean\n",
      "\n",
      "O./\n",
      "Figure 19.1 If the pdf of a random variable is bell-shaped, then the width of the bell is \n",
      "O. /\n",
      ".\n",
      "The proof of Theorem \n",
      "is trickier than the proof of Chebyshevs Theorem and we will not give the details here. Nor will we prove the fact that the bounds in Theorem \n",
      "are the best bounds that you can obtain if you know only the mean and standard deviation of the random variable \n",
      "R\n",
      ".\n",
      "Returning to the IQ example, Theorem \n",
      "tells us that\n",
      "which is a very slight improvement over Equation \n",
      ".\n",
      "As another example, suppose we give an exam. What fraction of the class can score more than 2 standard deviations from the average? If \n",
      "R\n",
      " is the score of a random student, then\n",
      "1\n",
      "Pr j\n",
      "R\n",
      "\tEx \n",
      "R\n",
      " j\n",
      "\t\n",
      "2 \n",
      "R\n",
      "\t\n",
      "4\n",
      ":\n",
      "\n",
      "For one-sided error, the fraction that could be 2 standard deviations or more above the average is at most\n",
      "This results holds no matter what the test scores are, and is again a deterministic fact derived using probabilistic tools.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 516  #522\n",
      "\n",
      "516\n",
      "\t\n",
      "Chapter 19\n",
      "\t\n",
      "Deviations\n",
      "\n",
      "19.4\n",
      "\t\n",
      "Bounds for Sums of Random Variables\n",
      "If all you know about a random variable is its mean and variance, then Cheby-shevs Theorem is the best you can do when it comes to bounding the probabil-ity that the random variable deviates from its mean. In some cases, however, we know morefor example, that the random variable has a binomial distribution and then it is possible to prove much stronger bounds. Instead of polynomially small bounds such as 1=c\n",
      "2\n",
      ", we can sometimes even obtain exponentially small bounds such as 1=e\n",
      "c\n",
      ". As we will soon discover, this is the case whenever the ran-dom variable T is the sum of n mutually independent random variables T\n",
      "1\n",
      ", T\n",
      "2\n",
      ", . . . , T\n",
      "n\n",
      " where 0 T\n",
      "i\n",
      " 1. A random variable with a binomial distribution is just one of many examples of such a T . Here is another.\n",
      "19.4.1\n",
      "\t\n",
      "A Motivating Example\n",
      "Fussbook is a new social networking site oriented toward unpleasant people.\n",
      "Like all major web services, Fussbook has a load balancing problem. Specif-ically, Fussbook receives 24,000 forum posts every 10 minutes. Each post is as-signed to one of m computers for processing, and each computer works sequen-tially through its assigned tasks. Processing an average post takes a computer 1=4 second. Some posts, such as pointless grammar critiques and snide witticisms, are easier. But the most protracted harangues require 1 full second.\n",
      "Balancing the work load across the m computers is vital; if any computer is as-signed more than 10 minutes of work in a 10-minute interval, then that computer is overloaded and system performance suffers. That would be bad, because Fussbook users are not a tolerant bunch.\n",
      "An early idea was to assign each computer an alphabetic range of forum topics. (That oughta work!, one programmer said.) But after the computer handling the privacy and preferred text editor threads melted, the drawback of an ad hoc approach was clear: there are no guarantees.\n",
      "If the length of every task were known in advance, then finding a balanced dis-tribution would be a kind of bin packing problem. Such problems are hard to solve exactly, though approximation algorithms can come close. But in this case, task lengths are not known in advance, which is typical for workload problems in the real world.\n",
      "So the load balancing problem seems sort of hopeless, because there is no data available to guide decisions. Heck, we might as well assign tasks to computers at random!\n",
      "As it turns out, random assignment not only balances load reasonably well, but\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 517  #523\n",
      "\n",
      "also permits provable performance guarantees in place of That oughta work! as-sertions. In general, a randomized approach to a problem is worth considering when a deterministic solution is hard to compute or requires unavailable information.\n",
      "Some arithmetic shows that Fussbooks traffic is sufficient to keep \n",
      "m\n",
      " D \n",
      "10\n",
      " com-puters running at 100% capacity with perfect load balancing. Surely, more than 10 servers are needed to cope with random fluctuations in task length and imperfect load balance. But how many is enough? 11? 15? 20? 100? Well answer that question with a new mathematical tool.\n",
      "19.4.2\n",
      "\t\n",
      "The Chernoff Bound\n",
      "The Chernoff\n",
      "bound is a hammer that you can use to nail a great many problems. Roughly, the Chernoff bound says that certain random variables are very unlikely to significantly exceed their expectation. For example, if the expected load on a computer is just a bit below its capacity, then that computer is unlikely to be overloaded, provided the conditions of the Chernoff bound are satisfied.\n",
      "More precisely, the Chernoff Bound says that the sum of lots of little, indepen-dent random variables is unlikely to significantly exceed the mean of the sum. The Markov and Chebyshev bounds lead to the same kind of conclusion but typically provide much weaker bounds. In particular, the Markov and Chebyshev bounds are polynomial, while the Chernoff bound is exponential.\n",
      "Here is the theorem. The proof will come later in Section \n",
      ".\n",
      "Theorem 19.4.1 (Chernoff Bound). Let \n",
      "T\n",
      "1\n",
      "; : : : T\n",
      "n\n",
      " be mutually independent ran-dom variables such that \n",
      "0 T\n",
      "i\n",
      " \n",
      "1\n",
      " for all \n",
      "i\n",
      ". Let \n",
      "T\n",
      " D \n",
      "T\n",
      "1\n",
      " C C \n",
      "T\n",
      "n\n",
      ". Then for all \n",
      "c 1\n",
      ",\n",
      "where \n",
      "k\n",
      " D \n",
      "c\n",
      " ln\n",
      ".c/\n",
      "\t\n",
      "c \n",
      "C\n",
      " 1\n",
      ".\n",
      "The Chernoff bound applies only to distributions of sums of independent random variables that take on values in the interval \n",
      "0; 1\n",
      " . The binomial distribution is of course such a distribution, but there are lots of other distributions because the Chernoff bound allows the variables in the sum to have differing, arbitrary, and even unknown distributions over the range \n",
      "0; 1\n",
      " . Furthermore, there is no direct dependence on the number of random variables in the sum or their expectations. In short, the Chernoff bound gives strong results for lots of problems based on little informationno wonder it is widely used!\n",
      "\n",
      "Yes, this is the same Chernoff who figured out how to beat the state lottery. So you might want to pay attentionthis guy knows a thing or two.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 518  #524\n",
      "\n",
      "518\n",
      "\t\n",
      "Chapter 19\n",
      "\t\n",
      "Deviations\n",
      "More Examples\n",
      "The Chernoff bound is pretty easy to apply, though the details can be daunting at first. Lets walk through a simple example to get the hang of it.\n",
      "What is the probability that the number of heads that come up in 1000 indepen-dent tosses of a fair coin exceeds the expectation by 20% or more? Let \n",
      "T\n",
      "i\n",
      " be an indicator variable for the event that the \n",
      "i\n",
      "-th coin is heads. Then the total number of heads is\n",
      "D \n",
      "T\n",
      "1\n",
      " C  C \n",
      "T\n",
      "1000\n",
      ":\n",
      "The Chernoff bound requires that the random variables \n",
      "T\n",
      "i\n",
      " be mutually independent and take on values in the range \n",
      "0; 1\n",
      " . Both conditions hold here. In fact, this example is similar to many applications of the Chernoff bound in that every \n",
      "T\n",
      "i\n",
      " is either 0 or 1, since theyre indicators.\n",
      "The goal is to bound the probability that the number of heads exceeds its expec-tation by 20% or more; that is, to bound Pr \n",
      "T c\n",
      " Ex \n",
      "T\n",
      " where c = \n",
      "1:2\n",
      ". To that end, we compute \n",
      "k\n",
      " as defined in the theorem:\n",
      "k \n",
      "D\n",
      " c \n",
      "ln\n",
      ".c/\n",
      "\t\n",
      "c \n",
      "C\n",
      " 1 \n",
      "D\n",
      " 0:0187 : : : :\n",
      "Plugging this value into the Chernoff bound gives:\n",
      "Pr \n",
      "T\n",
      "\t\n",
      "1:2 \n",
      "Ex\n",
      " T\n",
      "\t\n",
      "e\n",
      "k\n",
      "  \n",
      "Ex\n",
      " \n",
      "T\n",
      "D\n",
      " \n",
      "e\n",
      ".0:0187::: / 500\n",
      "< 0:0000834:\n",
      "So the probability of getting 20% or more extra heads on 1000 coins is less than 1 in 10,000.\n",
      "The bound becomes much stronger as the number of coins increases, because the expected number of heads appears in the exponent of the upper bound. For example, the probability of getting at least 20% extra heads on a million coins is at most\n",
      "e\n",
      ".0:0187::: / 500000\n",
      "\t\n",
      "< e\n",
      "9392\n",
      "which is pretty darn small.\n",
      "Alternatively, the bound also becomes stronger for larger deviations. For exam-ple, suppose were interested in the odds of getting 30% or more extra heads in 1000 tosses, rather than 20%. In that case, \n",
      "c\n",
      " D \n",
      "1:3\n",
      " instead of \n",
      "1:2\n",
      ". Consequently, the parameter \n",
      "k\n",
      " rises from \n",
      "0:0187\n",
      " to about \n",
      "0:0410\n",
      ", which may seem insignificant.\n",
      "\n",
      "Since we are analyzing a binomial distribution here, we can get somewhat better bounds using the methods from Section \n",
      ", but it is much easier to use the Chernoff bounds, and they provide results that are nearly as good.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 519  #525\n",
      "\n",
      "But because \n",
      "k\n",
      " appears in the exponent of the upper bound, the final probability decreases from around 1 in 10,000 to about 1 in a billion!\n",
      "Pick-4\n",
      "Pick-4 is a lottery game where you pick a 4-digit number between 0000 and 9999. If your number comes up in a random drawing, then you win $5,000. Your chance of winning is 1 in 10,000. And if 10 million people play, then the expected number of winners is 1000. The lottery operators nightmare is that the number of winners is much greater; say, 2000 or more. What is the probability that will happen?\n",
      "Let \n",
      "T\n",
      "i\n",
      " be an indicator for the event that the \n",
      "i\n",
      "-th player wins. Then \n",
      "T\n",
      " D \n",
      "T\n",
      "1\n",
      " C\n",
      "C\n",
      "T\n",
      "n\n",
      " is the total number of winners. If we assume\n",
      "that the players picks and the winning number are random, independent and uniform, then the indicators \n",
      "T\n",
      "i\n",
      " are independent, as required by the Chernoff bound.\n",
      "Since 2000 winners would be twice the expected number, we choose \n",
      "c\n",
      " D \n",
      "2\n",
      ", compute \n",
      "k\n",
      " D \n",
      "c\n",
      " ln\n",
      ".c/ c\n",
      " C \n",
      "1\n",
      " D \n",
      "0:386 : : :\n",
      " , and plug these values into the Chernoff bound:\n",
      " \n",
      "Pr \n",
      "T\n",
      "\t\n",
      "2000 \n",
      "D\n",
      " \n",
      "Pr\n",
      " T\t2 \n",
      "Ex\n",
      " T\n",
      "e\n",
      "k  \n",
      "Ex\n",
      " T\n",
      "e\n",
      ".0:386::: / 1000\n",
      "e\n",
      "386  \n",
      ":\n",
      "So there is almost no chance that the lottery operator pays out double. In fact, the number of winners wont even be 10% higher than expected very often. To prove that, let \n",
      "c\n",
      " D \n",
      "1:1\n",
      ", compute \n",
      "k\n",
      " D \n",
      "c\n",
      " ln\n",
      ".c/ c\n",
      " C \n",
      "1\n",
      " D \n",
      "0:00484 : : :\n",
      " , and plug in again:\n",
      "Pr \n",
      "T\n",
      "\t\n",
      "1:1 \n",
      "Ex\n",
      " T\n",
      "\t\n",
      "e\n",
      "k\n",
      "  \n",
      "Ex\n",
      " \n",
      "T\n",
      "D\n",
      " \n",
      "e\n",
      ".0:00484/ 1000\n",
      "< 0:01:\n",
      "So the Pick-4 lottery may be exciting for the players, but the lottery operator has little doubt about the outcome!\n",
      "Randomized Load Balancing\n",
      "Now lets return to Fussbook and its load balancing problem. Specifically, we need to determine how many machines suffice to ensure that no server is overloaded;\n",
      "\n",
      "As we noted in Chapter \n",
      ", human choices are often not uniform and they can be highly depen-dent. For example, lots of people will pick an important date. So the lottery folks should not get too much comfort from the analysis that follows, unless they assign random 4-digit numbers to each player.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 520  #526\n",
      "\n",
      "520\n",
      "\t\n",
      "Chapter 19\n",
      "\t\n",
      "Deviations\n",
      "that is, assigned to do more than 10 minutes of work in a 10-minute interval.\n",
      "To begin, lets find the probability that the first server is overloaded. Let \n",
      "T\n",
      "i\n",
      " be the number of seconds that the first server spends on the \n",
      "i\n",
      "-th task. So \n",
      "T\n",
      "i\n",
      " is zero if the task is assigned to another machine, and otherwise \n",
      "T\n",
      "i\n",
      " is the length of the task. Then\n",
      "D \n",
      "n\n",
      "iD1\n",
      " \n",
      "T\n",
      "i\n",
      " is the total length of tasks assigned to the server, where \n",
      "n\n",
      " D \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24;000\n",
      ". We need an upper bound on Pr \n",
      "T 600\n",
      " ; that is, the probability that the first server is assigned more than 600 seconds (or, equivalently, 10 minutes) of work.\n",
      "The Chernoff bound is applicable only if the \n",
      "T\n",
      "i\n",
      " are mutually independent and take on values in the range \n",
      "0; 1\n",
      " . The first condition is satisfied if we assume that task lengths and assignments are independent. And the second condition is satisfied because processing even the most interminable harangue takes at most 1 second.\n",
      "In all, there are 24,000 tasks, each with an expected length of 1/4 second. Since tasks are assigned to computers at random, the expected load on the first server is:\n",
      "P\n",
      "For example, if there are \n",
      "m\n",
      " D \n",
      "10\n",
      " machines, then the expected load on the first server is 600 seconds, which is 100% of its capacity.\n",
      "Now we can use the Chernoff bound to upper bound the probability that the first\n",
      "where \n",
      "c\n",
      " D \n",
      "m=10\n",
      ". The first equality follows from Equation \n",
      ".\n",
      "The probability that some server is overloaded is at most \n",
      "m\n",
      " times the probability that the first server is overloaded by the Sum Rule in Section \n",
      ". So\n",
      "D \n",
      "m\n",
      " Pr the first server is overloaded\n",
      "me\n",
      ".c\n",
      "\t\n",
      "ln.c/c\n",
      "\t\n",
      "C1/ 6000=m\n",
      ";\n",
      "where \n",
      "c\n",
      " D \n",
      "m=10\n",
      ". Some values of this upper bound are tabulated below:\n",
      "D \n",
      "11\n",
      " W \n",
      "0:784:::\n",
      "D \n",
      "12\n",
      " W \n",
      "0:000999 : : :\n",
      "D \n",
      "13\n",
      " W \n",
      "0:0000000760 : : :\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 521  #527\n",
      "\n",
      "These values suggest that a system with \n",
      "m\n",
      " D \n",
      "11\n",
      " machines might suffer immediate overload, \n",
      "m\n",
      " D \n",
      "12\n",
      " machines could fail in a few days, but \n",
      "m\n",
      " D \n",
      "13\n",
      " should be fine for a century or two!\n",
      "19.4.3\n",
      "\t\n",
      "Proof of the Chernoff Bound\n",
      "The proof of the Chernoff bound is somewhat involved. Heck, even Chernoff didnt come up with it! His friend, Herman Rubin, showed him the argument. Thinking the bound not very significant, Chernoff did not credit Rubin in print. He felt pretty bad when it became famous!\n",
      "Here is the theorem again, for reference:\n",
      "Theorem 19.4.2 (Chernoff Bound). Let \n",
      "T\n",
      "1\n",
      "; : : : ; T\n",
      "n\n",
      " be mutually independent ran-dom variables such that \n",
      "0 T\n",
      "i\n",
      " \n",
      "1\n",
      " for all \n",
      "i\n",
      ". Let \n",
      "T\n",
      " D \n",
      "T\n",
      "1\n",
      " C C \n",
      "T\n",
      "n\n",
      ". Then for all \n",
      "c 1\n",
      ",\n",
      "Proof. For clarity, well go through the proof top down; that is, well use facts that are proved immediately afterward.\n",
      "The key step is to exponentiate both sides of the inequality \n",
      "T\n",
      "\t\n",
      "c \n",
      "Ex\n",
      " T  \n",
      "and\n",
      "which is proved below in Lemma \n",
      ". The final step is simplification, using the\n",
      "fact that \n",
      "c\n",
      "c\n",
      " is equal to \n",
      "e\n",
      "c\n",
      " \n",
      "ln\n",
      ".c/\n",
      ".\n",
      "\n",
      "See A Conversation with Herman Chernoff, Statistical Science 1996, Vol. 11, No. 4, pp 335\n",
      "350.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 522  #528\n",
      "\n",
      "522\n",
      "\t\n",
      "Chapter 19\n",
      "\t\n",
      "Deviations\n",
      "Algebra aside, there is a brilliant idea in this proof: in this context, exponenti-ating somehow supercharges the Markov bound. This is not true in general! One unfortunate side-effect is that we have to bound some nasty expectations involving exponentials in order to complete the proof. This is done in the two lemmas below, where variables take on values as in Theorem \n",
      ".\n",
      "Lemma 19.4.3.\n",
      "Ex\n",
      " \n",
      "c\n",
      "T\n",
      "\t\n",
      "e\n",
      ".c1/\n",
      "  \n",
      "Ex\n",
      " \n",
      "T\n",
      " \n",
      ":\n",
      "Proof.\n",
      "Ex\n",
      " \n",
      "c\n",
      "T\n",
      "\t\n",
      "D \n",
      "Ex\n",
      " \n",
      "c\n",
      "T\n",
      "1\n",
      "C   C\n",
      "T\n",
      "n\n",
      "Ex \n",
      "c\n",
      "T\n",
      "1\n",
      "    \n",
      "c\n",
      "T\n",
      "n\n",
      "Ex \n",
      "c\n",
      "T\n",
      "1\n",
      "Ex \n",
      "c\n",
      "T\n",
      "n\n",
      "e\n",
      ".c1/  \n",
      "Ex\n",
      " T\n",
      "1\n",
      "\t\n",
      "e\n",
      ".c1/\n",
      "  \n",
      "Ex\n",
      " \n",
      "T\n",
      "n\n",
      "e\n",
      ".c1/.\n",
      "Ex\n",
      " T \n",
      "1\n",
      " \n",
      "C   CEx\n",
      " T\n",
      "n\n",
      " /\n",
      "e\n",
      ".c1/  \n",
      "Ex\n",
      " T\n",
      "1\n",
      "C   C\n",
      "T\n",
      "n\n",
      "D\n",
      " \n",
      "e\n",
      ".c1/  \n",
      "Ex\n",
      " T \n",
      ":\n",
      "The first step uses the definition of \n",
      "T\n",
      " , and the second is just algebra. The third step uses the fact that the expectation of a product of independent random variables is the product of the expectations. This is where the requirement that the \n",
      "T\n",
      "i\n",
      " be independent is used. Then we bound each term using the inequality\n",
      "Ex\n",
      " \n",
      "c\n",
      "T\n",
      "i\n",
      "\t\n",
      "e\n",
      ".c1/\n",
      "  \n",
      "Ex\n",
      " \n",
      "T\n",
      "i\n",
      " \n",
      ";\n",
      "which is proved in Lemma \n",
      ". The last steps are simplifications using algebra\n",
      "Proof. All summations below range over values \n",
      "v\n",
      " taken by the random variable \n",
      "T\n",
      "i\n",
      " ,\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 523  #529\n",
      "\n",
      "which are all required to be in the interval \n",
      "0; 1\n",
      " .\n",
      "D \n",
      "1\n",
      " C \n",
      ".c\n",
      "\t\n",
      "1/ \n",
      "Ex\n",
      " T\n",
      "i\n",
      "e\n",
      ".c1/\n",
      "\t\n",
      "Ex \n",
      "T\n",
      "i\n",
      " \n",
      ":\n",
      "The first step uses the definition of expectation.  The second step relies on the\n",
      "This inequality is why the variables \n",
      "T\n",
      "i\n",
      " are restricted to the interval \n",
      "0; 1\n",
      " . We then multiply out inside the summation and split into two sums. The first sum adds the probabilities of all possible outcomes, so it is equal to 1. After pulling the constant\n",
      "1 \n",
      "out of the second sum, were left with the definition of Ex\n",
      " T\n",
      "i\n",
      " \n",
      ". The final step\n",
      "uses the standard inequality \n",
      "1\n",
      " C \n",
      "z\n",
      "\t\n",
      "e\n",
      "z\n",
      ", which holds for all\n",
      " z > 0\n",
      ".\n",
      "\n",
      "19.5\n",
      "\t\n",
      "Mutually Independent Events\n",
      "Suppose that we have a collection of mutually independent events \n",
      "A\n",
      "1\n",
      ", \n",
      "A\n",
      "2\n",
      ", . . . , \n",
      "A\n",
      "n\n",
      ", and we want to know how many of the events are likely to occur.\n",
      "Let \n",
      "T\n",
      "i\n",
      " be the indicator random variable for \n",
      "A\n",
      "i\n",
      " and define\n",
      "p\n",
      "i\n",
      " \n",
      "D\n",
      " \n",
      "Pr\n",
      " T\n",
      "i\n",
      " \n",
      "D\n",
      " 1 \n",
      "D\n",
      " \n",
      "Pr\n",
      " A\n",
      "i\n",
      "for \n",
      "1\n",
      "\t\n",
      "i\n",
      "\t\n",
      "n\n",
      ". Define\n",
      "D \n",
      "T\n",
      "1\n",
      " C \n",
      "T\n",
      "2\n",
      " C  C \n",
      "T\n",
      "n\n",
      "to be the number of events that occur.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 524  #530\n",
      "\n",
      "524\n",
      "\t\n",
      "Chapter 19\n",
      "\t\n",
      "Deviations\n",
      "We know from Linearity of Expectation that\n",
      "Ex \n",
      "T\n",
      "  D Ex \n",
      "T\n",
      "1\n",
      " C Ex \n",
      "T\n",
      "2\n",
      " C\n",
      "\t\n",
      "C Ex \n",
      "T\n",
      "n\n",
      "n\n",
      "X\n",
      "p\n",
      "i\n",
      " :\n",
      "i\n",
      "D\n",
      "1\n",
      "This is true even if the events are not independent.\n",
      "By Theorem \n",
      ", we also know that\n",
      "Var \n",
      "T\n",
      "  D Var \n",
      "T\n",
      "1\n",
      " C Var \n",
      "T\n",
      "2\n",
      " C\n",
      "\t\n",
      "C Var \n",
      "T\n",
      "n\n",
      "n\n",
      "X\n",
      "D\n",
      "\t\n",
      "p\n",
      "i\n",
      " .1\tp\n",
      "i\n",
      " /;\n",
      "D\n",
      "1\n",
      "and thus that\n",
      "This is true even if the events are only pairwise independent.\n",
      "Markovs Theorem tells us that for any \n",
      "c > 1\n",
      ",\n",
      "Pr \n",
      "T\n",
      "\t\n",
      "c \n",
      "Ex\n",
      " T\n",
      "\t\n",
      "c\n",
      "1\n",
      ":\n",
      "\n",
      "Chebyshevs Theorem gives us the stronger result that\n",
      "1\n",
      "Pr j\n",
      "T\n",
      "\tEx \n",
      "T\n",
      " j\n",
      "\t\n",
      "c \n",
      "T\n",
      "\t\n",
      "c\n",
      "2\n",
      " \n",
      ":\n",
      "\n",
      "The Chernoff Bound gives us an even stronger result; namely, that for any \n",
      "c > 0\n",
      ",\n",
      "Pr \n",
      "T\n",
      "\tEx \n",
      "T\n",
      "\t\n",
      "c \n",
      "Ex\n",
      " T\n",
      "\t\n",
      "e\n",
      ".c\n",
      "  \n",
      "ln\n",
      ".c/c\n",
      "  \n",
      "C\n",
      "1/\n",
      " \n",
      "Ex\n",
      " \n",
      "T\n",
      " :\n",
      "In this case, the probability of exceeding the mean by \n",
      "c\n",
      " Ex \n",
      "T\n",
      " decreases as an exponentially small function of the deviation.\n",
      "By considering the random variable \n",
      "n T\n",
      " , we can also use the Chernoff Bound to prove that the probability that \n",
      "T\n",
      " is much lower than Ex \n",
      "T\n",
      " is also exponentially small.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 525  #531\n",
      "\n",
      "19.5.1\tMurphys Law\n",
      "Suppose we want to know the probability that at least 1 event occurs. If Ex \n",
      "T < 1\n",
      ", then Markovs Theorem tells us that\n",
      "Pr \n",
      "T\n",
      "\t\n",
      "1\n",
      "\t\n",
      "Ex \n",
      "T :\n",
      "On the other hand, if Ex \n",
      "T 1\n",
      ", then we can obtain a lower bound on Pr \n",
      "T 1\n",
      " using a result that we call Murphys Law\n",
      ".\n",
      "Theorem 19.5.1 (Murphys Law). Let \n",
      "A\n",
      "1\n",
      ", \n",
      "A\n",
      "2\n",
      ", . . . , \n",
      "A\n",
      "n\n",
      " be mutually independent events. Let \n",
      "T\n",
      "i\n",
      " be the indicator random variable for \n",
      "A\n",
      "i\n",
      " and define\n",
      "WWD \n",
      "T\n",
      "1\n",
      " C \n",
      "T\n",
      " C \n",
      "2\n",
      " C  C \n",
      "T\n",
      "n\n",
      "to be the number of events that occur. Then\n",
      "Pr \n",
      "T\n",
      " D \n",
      "0\n",
      "\t\n",
      "e  \n",
      "Ex\n",
      " \n",
      "T\n",
      " :\n",
      "Proof.\n",
      "Pr \n",
      "T\n",
      " D \n",
      "0\n",
      " D Pr \n",
      "A\n",
      "1\n",
      " ^ \n",
      "A\n",
      "2\n",
      " ^\n",
      "\t\n",
      "^ \n",
      "A\n",
      "n\n",
      "\n",
      "n\n",
      "Y\n",
      "\n",
      "Pr \n",
      "A\n",
      "i\n",
      "D\n",
      "1\n",
      "\n",
      "\n",
      "(by independence of \n",
      "A\n",
      "i\n",
      " )\n",
      "(since 8\n",
      "x:1\n",
      "\t\n",
      "x\n",
      "\t\n",
      "e\n",
      "x\n",
      "  \n",
      ")\n",
      "(since \n",
      "T\n",
      "i\n",
      " is an indicator for \n",
      "A\n",
      "i\n",
      " ) (Linearity of Expectation)\n",
      "For example, given any set of mutually independent events, if you expect 10 of them to happen, then at least one of them will happen with probability at least \n",
      "1\n",
      " \n",
      "e\n",
      "10\n",
      " \n",
      ". The probability that none of them happen is at most\n",
      " e\n",
      "10\n",
      " < 1=22000\n",
      ".\n",
      "So if there are a lot of independent things that can go wrong and their probabil-ities sum to a number much greater than 1, then Theorem \n",
      "proves that some of them surely will go wrong.\n",
      "\n",
      "This is in reference and deference to the famous saying that If something can go wrong, it will go wrong.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 526  #532\n",
      "\n",
      "526\n",
      "\t\n",
      "Chapter 19\n",
      "\t\n",
      "Deviations\n",
      "This result can help to explain coincidences, miracles, and crazy events that seem to have been very unlikely to happen. Such events do happen, in part, because there are so many possible unlikely events that the sum of their probabilities is greater than one. For example, someone does win the lottery.\n",
      "In fact, if there are 100,000 random tickets in Pick-4, Theorem \n",
      "says that the probability that there is no winner is less than e\n",
      "10\n",
      " < 1=22000. More generally, there are literally millions of one-in-a-million possible events and so some of them will surely occur.\n",
      "19.5.2\tAnother Magic Trick\n",
      "Theorem \n",
      "is surprisingly powerful. In fact, it is so powerful that it can enable us to read your mind. Heres how.\n",
      "You choose a secret number n from 1 to 9. Then we randomly shuffle an ordinary deck of 52 cards and display the cards one at a time. You watch as we reveal the cards and when we reveal the nth card, that card becomes your secret card. If the card is an Ace, a 10, or a face card, then you assign that card a value of 1. Otherwise, you assign that card a value that is its number. For example, the J ~ gets assigned a value v\n",
      "1\n",
      " D 1 and the 4} gets assigned a value v\n",
      "1\n",
      " D 4. You do all of this in your mind so that we cant tell when the nth card shows up.\n",
      "We keep revealing the cards, and when the (n C v\n",
      "1\n",
      ")th card shows up, that card becomes your new secret card. You compute its value v\n",
      "2\n",
      " using the same scheme as for v\n",
      "1\n",
      ". For example, if your new secret card is the 10|, then v\n",
      "2\n",
      " D 1. The .n C v\n",
      "1\n",
      " C v\n",
      "2\n",
      "/th card will then become your next secret card, and so forth.\n",
      "We proceed in this fashion until all 52 cards have been revealed, whereupon we read your mind by predicting your last secret card! How is this possible?\n",
      "For the purposes of illustration, suppose that your secret number was n D 3 and the deck consisted of the 11 cards:\n",
      "3}\t5\t2}\t3|\t10|\tQ}\t3~\t7\t6|\t4}\t2~:\n",
      "Then your secret cards would be\n",
      "2}; 10|; Q}; 3~; 4}\n",
      "since v\n",
      "1\n",
      " D 2, v\n",
      "2\n",
      " D 1, v\n",
      "3\n",
      " D 1, v\n",
      "4\n",
      " D 3, and v\n",
      "5\n",
      " D 4. In this example, your last secret card is the 4}.\n",
      "To make the trick work, we follow the same rules as you, except that we start with n D 1. With the 11-card deck shown above, our secret cards would be\n",
      "3}; 3|; 3~; 4}:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 527  #533\n",
      "\n",
      "We have the same last secret card as you do! That is not a coincidence. In fact, this is how we predict your last cardwe just guess that it is the same as our last card. And, we will be right with probability greater than 90%.\n",
      "To see why the trick is likely to work, you need to notice that if we ever share a secret card, then we will surely have the same last secret card. Thats because we will perform exactly the same steps as the cards are revealed.\n",
      "Each time we get a new secret card, there is always a chance that it was one of your secret cards. For any given step, the chance of a match is small but we get a lot of chances. In fact, the number of chances will typically outweigh the inverse of the probability of a match on any given step and so, at least informally, Murphys Law suggests that we are likely to eventually get a match, whereupon we can read your mind.\n",
      "The details of the proof are complicated and we will not present them here. One of the main complications is that when you are revealing cards from a deck without replacement, the probability of getting a match on a given step is conditional based on the cards that have already been revealed.\n",
      "19.5.3\n",
      "\t\n",
      "The Subprime Mortgage Disaster\n",
      "Throughout the last few chapters, we have seen many examples where powerful conclusions can be drawn about a collection of events if the events are independent. Of course, such conclusions are totally invalid if the events have dependencies. Unforeseen dependencies can result in disaster in practice. For example, misguided assumptions about the independence of loans (combined with a large amount of greed) triggered the global financial meltdown in 20082009.\n",
      "In what follows, well explain some of what went wrong. You may notice that we have changed the names of the key participants. That is not to protect the innocent, since innocents are few and far between in this sordid tale. Rather, we changed the names to protect ourselves.\n",
      "In fact, just to be on the safe side, well forget about what really happened here on Earth and instead tell you a fairy tale that took place in a land far, far away.\n",
      "The central players in our story are the major Wall Street firms, of which Golden Scoundrels (commonly referred to as Golden) is the biggest and most aggressive. Firms such as Golden ostensibly exist to make markets; they purport to create an open and orderly market in which buyers and sellers can be brought together and through which capitalism can flourish. It all sounds good, but the fees that can be had from facilitating transactions in a truly open and orderly market are often just not enough to satisfy the ever-increasing need to make more. So the employees at\n",
      "\n",
      "For a much more detailed accounting of these events (and one that does name names), you may enjoy reading The Big Short by Michael Lewis.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 528  #534\n",
      "\n",
      "528\n",
      "\t\n",
      "Chapter 19\n",
      "\t\n",
      "Deviations\n",
      "such firms are always trying to figure out a way to create new opportunities to make even more money.\n",
      "One day, they came up with a whopper. Suppose they bought a collection of 1000 (say) subprime mortgage loans from all around the country and packaged them up into a single entity called a bond. A mortgage loan is a loan to a homeowner using the house as collateral; if the homeowner stops paying on the loan (in which case the loan is said to be in default), then the owner of the loan takes ownership of the house. A mortgage loan is classified as subprime if the homeowner does not have a very good credit history. Subprime loans are considered to be more risky than prime loans since they are more likely to default. Defaults are bad for everyone; the homeowner loses the home and the loan owner gets stuck trying to sell the house, which can take years and often results in very high losses.\n",
      "Of course, a bond consisting of 1000 subprime loans doesnt sound very appeal-ing to investors, so to dress it up, Golden sells the bond in tranches. The idea behind the tranches is to provide a way to assign losses from defaults. In a typical scenario, there would be 10 tranches and they are prioritized from 1 to 10. The defaults are assessed against the lowest tranches first. For example, suppose that there were 150 defaults in the collection of 1000 loans (an impossibly high number of defaults according to Golden). Then the lowest tranche would absorb the first 100 defaults (effectively wiping them out since all 100 of their loans would be in default) and the second-lowest tranche would be assigned the next 50 defaults, (wiping out half of their investment). The remaining 8 tranches would be doing greatnone of their loans would be in default.\n",
      "Because they are taking on more risk, the lower tranches would get more of the interest payments. The top tranche would get the lowest rate of return and would also be the safest. The lowest tranche would get the most interest, but also be the most exposed.\n",
      "But how much should you pay for a tranche? Suppose the probability that any given loan defaults in a year is 1%. In other words, suppose you expect 10 of the 1000 loans to default in each year. If the defaults are independent, then we can use the Chernoff bound to conclude that the chances of more than 100 defaults (10%) in the 1000-loan collection is exceedingly tiny. This means that every tranche but the lowest is essentially risk-free. That is excellent news for Golden since they can buy 1000 cheap\n",
      "subprime loans and then sell the top 9 tranches at premium rates, thereby making a large and instant profit on 900 of the 1000 loans. It is like turning a bunch of junk into a bunch of gold with a little junk left over.\n",
      "There remains the problem of the lowest tranche, which is expected to have 10 defaults in a pool of 100 loans for a default rate of 10%. This isnt so good\n",
      "\n",
      "They are subprime loans after all.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 529  #535\n",
      "\n",
      "so the first thing to do is to give the tranche a better sounding name than lowest tranche. Mezzanine tranche sounds much less ominous and so that is what they used.\n",
      "By the Chernoff bound, the default rate in the Mezzanine tranche is very un-likely to be much greater than 10%, and so the risk of owning this tranche can be addressed in part by increasing the interest payments for the tranche by 10%. But Golden had an even better idea (whopper number two)rather than pay the ex-tra 10%, why not collect together a bunch of mezzanine tranches from a bunch of bonds and then package them together into a super bond and then create tranches in the super-bond? The technical name for such a super bond is a collateralized debt obligation or CDO. This way, 90% of the mezzanine tranches instantly be-came essentially risk-free, or so Golden claimed as they were marketing them.\n",
      "The only problem now is getting the pension funds and other big investors to buy the CDOs at the same price as if they were AAA-rated risk-free bonds. This was a little tricky because 1) it was virtually impossible for the buyer to figure out exactly what loans they were effectively buying since they were buying a tranche of a collection of tranches, and 2) if you could ever figure out what it was, you would discover that it was the junk of the junk when it comes to loans.\n",
      "The solution was to enlist the help of the big bond-rating agencies: Substandard and Prevaricators (S&P) and Mopeys. If Golden could get AAA ratings\n",
      "on their tranches, then the pension funds and other big investors would buy them at premium rates.\n",
      "It turned out to be easier than you might think (or hope) to convince S&P and Mopeys to give high ratings to the CDO tranches. After all, the ratings agencies are trying to make money too and they make money by rating bonds. And Golden was only going to pay them if their bonds and CDOs got good ratings. And, since defaults were assumed to be essentially independent, there was a good argument as to why all but the mezzanine tranche of a bond or CDO would be essentially risk-free.\n",
      "So the stage is set for Golden to make a bundle of money. Cheap junk loans come in the back door and exit as expensive AAA-rated bonds and CDOs out the front door. The remaining challenge is to ramp up the new money-making machine. That\n",
      "\n",
      "11\n",
      "AAA ratings are the best you can get and are supposed to imply that there is virtually no chance of default.\n",
      "The logic gets a little fuzzy when you keep slicing and dicing the tranchesafter a few iterations, you should be able to conclude that the mezzanine tranche of a CDO is sure to have 100% defaults, but it required effort to see what was going on under the covers and effort costs money, and so the ratings agencies considered the risk of the mezzanine tranche of one CDO to be the same as the mezzanine tranche of any other, even though they could have wildly different probabilities of sustaining large numbers of defaults.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 530  #536\n",
      "\n",
      "530\n",
      "\t\n",
      "Chapter 19\n",
      "\t\n",
      "Deviations\n",
      "means creating more (preferably, many, many more) junk loans to fuel the machine. This is where Joe enters the scene.  Joe is a migrant laborer earning $15,000 per year. Joes credit history is not great (since he has never had a loan or credit card) but it is also not bad (since he has never missed a payment on a credit card and never defaulted on a loan). In short, Joe is a perfect candidate for a subprime\n",
      "mortgage loan on a $750,000 home.\n",
      "When Loans-R-Us approaches Joe for a home loan,\n",
      "Joe dutifully explains that while he would love to own a $750,000 home, he doesnt have enough money to pay for food, let alone the interest payments on the mortgage. No problem! replies Loans-R-Us. It is Joes lucky day. The interest rates are super-low for the first 2 years and Joe can take out a second loan to cover them during that period. What happens after 2 years? Joe wants to know. No problem! replies Loans-R-Us. Joe can refinancehis home will surely be worth more in 2 years. Indeed, Joe can even make money while he enjoys the comforts of his new home. If all goes well, he can even ease off on the laborer work, and maybe even by a second home. Joe is sold. In fact, millions of Joes are sold and, before long, the subprime loan business is booming.\n",
      "It turns out that there were a few folks out there who really did their math homework when they were in college. They were running hedge funds and, as the money-making machine was cranking away, they realized that a disaster was looming. They knew that loan defaults are not independentin fact, they are very dependent. Once home values stop rising, or a recession hits, or it comes time for Joe to refinance, defaults will occur at much higher rates than projected and the CDOs and many tranches of the underlying bonds will become worthless. And there is so much money invested in these bonds and CDOs that the economy could be ruined.\n",
      "Unfortunately, the folks who figured out what was going to happen didnt alert anyone. They didnt go to the newspapers. They didnt call the See no Evil Com-mission. They didnt even call 911. Instead, they worked with Golden to find a new way to make even more moneybetting against the CDO market.\n",
      "If you think a stock is going to decline, you can profit from the decline by bor-rowing the stock and selling it. After the stock declines in value, you buy it back and return it to the person that lent it to you. Your profit is the decline in price. This process is called shorting the stock.\n",
      "So the hedge funds wanted to short the CDOs. Unfortunately, there was no established way to borrow a tranche of a CDO. Always looking for a new way to make money, the investment houses came up with an even bigger whopper than the\n",
      "\n",
      "Yes, we know it is supposed to go the other way aroundJoe is supposed to approach the loan\n",
      "companybut these are extraordinary times.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 531  #537\n",
      "\n",
      "CDOthey invented the credit default swap.\n",
      "The idea behind the credit default swap is to provide a kind of insurance against the event that a bond or CDO suffers a certain number of defaults. Since the hedge funds believe that the CDOs were going to have lots of defaults, they want to buy the insurance. The trick is to find someone dumb enough to sell the insurance. Thats where the worlds largest insurance company, Awful Insurance Group (AIG), enters the fray. AIG sells insurance on just about anything and they, too, are looking for new ways to make money, so why not sell insurance on CDO defaults?\n",
      "Golden has a new business! They buy the CDO insurance from AIG for an astonishingly low price (about $2 annually for every $1000 of CDO value) and sell it to the hedge funds for a much higher price (about $20 annually for every $1000 of CDO value). If a CDO sustains defaults, then AIG needs to pay the value of the CDO ($1000 in this hypothetical example) to the hedge funds who own the insurance. Until that time, the hedge funds are paying the annual fee for the insurance, 90% of which is pocketed by Golden. This is a great business; Golden pockets 90% of the money and AIG takes all the risk. The only risk that Golden has is if AIG goes down, but AIG is too big to fail. . . . \n",
      "Goldens new credit default swap business is even better than the CDO business. The only trouble now is that there are only so many Joes out there who can take out subprime loans. This means that there is a hard limit on how many billions Golden can make. This challenge led to whopper number four.\n",
      "If the hedge funds want to buy insurance and AIG wants to sell it, who really cares if there is only one insurance policy per loan or CDO? Indeed, why not just sell lots of credit default swaps on the same set of junk CDOs? This way, the profits could be unlimited! And so it went. Synthetic CDOs were created and soon the insurance quickly turned into a very high-stakes (and very stupid, at least for AIG) bet. The odds were weighted heavily in favor of the folks who did their math homework (the hedge funds); the hedge funds had figured out that the failure of the CDOs was a virtual certainty, whereas AIG believed that failure was virtually impossible.\n",
      "Of course, we all know how the story ends. The holders of the CDOs and sub-prime debt and the sellers of insurance got wiped out, losing hundreds of billions of dollars. Since many of these folks were deemed by the Government as too big to fail, they were bailed out using nearly a trillion dollars of taxpayer money. The executives who presided over the disaster were given huge bonuses because, well, thats how it works for executives in the land far, far away. The story also ends well for the hedge funds that bought the insurancethey made many, many billions of dollars.\n",
      "So everyone involved in the disaster ends up very rich. Everyone except Joe, of\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 532  #538\n",
      "\n",
      "532\n",
      "\t\n",
      "Chapter 19\n",
      "\t\n",
      "Deviations\n",
      "course. Joe got kicked out of his home and lost his job in the recession.\n",
      "Too bad for Joe that it isnt just a fairy tale.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 533  #539\n",
      "\n",
      "20\n",
      "\t\n",
      "Random Walks\n",
      "Random Walks are used to model situations in which an object moves in a sequence of steps in randomly chosen directions. Many phenomena can be modeled as a random walk and we will see several examples in this chapter. Among other things, well see why it is rare that you leave the casino with more money than you entered with and well see how the Google search engine uses random walks through the graph of the world-wide web links to determine the relative importance of websites.\n",
      "\n",
      "20.1\n",
      "\t\n",
      "Unbiased Random Walks\n",
      "20.1.1\n",
      "\t\n",
      "A Bugs Life\n",
      "There is a small flea named Stencil. To his right, there is an endless flat plateau. One inch to his left is the Cliff of Doom, which drops to a raging sea filled with flea-eating monsters.\n",
      "1 inch\n",
      "\n",
      "Cliff of Doom\n",
      "\n",
      "Each second, Stencil hops 1 inch to the right or 1 inch to the left with equal probability, independent of the direction of all previous hops. If he ever lands on the very edge of the cliff, then he teeters over and falls into the sea. So, for example, if Stencils first hop is to the left, hes fishbait. On the other hand, if his first few hops are to the right, then he may bounce around happily on the plateau for quite\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 534  #540\n",
      "\n",
      "534\n",
      "\t\n",
      "Chapter 20\n",
      "\t\n",
      "Random Walks\n",
      "\n",
      "oops...\n",
      "some time.\n",
      "Our job is to analyze the life of Stencil. Does he have any chance of avoiding a fatal plunge? If not, how long will he hop around before he takes the plunge?\n",
      "Stencils movement is an example of a random walk. A typical one-dimensional random walk involves some value that randomly wavers up and down over time. The walk is said to be unbiased if the value is equally likely to move up or down. If the walk ends when a certain value is reached, then that value is called a boundary condition or absorbing barrier. For example, the Cliff of Doom is a boundary condition in the example above.\n",
      "Many natural phenomena are nicely modeled by random walks. However, for some reason, they are traditionally discussed in the context of some social vice. For example, the value is often regarded as the position of a drunkard who randomly staggers left, staggers right, or just wobbles in place during each time step. Or the value is the wealth of a gambler who is continually winning and losing bets. So discussing random walks in terms of fleas is actually sort of elevating the discourse.\n",
      "20.1.2\n",
      "\t\n",
      "A Simpler Problem\n",
      "Lets begin with a simpler problem. Suppose that Stencil is on a small island; now, not only is the Cliff of Doom 1 inch to his left, but also there is another boundary condition, the Pit of Disaster, 2 inches to his right! For example, see Figure \n",
      "In the figure, weve worked out a tree diagram for Stencils possible fates. In\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 535  #541\n",
      "\n",
      "\n",
      "Figure 20.1 An unbiased, one-dimensional random walk with absorbing barriers at positions 0 and 3. The walk begins at position 1. The tree diagram shows the probabilities of hitting each barrier.\n",
      "particular, he falls off the Cliff of Doom on the left side with probability:\n",
      "Similarly, he falls into the Pit of Disaster on the right side with probability:\n",
      "1\n",
      "4\n",
      " C \n",
      "16\n",
      "1\n",
      " C \n",
      "64\n",
      "1\n",
      " C::: D \n",
      "1\n",
      "3\n",
      ":\n",
      "\n",
      "There is a remaining possibility: Stencil could hop back and forth in the middle of the island forever. However, weve already identified two disjoint events with probabilities 2=3 and 1=3, so this happy alternative must have probability 0.\n",
      "20.1.3\n",
      "\t\n",
      "A Big Island\n",
      "Putting Stencil on such a tiny island was sort of cruel. Sure, hes probably carrying bubonic plague, but theres no reason to pick on the little fella. So suppose that we instead place him n inches from the left side of an island w inches across: In\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 536  #542\n",
      "\n",
      "536\n",
      "\t\n",
      "Chapter 20\n",
      "\t\n",
      "Random Walks\n",
      "\n",
      "other words, Stencil starts at position n and his random walk ends if he ever reaches positions 0 or w.\n",
      "Now he has three possible fates: he could fall off the Cliff of Doom, fall into the Pit of Disaster, or hop around on the island forever. We could compute the probabilities of these three events with a horrific summation, but fortunately theres a far easier method: we can use a linear recurrence.\n",
      "Let R\n",
      "n\n",
      " be the probability that Stencil falls to the right into the Pit of Disaster, given that he starts at position n. In a couple special cases, the value of R\n",
      "n\n",
      " is easy to determine. If he starts at position w, he falls into the Pit of Disaster immediately, so R\n",
      "w\n",
      " D 1. On the other hand, if he starts at position 0, then he falls from the Cliff of Doom immediately, so R\n",
      "0\n",
      " D 0.\n",
      "Now suppose that our frolicking friend starts somewhere in the middle of the island; that is, 0 < n < w. Then we can break the analysis of his fate into two cases based on the direction of his first hop:\n",
      "If his first hop is to the left, then he lands at position n 1 and eventually falls into the Pit of Disaster with probability R\n",
      "n1\n",
      " .\n",
      "On the other hand, if his first hop is to the right, then he lands at position nC1 and eventually falls into the Pit of Disaster with probability R\n",
      "nC1\n",
      ".\n",
      "Therefore, by the Total Probability Theorem, we have:\n",
      "Solving the Recurrence\n",
      "Lets assemble all our observations about R\n",
      "n\n",
      ", the probability that Stencil falls into the Pit of Disaster if he starts at position n:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 537  #543\n",
      "\n",
      "This is just a linear recurrenceand we know how to solve those!\n",
      "\t\n",
      "Uh, right?\n",
      "Remember Chapter \n",
      "or Chapter \n",
      "?\n",
      "There is one unusual complication: in a normal recurrence, R\n",
      "n\n",
      " is written a func-tion of preceding terms. In this recurrence equation, however, R\n",
      "n\n",
      " is a function of both a preceding term (R\n",
      "n1\n",
      " ) and a following term (R\n",
      "nC1\n",
      "). This is no big deal, however, since we can just rearrange the terms in the recurrence equation:\n",
      "R\n",
      "nC1 \n",
      "D\n",
      " \n",
      "2R\n",
      "n\n",
      "\t\n",
      "R\n",
      "n1\n",
      "  \n",
      ":\n",
      "Now were back on familiar territory.\n",
      "Lets solve the recurrence. The characteristic equation is:\n",
      "x\n",
      "2\n",
      "\t\n",
      "2x C 1 D 0:\n",
      "This equation has a double root at x D 1. There is no inhomogeneous part, so the general solution has the form:\n",
      "R\n",
      "n\n",
      " D a 1\n",
      "n\n",
      " C b n1\n",
      "n\n",
      " D a C bn:\n",
      "Substituting in the boundary conditions R\n",
      "0\n",
      " D 0 and R\n",
      "w\n",
      " D 1 gives two linear equations:\n",
      "0 D a;\n",
      "1 D a C bw:\n",
      "The solution to this system is a D 0, b D 1=w. Therefore, the solution to the recurrence is:\n",
      "R\n",
      "n\n",
      " D n=w:\n",
      "20.1.4\n",
      "\t\n",
      "Death Is Certain\n",
      "Our analysis shows that if we place Stencil n inches from the left side of an island w inches across, then he falls off the right side with probability n=w. For example, if Stencil is n D 4 inches from the left side of an island w D 12 inches across, then he falls off the right side with probability n=w D 4=12 D 1=3.\n",
      "We can compute the probability that he falls off the left side by exploiting the symmetry of the problem: the probability that he falls off the left side starting at position n is the same as the probability that he falls of the right side starting at position w n, which is .w n/=n.\n",
      "This is bad news. The probability that Stencil eventually falls off one side or the other is:\n",
      "w\n",
      "n\n",
      " C \n",
      "w\n",
      " \n",
      "w\n",
      " \n",
      "n\n",
      " D 1:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 538  #544\n",
      "\n",
      "538\n",
      "\t\n",
      "Chapter 20\n",
      "\t\n",
      "Random Walks\n",
      "Theres no hope! The probability that Stencil hops around on the island forever is zero.\n",
      "And theres even worse news. Lets go back to the original problem where Sten-cil is 1 inch from the left edge of an infinite plateau. In this case, the probability that he eventually falls into the sea is:\n",
      "So even if there were no Pit of Disaster, Stencil still falls off the Cliff of Doom with probability 1. And since\n",
      "for any finite n, this is true no matter where Stencil starts. Our little friend is doomed!\n",
      "Hey, you know how in the movies they often make it look like the hero dies, but then he comes back in the end and everything turns out okay? Well, were not sayin anything, just pointing that out.\n",
      "20.1.5\n",
      "\t\n",
      "Life Expectancy\n",
      "On the bright side, Stencil may get to hop around for a while before he goes over an edge. Lets use the same setup as before, where he starts out n inches from the left side of an island w inches across: What is the expected number of hops he takes\n",
      "\n",
      "before falling off an edge?\n",
      "Let X\n",
      "n\n",
      " be Stencils expected lifespan, measured in hops. If he starts at either edge of the island, then he dies immediately:\n",
      "X\n",
      "0\n",
      "D0;\n",
      "X\n",
      "w\n",
      " D 0:\n",
      "If he starts somewhere in the middle of the island (0 < n < w), then we can again break down the analysis into two cases based on his first hop:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 539  #545\n",
      "\n",
      "20.1. Unbiased Random Walks\n",
      "\t\n",
      "539\n",
      "If his first hop is to the left, then he lands at position n\n",
      "\t\n",
      "1 and can expect to\n",
      "live for another X\n",
      "n1\n",
      "\t\n",
      "steps.\n",
      "If his first hop is to the right, then he lands at position n C 1 and can expect to live for another X\n",
      "nC1\n",
      " steps.\n",
      "Thus, by the Law of Total Expectation and Linearity of Expectation, Stencils ex-pected lifespan is:\n",
      "1\n",
      "X\n",
      "n \n",
      "D\n",
      " \n",
      "1\n",
      " \n",
      "C\n",
      " \n",
      "2\n",
      "X\n",
      "n1\n",
      "\n",
      "The leading 1 accounts for his first hop.\n",
      "Solving the Recurrence\n",
      "\n",
      "\n",
      "1\n",
      "C\n",
      " \n",
      "2\n",
      "X\n",
      "nC1\n",
      ":\n",
      "\n",
      "Once again, Stencils fate hinges on a recurrence equation:\n",
      "We can rewrite the last line as:\n",
      "As before, the characteristic equation is:\n",
      "x\n",
      "2\n",
      "\t\n",
      "2x C 1 D 0:\n",
      "There is a double-root at 1, so the homogeneous solution has the form:\n",
      "X\n",
      "n\n",
      " D a C bn:\n",
      "But this time, theres an inhomogeneous term, so we also need to find a particular solution. Since this term is a constant, we should try a particular solution of the form X\n",
      "n\n",
      " D c and then try X\n",
      "n\n",
      " D c C d n and then X\n",
      "n\n",
      " D c C d n C en\n",
      "2\n",
      " and so forth. As it turns out, the first two possibilities dont work, but the third does. Substituting X\n",
      "n\n",
      " D c C d n C en\n",
      "2\n",
      " into Equation \n",
      "gives\n",
      "is a particular solution for all c and d . For simplicity, lets take c D d D 0. Thus, our particular solution is X\n",
      "n\n",
      " D n \n",
      "2\n",
      ".\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 540  #546\n",
      "\n",
      "Yes, Stencil is certain to eventually fall off the Cliff of Doombut his expected lifespan is infinite! This sounds almost like a contradiction, but both answers are correct!\n",
      "Heres an informal explanation. It turns out that the probability p\n",
      "k\n",
      " that Stencil falls from the Cliff of Doom on the kth step is .1=k\n",
      "3=2\n",
      "/. You can verify by the\n",
      "integration bound that \n",
      "P\n",
      "1\n",
      "\t\n",
      "1=k\n",
      "3=2\n",
      " converges.\n",
      "D1\n",
      "On the other hand, the expected time until Stencil falls over the edge is\n",
      "\n",
      "D 1;\n",
      "where c is a constant that comes from the notation. So our answers are compati-ble.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 541  #547\n",
      "\n",
      "20.1.6\n",
      "\t\n",
      "Application to Fair Gambling Games\n",
      "We took the high road for a while, but lets now discuss random walks in a more conventional settinggambling.\n",
      "A gambler goes to Las Vegas with $n in her pocket. Her plan is to make only $1 bets and somehow she has found a casino that will offer her truly even odds\n",
      "; namely, she will win or lose $1 on each bet with probability 1=2. Shell play until she is broke or she has won $m. In the latter case, she will go home with\n",
      "D n C m\n",
      "dollars. Whats the probability that she goes home a winner?\n",
      "This is identical to the flea problem that we just analyzed. Going broke is analo-gous to falling off the Cliff of Doom. Going home a winner is analogous to falling into the Pit of Disaster, just a lot more fun.\n",
      "Our analysis of Stencils life tells us everything we want to know about the gam-blers prospects:\n",
      "The gambler goes home broke with probability \n",
      "w\n",
      "n\n",
      " D \n",
      "n\n",
      " \n",
      "C\n",
      "m\n",
      " \n",
      "m\n",
      ";\n",
      "the gambler goes home a winner with probability \n",
      "w\n",
      " \n",
      "w\n",
      " \n",
      "n\n",
      " D \n",
      "n\n",
      " \n",
      "C\n",
      "n\n",
      " \n",
      "m\n",
      ";\n",
      "the gambler goes home with probability\n",
      "\n",
      "and the number of bets before the gambler goes home is expected to be\n",
      "n.w\tn/ D nm:\n",
      "If the gambler gets greedy and keeps playing until she goes broke, then\n",
      "the gambler eventually goes broke with probability 1, and\n",
      "the number of bets before the gambler goes broke is expected to be infinite.\n",
      "The bottom line here is clear: when gambling, quit while you are aheadif you play until you go broke, you will certainly go broke.\n",
      "And thats the good news! Matters get much worse for the more typical scenario where the odds are against you. Lets see why.\n",
      "\n",
      "Dont worry, well get to the more realistic scenario when she is more likely to lose than win in a moment, but lets just fantasize about the fair scenario for a bit.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 542  #548\n",
      "\n",
      "542\n",
      "\t\n",
      "Chapter 20\n",
      "\t\n",
      "Random Walks\n",
      "\n",
      "20.2\n",
      "\t\n",
      "Gamblers Ruin\n",
      "So far, we have considered unbiased random walks, where the probability of mov-ing up or down (or left or right) is 1=2. Unfortunately, things are never quite this simple (or fair) in real casinos.\n",
      "For example, suppose the gambler goes to Las Vegas and makes $1 bets on red or black in roulette. In this case, she will win $1 with probability\n",
      "18\n",
      "38\n",
      "\t\n",
      "0:473\n",
      "\n",
      "and she will lose $1 with probability\n",
      "20\n",
      "38\n",
      "\t\n",
      "0:527:\n",
      "\n",
      "Thats because the casinos add those bothersome green 0 and 00 to give the house a slight advantage.\n",
      "At first glance (or after a few drinks), 18=38 seems awfully close to 1=2 and so our intuition tells us that the game is almost fair. So we might expect the analysis we just did for the fair game to be almost right for the real game. For example, if the gambler starts with $100 and quits when she gets ahead by $100 in the fair game, then she goes home a winner with probability\n",
      "100\n",
      "200\n",
      " D :5:\n",
      "\n",
      "And, if she wants to improve her chances of going home a winner, she could bring more money. If she brings $1000 and quits when she gets ahead by $100 in the fair game, then she goes home a winner with probability\n",
      "1000\n",
      "1100\n",
      "\t\n",
      ":91:\n",
      "\n",
      "So, given that the real game is almost fair, we might expect the probabilities of going home a winner in these two scenarios to be almost 50% and 91%, respec-tively.\n",
      "Unfortunately for the gambler, all this almost reasoning will almost surely lead to disaster. Here are the grim facts for the real game where the gambler wins $1 with probability 18=38.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 543  #549\n",
      "\n",
      "Except on the very low end, the amount of money she brings makes almost no difference!\n",
      "She is almost certain to go broke before winning $100. Lets see why.\n",
      "20.2.1\n",
      "\t\n",
      "Finding a Recurrence\n",
      "We can approach the gambling problem the same way we studied the life of Stencil. Suppose that the gambler starts with n dollars. She wins each bet with probability p and plays until she either goes bankrupt or has w D n C m dollars in her pocket. (To be clear, w is the total amount of money she wants to end up with, not the amount by which she wants to increase her wealth, which is m.) Our objective is to compute R\n",
      "n\n",
      ", the probability that she goes home a winner.\n",
      "As usual, we begin by identifying some boundary conditions. If she starts with no money, then shes bankrupt immediately so R\n",
      "0\n",
      " D 0. On the other hand, if she starts with w dollars, then shes an instant winner, so R\n",
      "w\n",
      " D 1.\n",
      "Now we divide the analysis of the general situation into two cases based on the outcome of her first bet:\n",
      "She wins her first bet with probability p. She then has n C 1 dollars and probability R\n",
      "nC1\n",
      " of reaching her goal of w dollars.\n",
      "She loses her first bet with probability 1 p. This leaves her with n 1 dollars and probability R\n",
      "n1\n",
      " of reaching her goal.\n",
      "Plugging these facts into the Total Probability Theorem gives the equation:\n",
      "20.2.2\n",
      "\t\n",
      "Solving the Recurrence\n",
      "Rearranging the terms in Equation \n",
      "gives us a recurrence for R\n",
      "n\n",
      ", the probability that the gambler reaches her goal of w dollars if she starts with n:\n",
      "R\n",
      "0\n",
      "D0\n",
      "R\n",
      "w\n",
      " D 1\n",
      "pR\n",
      "nC1\n",
      "\tR\n",
      "n\n",
      " C .1\n",
      "\t\n",
      "p/R\n",
      "n1\n",
      "\t\n",
      "D 0\n",
      "\t\n",
      ".0 < n < w/:\n",
      "The characteristic equation is:\n",
      "px\n",
      "2\n",
      "\tx C .1\tp/ D 0:\n",
      "\n",
      "The fact that only one digit changes from the first case to the second is a peripheral bit of bizarreness that well leave in your hands.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 544  #550\n",
      "\n",
      "544\n",
      "\t\n",
      "Chapter 20\n",
      "\t\n",
      "Random Walks\n",
      "The quadratic formula gives the roots:\n",
      "1\n",
      " \n",
      "p\n",
      " \n",
      "p\n",
      " or 1:\n",
      "\n",
      "Theres an important point lurking here. If the gambler is equally likely to win or lose each bet, then p D 1=2, and the characteristic equation has a double root at\n",
      "D 1. This is the situation we considered in the flea problem. The double root led to a general solution of the form:\n",
      "R\n",
      "n\n",
      " D a C bn\n",
      "Now suppose that the gambler is not equally likely to win or lose each bet; that is,\n",
      " 1=2. Then the two roots of the characteristic equation are different, which means that the solution has a completely different form:\n",
      "R\n",
      "n\n",
      " \n",
      "D\n",
      " \n",
      "a\n",
      "\t\n",
      "1\n",
      "\t\n",
      "p  \n",
      "n\n",
      " \n",
      "C\n",
      " \n",
      "b 1\n",
      "n\n",
      "\n",
      "p\n",
      "In mathematical terms, this is where the fair game and the almost fair game take off in completely different directions: in one case we get a linear solution and in the other we get an exponential solution! This is going to be bad news for anyone playing the almost fair game.\n",
      "Anyway, substituting the boundary conditions into the general form of the solu-tion gives a system of linear equations:\n",
      "0 D a C b\n",
      "1\n",
      " \n",
      "D\n",
      " \n",
      "a\n",
      "\t1\n",
      "\t\n",
      "p  \n",
      "w\n",
      " \n",
      "C\n",
      " \n",
      "b:\n",
      "\n",
      "p\n",
      "Solving this system, gives:\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 545  #551\n",
      "\n",
      "Substituting these values back into the general solution gives:\n",
      "1\n",
      "(Suddenly, Stencils life doesnt seem so bad, huh?)\n",
      "20.2.3\n",
      "\t\n",
      "Bad News!\n",
      "We have an answer! But its not good news. If the gambler starts with n dollars and wins each bet with probability p, then the probability she reaches w dollars before going broke is:\n",
      "Lets try to make sense of this expression. If the game is biased against her, as with roulette, then 1 p (the probability she loses) is greater than p (the probability she wins). If n, her starting wealth, is also reasonably large, then both exponenti-ated fractions are big numbers and the -1s dont make much difference. Thus, her probability of reaching w dollars is very close to:\n",
      "1\tp  \n",
      "nw\n",
      "\t\n",
      "D  \n",
      "1  p  \n",
      "m\n",
      " \n",
      ":\n",
      "\n",
      "p\n",
      "\t\n",
      "p\n",
      "In particular, if she is hoping to come out m D $100 ahead in roulette, then p D 18=38 and her probability of success is:\n",
      "This explains the strange number we arrived at earlier! In fact, this number does not change no matter how large n gets, so even if the gambler starts with a trillion dollars, she is sill not likely to ever get ahead by even $100.\n",
      "20.2.4\n",
      "\t\n",
      "But Why?\n",
      "Why does the gamblers starting wealth have so little impact on her probability of coming out ahead? Intuitively, there are two forces at work. First, the gamblers\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 546  #552\n",
      "\n",
      "546\n",
      "\t\n",
      "Chapter 20\n",
      "\t\n",
      "Random Walks\n",
      "wealth has random upward and downward swings due to runs of good and bad luck. Second, her wealth has a steady, downward drift because she has a small expected loss on every bet. The situation is illustrated in Figure \n",
      ".\n",
      "w\n",
      "\n",
      "upward\n",
      "n \n",
      "\n",
      "         swing\n",
      "(too late)\n",
      "gamblers\n",
      "\t\n",
      "downward\n",
      "wealth\n",
      "\t\n",
      "drift\n",
      "0\n",
      "time\n",
      "Figure 20.2 In a biased random walk, the downward drift usually dominates swings of good luck.\n",
      "For example, in roulette, the gambler wins a dollar with probability 18=38 and loses a dollar with probability 20=38. Therefore, her expected return on each bet is\n",
      "Thus, her expected wealth drifts downward by a little over 5 cents per bet.\n",
      "One might think that if the gambler starts with a billion dollars, then she will play for a long time, so at some point she should have a lucky, upward swing that puts her $100 ahead. The problem is that her capital is steadily drifting downward. And after her capital drifts down a few hundred dollars, she needs a huge upward swing to save herself. And such a huge swing is extremely improbable. So if she does not have a lucky, upward swing early on, shes doomed forever. As a rule of thumb, drift dominates swings over the long term.\n",
      "20.2.5\n",
      "\t\n",
      "Expected Playing Time\n",
      "Even though casino gamblers are destined to lose, some of them enjoy the process.\n",
      "So lets figure out how long their enjoyment is expected to last.\n",
      "Let X\n",
      "n\n",
      " be the expected number of bets before going home (broke or a winner).\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 547  #553\n",
      "\n",
      "Reasoning as in Section \n",
      ", we can set up a recurrence for X\n",
      "n\n",
      ":\n",
      "This is the same as the recurrence for R\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n\n",
      " in Equation \n",
      "except for the inhomo-geneous part.\n",
      "To find the particular solution, we try X\n",
      "n\n",
      " D c (which doesnt work) and then X\n",
      "n\n",
      " D c C d n (which does work as long as p  1=2). Plugging X\n",
      "n\n",
      " D c C d n into\n",
      "We have already determined that the roots for this equation are\n",
      "0\n",
      " \n",
      "D\n",
      " \n",
      "a\n",
      "\t1\tp  \n",
      "w\n",
      " \n",
      "C\n",
      " \n",
      "b\n",
      " \n",
      "C\n",
      "\tw\n",
      "\t\n",
      ":\n",
      "\n",
      "p\n",
      "\t\n",
      "1\n",
      "\t\n",
      "2p\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 548  #554\n",
      "\n",
      "The final solution to the recurrence is then\n",
      "Yikes! The gambler wont have any fun at all if she is thinking about this equa-tion. Lets see if we can make it simpler in the case when m D w n is large.\n",
      "Since p < 1=2, .1\n",
      "\t\n",
      "p/=p > 1 and for large m,\n",
      "which is much simpler. It says that if the gambler starts with $n, she will expect to make about n=.1 2p/ bets before she goes home broke. This seems to make sense since she expects to lose\n",
      "1 .1\tp/ C .1/p\n",
      "\t\n",
      "D 1\n",
      "\t\n",
      "2p\n",
      "dollars on every bet and she started with n dollars.\n",
      "\n",
      "Be careful, it is tempting to use such a direct and simple argument instead of all those nasty recurrences, but such an argument is not correct. There are examples where the expected duration of a process is not close to the starting point divided by the expected decrease at each step.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 549  #555\n",
      "\n",
      "k  k\n",
      "\t\n",
      "1\n",
      "Figure 20.3 n C 1 people sitting in a circle. The B indicates the person with the broccoliin this case, person 0.\n",
      "\n",
      "20.3\n",
      "\t\n",
      "Walking in Circles\n",
      "So far, we have considered random walks on a line. Now well look at a problem where the random walk is on a circle. Going from a line to a circle may not seem like such a big change, but as we have seen so often with probability, small changes can have large consequences that are often beyond the grasp of our intuition.\n",
      "20.3.1\n",
      "\t\n",
      "Pass the Broccoli\n",
      "Suppose there are n C 1 people, numbered 0, 1, . . . , n, sitting in a circle as shown in Figure \n",
      ". The B in Figure \n",
      "indicates that person 0 has a big stalk of nutritious broccoli, which provides 250% of the US recommended daily allowance of vitamin C and is also a good source of vitamin A and iron. (Typical for a random walk problem, this game originally involved a pitcher of beer instead of a broccoli. Were taking the high road again.)\n",
      "Person 0 passes the broccoli either to the person on his left or the person on his right with equal probability. Then, that person also passes the broccoli left or right at random and so on. After a while, everyone in an arc of the circle has touched the broccoli and everyone outside that arc has not. Eventually, the arc grows until all but one person has touched the broccoli. That final person is declared the winner because they have avoided the brocolli for the longest time.\n",
      "Suppose that you are allowed to position yourself anywhere in the circle. Where should you stand in order to maximize the probability that you win? You shouldnt be person 0; you cant win in that position. The answer is intuitively obvious: you should sit as far as possible from person 0, which would be position n=2 or .n C 1/=2 depending on whether n is even or odd.\n",
      "\n",
      "mcs-ftl  2010/9/8  0:40  page 550  #556\n",
      "\n",
      "550\n",
      "\t\n",
      "Chapter 20\n",
      "\t\n",
      "Random Walks\n",
      "20.3.2\n",
      "\t\n",
      "There Is No Escape\n",
      "Lets try to verify this intuition. Suppose that you sit at position k  0. At some point, the broccoli is going to end up in the hands of one of your neighbors. This has to happen eventually; the game cant end until at least one of them touches it. Lets say that person k 1 gets the broccoli first. Now lets cut the circle between yourself and your other neighbor, person k C 1:\n",
      "k\t.k\t1/\t: : :\t3\t2\t1\t0\tn\t.n\t1/\t: : :\t.k C 1/:\n",
      "B\n",
      "There are two possibilities. If the broccoli reaches you before it reaches person k C 1, then you lose. But if the broccoli reaches person k C 1 before it reaches you, then every other person has touched the broccoli and you win. So we need to compute the probability that the broccoli hops n 1 people to the right before it takes 1 hop to the left. This will be the probability that you win.\n",
      "But this is just the flea problem all over again. From the analysis in Section \n",
      ", we know that the probability of moving n 1 steps rightward before moving one step leftward is simply 1=n. This means that wherever you sit (aside from posi-tion 0, of course), your probability of getting the broccoli last is 1=n.\n",
      "So our intuition was completely wrong (again)! It doesnt matter where you sit. Being close to the broccoli or far away at the start makes no difference; there is no escapeyou still get the broccoli last with probability 1=n.\n",
      "Enough with the bad news: Stencils doomed, you go home broke from the casino, and you cant escape the broccoli. Lets see how to use probability to make some money.\n",
      "\n",
      "MIT OpenCourseWare\n",
      "6.042J / 18.062J Mathematics for Computer Science\n",
      "Fall 2010\n",
      "For information about citing these materials or our Terms of Use, visit: \n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for para in michal.paragraphs:\n",
    "        #print(\"next paragraph:\")\n",
    "        #rint(para.text)\n",
    "        for run in para.runs:\n",
    "            print(run.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.data.docx import read_docx,process_docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text,font_sizes = read_docx('../data/raw/docx/bTyxpoi2dmM/MIT6_042JF10_notes.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mathematics for Computer Science',\n",
       " 'revised Wednesday 8',\n",
       " 'th',\n",
       " 'Eric Lehman',\n",
       " 'Google Inc.',\n",
       " 'F Thomson Leighton',\n",
       " 'Department of Mathematics and CSAIL, MIT',\n",
       " 'Akamai Technologies',\n",
       " 'Albert R Meyer',\n",
       " 'Massachusets Institute of Technology',\n",
       " 'Copyright  2010, Eric Lehman, F Tom Leighton,',\n",
       " 'Contents',\n",
       " 'Proofs',\n",
       " 'Propositions',\n",
       " 'Induction',\n",
       " 'Number Theory',\n",
       " 'iv',\n",
       " 'Contents',\n",
       " 'II  Structures',\n",
       " 'Graph Theory',\n",
       " 'Directed Graphs',\n",
       " 'State Machines',\n",
       " 'Counting',\n",
       " 'v',\n",
       " 'Contents',\n",
       " '9.7\\tAsymptotic Notation',\n",
       " '10\\tRecurrences',\n",
       " '11\\tCardinality Rules',\n",
       " '12\\tGenerating Functions',\n",
       " '13\\tInfinite Sets',\n",
       " 'IV Probability',\n",
       " '14\\tEvents and Probability Spaces',\n",
       " 'vi',\n",
       " 'Contents',\n",
       " 'I',\n",
       " 'Proofs',\n",
       " 'Introduction',\n",
       " 'This text explains how to use mathematical models and methods to analyze prob-lems that arise in computer science. The notion of a proof plays a central role in this work.',\n",
       " 'Simply put, a proof is a method of establishing truth. Like beauty, truth some-times depends on the eye of the beholder, and it should not be surprising that what constitutes a proof differs among fields. For example, in the judicial system, legal truth is decided by a jury based on the allowable evidence presented at trial. In the business world, authoritative truth is specified by a trusted person or organization, or maybe just your boss. In fields such as physics and biology, scientific truth',\n",
       " 'is confirmed by experiment. In statistics, probable truth is established by statistical analysis of sample data.',\n",
       " 'Philosophical proof involves careful exposition and persuasion typically based on a series of small, plausible arguments. The best example begins with Cogito ergo sum, a Latin sentence that translates as I think, therefore I am. It comes from the beginning of a 17th century essay by the mathematician/philosopher, Rene Descartes, and it is one of the most famous quotes in the world: do a web search on the phrase and you will be flooded with hits.',\n",
       " 'Deducing your existence from the fact that youre thinking about your existence is a pretty cool and persuasive-sounding idea. However, with just a few more lines of argument in this vein, Descartes',\n",
       " 'to conclude that there is an infinitely beneficent God. Whether or not you believe in a beneficent God, youll probably agree that any very short proof of Gods existence is bound to be far-fetched. So',\n",
       " 'Actually, only scientific falsehood can be demonstrated by an experimentwhen the experiment fails to behave as predicted. But no amount of experiment can confirm that the next experiment wont fail. For this reason, scientists rarely speak of truth, but rather of theories that accurately predict past, and anticipated future, experiments.',\n",
       " '4',\n",
       " 'Part I',\n",
       " 'Proofs',\n",
       " 'even in masterful hands, this approach is not reliable. Mathematics has its own specific notion of proof.',\n",
       " 'Definition. A mathematical proof of a proposition is a chain of logical deductions leading to the proposition from a base set of axioms.',\n",
       " 'The three key ideas in this definition are highlighted: proposition, logical de-duction, and axiom. These three ideas are explained in the following chapters, beginning with propositions in Chapter',\n",
       " 'Creating a good proof is a lot like creating a beautiful work of art. In fact, mathematicians often refer to really good proofs as being elegant or beautiful. As with any endeavor, it will probably take a little practice before your fellow students use such praise when referring to your proofs, but to get you started in the right direction, we will provide templates for the most useful proof techniques in Chapters',\n",
       " 'and',\n",
       " 'to establish some important facts about numbers; facts that form the underpinning of one of the worlds most widely-used cryptosystems.',\n",
       " 'Propositions',\n",
       " 'Definition. A proposition is a statement that is either true or false.',\n",
       " 'For example, both of the following statements are propositions. The first is true and the second is false.',\n",
       " 'Proposition 1.0.1. 2 + 3 = 5.',\n",
       " 'Proposition 1.0.2. 1 + 1 = 3.',\n",
       " 'Being true or false doesnt sound like much of a limitation, but it does exclude statements such as, Wherefore art thou Romeo? and Give me an A!.',\n",
       " 'Unfortunately, it is not always easy to decide if a proposition is true or false, or even what the proposition means. In part, this is because the English language is riddled with ambiguities. For example, consider the following statements:',\n",
       " 'What precisely do these sentences mean? Can you have both cake and ice cream or must you choose just one dessert? If the second sentence is true, then is the Chebyshev bound incomprehensible? If you can solve some problems we come up with but not all, then do you get an A for the course? And can you still get an A even if you cant solve any of the problems? Does the last sentence imply that all Americans have the same dream or might some of them have different dreams?',\n",
       " 'Some uncertainty is tolerable in normal conversation. But when we need to formulate ideas preciselyas in mathematics and programmingthe ambiguities inherent in everyday language can be a real problem. We cant hope to make an exact argument if were not sure exactly what the statements mean. So before we start into mathematics, we need to investigate the problem of how to talk about mathematics.',\n",
       " 'To get around the ambiguity of English, mathematicians have devised a special mini-language for talking about logical relationships. This language mostly uses ordinary English words and phrases such as or, implies, and for all. But',\n",
       " '6',\n",
       " 'Chapter 1',\n",
       " 'Propositions',\n",
       " 'mathematicians endow these words with definitions more precise than those found in an ordinary dictionary. Without knowing these definitions, you might sometimes get the gist of statements in this language, but you would regularly get misled about what they really meant.',\n",
       " 'Surprisingly, in the midst of learning the language of mathematics, well come across the most important open problem in computer sciencea problem whose solution could change the world.',\n",
       " '1.1',\n",
       " 'Compound Propositions',\n",
       " 'In English, we can modify, combine, and relate propositions with words such as not, and, or, implies, and if-then. For example, we can combine three propositions into one like this:',\n",
       " 'If all humans are mortal and all Greeks are human, then all Greeks are mortal.',\n",
       " 'For the next while, we wont be much concerned with the internals of propositions whether they involve mathematics or Greek mortalitybut rather with how propo-sitions are combined and related. So well frequently use variables such as P and Q in place of specific propositions such as All humans are mortal and 2 C 3 D 5. The understanding is that these variables, like propositions, can take on only the values T (true) and F (false). Such true/false variables are sometimes called Boolean variables after their inventor, Georgeyou guessed itBoole.',\n",
       " '1.1.1',\n",
       " 'NOT',\n",
       " 'We can precisely define these special words using truth tables.  For example, if',\n",
       " 'denotes an arbitrary proposition, then the truth of the proposition ',\n",
       " 'NOT',\n",
       " 'P',\n",
       " 'NOT',\n",
       " 'T',\n",
       " 'F',\n",
       " 'F',\n",
       " 'T',\n",
       " 'The first row of the table indicates that when proposition P is true, the proposition ',\n",
       " 'NOT',\n",
       " 'NOT',\n",
       " 'In general, a truth table indicates the true/false value of a proposition for each possible setting of the variables. For example, the truth table for the proposition',\n",
       " 'AND',\n",
       " 'Q P',\n",
       " 'AND',\n",
       " 'Q',\n",
       " 'According to this table, the proposition P',\n",
       " 'AND',\n",
       " 'There is a subtlety in the truth table for P',\n",
       " 'OR',\n",
       " 'Q P',\n",
       " 'OR',\n",
       " 'Q',\n",
       " 'The third row of this table says that P',\n",
       " 'OR',\n",
       " 'If you want to exclude the possibility of both having and eating, you should use exclusive-or (',\n",
       " 'XOR',\n",
       " 'Q P',\n",
       " 'XOR',\n",
       " 'Q',\n",
       " '1.1.2',\n",
       " 'IMPLIES',\n",
       " 'The least intuitive connecting word is implies. Here is its truth table, with the lines labeled so we can refer to them later.',\n",
       " 'Q  P',\n",
       " 'IMPLIES',\n",
       " 'Lets experiment with this definition. For example, is the following proposition true or false?',\n",
       " '8',\n",
       " 'Chapter 1',\n",
       " 'Propositions',\n",
       " '2',\n",
       " '0 for every real number x.',\n",
       " 'The Riemann Hypothesis is a famous unresolved conjecture in mathematics no one knows if it is true or false. But that doesnt prevent you from answering the question! This proposition has the form P',\n",
       " 'IMPLIES',\n",
       " '2',\n",
       " 'One of our original examples demonstrates an even stranger side of implications.',\n",
       " 'Dont take this as an insult; we just need to figure out whether this proposition is true or false. Curiously, the answer has nothing to do with whether or not you can understand the Chebyshev bound. Pigs cannot fly, so were on either line (ft) or line (ff) of the truth table. In both cases, the proposition is true!',\n",
       " 'In contrast, heres an example of a false implication:',\n",
       " 'Yes, the moon shines white. But, no, the moon is not made of white cheddar cheese.',\n",
       " 'So were on line (tf) of the truth table, and the proposition is false.',\n",
       " 'The truth table for implications can be summarized in words as follows:',\n",
       " 'An implication is true exactly when the if-part is false or the then-part is true.',\n",
       " 'This sentence is worth remembering; a large fraction of all mathematical statements are of the if-then form!',\n",
       " '1.1.3\\tIFF',\n",
       " 'Mathematicians commonly join propositions in one additional way that doesnt arise in ordinary speech. The proposition P if and only if Q asserts that P and Q are logically equivalent; that is, either both are true or both are false.',\n",
       " 'For example, the following if-and-only-if statement is true for every real number',\n",
       " 'x',\n",
       " '2',\n",
       " 'iff',\n",
       " 'jxj',\n",
       " '2',\n",
       " 'For some values of x, both inequalities are true. For other values of x, neither inequality is true . In every case, however, the proposition as a whole is true.',\n",
       " '1.1.4',\n",
       " 'Notation',\n",
       " 'Mathematicians have devised symbols to represent words like ',\n",
       " 'AND',\n",
       " 'NOT',\n",
       " 'The most commonly-used symbols are summarized in the table below.',\n",
       " 'For example, using this notation, If P',\n",
       " 'AND NOT',\n",
       " 'This symbolic language is helpful for writing complicated logical expressions com-pactly. But words such as ',\n",
       " 'OR',\n",
       " 'IMPLIES',\n",
       " '1.1.5',\n",
       " 'Logically Equivalent Implications',\n",
       " 'Do these two sentences say the same thing?',\n",
       " 'If I am hungry, then I am grumpy.',\n",
       " 'If I am not grumpy, then I am not hungry.',\n",
       " 'We can settle the issue by recasting both sentences in terms of propositional logic. Let P be the proposition I am hungry, and let Q be I am grumpy. The first sentence says P',\n",
       " 'IMPLIES',\n",
       " 'NOT',\n",
       " 'IMPLIES NOT',\n",
       " 'Sure enough, the columns of truth values under these two statements are the same, which precisely means they are equivalent. In general, ',\n",
       " 'NOT',\n",
       " 'IMPLIES NOT',\n",
       " '10',\n",
       " 'Chapter 1',\n",
       " 'Propositions',\n",
       " 'is called the contrapositive of the implication P',\n",
       " 'IMPLIES',\n",
       " 'In contrast, the converse of P',\n",
       " 'IMPLIES',\n",
       " 'IMPLIES',\n",
       " 'In terms of our example, the converse is:',\n",
       " 'If I am grumpy, then I am hungry.',\n",
       " 'This sounds like a rather different contention, and a truth table confirms this suspi-cion:',\n",
       " 'Thus, an implication is logically equivalent to its contrapositive but is not equiva-lent to its converse.',\n",
       " 'One final relationship: an implication and its converse together are equivalent to an iff statement. For example,',\n",
       " 'If I am grumpy, then I am hungry,',\n",
       " 'AND',\n",
       " 'if I am hungry, then I am grumpy.',\n",
       " 'are equivalent to the single statement:',\n",
       " 'I am grumpy',\n",
       " 'IFF',\n",
       " 'Once again, we can verify this with a truth table:',\n",
       " '1.2',\n",
       " 'Propositional Logic in Computer Programs',\n",
       " 'Propositions and logical connectives arise all the time in computer programs. For example, consider the following snippet, which could be either C, C++, or Java:',\n",
       " 'if ( x > 0 || (x <= 0 && y > 100) )',\n",
       " 'The symbol || denotes ',\n",
       " 'OR',\n",
       " 'AND',\n",
       " 'OR',\n",
       " 'NOT',\n",
       " 'AND',\n",
       " 'OR',\n",
       " 'This means that we can simplify the code snippet without changing the programs behavior:',\n",
       " 'if ( x > 0 || y > 100 )',\n",
       " 'Rewriting a logical expression involving many variables in the simplest form is both difficult and important. Simplifying expressions in software can increase the speed of your program. Chip designers face a similar challengeinstead of minimizing && and || symbols in a program, their job is to minimize the number of analogous physical devices on a chip. The payoff is potentially enormous: a chip with fewer devices is smaller, consumes less power, has a lower defect rate, and is cheaper to manufacture.',\n",
       " '1.3',\n",
       " 'Predicates and Quantifiers',\n",
       " '1.3.1',\n",
       " 'Propositions with Infinitely Many Cases',\n",
       " 'Most of the examples of propositions that we have considered thus far have been straightforward in the sense that it has been relatively easy to determine if they are true or false. At worse, there were only a few cases to check in a truth table. Unfortunately, not all propositions are so easy to check. That is because some propositions may involve a large or infinite number of possible cases. For example, consider the following proposition involving prime numbers. (A prime is an integer greater than 1 that is divisible only by itself and 1. For example, 2, 3, 5, 7, and 11',\n",
       " '12',\n",
       " 'Chapter 1',\n",
       " 'Propositions',\n",
       " 'are primes, but 4, 6, and 9 are not. A number greater than 1 that is not prime is said to be composite.)',\n",
       " 'Proposition 1.3.1. For every nonnegative integer, n, the value of n',\n",
       " '2',\n",
       " 'It is not immediately clear whether this proposition is true or false. In such circumstances, it is tempting to try to determine its veracity by computing the value of',\n",
       " 'for several values of n and then checking to see if they are prime. If any of the computed values is not prime, then we will know that the proposition is false. If all the computed values are indeed prime, then we might be tempted to conclude that the proposition is true.',\n",
       " 'We begin the checking by evaluating p.0/ D 41, which is prime. p.1/ D 43 is also prime. So is p.2/ D 47, p.3/ D 53, . . . , and p.20/ D 461, all of which are prime. Hmmm. . . It is starting to look like p.n/ is a prime for every nonnegative integer n. In fact, continued checking reveals that p.n/ is prime for all n 39. The proposition certainly does seem to be true.',\n",
       " 'But p.40/ D 40',\n",
       " '2',\n",
       " 'Although surprising, this example is not as contrived or rare as you might sus-pect. As we will soon see, there are many examples of propositions that seem to be true when you check a few cases (or even many), but which turn out to be false. The key to remember is that you cant check a claim about an infinite set by checking a finite set of its elements, no matter how large the finite set.',\n",
       " 'Propositions that involve all numbers are so common that there is a special no-tation for them. For example, Proposition',\n",
       " 'can also be written as',\n",
       " 'Here the symbol 8 is read for all. The symbol N stands for the set of nonnegative integers, namely, 0, 1, 2, 3, . . . (ask your instructor for the complete list). The symbol 2 is read as is a member of, or belongs to, or simply as is in. The period after the N is just a separator between phrases.',\n",
       " 'Here is another example of a proposition that, at first, seems to be true but which turns out to be false.',\n",
       " 'The symbol WWD means equal by definition. Its always ok to simply write = instead of WWD, but reminding the reader that an equality holds by definition can be helpful.',\n",
       " 'Proposition 1.3.2. a',\n",
       " '4',\n",
       " '4',\n",
       " '4',\n",
       " '4',\n",
       " 'Euler (pronounced oiler) conjectured this proposition to be true in 1769. It was checked by humans and then by computers for many values of a, b, c, and d over the next two centuries. Ultimately the proposition was proven false in 1987 by Noam Elkies. The solution he found was a D 95800; b D 217519; c D 414560; d D 422481. No wonder it took 218 years to show the proposition is false!',\n",
       " 'In logical notation, Proposition',\n",
       " 'could be written,',\n",
       " '8a 2 Z',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " '4',\n",
       " '4',\n",
       " '4',\n",
       " '4',\n",
       " 'Here, Z',\n",
       " 'C',\n",
       " '8a; b; c; d 2 Z',\n",
       " 'C',\n",
       " '4',\n",
       " '4',\n",
       " '4',\n",
       " '4',\n",
       " 'The following proposition is even nastier.',\n",
       " 'Proposition 1.3.3. 313.x',\n",
       " '3',\n",
       " '3',\n",
       " '3',\n",
       " 'C',\n",
       " 'This proposition is also false, but the smallest counterexample values for x, y, and z have more than 1000 digits! Even the worlds largest computers would not be able to get that far with brute force. Of course, you may be wondering why anyone would care whether or not there is a solution to 313.x',\n",
       " '3',\n",
       " '3',\n",
       " '3',\n",
       " 'Of course, not all propositions that have infinitely many cases to check turn out to be false. The following proposition (known as the Four-Color Theorem) turns out to be true.',\n",
       " 'Proposition 1.3.4. Every map can be colored with 4 colors so that adjacent',\n",
       " 're-gions have different colors.',\n",
       " 'The proof of this proposition is difficult and took over a century to perfect. Along the way, many incorrect proofs were proposed, including one that stood for 10 years',\n",
       " '2',\n",
       " 'Two regions are adjacent only when they share a boundary segment of positive length. They are not considered to be adjacent if their boundaries meet only at a few points.',\n",
       " '14',\n",
       " 'Chapter 1',\n",
       " 'Propositions',\n",
       " 'in the late 19th century before the mistake was found. An extremely laborious proof was finally found in 1976 by mathematicians Appel and Haken, who used a complex computer program to categorize the four-colorable maps; the program left a few thousand maps uncategorized, and these were checked by hand by Haken and his assistantsincluding his 15-year-old daughter. There was a lot of debate about whether this was a legitimate proof: the proof was too big to be checked without a computer, and no one could guarantee that the computer calculated correctly, nor did anyone have the energy to recheck the four-colorings of the thousands of maps that were done by hand. Within the past decade, a mostly intelligible proof of the Four-Color Theorem was found, though a computer is still needed to check the colorability of several hundred special maps.',\n",
       " 'In some cases, we do not know whether or not a proposition is true. For exam-ple, the following simple proposition (known as Goldbachs Conjecture) has been heavily studied since 1742 but we still do not know if it is true. Of course, it has been checked by computer for many values of n, but as we have seen, that is not sufficient to conclude that it is true.',\n",
       " 'Proposition 1.3.5 (Goldbach). Every even integer n greater than 2 is the sum of two primes.',\n",
       " 'While the preceding propositions are important in mathematics, computer scien-tists are often interested in propositions concerning the correctness of programs and systems, to determine whether a program or system does what its supposed to do. Programs are notoriously buggy, and theres a growing community of re-searchers and practitioners trying to find ways to prove program correctness. These efforts have been successful enough in the case of CPU chips that they are now routinely used by leading chip manufacturers to prove chip correctness and avoid mistakes like the notorious Intel division bug in the 1990s.',\n",
       " 'Developing mathematical methods to verify programs and systems remains an active research area. Well consider some of these methods later in the text.',\n",
       " '1.3.2',\n",
       " 'Predicates',\n",
       " 'A predicate is a proposition whose truth depends on the value of one or more vari-ables. Most of the propositions above were defined in terms of predicates. For example,',\n",
       " 'See',\n",
       " 'The story of the Four-Color Proof is told in a well-reviewed popular (non-technical) book: Four Colors Suffice. How the Map Problem was Solved. Robin Wilson. Princeton Univ. Press, 2003, 276pp. ISBN 0-691-11533-8.',\n",
       " 'is a predicate whose truth depends on the value of n. The predicate is true for n D 4 since four is a perfect square, but false for n D 5 since five is not a perfect square.',\n",
       " 'Like other propositions, predicates are often named with a letter. Furthermore, a function-like notation is used to denote a predicate supplied with specific variable values. For example, we might name our earlier predicate P :',\n",
       " 'P .n/ WWD n is a perfect square',\n",
       " 'Now P .4/ is true, and P .5/ is false.',\n",
       " 'This notation for predicates is confusingly similar to ordinary function notation.',\n",
       " 'If P is a predicate, then P .n/ is either true or false, depending on the value of n.',\n",
       " 'On the other hand, if p is an ordinary function, like n',\n",
       " '2',\n",
       " 'quantity. Dont confuse these two!',\n",
       " '1.3.3',\n",
       " 'Quantifiers',\n",
       " 'There are a couple of assertions commonly made about a predicate: that it is some-times true and that it is always true. For example, the predicate',\n",
       " '2',\n",
       " '0',\n",
       " 'is always true when x is a real number. On the other hand, the predicate',\n",
       " 'true in English. The table below gives some general formats on the left and specific examples using those formats on the right. You can expect to see such phrases hundreds of times in mathematical writing!',\n",
       " 'Always True',\n",
       " 'For all n, P .n/ is true.',\n",
       " 'P .n/ is true for every n.',\n",
       " 'For all x 2 R, x',\n",
       " '2',\n",
       " '0.',\n",
       " 'x',\n",
       " '2',\n",
       " '0 for every x 2 R.',\n",
       " 'Sometimes True',\n",
       " 'There exists an n such that P .n/ is true.',\n",
       " 'P .n/ is true for some n.',\n",
       " 'P .n/ is true for at least one n.',\n",
       " 'All these sentences quantify how often the predicate is true. Specifically, an assertion that a predicate is always true, is called a universally quantified statement.',\n",
       " '16',\n",
       " 'Chapter 1',\n",
       " 'Propositions',\n",
       " 'An assertion that a predicate is sometimes true, is called an existentially quantified statement.',\n",
       " 'Sometimes English sentences are unclear about quantification:',\n",
       " 'The phrase you can solve any problem we can come up with could reasonably be interpreted as either a universal or existential statement. It might mean:',\n",
       " 'or maybe',\n",
       " 'In the preceding example, the quantified phrase appears inside a larger if-then statement. This is quite normal; quantified statements are themselves propositions and can be combined with',\n",
       " 'AND',\n",
       " 'OR',\n",
       " 'IMPLIES',\n",
       " '1.3.4',\n",
       " 'More Notation',\n",
       " 'There are symbols to represent universal and existential quantification, just as there are symbols for ',\n",
       " 'AND',\n",
       " 'IMPLIES',\n",
       " 'The universal quantifier symbol 8 is read for all, so this whole expression (',\n",
       " 'To say that a predicate P .x/ is true for at least one value of x in D, we write:',\n",
       " 'The existential quantifier symbol 9, is read there exists. So expression (',\n",
       " 'The symbols 8 and 9 are always followed by a variabletypically with an in-dication of the set the variable ranges overand then a predicate, as in the two examples above.',\n",
       " 'As an example, let Probs be the set of problems we come up with, Solves.x/ be the predicate You can solve problem x, and G be the proposition, You get an A for the course. Then the two different interpretations of',\n",
       " 'can be written as follows:',\n",
       " 'IMPLIES',\n",
       " 'or maybe',\n",
       " 'IMPLIES',\n",
       " '1.3.5\\tMixing Quantifiers',\n",
       " 'Many mathematical statements involve several quantifiers. For example, Gold-bachs Conjecture states:',\n",
       " 'Lets write this more verbosely to make the use of quantification clearer:',\n",
       " 'For every even integer n greater than 2, there exist primes p and q such that n D p C q.',\n",
       " 'Let Evens be the set of even integers greater than 2, and let Primes be the set of primes. Then we can write Goldbachs Conjecture in logic notation as follows:',\n",
       " 'The proposition can also be written more simply as',\n",
       " '8n 2 Evens: 9p; q 2 Primes: p C q D n:',\n",
       " '1.3.6',\n",
       " 'Order of Quantifiers',\n",
       " 'Swapping the order of different kinds of quantifiers (existential or universal) usually changes the meaning of a proposition. For example, lets return to one of our initial, confusing statements:',\n",
       " 'This sentence is ambiguous because the order of quantifiers is unclear. Let A be the set of Americans, let D be the set of dreams, and define the predicate H.a; d / to be American a has dream d . Now the sentence could mean that there is a single dream that every American shares:',\n",
       " '9 d 2 D: 8a 2 A: H.a; d /',\n",
       " '18',\n",
       " 'Chapter 1',\n",
       " 'Propositions',\n",
       " 'For example, it might be that every American shares the dream of owning their own home.',\n",
       " 'Or it could mean that every American has a personal dream:',\n",
       " '8a 2 A: 9 d 2 D: H.a; d /',\n",
       " 'For example, some Americans may dream of a peaceful retirement, while others dream of continuing practicing their profession as long as they live, and still others may dream of being so rich they neednt think at all about work.',\n",
       " 'Swapping quantifiers in Goldbachs Conjecture creates a patently false state-ment; namely that every even number 2 is the sum of the same two primes:',\n",
       " '9 p; q 2 Primes: 8n 2 Evens: n D p C q:',\n",
       " '1.3.7',\n",
       " 'Variables Over One Domain',\n",
       " 'When all the variables in a formula are understood to take values from the same nonempty set, D, its conventional to omit mention of D. For example, instead of 8x 2 D 9y 2 D: Q.x; y/ wed write 8x9y: Q.x; y/. The unnamed nonempty set that x and y range over is called the domain of discourse, or just plain domain, of the formula.',\n",
       " 'Its easy to arrange for all the variables to range over one domain. For exam-ple, Goldbachs Conjecture could be expressed with all variables ranging over the domain N as',\n",
       " '8n: .n 2 Evens/',\n",
       " 'IMPLIES',\n",
       " 'AND',\n",
       " 'AND',\n",
       " '1.3.8',\n",
       " 'Negating Quantifiers',\n",
       " 'There is a simple relationship between the two kinds of quantifiers. The following two sentences mean the same thing:',\n",
       " 'It is not the case that everyone likes to snowboard.',\n",
       " 'There exists someone who does not like to snowboard.',\n",
       " 'In terms of logic notation, this follows from a general property of predicate formu-las:',\n",
       " 'NOT',\n",
       " 'is equivalent to',\n",
       " '9x:',\n",
       " 'NOT',\n",
       " 'Similarly, these sentences mean the same thing:',\n",
       " 'There does not exist anyone who likes skiing over magma.',\n",
       " 'Everyone dislikes skiing over magma.',\n",
       " 'We can express the equivalence in logic notation this way:',\n",
       " 'The general principle is that moving a not across a quantifier changes the kind of quantifier.',\n",
       " '1.4\\tValidity',\n",
       " 'A propositional formula is called valid when it evaluates to T no matter what truth values are assigned to the individual propositional variables. For example, the propositional version of the Distributive Law is that',\n",
       " 'P',\n",
       " 'AND',\n",
       " 'OR',\n",
       " 'R/',\n",
       " 'AND',\n",
       " 'Q/',\n",
       " 'OR',\n",
       " 'AND',\n",
       " 'R/',\n",
       " 'is valid. This can be verified by checking the truth table for',\n",
       " 'P',\n",
       " 'AND',\n",
       " 'OR',\n",
       " 'R/',\n",
       " 'AND',\n",
       " 'OR',\n",
       " 'AND',\n",
       " 'The same idea extends to predicate formulas, but to be valid, a formula now must evaluate to true no matter what values its variables may take over any unspecified domain, and no matter what interpretation a predicate variable may be given. For example, we already observed that the rule for negating a quantifier is captured by the valid assertion (',\n",
       " 'Another useful example of a valid assertion is',\n",
       " 'Heres an explanation why this is valid:',\n",
       " '20',\n",
       " 'Chapter 1',\n",
       " 'Propositions',\n",
       " 'Let D be the domain for the variables and P',\n",
       " '0',\n",
       " 'on D. We need to show that if',\n",
       " 'holds under this interpretation, then so does',\n",
       " 'So suppose (',\n",
       " '0',\n",
       " '8y 2 D: P',\n",
       " '0',\n",
       " '0',\n",
       " 'By definition of 8, this means that',\n",
       " 'P',\n",
       " '0',\n",
       " '0',\n",
       " 'is true for all d 2 D. So given any d 2 D, there is an element in D, namely, d',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " 'We hope this is helpful as an explanation, although purists would not really want to call it a proof. The problem is that with something as basic as (',\n",
       " 'In contrast to (',\n",
       " 'is not valid. We can prove this by describing an interpretation where the hypoth-esis, 8y9x: P .x; y/, is true but the conclusion, 9x8y: P .x; y/, is not true. For example, let the domain be the integers and P .x; y/ mean x > y. Then the hypoth-esis would be true because, given a value, n, for y we could, for example, choose the value of x to be n C 1. But under this interpretation the conclusion asserts that there is an integer that is bigger than all integers, which is certainly false. An interpretation like this which falsifies an assertion is called a counter model to the assertion.',\n",
       " 'That is, a predicate that depends on two variables.',\n",
       " '1.5\\tSatisfiability',\n",
       " 'A proposition is satisfiable if some setting of the variables makes the proposition true. For example, P',\n",
       " 'AND',\n",
       " 'AND',\n",
       " 'OR',\n",
       " 'OR',\n",
       " 'AND',\n",
       " 'OR',\n",
       " 'AND',\n",
       " 'OR',\n",
       " 'AND',\n",
       " 'OR',\n",
       " 'The general problem of deciding whether a proposition is satisfiable is called SAT. One approach to SAT is to construct a truth table and check whether or not a T ever appears. But this approach is not very efficient; a proposition with n variables has a truth table with 2',\n",
       " 'n',\n",
       " 'Is there a more efficient solution to SAT? In particular, is there some, presum-ably very ingenious, procedure that determines in a number of steps that grows polynomiallylike n',\n",
       " '2',\n",
       " '14',\n",
       " 'Recently there has been exciting progress on sat-solvers for practical applica-tions like digital circuit verification. These programs find satisfying assignments with amazing efficiency even for formulas with millions of variables. Unfortu-nately, its hard to predict which kind of formulas are amenable to sat-solver meth-ods, and for formulas that are NOT satisfiable, sat-solvers generally take exponen-tial time to verify that.',\n",
       " 'So no one has a good idea how to solve SAT in polynomial time, or how to prove that it cant be doneresearchers are completely stuck. The problem of determining whether or not SAT has a polynomial time solution is known as the P vs. NP problem. It is the outstanding unanswered question in theoretical computer science. It is also one of the seven',\n",
       " 'Patterns of Proof',\n",
       " '2.1',\n",
       " 'The Axiomatic Method',\n",
       " 'The standard procedure for establishing truth in mathematics was invented by Eu-clid, a mathematician working in Alexandria, Egypt around 300 BC. His idea was to begin with five assumptions about geometry, which seemed undeniable based on direct experience. For example, one of the assumptions was There is a straight line segment between every pair of points. Propositions like these that are simply accepted as true are called axioms.',\n",
       " 'Starting from these axioms, Euclid established the truth of many additional propo-sitions by providing proofs. A proof is a sequence of logical deductions from axioms and previously-proved statements that concludes with the proposition in question. You probably wrote many proofs in high school geometry class, and youll see a lot more in this course.',\n",
       " 'There are several common terms for a proposition that has been proved. The different terms hint at the role of the proposition within a larger body of work.',\n",
       " 'Important propositions are called theorems.',\n",
       " 'A lemma is a preliminary proposition useful for proving later propositions. A corollary is a proposition that follows in just a few logical steps from a',\n",
       " 'lemma or a theorem.',\n",
       " 'The definitions are not precise. In fact, sometimes a good lemma turns out to be far more important than the theorem it was originally used to prove.',\n",
       " 'Euclids axiom-and-proof approach, now called the axiomatic method, is the foundation for mathematics today. In fact, just a handful of axioms, collectively called Zermelo-Frankel Set Theory with Choice (ZFC), together with a few logical deduction rules, appear to be sufficient to derive essentially all of mathematics.',\n",
       " '2.1.1\\tOur Axioms',\n",
       " 'The ZFC axioms are important in studying and justifying the foundations of math-ematics, but for practical purposes, they are much too primitive. Proving theorems in ZFC is a little like writing programs in byte code instead of a full-fledged pro-gramming languageby one reckoning, a formal proof in ZFC that 2 C 2 D 4 requires more than 20,000 steps! So instead of starting with ZFC, were going to',\n",
       " '24',\n",
       " 'Chapter 2',\n",
       " 'Patterns of Proof',\n",
       " 'take a huge set of axioms as our foundation: well accept all familiar facts from high school math!',\n",
       " 'This will give us a quick launch, but you may find this imprecise specification of the axioms troubling at times. For example, in the midst of a proof, you may find yourself wondering, Must I prove this little fact or can I take it as an axiom? Feel free to ask for guidance, but really there is no absolute answer. Just be up front about what youre assuming, and dont try to evade homework and exam problems by declaring everything an axiom!',\n",
       " '2.1.2',\n",
       " 'Logical Deductions',\n",
       " 'Logical deductions or inference rules are used to prove new propositions using previously proved ones.',\n",
       " 'A fundamental inference rule is modus ponens. This rule says that a proof of P together with a proof that P',\n",
       " 'IMPLIES',\n",
       " 'Inference rules are sometimes written in a funny notation. For example, modus ponens is written:',\n",
       " 'Rule 2.1.1.',\n",
       " 'P;\\tP',\n",
       " 'IMPLIES',\n",
       " 'Q',\n",
       " 'When the statements above the line, called the antecedents, are proved, then we can consider the statement below the line, called the conclusion or consequent, to also be proved.',\n",
       " 'A key requirement of an inference rule is that it must be sound: any assignment of truth values that makes all the antecedents true must also make the consequent true. So if we start off with true axioms and apply sound inference rules, everything we prove will also be true.',\n",
       " 'You can see why modus ponens is a sound inference rule by checking the truth table of P',\n",
       " 'IMPLIES',\n",
       " 'IMPLIES',\n",
       " 'QP!Q',\n",
       " 'There are many other natural, sound inference rules, for example:',\n",
       " 'Rule 2.1.2.',\n",
       " 'P',\n",
       " 'IMPLIES',\n",
       " 'IMPLIES',\n",
       " 'IMPLIES',\n",
       " 'R',\n",
       " 'Rule 2.1.3.',\n",
       " 'P',\n",
       " 'IMPLIES',\n",
       " 'NOT',\n",
       " 'NOT',\n",
       " 'Rule 2.1.4.',\n",
       " 'NOT',\n",
       " 'Q',\n",
       " 'IMPLIES',\n",
       " 'On the other hand,',\n",
       " 'Non-Rule.',\n",
       " 'NOT',\n",
       " 'IMPLIES',\n",
       " 'Q',\n",
       " 'is not sound: if P is assigned T and Q is assigned F, then the antecedent is true and the consequent is not.',\n",
       " 'Note that a propositional inference rule is sound precisely when the conjunction (AND) of all its antecedents implies its consequent.',\n",
       " 'As with axioms, we will not be too formal about the set of legal inference rules. Each step in a proof should be clear and logical; in particular, you should state what previously proved facts are used to derive each new conclusion.',\n",
       " '2.1.3',\n",
       " 'Proof Templates',\n",
       " 'In principle, a proof can be any sequence of logical deductions from axioms and previously proved statements that concludes with the proposition in question. This freedom in constructing a proof can seem overwhelming at first. How do you even start a proof?',\n",
       " 'Heres the good news: many proofs follow one of a handful of standard tem-plates. Each proof has it own details, of course, but these templates at least provide you with an outline to fill in. In the remainder of this chapter, well go through several of these standard patterns, pointing out the basic idea and common pitfalls and giving some examples. Many of these templates fit together; one may give you a top-level outline while others help you at the next level of detail. And well show you other, more sophisticated proof techniques in Chapter',\n",
       " 'The recipes that follow are very specific at times, telling you exactly which words to write down on your piece of paper. Youre certainly free to say things your own way instead; were just giving you something you could say so that youre never at a complete loss.',\n",
       " '26',\n",
       " 'Chapter 2',\n",
       " 'Patterns of Proof',\n",
       " '2.2',\n",
       " 'Proof by Cases',\n",
       " 'Breaking a complicated proof into cases and proving each case separately is a use-ful and common proof strategy. In fact, we have already implicitly used this strategy when we used truth tables to show that certain propositions were true or valid. For example, in section',\n",
       " 'IMPLIES',\n",
       " 'NOT',\n",
       " 'IMPLIES NOT',\n",
       " 'IMPLIES',\n",
       " 'Q',\n",
       " 'is true if and only if',\n",
       " 'is true. For exam-ple, if P D T and Q D F, then both P',\n",
       " 'IMPLIES',\n",
       " 'NOT',\n",
       " 'IMPLIES NOT',\n",
       " 'IMPLIES',\n",
       " 'IFF',\n",
       " 'NOT',\n",
       " 'IMPLIES NOT',\n",
       " 'Proof by cases works in much more general environments than propositions in-volving Boolean variables. In what follows, we will use this approach to prove a simple fact about acquaintances. As background, we will assume that for any pair of people, either they have met or not. If every pair of people in a group has met, well call the group a club. If every pair of people in a group has not met, well call it a group of strangers.',\n",
       " 'Theorem. Every collection of 6 people includes a club of 3 people or a group of 3 strangers.',\n",
       " 'Proof. The proof is by case analysis',\n",
       " 'Among the other 5 people besides x, at least 3 have met x.',\n",
       " 'Among the other 5 people, at least 3 have not met x.',\n",
       " 'Now we have to be sure that at least one of these two cases must hold,',\n",
       " 'but thats easy: weve split the 5 people into two groups, those who have shaken hands with x and those who have not, so one of the groups must have at least half the people.',\n",
       " 'Case 1: Suppose that at least 3 people have met x.',\n",
       " 'This case splits into two subcases:',\n",
       " 'Describing your approach at the outset helps orient the reader. Try to remember to always do',\n",
       " 'this.',\n",
       " '2',\n",
       " 'Part of a case analysis argument is showing that youve covered all the cases. Often this is obvious, because the two cases are of the form P  and not P . However, the situation above is not stated quite so simply.',\n",
       " 'Case 1.1: Among the people who have met x, none have met each other. Then the people who have met x are a group of at least 3 strangers. So the Theorem holds in this subcase.',\n",
       " 'Case 1.2: Among the people who have met x, some pair have met each other. Then that pair, together with x, form a club of 3 people. So the Theorem holds in this subcase.',\n",
       " 'This implies that the Theorem holds in Case 1.',\n",
       " 'Case 2: Suppose that at least 3 people have not met x.',\n",
       " 'This case also splits into two subcases:',\n",
       " 'Case 2.1: Among the people who have not met x, every pair has met each other. Then the people who have not met x are a club of at least 3 people. So the Theorem holds in this subcase.',\n",
       " 'Case 2.2: Among the people who have not met x, some pair have not met each other. Then that pair, together with x, form a group of at least 3 strangers. So the Theorem holds in this subcase.',\n",
       " 'This implies that the Theorem also holds in Case 2, and therefore holds in all cases.',\n",
       " '2.3',\n",
       " 'Proving an Implication',\n",
       " 'Propositions of the form If P , then Q are called implications. This implication is often rephrased as P',\n",
       " 'IMPLIES',\n",
       " 'Here are some examples of implications:',\n",
       " '2',\n",
       " 'If 0',\n",
       " 'x',\n",
       " '2, then x',\n",
       " '3',\n",
       " 'There are a couple of standard methods for proving an implication.',\n",
       " '28',\n",
       " 'Chapter 2',\n",
       " 'Patterns of Proof',\n",
       " '2.3.1',\n",
       " 'Method #1: Assume P is true',\n",
       " 'When proving P',\n",
       " 'IMPLIES',\n",
       " 'IMPLIES',\n",
       " 'IMPLIES',\n",
       " 'Write, Assume P .',\n",
       " 'Show that Q logically follows.',\n",
       " 'For example, we will use this method to prove',\n",
       " 'Theorem 2.3.1. If 0',\n",
       " 'x',\n",
       " '2, then x',\n",
       " '3',\n",
       " 'Before we write a proof of this theorem, we have to do some scratchwork to figure out why it is true.',\n",
       " 'The inequality certainly holds for x D 0; then the left side is equal to 1 and',\n",
       " '1 > 0. As x grows, the 4x term (which is positive) initially seems to have greater',\n",
       " 'So far, so good. But we still have to replace all those seems like phrases with solid, logical arguments. We can get a better handle on the critical x',\n",
       " '3',\n",
       " 'x',\n",
       " '3',\n",
       " 'Aha! For x between 0 and 2, all of the terms on the right side are nonnegative. And a product of nonnegative terms is also nonnegative. Lets organize this blizzard of observations into a clean proof.',\n",
       " 'Proof. Assume 0 x 2. Then x, 2 x, and 2Cx are all nonnegative. Therefore, the product of these terms is also nonnegative. Adding 1 to this product gives a positive number, so:',\n",
       " 'x.2\\tx/.2 C x/ C 1 > 0',\n",
       " 'Multiplying out on the left side proves that',\n",
       " '3',\n",
       " 'as claimed.',\n",
       " 'There are a couple points here that apply to all proofs:',\n",
       " 'Youll often need to do some scratchwork while youre trying to figure out the logical steps of a proof. Your scratchwork can be as disorganized as you likefull of dead-ends, strange diagrams, obscene words, whatever. But keep your scratchwork separate from your final proof, which should be clear and concise.',\n",
       " 'Proofs typically begin with the word Proof and end with some sort of doohickey like or or q.e.d. The only purpose for these conventions is to clarify where proofs begin and end.',\n",
       " 'Potential Pitfall',\n",
       " 'For the purpose of proving an implication P',\n",
       " 'IMPLIES',\n",
       " 'holds! For example, Theorem',\n",
       " 'has the form if P , then Q with P being',\n",
       " '3',\n",
       " '2.3.2',\n",
       " 'Method #2: Prove the Contrapositive',\n",
       " 'We have already seen that an implication P',\n",
       " 'IMPLIES',\n",
       " 'NOT',\n",
       " 'Proving one is as good as proving the other, and proving the contrapositive is some-times easier than proving the original statement. Hence, you can proceed as fol-lows:',\n",
       " 'Write, We prove the contrapositive: and then state the contrapositive.',\n",
       " 'Proceed as in Method #1.',\n",
       " 'For example, we can use this approach to prove',\n",
       " 'p',\n",
       " 'Theorem 2.3.2. If r is irrational, then',\n",
       " 'r is also irrational.',\n",
       " 'Recall that rational numbers are equal to a ratio of integers and irrational num-p',\n",
       " 'bers are not. So we must show that if r is not a ratio of integers, then r is also not a ratio of integers. Thats pretty convoluted! We can eliminate both nots and make the proof straightforward by considering the contrapositive instead.',\n",
       " '2.4\\tProving an If and Only If',\n",
       " 'Many mathematical theorems assert that two statements are logically equivalent; that is, one holds if and only if the other does. Here is an example that has been known for several thousand years:',\n",
       " 'Two triangles have the same side lengths if and only if two side lengths and the angle between those sides are the same in each triangle.',\n",
       " 'The phrase if and only if comes up so often that it is often abbreviated iff.',\n",
       " '2.4.1',\n",
       " 'Method #1: Prove Each Statement Implies the Other',\n",
       " 'The statement P',\n",
       " 'IFF',\n",
       " 'IMPLIES',\n",
       " 'IMPLIES',\n",
       " 'Write, We prove P implies Q and vice-versa.',\n",
       " 'Write, First, we show P implies Q. Do this by one of the methods in Section',\n",
       " 'Write, Now, we show Q implies P . Again, do this by one of the methods in Section',\n",
       " '2.4.2',\n",
       " 'Method #2: Construct a Chain of',\n",
       " 'IFF',\n",
       " 's',\n",
       " 'In order to prove that P is true iff Q is true:',\n",
       " 'Write, We construct a chain of if-and-only-if implications.',\n",
       " 'Prove P is equivalent to a second statement which is equivalent to a third statement and so forth until you reach Q.',\n",
       " 'This method sometimes requires more ingenuity than the first, but the result can be a short, elegant proof, as we see in the following example.',\n",
       " 'Theorem 2.4.1. The standard deviation of a sequence of values x',\n",
       " '1',\n",
       " 'n',\n",
       " 'Definition. The standard deviation of a sequence of values x',\n",
       " '1',\n",
       " '2',\n",
       " 'n',\n",
       " 's',\n",
       " 'As an example, Theorem',\n",
       " 'says that the standard deviation of test scores is zero if and only if everyone scored exactly the class average. (We will talk a lot more about means and standard deviations in Part IV of the book.)',\n",
       " 'Proof. We construct a chain of iff implications, starting with the statement that the standard deviation (',\n",
       " 's',\n",
       " 'Since zero is the only number whose square root is zero, equation (',\n",
       " 'Squares of real numbers are always nonnegative, and so every term on the left hand side of equation (',\n",
       " 'Every term on the left hand side of (',\n",
       " 'But a term .x',\n",
       " 'i',\n",
       " '2',\n",
       " 'i',\n",
       " 'Every x',\n",
       " 'i',\n",
       " '32',\n",
       " 'Chapter 2',\n",
       " 'Patterns of Proof',\n",
       " '2.5',\n",
       " 'Proof by Contradiction',\n",
       " 'In a proof by contradiction or indirect proof, you show that if a proposition were false, then some false fact would be true. Since a false fact cant be true, the propo-sition had better not be false. That is, the proposition really must be true.',\n",
       " 'Proof by contradiction is always a viable approach. However, as the name sug-gests, indirect proofs can be a little convoluted. So direct proofs are generally preferable as a matter of clarity.',\n",
       " 'Method: In order to prove a proposition P by contradiction:',\n",
       " 'Write, We use proof by contradiction.',\n",
       " 'Write, Suppose P is false.',\n",
       " 'Deduce something known to be false (a logical contradiction).',\n",
       " 'Write, This is a contradiction. Therefore, P must be true.',\n",
       " 'p',\n",
       " 'As an example, we will use proof by contradiction to prove that 2 is irrational. Recall that a number is rational if it is equal to a ratio of integers. For example, 3:5 D 7=2 and 0:1111 D 1=9 are rational numbers.',\n",
       " 'integers. Furthermore, lets take n and d so that n=d is in lowest terms (that is, so that there is no number greater than 1 that divides both n and d ).',\n",
       " 'Squaring both sides gives 2 D n',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " 'So the numerator and denominator have 2 as a common factor, which contradicts',\n",
       " 'p',\n",
       " 'the fact that n=d is in lowest terms. So',\n",
       " '2 must be irrational.',\n",
       " 'Potential Pitfall',\n",
       " 'A proof of a proposition P by contradiction is really the same as proving the impli-cation T',\n",
       " 'IMPLIES',\n",
       " 'IMPLIES',\n",
       " 'NOT',\n",
       " 'IMPLIES',\n",
       " 'NOT',\n",
       " 'No matter how you think about it, it is important to remember that when you start by assuming',\n",
       " 'NOT',\n",
       " '2.6',\n",
       " 'Proofs about Sets',\n",
       " 'Sets are simple, flexible, and everywhere. You will find some set mentioned in nearly every section of this text. In fact, we have already talked about a lot of sets: the set of integers, the set of real numbers, and the set of positive even numbers, to name a few.',\n",
       " 'In this section, well see how to prove basic facts about sets. Well start with some definitions just to make sure that you know the terminology and that you are comfortable working with sets.',\n",
       " '2.6.1',\n",
       " 'Definitions',\n",
       " 'Informally, a set is a bunch of objects, which are called the elements of the set. The elements of a set can be just about anything: numbers, points in space, or even other sets. The conventional way to write down a set is to list the elements inside curly-braces. For example, here are some sets:',\n",
       " 'D fAlex; Tippy; Shells; Shadowg dead pets',\n",
       " 'B',\n",
       " 'D fred; blue; yellowg',\n",
       " 'primary colors',\n",
       " 'C',\n",
       " 'D ffa; bg; fa; cg; fb; cgg',\n",
       " 'a set of sets',\n",
       " 'This works fine for small finite sets. Other sets might be defined by indicating how to generate a list of them:',\n",
       " 'D D f1; 2; 4; 8; 16; : : : g',\n",
       " 'the powers of 2',\n",
       " 'The order of elements is not significant, so fx; y g and fy; xg are the same set written two different ways. Also, any object is, or is not, an element of a given',\n",
       " '34',\n",
       " 'Chapter 2',\n",
       " 'Patterns of Proof',\n",
       " 'setthere is no notion of an element appearing more than once in a set.',\n",
       " 'So writ-ing fx; xg is just indicating the same thing twice, namely, that x is in the set. In particular, fx; xg D fxg.',\n",
       " 'The expression e 2 S asserts that e is an element of set S. For example, 32 2 D and blue 2 B, but Tailspin 62Ayet.',\n",
       " 'Some Popular Sets',\n",
       " 'Mathematicians have devised special symbols to represent some common sets.',\n",
       " 'A superscript ',\n",
       " 'C',\n",
       " 'C',\n",
       " 'Comparing and Combining Sets',\n",
       " 'The expression S T indicates that set S is a subset of set T , which means that every element of S is also an element of T (it could be that S D T ). For example, N Z and Q R (every rational number is a real number), but C 6 Z (not every complex number is an integer).',\n",
       " 'As a memory trick, notice that the points to the smaller set, just like a sign points to the smaller number. Actually, this connection goes a little further: there is a symbol analogous to <. Thus, S T means that S is a subset of T , but the two are not equal. So A A, but A 6 A, for every set A.',\n",
       " 'There are several ways to combine sets. Lets define a couple of sets for use in examples:',\n",
       " 'X WWD f1; 2; 3g',\n",
       " 'Y WWD f2; 3; 4g',\n",
       " 'The union of sets X and Y (denoted X [ Y ) contains all elements appearing',\n",
       " 'in X or Y or both. Thus, X [ Y D f1; 2; 3; 4g.',\n",
       " 'Its not hard to develop a notion of multisets in which elements can occur more than once, but multisets are not ordinary sets.',\n",
       " 'The intersection of X and Y (denoted X \\\\ Y ) consists of all elements that appear in both X and Y . So X \\\\ Y D f2; 3g.',\n",
       " 'The set difference of X and Y (denoted X Y ) consists of all elements that are in X, but not in Y . Therefore, X Y D f1g and Y X D f4g.',\n",
       " 'The Complement of a Set',\n",
       " 'Sometimes we are focused on a particular domain, D. Then for any subset, A, of D, we define A to be the set of all elements of D not in A. That is, A WWD D A. The set A is called the complement of A.',\n",
       " 'For example, when the domain were working with is the real numbers, the com-plement of the positive real numbers is the set of negative real numbers together with zero. That is,',\n",
       " 'R',\n",
       " 'C',\n",
       " 'It can be helpful to rephrase properties of sets using complements. For example, two sets, A and B, are said to be disjoint iff they have no elements in common, that is, A \\\\ B D ;. This is the same as saying that A is a subset of the complement of B, that is, A B.',\n",
       " 'Cardinality',\n",
       " 'The cardinality of a set A is the number of elements in A and is denoted by jAj. For example,',\n",
       " 'j;j D 0;',\n",
       " 'jf1; 2; 4gj D 3, and',\n",
       " 'jNj is infinite.',\n",
       " 'The Power Set',\n",
       " 'The set of all the subsets of a set, A, is called the power set, P.A/, of A.  So',\n",
       " '2 P.A/ iff B A. For example, the elements of P.f1; 2g/ are ;; f1g; f2g and f1; 2g.',\n",
       " 'More generally, if A has n elements, then there are 2',\n",
       " 'n',\n",
       " 'jAj',\n",
       " 'A',\n",
       " 'Sequences',\n",
       " 'Sets provide one way to group a collection of objects. Another way is in a se-quence, which is a list of objects called terms or components. Short sequences',\n",
       " '36',\n",
       " 'Chapter 2',\n",
       " 'Patterns of Proof',\n",
       " 'are commonly described by listing the elements between parentheses; for example, .a; b; c/ is a sequence with three terms.',\n",
       " 'While both sets and sequences perform a gathering role, there are several differ-ences.',\n",
       " 'The elements of a set are required to be distinct, but terms in a sequence can be the same. Thus, .a; b; a/ is a valid sequence of length three, but fa; b; ag is a set with two elementsnot three.',\n",
       " 'The terms in a sequence have a specified order, but the elements of a set do not. For example, .a; b; c/ and .a; c; b/ are different sequences, but fa; b; cg and fa; c; bg are the same set.',\n",
       " 'Texts differ on notation for the empty sequence; we use for the empty sequence and ; for the empty set.',\n",
       " 'Cross Products',\n",
       " 'The product operation is one link between sets and sequences. A product of sets, S',\n",
       " '1',\n",
       " '2',\n",
       " 'n',\n",
       " '1',\n",
       " '2',\n",
       " 'fa; bg D f.0; a/; .0; b/; .1; a/; .1; b/; .2; a/; .2; b/; : : : g',\n",
       " 'A product of n copies of a set S is denoted S',\n",
       " 'n',\n",
       " '3',\n",
       " 'f0; 1g',\n",
       " '3',\n",
       " '2.6.2',\n",
       " 'Set Builder Notation',\n",
       " 'An important use of predicates is in set builder notation. Well often want to talk about sets that cannot be described very well by listing the elements explicitly or by taking unions, intersections, etc., of easily-described sets. Set builder notation often comes to the rescue. The idea is to define a set using a predicate; in particular, the set consists of all values that make the predicate true. Here are some examples of set builder notation:',\n",
       " 'A WWD fn 2 N j n is a prime and n D 4k C 1 for some integer kg B WWD fx 2 R j x',\n",
       " '3',\n",
       " 'WWD fa C bi 2 C j a',\n",
       " '2',\n",
       " '2',\n",
       " 'The set A consists of all nonnegative integers n for which the predicate',\n",
       " 'n',\n",
       " 'n',\n",
       " '4k',\n",
       " '1',\n",
       " 'k',\n",
       " 'A',\n",
       " '5; 13; 17; 29; 37; 41; 53; 57; 61; 73; : : : :',\n",
       " 'Trying to indicate the set',\n",
       " 'A',\n",
       " 'B',\n",
       " 'x',\n",
       " 'x',\n",
       " '3',\n",
       " 'C',\n",
       " 'is true. In this case, an explicit description of the set',\n",
       " 'B',\n",
       " 'C',\n",
       " 'a',\n",
       " 'C',\n",
       " 'such that:',\n",
       " 'a',\n",
       " '2',\n",
       " 'C',\n",
       " '2',\n",
       " '1',\n",
       " 'This is an oval-shaped region around the origin in the complex plane.',\n",
       " '2.6.3',\n",
       " 'Proving Set Equalities',\n",
       " 'Two sets are defined to be equal if they contain the same elements. That is,',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'z',\n",
       " 'X',\n",
       " 'z',\n",
       " 'Y',\n",
       " 'z',\n",
       " 'Theorem 2.6.1 (Distributive Law for Sets). Let',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'Proof. The equality (',\n",
       " 'for all',\n",
       " 'z',\n",
       " 'AND',\n",
       " 'OR',\n",
       " 'that we proved in Section',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'are',\n",
       " 'propositions, then',\n",
       " '38',\n",
       " 'Chapter 2',\n",
       " 'Patterns of Proof',\n",
       " 'Many other set equalities can be derived from other valid propositions and proved in an analogous manner. In particular, propositions such as P , Q and R are re-placed with sets such as A, B, and C ,',\n",
       " 'AND',\n",
       " 'OR',\n",
       " 'is replaced with complement (for example,',\n",
       " 'would become A), and',\n",
       " 'IFF',\n",
       " '2.6.4',\n",
       " 'Russells Paradox and the Logic of Sets',\n",
       " 'Reasoning naively about sets can sometimes be tricky. In fact, one of the earliest at-tempts to come up with precise axioms for sets by a late nineteenth century logician named Gotlob Frege was shot down by a three line argument known as Russells Paradox:',\n",
       " 'This was an astonishing blow to efforts to provide an axiomatic founda-tion for mathematics.',\n",
       " 'Russells Paradox',\n",
       " 'Let S be a variable ranging over all sets, and define',\n",
       " 'WWD fS j S 62Sg:',\n",
       " 'So by definition, for any set S,',\n",
       " 'S 2 W iff S 62S:',\n",
       " 'In particular, we can let S be W , and obtain the contradictory result that',\n",
       " 'W 2 W iff W 62W:',\n",
       " 'A way out of the paradox was clear to Russell and others at the time: its unjus-tified to assume that W is a set. So the step in the proof where we let S be W has no justification, because S ranges over sets, and W may not be a set. In fact, the paradox implies that W had better not be a set!',\n",
       " 'But denying that W is a set means we must reject the very natural axiom that every mathematically well-defined collection of elements is actually a set. So the problem faced by Frege, Russell and their colleagues was how to specify which',\n",
       " 'Bertrand Russell was a mathematician/logician at Cambridge University at the turn of the Twen-tieth Century. He reported that when he felt too old to do mathematics, he began to study and write about philosophy, and when he was no longer smart enough to do philosophy, he began writing about politics. He was jailed as a conscientious objector during World War I. For his extensive philosophical and political writing, he won a Nobel Prize for Literature.',\n",
       " 'well-defined collections are sets. Russell and his fellow Cambridge University col-league Whitehead immediately went to work on this problem. They spent a dozen years developing a huge new axiom system in an even huger monograph called Principia Mathematica.',\n",
       " 'Over time, more efficient axiom systems were developed and today, it is gen-erally agreed that, using some simple logical deduction rules, essentially all of mathematics can be derived from the Axioms of Zermelo-Frankel Set Theory with Choice (ZFC). We are not going to be working with these axioms in this course, but just in case you are interested, we have included them as a sidebar below.',\n",
       " 'The ZFC axioms avoid Russells Paradox because they imply that no set is ever a member of itself. Unfortunately, this does not necessarily mean that there are not other paradoxes lurking around out there, just waiting to be uncovered by future mathematicians.',\n",
       " 'ZFC Axioms',\n",
       " 'Extensionality. Two sets are equal if they have the same members. In formal log-ical notation, this would be stated as:',\n",
       " '8',\n",
       " 'z: .z',\n",
       " '2',\n",
       " 'IFF',\n",
       " '2',\n",
       " 'IMPLIES',\n",
       " 'D',\n",
       " 'Pairing. For any two sets',\n",
       " 'x',\n",
       " 'y',\n",
       " 'x; y',\n",
       " 'g, with',\n",
       " 'x',\n",
       " 'y',\n",
       " '8',\n",
       " 'x; y:',\n",
       " 'u:',\n",
       " 'z: z',\n",
       " 'u',\n",
       " 'IFF',\n",
       " 'x',\n",
       " 'OR',\n",
       " 'z',\n",
       " 'y/',\n",
       " 'Union. The union,',\n",
       " 'u',\n",
       " 'z',\n",
       " '8',\n",
       " 'z:',\n",
       " 'u',\n",
       " '8',\n",
       " 'x: .',\n",
       " '9',\n",
       " 'y: x',\n",
       " 'y',\n",
       " 'AND',\n",
       " 'y',\n",
       " 'z/',\n",
       " 'IFF',\n",
       " 'x',\n",
       " 'u:',\n",
       " 'Infinity. There is an infinite set. Specifically, there is a nonempty set,',\n",
       " 'x',\n",
       " 'y',\n",
       " 'x',\n",
       " 'y',\n",
       " 'g is also a member of',\n",
       " 'x',\n",
       " 'Subset. Given any set,',\n",
       " 'x',\n",
       " 'P .y/',\n",
       " 'y',\n",
       " 'x',\n",
       " 'P .y/',\n",
       " 'Power Set. All the subsets of a set form another set:',\n",
       " '8',\n",
       " 'x:',\n",
       " 'p:',\n",
       " 'u: u',\n",
       " 'x',\n",
       " 'IFF',\n",
       " '2',\n",
       " 'Replacement. Suppose a formula,',\n",
       " '8',\n",
       " 'x; y; z:  .x; y/',\n",
       " 'AND',\n",
       " 'IMPLIES',\n",
       " 'y',\n",
       " 'z:',\n",
       " '40',\n",
       " 'Chapter 2',\n",
       " 'Patterns of Proof',\n",
       " 'Then the image of any set,',\n",
       " 's',\n",
       " 't',\n",
       " '8',\n",
       " 's',\n",
       " 't',\n",
       " 'y:',\n",
       " 'x:  .x; y/',\n",
       " 'IFF',\n",
       " 'y',\n",
       " 't :',\n",
       " 'Foundation. There cannot be an infinite sequence',\n",
       " '2',\n",
       " 'x',\n",
       " 'n',\n",
       " 'x',\n",
       " '1',\n",
       " 'x',\n",
       " '0',\n",
       " 'of sets each of which is a member of the previous one. This is equivalent to saying every nonempty set has a member-minimal element. Namely, define',\n",
       " 'member-minimal',\n",
       " 'm',\n",
       " 'x',\n",
       " 'AND',\n",
       " 'y',\n",
       " 'x: y',\n",
       " 'm :',\n",
       " 'Then the Foundation axiom is',\n",
       " '8',\n",
       " 'x: x',\n",
       " 'IMPLIES',\n",
       " 'm:',\n",
       " 'Choice. Given a set,',\n",
       " 's',\n",
       " 'c',\n",
       " 's',\n",
       " '2.7',\n",
       " 'Good Proofs in Practice',\n",
       " 'One purpose of a proof is to establish the truth of an assertion with absolute cer-tainty. Mechanically checkable proofs of enormous length or complexity can ac-complish this. But humanly intelligible proofs are the only ones that help someone understand the subject. Mathematicians generally agree that important mathemati-cal results cant be fully understood until their proofs are understood. That is why proofs are an important part of the curriculum.',\n",
       " 'To be understandable and helpful, more is required of a proof than just logical correctness: a good proof must also be clear. Correctness and clarity usually go together; a well-written proof is more likely to be a correct proof, since mistakes are harder to hide.',\n",
       " 'In practice, the notion of proof is a moving target. Proofs in a professional research journal are generally unintelligible to all but a few experts who know all the terminology and prior results used in the proof. Conversely, proofs in the first weeks of an introductory course like Mathematics for Computer Science would be regarded as tediously long-winded by a professional mathematician. In fact, what we accept as a good proof later in the term will be different than what we consider to be a good proof in the first couple of weeks of this course. But even so, we can offer some general tips on writing good proofs:',\n",
       " 'State your game plan. A good proof begins by explaining the general line of rea-soning. For example, We use case analysis or We argue by contradiction.',\n",
       " 'Keep a linear flow. Sometimes proofs are written like mathematical mosaics, with juicy tidbits of independent reasoning sprinkled throughout. This is not good. The steps of an argument should follow one another in an intelligible order.',\n",
       " 'A proof is an essay, not a calculation. Many students initially write proofs the way they compute integrals. The result is a long sequence of expressions without explanation, making it very hard to follow. This is bad. A good proof usually looks like an essay with some equations thrown in. Use complete sentences.',\n",
       " 'Avoid excessive symbolism. Your reader is probably good at understanding words, but much less skilled at reading arcane mathematical symbols. So use words where you reasonably can.',\n",
       " 'Revise and simplify. Your readers will be grateful.',\n",
       " 'Introduce notation thoughtfully. Sometimes an argument can be greatly simpli-fied by introducing a variable, devising a special notation, or defining a new term. But do this sparingly since youre requiring the reader to remember all that new stuff. And remember to actually define the meanings of new variables, terms, or notations; dont just start using them!',\n",
       " 'Structure long proofs. Long programs are usually broken into a hierarchy of smaller procedures. Long proofs are much the same. Facts needed in your proof that are easily stated, but not readily proved are best pulled out and proved in pre-liminary lemmas. Also, if you are repeating essentially the same argument over and over, try to capture that argument in a general lemma, which you can cite repeatedly instead.',\n",
       " 'Be wary of the obvious. When familiar or truly obvious facts are needed in a proof, its OK to label them as such and to not prove them. But remember',\n",
       " '42',\n",
       " 'Chapter 2',\n",
       " 'Patterns of Proof',\n",
       " 'that whats obvious to you, may not beand typically is notobvious to your reader.',\n",
       " 'Most especially, dont use phrases like clearly or obviously in an attempt to bully the reader into accepting something youre having trouble proving. Also, go on the alert whenever you see one of these phrases in someone elses proof.',\n",
       " 'Finish. At some point in a proof, youll have established all the essential facts you need. Resist the temptation to quit and leave the reader to draw the obvious conclusion. Instead, tie everything together yourself and explain why the original claim follows.',\n",
       " 'The analogy between good proofs and good programs extends beyond structure. The same rigorous thinking needed for proofs is essential in the design of criti-cal computer systems. When algorithms and protocols only mostly work due to reliance on hand-waving arguments, the results can range from problematic to catastrophic. An early example was the Therac 25, a machine that provided radia-tion therapy to cancer victims, but occasionally killed them with massive overdoses due to a software race condition. A more recent (August 2004) example involved a single faulty command to a computer system used by United and American Airlines that grounded the entire fleet of both companiesand all their passengers!',\n",
       " 'It is a certainty that well all one day be at the mercy of critical computer systems designed by you and your classmates. So we really hope that youll develop the ability to formulate rock-solid logical arguments that a system actually does what you think it does!',\n",
       " 'Induction',\n",
       " 'Now that you understand the basics of how to prove that a proposition is true, it is time to equip you with the most powerful methods we have for establishing truth: the Well Ordering Principle, the Induction Rule, and Strong Induction. These methods are especially useful when you need to prove that a predicate is true for all natural numbers.',\n",
       " 'Although the three methods look and feel different, it turns out that they are equivalent in the sense that a proof using any one of the methods can be automat-ically reformatted so that it becomes a proof using any of the other methods. The choice of which method to use is up to you and typically depends on whichever seems to be the easiest or most natural for the problem at hand.',\n",
       " '3.1',\n",
       " 'The Well Ordering Principle',\n",
       " 'Every nonempty set of nonnegative integers has a smallest element.',\n",
       " 'This statement is known as The Well Ordering Principle. Do you believe it? Seems sort of obvious, right? But notice how tight it is: it requires a nonempty setits false for the empty set which has no smallest element because it has no elements at all! And it requires a set of nonnegative integersits false for the set of negative integers and also false for some sets of nonnegative rationalsfor example, the set of positive rationals. So, the Well Ordering Principle captures something special about the nonnegative integers.',\n",
       " '3.1.1',\n",
       " 'Well Ordering Proofs',\n",
       " 'While the Well Ordering Principle may seem obvious, its hard to see offhand why it is useful. But in fact, it provides one of the most important proof rules in discrete mathematics.',\n",
       " 'In fact, looking back, we took the Well Ordering Principle for granted in proving p',\n",
       " 'that 2 is irrational. That proof assumed that for any positive integers m and n, the fraction m=n can be written in lowest terms, that is, in the form m',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " 'so any way of expressing the left hand fraction in lowest terms would also work for m',\n",
       " '0',\n",
       " '0',\n",
       " 'm',\n",
       " '0',\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_text = [tx.strip() for tx in full_text]\n",
    "full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#big_txt#.index('Pattern of proof')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''find titles'''\n",
    "\n",
    "p_subsection_numbering = re.compile(r'((\\d+\\.)+\\d*\\t[A-Za-z0-9? ]+)')\n",
    "p_subsection_numbering_2 = re.compile(r'((\\d+\\.)+\\d*)')\n",
    "\n",
    "main_titles = []\n",
    "total_titles = []\n",
    "sub_titles = []\n",
    "main_titles_index = []\n",
    "sub_titles_index = []\n",
    "\n",
    "for i,txt in enumerate(full_text):\n",
    "    \n",
    "    '''If it is a main chapter title'''\n",
    "    if re.match('[a-zA-Z]{4,}',txt) is not None and font_sizes[i] == 228600:\n",
    "        total_titles.append(txt)\n",
    "        main_titles.append(txt)\n",
    "        main_titles_index.append(i)\n",
    "    else:\n",
    "        str_print = None\n",
    "        if p_subsection_numbering.match(full_text[i]) is not None:\n",
    "            str_print = txt\n",
    "        elif p_subsection_numbering_2.match(full_text[i]) is not None:\n",
    "            str_print = (\"%s %s\" %(txt,full_text[i+1]))\n",
    "        if str_print is not None and (font_sizes[i] == 152400  or font_sizes[i] == 184150):\n",
    "            #print(\"%s %d \" %(str_print,font_sizes[i]))\n",
    "            total_titles.append(str_print)\n",
    "            sub_titles.append(str_print)\n",
    "            sub_titles_index.append(i)\n",
    "            \n",
    "total_titles = total_titles[1:-1]\n",
    "main_titles = main_titles[1:]\n",
    "main_titles_index = main_titles_index[1:]\n",
    "sub_titles = sub_titles[:-1]\n",
    "sub_titles_index = sub_titles_index[:-1]\n",
    "total_titles_index = main_titles_index + sub_titles_index\n",
    "total_titles_index = sorted(total_titles_index)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_titles_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_corpus  = []\n",
    "for i in range(len(total_titles_index)):\n",
    "    next_pointer = len(full_text) -1\n",
    "    if i < len(total_titles_index) -1 :\n",
    "         next_pointer = total_titles_index[i+1]\n",
    "    sec_as_text = reduce(lambda acc,x: acc+\" \" +x,\n",
    "                         full_text[total_titles_index[i]:next_pointer],\"\")\n",
    "    if sec_as_text is not None:\n",
    "        sec_as_text = sec_as_text + '.'\n",
    "        total_corpus.append(sec_as_text)\n",
    "        \n",
    "#total_corpus +=reducefull_text[total_titles_index[-1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440\n",
      "440\n",
      "20.3.2 There Is No Escape\n",
      "20.3.2 There Is No Escape\n"
     ]
    }
   ],
   "source": [
    "print(len(total_corpus))\n",
    "print(len(total_titles))\n",
    "print(total_titles[-1])\n",
    "print(sub_titles[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 20.3.2 There Is No Escape Lets try to verify this intuition. Suppose that you sit at position k  0. At some point, the broccoli is going to end up in the hands of one of your neighbors. This has to happen eventually; the game cant end until at least one of them touches it. Lets say that person k 1 gets the broccoli first. Now lets cut the circle between yourself and your other neighbor, person k C 1: k\\t.k\\t1/\\t: : :\\t3\\t2\\t1\\t0\\tn\\t.n\\t1/\\t: : :\\t.k C 1/: B There are two possibilities. If the broccoli reaches you before it reaches person k C 1, then you lose. But if the broccoli reaches person k C 1 before it reaches you, then every other person has touched the broccoli and you win. So we need to compute the probability that the broccoli hops n 1 people to the right before it takes 1 hop to the left. This will be the probability that you win. But this is just the flea problem all over again. From the analysis in Section  So our intuition was completely wrong (again)! It doesnt matter where you sit. Being close to the broccoli or far away at the start makes no difference; there is no escapeyou still get the broccoli last with probability 1=n. Enough with the bad news: Stencils doomed, you go home broke from the casino, and you cant escape the broccoli. Lets see how to use probability to make some money. MIT OpenCourseWare 6.042J / 18.062J Mathematics for Computer Science Fall 2010.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_corpus[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[total_corpus[i] for i in range(len(total_corpus)) if type(total_corpus[i]) == type([])]\n",
    "len(total_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['proposition', 'definition'],\n",
       "  ['proposition', 'statement', 'true_false'],\n",
       "  ['example', 'follow', 'statement', 'proposition'],\n",
       "  ['first', 'true', 'second', 'false'],\n",
       "  ['proposition'],\n",
       "  ['proposition'],\n",
       "  ['true_false',\n",
       "   'sound',\n",
       "   'much',\n",
       "   'limitation',\n",
       "   'exclude',\n",
       "   'statement',\n",
       "   'art',\n",
       "   'thou',\n",
       "   'romeo',\n",
       "   'give'],\n",
       "  ['unfortunately',\n",
       "   'always',\n",
       "   'easy',\n",
       "   'decide',\n",
       "   'proposition_true',\n",
       "   'false',\n",
       "   'even',\n",
       "   'proposition',\n",
       "   'mean'],\n",
       "  ['part', 'english', 'language', 'riddled', 'ambiguity'],\n",
       "  ['example_consider',\n",
       "   'follow',\n",
       "   'statement',\n",
       "   'precisely',\n",
       "   'sentence',\n",
       "   'mean',\n",
       "   'cake',\n",
       "   'ice',\n",
       "   'cream',\n",
       "   'must',\n",
       "   'choose',\n",
       "   'dessert',\n",
       "   'second',\n",
       "   'sentence',\n",
       "   'true',\n",
       "   'chebyshev',\n",
       "   'bind',\n",
       "   'solve_problem',\n",
       "   'come',\n",
       "   'course',\n",
       "   'still',\n",
       "   'even',\n",
       "   'solve_problem',\n",
       "   'last',\n",
       "   'sentence',\n",
       "   'imply',\n",
       "   'americans',\n",
       "   'dream',\n",
       "   'may',\n",
       "   'different',\n",
       "   'dream',\n",
       "   'uncertainty',\n",
       "   'tolerable',\n",
       "   'normal',\n",
       "   'conversation'],\n",
       "  ['need',\n",
       "   'formulate',\n",
       "   'idea',\n",
       "   'precisely',\n",
       "   'mathematic',\n",
       "   'programming',\n",
       "   'ambiguity',\n",
       "   'inherent',\n",
       "   'everyday',\n",
       "   'language',\n",
       "   'real',\n",
       "   'problem'],\n",
       "  ['hope',\n",
       "   'make',\n",
       "   'exact',\n",
       "   'argument',\n",
       "   'sure',\n",
       "   'exactly',\n",
       "   'statement',\n",
       "   'mean'],\n",
       "  ['start',\n",
       "   'mathematic',\n",
       "   'need',\n",
       "   'investigate',\n",
       "   'problem',\n",
       "   'talk',\n",
       "   'mathematic'],\n",
       "  ['ambiguity',\n",
       "   'english',\n",
       "   'mathematician',\n",
       "   'devise',\n",
       "   'special',\n",
       "   'mini',\n",
       "   'language',\n",
       "   'talk',\n",
       "   'logical',\n",
       "   'relationship'],\n",
       "  ['language',\n",
       "   'mostly',\n",
       "   'use',\n",
       "   'ordinary',\n",
       "   'english',\n",
       "   'word',\n",
       "   'phrase',\n",
       "   'imply'],\n",
       "  ['chapter',\n",
       "   'propositions',\n",
       "   'mathematicians',\n",
       "   'endow',\n",
       "   'word',\n",
       "   'definition',\n",
       "   'precise',\n",
       "   'find',\n",
       "   'ordinary',\n",
       "   'dictionary'],\n",
       "  ['know',\n",
       "   'definition',\n",
       "   'may',\n",
       "   'sometimes',\n",
       "   'gist',\n",
       "   'statement',\n",
       "   'language',\n",
       "   'would',\n",
       "   'regularly',\n",
       "   'mislead',\n",
       "   'really',\n",
       "   'mean'],\n",
       "  ['surprisingly',\n",
       "   'midst',\n",
       "   'learning',\n",
       "   'language',\n",
       "   'mathematic',\n",
       "   'come',\n",
       "   'important',\n",
       "   'open',\n",
       "   'problem',\n",
       "   'computer_science',\n",
       "   'problem',\n",
       "   'solution',\n",
       "   'could',\n",
       "   'change',\n",
       "   'world']],\n",
       " [['compound',\n",
       "   'proposition',\n",
       "   'english',\n",
       "   'modify',\n",
       "   'combine',\n",
       "   'relate',\n",
       "   'proposition',\n",
       "   'word',\n",
       "   'imply'],\n",
       "  ['example',\n",
       "   'combine',\n",
       "   'proposition',\n",
       "   'human',\n",
       "   'mortal',\n",
       "   'greeks',\n",
       "   'human',\n",
       "   'greeks',\n",
       "   'mortal'],\n",
       "  ['much',\n",
       "   'concerned',\n",
       "   'internal',\n",
       "   'proposition',\n",
       "   'involve',\n",
       "   'mathematic',\n",
       "   'greek',\n",
       "   'mortality',\n",
       "   'rather',\n",
       "   'propo',\n",
       "   'sition',\n",
       "   'combine',\n",
       "   'relate'],\n",
       "  ['frequently',\n",
       "   'use',\n",
       "   'variable',\n",
       "   'place',\n",
       "   'specific',\n",
       "   'proposition',\n",
       "   'human',\n",
       "   'mortal'],\n",
       "  ['understanding', 'variable', 'proposition', 'take', 'value', 'true_false'],\n",
       "  ['true_false',\n",
       "   'variable',\n",
       "   'sometimes',\n",
       "   'call',\n",
       "   'boolean',\n",
       "   'variable',\n",
       "   'inventor',\n",
       "   'george',\n",
       "   'guess',\n",
       "   'boole']],\n",
       " [['precisely', 'define', 'special', 'word', 'use', 'truth_table'],\n",
       "  ['example',\n",
       "   'denote',\n",
       "   'arbitrary',\n",
       "   'proposition',\n",
       "   'truth',\n",
       "   'proposition',\n",
       "   'first',\n",
       "   'row',\n",
       "   'table',\n",
       "   'indicate',\n",
       "   'proposition_true',\n",
       "   'proposition',\n",
       "   'general',\n",
       "   'truth_table',\n",
       "   'indicate',\n",
       "   'true_false',\n",
       "   'value',\n",
       "   'proposition',\n",
       "   'possible',\n",
       "   'set',\n",
       "   'variable'],\n",
       "  ['example',\n",
       "   'truth_table',\n",
       "   'proposition',\n",
       "   'accord',\n",
       "   'table',\n",
       "   'proposition',\n",
       "   'subtlety',\n",
       "   'truth_table',\n",
       "   'third',\n",
       "   'row',\n",
       "   'table',\n",
       "   'say',\n",
       "   'want',\n",
       "   'exclude',\n",
       "   'possibility',\n",
       "   'eat',\n",
       "   'use',\n",
       "   'exclusive',\n",
       "   'xor',\n",
       "   'xor']],\n",
       " [['imply', 'least', 'intuitive', 'connect', 'word', 'imply'],\n",
       "  ['truth_table', 'line', 'label', 'refer', 'later'],\n",
       "  ['imply', 'let', 'experiment', 'definition'],\n",
       "  ['example',\n",
       "   'follow',\n",
       "   'proposition_true',\n",
       "   'false',\n",
       "   'chapter',\n",
       "   'proposition',\n",
       "   'real_number'],\n",
       "  ['riemann',\n",
       "   'hypothesis',\n",
       "   'famous',\n",
       "   'unresolved',\n",
       "   'conjecture',\n",
       "   'mathematic',\n",
       "   'one',\n",
       "   'know',\n",
       "   'true_false'],\n",
       "  ['prevent',\n",
       "   'answering',\n",
       "   'question',\n",
       "   'proposition',\n",
       "   'form',\n",
       "   'imply',\n",
       "   'original',\n",
       "   'example',\n",
       "   'demonstrate',\n",
       "   'even',\n",
       "   'strange',\n",
       "   'side',\n",
       "   'implication'],\n",
       "  ['take', 'insult', 'need', 'figure', 'proposition_true', 'false'],\n",
       "  ['curiously', 'answer', 'understand', 'chebyshev', 'bind'],\n",
       "  ['pig', 'can', 'fly', 'line', 'ft', 'line', 'ff', 'truth_table'],\n",
       "  ['case',\n",
       "   'proposition_true',\n",
       "   'contrast',\n",
       "   'example',\n",
       "   'false',\n",
       "   'implication',\n",
       "   'moon',\n",
       "   'shine',\n",
       "   'white'],\n",
       "  ['moon', 'make', 'white', 'cheddar', 'cheese'],\n",
       "  ['line', 'tf', 'truth_table', 'proposition', 'false'],\n",
       "  ['truth_table',\n",
       "   'implication',\n",
       "   'summarize',\n",
       "   'word',\n",
       "   'follow',\n",
       "   'implication',\n",
       "   'true',\n",
       "   'exactly',\n",
       "   'part',\n",
       "   'false',\n",
       "   'part',\n",
       "   'true'],\n",
       "  ['sentence',\n",
       "   'worth',\n",
       "   'remember',\n",
       "   'large',\n",
       "   'fraction',\n",
       "   'mathematical',\n",
       "   'statement',\n",
       "   'form']],\n",
       " [['iff',\n",
       "   'mathematicians',\n",
       "   'commonly',\n",
       "   'join',\n",
       "   'proposition',\n",
       "   'additional',\n",
       "   'way',\n",
       "   'arise',\n",
       "   'ordinary',\n",
       "   'speech'],\n",
       "  ['proposition', 'assert', 'logically', 'equivalent', 'true_false'],\n",
       "  ['example',\n",
       "   'follow',\n",
       "   'statement',\n",
       "   'true',\n",
       "   'real_number',\n",
       "   'iff',\n",
       "   'jxj',\n",
       "   'value',\n",
       "   'inequalitie',\n",
       "   'true'],\n",
       "  ['value', 'inequality', 'true'],\n",
       "  ['case', 'however', 'proposition', 'whole', 'true']],\n",
       " [['notation',\n",
       "   'mathematician',\n",
       "   'devise',\n",
       "   'symbol',\n",
       "   'represent',\n",
       "   'word',\n",
       "   'commonly_use',\n",
       "   'symbol',\n",
       "   'summarize',\n",
       "   'table'],\n",
       "  ['example',\n",
       "   'use',\n",
       "   'notation',\n",
       "   'symbolic',\n",
       "   'language',\n",
       "   'helpful',\n",
       "   'writing',\n",
       "   'complicate',\n",
       "   'logical',\n",
       "   'expression',\n",
       "   'com',\n",
       "   'pactly'],\n",
       "  ['word', 'imply']],\n",
       " [['logically',\n",
       "   'equivalent',\n",
       "   'implication',\n",
       "   'sentence',\n",
       "   'say',\n",
       "   'thing',\n",
       "   'hungry',\n",
       "   'grumpy'],\n",
       "  ['grumpy', 'hungry'],\n",
       "  ['settle', 'issue', 'recast', 'sentence', 'term', 'propositional', 'logic'],\n",
       "  ['let', 'proposition', 'hungry', 'let', 'grumpy'],\n",
       "  ['first',\n",
       "   'sentence',\n",
       "   'say',\n",
       "   'imply_imply',\n",
       "   'sure_enough',\n",
       "   'column',\n",
       "   'truth',\n",
       "   'value',\n",
       "   'statement',\n",
       "   'precisely',\n",
       "   'mean',\n",
       "   'equivalent'],\n",
       "  ['general',\n",
       "   'imply',\n",
       "   'chapter',\n",
       "   'proposition',\n",
       "   'call',\n",
       "   'contrapositive',\n",
       "   'implication',\n",
       "   'imply',\n",
       "   'contrast',\n",
       "   'converse',\n",
       "   'imply_imply',\n",
       "   'term',\n",
       "   'example',\n",
       "   'converse',\n",
       "   'grumpy',\n",
       "   'hungry'],\n",
       "  ['sound',\n",
       "   'rather',\n",
       "   'different',\n",
       "   'contention',\n",
       "   'truth_table',\n",
       "   'confirm',\n",
       "   'suspi',\n",
       "   'cion',\n",
       "   'thus',\n",
       "   'implication',\n",
       "   'logically',\n",
       "   'equivalent',\n",
       "   'contrapositive',\n",
       "   'equiva',\n",
       "   'lent',\n",
       "   'converse'],\n",
       "  ['final',\n",
       "   'relationship',\n",
       "   'implication',\n",
       "   'converse',\n",
       "   'together',\n",
       "   'equivalent',\n",
       "   'iff',\n",
       "   'statement'],\n",
       "  ['example', 'grumpy', 'hungry', 'hungry', 'grumpy'],\n",
       "  ['equivalent',\n",
       "   'single',\n",
       "   'statement',\n",
       "   'grumpy',\n",
       "   'iff',\n",
       "   'verify',\n",
       "   'truth_table']],\n",
       " [['propositional',\n",
       "   'logic',\n",
       "   'computer',\n",
       "   'program',\n",
       "   'proposition',\n",
       "   'logical',\n",
       "   'connective',\n",
       "   'arise',\n",
       "   'time',\n",
       "   'computer',\n",
       "   'program'],\n",
       "  ['example_consider',\n",
       "   'follow',\n",
       "   'snippet',\n",
       "   'could',\n",
       "   'java',\n",
       "   'symbol',\n",
       "   'denote',\n",
       "   'mean',\n",
       "   'simplify',\n",
       "   'code',\n",
       "   'snippet',\n",
       "   'change',\n",
       "   'program',\n",
       "   'behavior',\n",
       "   'rewrite',\n",
       "   'logical',\n",
       "   'expression',\n",
       "   'involve',\n",
       "   'many',\n",
       "   'variable',\n",
       "   'simple',\n",
       "   'form',\n",
       "   'difficult',\n",
       "   'important'],\n",
       "  ['simplify', 'expression', 'software', 'increase', 'speed', 'program'],\n",
       "  ['chip',\n",
       "   'designer',\n",
       "   'face',\n",
       "   'similar',\n",
       "   'challenge',\n",
       "   'instead',\n",
       "   'minimize',\n",
       "   'symbol',\n",
       "   'program',\n",
       "   'job',\n",
       "   'minimize',\n",
       "   'number',\n",
       "   'analogous',\n",
       "   'physical',\n",
       "   'device',\n",
       "   'chip'],\n",
       "  ['payoff',\n",
       "   'potentially',\n",
       "   'enormous',\n",
       "   'chip',\n",
       "   'few',\n",
       "   'device',\n",
       "   'small',\n",
       "   'consume',\n",
       "   'less',\n",
       "   'power',\n",
       "   'low',\n",
       "   'defect',\n",
       "   'rate',\n",
       "   'cheap',\n",
       "   'manufacture']],\n",
       " [['predicate', 'quantifier']],\n",
       " [['proposition',\n",
       "   'infinitely_many',\n",
       "   'case',\n",
       "   'example',\n",
       "   'proposition',\n",
       "   'consider',\n",
       "   'thus',\n",
       "   'far',\n",
       "   'straightforward',\n",
       "   'sense',\n",
       "   'relatively',\n",
       "   'easy',\n",
       "   'determine',\n",
       "   'true_false'],\n",
       "  ['bad', 'case', 'check', 'truth_table'],\n",
       "  ['unfortunately', 'proposition', 'easy', 'check'],\n",
       "  ['proposition',\n",
       "   'may',\n",
       "   'involve',\n",
       "   'large',\n",
       "   'infinite',\n",
       "   'number',\n",
       "   'possible',\n",
       "   'case'],\n",
       "  ['example_consider', 'follow', 'proposition', 'involve', 'prime_number'],\n",
       "  ['prime', 'integer', 'great', 'divisible'],\n",
       "  ['example', 'chapter', 'proposition', 'prime'],\n",
       "  ['number', 'great', 'prime', 'say', 'composite'],\n",
       "  ['proposition'],\n",
       "  ['nonnegative_integer',\n",
       "   'value',\n",
       "   'immediately',\n",
       "   'clear',\n",
       "   'proposition_true',\n",
       "   'false'],\n",
       "  ['circumstance',\n",
       "   'tempt',\n",
       "   'try',\n",
       "   'determine',\n",
       "   'veracity',\n",
       "   'computing',\n",
       "   'value',\n",
       "   'several',\n",
       "   'value',\n",
       "   'check',\n",
       "   'see',\n",
       "   'prime'],\n",
       "  ['computed', 'value', 'prime', 'know', 'proposition', 'false'],\n",
       "  ['computed',\n",
       "   'value',\n",
       "   'indeed',\n",
       "   'prime',\n",
       "   'may',\n",
       "   'tempt',\n",
       "   'conclude',\n",
       "   'proposition_true'],\n",
       "  ['begin', 'check', 'evaluate'],\n",
       "  ['prime'],\n",
       "  ['also', 'prime'],\n",
       "  ['prime'],\n",
       "  ['hmmm'],\n",
       "  ['start', 'look'],\n",
       "  ['prime', 'nonnegative_integer'],\n",
       "  ['fact', 'continue', 'check', 'reveal'],\n",
       "  ['prime'],\n",
       "  ['proposition', 'certainly', 'seem', 'true'],\n",
       "  ['surprising', 'example', 'contrive', 'rare', 'may', 'sus', 'pect'],\n",
       "  ['soon',\n",
       "   'see',\n",
       "   'many',\n",
       "   'example',\n",
       "   'proposition',\n",
       "   'seem',\n",
       "   'true',\n",
       "   'check',\n",
       "   'case',\n",
       "   'even',\n",
       "   'many',\n",
       "   'turn',\n",
       "   'false'],\n",
       "  ['key',\n",
       "   'remember',\n",
       "   'check',\n",
       "   'claim',\n",
       "   'infinite_set',\n",
       "   'check',\n",
       "   'finite_set',\n",
       "   'element',\n",
       "   'matter',\n",
       "   'large',\n",
       "   'finite_set'],\n",
       "  ['proposition', 'involve', 'number', 'common', 'special', 'tation'],\n",
       "  ['example', 'proposition', 'also', 'write', 'symbol', 'read'],\n",
       "  ['symbol', 'stand', 'set', 'nonnegative_integer', 'namely'],\n",
       "  ['ask', 'instructor', 'complete', 'list'],\n",
       "  ['symbol', 'read', 'member', 'belong', 'simply'],\n",
       "  ['period', 'separator', 'phrase'],\n",
       "  ['example', 'proposition', 'first', 'seem', 'true', 'turn', 'false'],\n",
       "  ['symbol', 'wwd', 'mean', 'equal', 'definition'],\n",
       "  ['always',\n",
       "   'simply',\n",
       "   'write',\n",
       "   'instead',\n",
       "   'wwd',\n",
       "   'remind',\n",
       "   'reader',\n",
       "   'equality',\n",
       "   'hold',\n",
       "   'definition',\n",
       "   'helpful'],\n",
       "  ['proposition'],\n",
       "  ['euler', 'pronounce', 'oiler', 'conjecture', 'proposition_true'],\n",
       "  ['check', 'human', 'computer', 'many', 'value', 'century'],\n",
       "  ['ultimately', 'proposition', 'prove', 'false', 'noam', 'elkie'],\n",
       "  ['solution', 'find'],\n",
       "  ['wonder',\n",
       "   'take',\n",
       "   'year',\n",
       "   'show',\n",
       "   'proposition',\n",
       "   'false',\n",
       "   'logical',\n",
       "   'notation',\n",
       "   'proposition',\n",
       "   'could',\n",
       "   'write',\n",
       "   'follow',\n",
       "   'proposition',\n",
       "   'even',\n",
       "   'nastier'],\n",
       "  ['proposition'],\n",
       "  ['proposition',\n",
       "   'also',\n",
       "   'false',\n",
       "   'small',\n",
       "   'counterexample',\n",
       "   'value',\n",
       "   'digit',\n",
       "   'even',\n",
       "   'world',\n",
       "   'large',\n",
       "   'computer',\n",
       "   'would',\n",
       "   'able',\n",
       "   'far',\n",
       "   'brute',\n",
       "   'force'],\n",
       "  ['course', 'may', 'wonder', 'would', 'care', 'solution'],\n",
       "  ['course',\n",
       "   'proposition',\n",
       "   'infinitely_many',\n",
       "   'case',\n",
       "   'check',\n",
       "   'turn',\n",
       "   'false'],\n",
       "  ['follow', 'proposition', 'know', 'color', 'theorem', 'turn', 'true'],\n",
       "  ['proposition'],\n",
       "  ['map', 'colored', 'color', 'adjacent', 'gion', 'different_color'],\n",
       "  ['proof', 'proposition', 'difficult', 'take', 'century', 'perfect'],\n",
       "  ['way',\n",
       "   'many',\n",
       "   'incorrect',\n",
       "   'proof',\n",
       "   'propose',\n",
       "   'include',\n",
       "   'stand',\n",
       "   'year',\n",
       "   'region',\n",
       "   'adjacent',\n",
       "   'share',\n",
       "   'boundary',\n",
       "   'segment',\n",
       "   'positive',\n",
       "   'length'],\n",
       "  ['consider', 'adjacent', 'boundary', 'meet', 'point'],\n",
       "  ['chapter', 'proposition', 'late', 'century', 'mistake', 'find'],\n",
       "  ['extremely',\n",
       "   'laborious',\n",
       "   'proof',\n",
       "   'finally',\n",
       "   'find',\n",
       "   'mathematician',\n",
       "   'appel',\n",
       "   'haken',\n",
       "   'use',\n",
       "   'complex',\n",
       "   'computer',\n",
       "   'program',\n",
       "   'categorize',\n",
       "   'colorable',\n",
       "   'map',\n",
       "   'program',\n",
       "   'leave',\n",
       "   'map',\n",
       "   'uncategorized',\n",
       "   'check',\n",
       "   'hand',\n",
       "   'haken',\n",
       "   'assistant',\n",
       "   'include',\n",
       "   'year',\n",
       "   'old',\n",
       "   'daughter'],\n",
       "  ['lot',\n",
       "   'debate',\n",
       "   'legitimate',\n",
       "   'proof',\n",
       "   'proof',\n",
       "   'big',\n",
       "   'check',\n",
       "   'computer',\n",
       "   'could',\n",
       "   'guarantee',\n",
       "   'computer',\n",
       "   'calculate',\n",
       "   'correctly',\n",
       "   'energy',\n",
       "   'recheck',\n",
       "   'coloring',\n",
       "   'thousand',\n",
       "   'map',\n",
       "   'do',\n",
       "   'hand'],\n",
       "  ['past',\n",
       "   'decade',\n",
       "   'mostly',\n",
       "   'intelligible',\n",
       "   'proof',\n",
       "   'color',\n",
       "   'theorem',\n",
       "   'find',\n",
       "   'computer',\n",
       "   'still',\n",
       "   'need',\n",
       "   'check',\n",
       "   'colorability',\n",
       "   'several',\n",
       "   'special',\n",
       "   'map'],\n",
       "  ['case', 'know', 'proposition_true'],\n",
       "  ['exam_ple',\n",
       "   'follow',\n",
       "   'simple',\n",
       "   'proposition',\n",
       "   'know',\n",
       "   'goldbach',\n",
       "   'conjecture',\n",
       "   'heavily',\n",
       "   'study',\n",
       "   'still',\n",
       "   'know',\n",
       "   'true'],\n",
       "  ['course',\n",
       "   'check',\n",
       "   'computer',\n",
       "   'many',\n",
       "   'value',\n",
       "   'see',\n",
       "   'sufficient',\n",
       "   'conclude',\n",
       "   'true'],\n",
       "  ['proposition'],\n",
       "  ['goldbach'],\n",
       "  ['even', 'integ', 'great', 'sum', 'prime'],\n",
       "  ['precede',\n",
       "   'proposition',\n",
       "   'important',\n",
       "   'mathematic',\n",
       "   'computer',\n",
       "   'scien',\n",
       "   'tist',\n",
       "   'often',\n",
       "   'interested',\n",
       "   'proposition',\n",
       "   'concern',\n",
       "   'correctness',\n",
       "   'program',\n",
       "   'system',\n",
       "   'determine',\n",
       "   'program',\n",
       "   'system',\n",
       "   'suppose'],\n",
       "  ['program',\n",
       "   'notoriously',\n",
       "   'buggy',\n",
       "   'grow',\n",
       "   'community',\n",
       "   'searcher',\n",
       "   'practitioner',\n",
       "   'try',\n",
       "   'find',\n",
       "   'way',\n",
       "   'prove',\n",
       "   'program',\n",
       "   'correctness'],\n",
       "  ['effort',\n",
       "   'successful',\n",
       "   'enough',\n",
       "   'case',\n",
       "   'cpu',\n",
       "   'chip',\n",
       "   'routinely',\n",
       "   'use',\n",
       "   'lead',\n",
       "   'chip',\n",
       "   'manufacturer',\n",
       "   'prove',\n",
       "   'chip',\n",
       "   'correctness',\n",
       "   'avoid',\n",
       "   'mistake',\n",
       "   'notorious',\n",
       "   'intel',\n",
       "   'division',\n",
       "   'bug'],\n",
       "  ['develop',\n",
       "   'mathematical',\n",
       "   'method',\n",
       "   'verify',\n",
       "   'program',\n",
       "   'system',\n",
       "   'remain',\n",
       "   'active',\n",
       "   'research',\n",
       "   'area'],\n",
       "  ['consider', 'method', 'later', 'text']],\n",
       " [['predicate',\n",
       "   'predicate',\n",
       "   'proposition',\n",
       "   'truth',\n",
       "   'depend',\n",
       "   'value',\n",
       "   'vari',\n",
       "   'able'],\n",
       "  ['proposition', 'define', 'term', 'predicate'],\n",
       "  ['example',\n",
       "   'see',\n",
       "   'story',\n",
       "   'color',\n",
       "   'proof',\n",
       "   'tell',\n",
       "   'well',\n",
       "   'review',\n",
       "   'popular',\n",
       "   'non',\n",
       "   'technical',\n",
       "   'book',\n",
       "   'color',\n",
       "   'suffice'],\n",
       "  ['map', 'problem', 'solve'],\n",
       "  ['robin', 'wilson'],\n",
       "  ['princeton', 'univ'],\n",
       "  ['press', 'pp'],\n",
       "  ['isbn'],\n",
       "  ['predicate', 'truth', 'depend', 'value'],\n",
       "  ['predicate', 'true', 'perfect', 'square', 'false', 'perfect', 'square'],\n",
       "  ['proposition', 'predicate', 'often', 'name', 'letter'],\n",
       "  ['furthermore',\n",
       "   'function',\n",
       "   'notation',\n",
       "   'use',\n",
       "   'denote',\n",
       "   'predicate',\n",
       "   'supply',\n",
       "   'specific',\n",
       "   'variable',\n",
       "   'value'],\n",
       "  ['example', 'may', 'name', 'earlier', 'predicate'],\n",
       "  ['wwd', 'perfect', 'square'],\n",
       "  ['true'],\n",
       "  ['false'],\n",
       "  ['notation',\n",
       "   'predicate',\n",
       "   'confusingly',\n",
       "   'similar',\n",
       "   'ordinary',\n",
       "   'function',\n",
       "   'notation'],\n",
       "  ['predicate'],\n",
       "  ['true_false', 'depending', 'value'],\n",
       "  ['hand', 'ordinary', 'function', 'quantity'],\n",
       "  ['confuse']],\n",
       " [['quantifier',\n",
       "   'couple',\n",
       "   'assertion',\n",
       "   'commonly',\n",
       "   'make',\n",
       "   'predicate',\n",
       "   'time',\n",
       "   'true',\n",
       "   'always',\n",
       "   'true'],\n",
       "  ['example', 'predicate', 'always', 'true', 'real_number'],\n",
       "  ['hand', 'predicate', 'true', 'english'],\n",
       "  ['table',\n",
       "   'give',\n",
       "   'general',\n",
       "   'format',\n",
       "   'leave',\n",
       "   'specific',\n",
       "   'example',\n",
       "   'use',\n",
       "   'format',\n",
       "   'right'],\n",
       "  ['expect',\n",
       "   'see',\n",
       "   'phrase',\n",
       "   'hundred',\n",
       "   'time',\n",
       "   'mathematical',\n",
       "   'writing',\n",
       "   'always',\n",
       "   'true'],\n",
       "  ['true'],\n",
       "  ['true'],\n",
       "  ['sometimes', 'true', 'exist'],\n",
       "  ['true'],\n",
       "  ['true'],\n",
       "  ['true', 'least'],\n",
       "  ['sentence', 'quantify', 'often', 'predicate', 'true'],\n",
       "  ['specifically',\n",
       "   'assertion',\n",
       "   'predicate',\n",
       "   'always',\n",
       "   'true',\n",
       "   'call',\n",
       "   'universally',\n",
       "   'quantify',\n",
       "   'statement'],\n",
       "  ['chapter',\n",
       "   'proposition',\n",
       "   'assertion',\n",
       "   'predicate',\n",
       "   'sometimes',\n",
       "   'true',\n",
       "   'call',\n",
       "   'existentially',\n",
       "   'quantify',\n",
       "   'statement'],\n",
       "  ['sometimes',\n",
       "   'english',\n",
       "   'sentence',\n",
       "   'unclear',\n",
       "   'quantification',\n",
       "   'phrase',\n",
       "   'solve_problem',\n",
       "   'come',\n",
       "   'could',\n",
       "   'reasonably',\n",
       "   'interpret',\n",
       "   'universal',\n",
       "   'existential',\n",
       "   'statement'],\n",
       "  ['may',\n",
       "   'mean',\n",
       "   'maybe',\n",
       "   'precede',\n",
       "   'example',\n",
       "   'quantified',\n",
       "   'phrase',\n",
       "   'appear',\n",
       "   'large',\n",
       "   'statement'],\n",
       "  ['quite',\n",
       "   'normal',\n",
       "   'quantify',\n",
       "   'statement',\n",
       "   'proposition',\n",
       "   'combine',\n",
       "   'implie']],\n",
       " [['notation',\n",
       "   'symbol',\n",
       "   'represent',\n",
       "   'universal',\n",
       "   'existential',\n",
       "   'quantification',\n",
       "   'symbol',\n",
       "   'imply',\n",
       "   'universal',\n",
       "   'quantifier',\n",
       "   'symbol',\n",
       "   'read',\n",
       "   'whole',\n",
       "   'expression',\n",
       "   'say',\n",
       "   'predicate'],\n",
       "  ['true',\n",
       "   'least',\n",
       "   'value',\n",
       "   'write',\n",
       "   'existential',\n",
       "   'quantifier',\n",
       "   'symbol',\n",
       "   'read',\n",
       "   'exist'],\n",
       "  ['expression',\n",
       "   'symbol',\n",
       "   'always',\n",
       "   'follow',\n",
       "   'variable',\n",
       "   'typically',\n",
       "   'dication',\n",
       "   'set',\n",
       "   'variable_range',\n",
       "   'predicate',\n",
       "   'example'],\n",
       "  ['example', 'let', 'probs', 'set', 'problem', 'come', 'solve'],\n",
       "  ['predicate', 'solve_problem', 'proposition', 'get', 'course'],\n",
       "  ['different',\n",
       "   'interpretation',\n",
       "   'write',\n",
       "   'follow',\n",
       "   'implie',\n",
       "   'maybe',\n",
       "   'imply']],\n",
       " [['mix',\n",
       "   'quantifier',\n",
       "   'many',\n",
       "   'mathematical',\n",
       "   'statement',\n",
       "   'involve',\n",
       "   'several',\n",
       "   'quantifier'],\n",
       "  ['example',\n",
       "   'gold',\n",
       "   'bach',\n",
       "   'conjecture',\n",
       "   'state',\n",
       "   'let',\n",
       "   'write',\n",
       "   'verbosely',\n",
       "   'make',\n",
       "   'use',\n",
       "   'quantification',\n",
       "   'clear',\n",
       "   'even',\n",
       "   'integ',\n",
       "   'great',\n",
       "   'exist',\n",
       "   'prime'],\n",
       "  ['let',\n",
       "   'even',\n",
       "   'set',\n",
       "   'even',\n",
       "   'integer',\n",
       "   'great',\n",
       "   'let',\n",
       "   'prime',\n",
       "   'set',\n",
       "   'prime'],\n",
       "  ['write',\n",
       "   'goldbach',\n",
       "   'conjecture',\n",
       "   'logic',\n",
       "   'notation',\n",
       "   'follow',\n",
       "   'proposition',\n",
       "   'also',\n",
       "   'write',\n",
       "   'simply',\n",
       "   'even',\n",
       "   'prime']],\n",
       " [['order',\n",
       "   'quantifier',\n",
       "   'swap',\n",
       "   'order',\n",
       "   'different',\n",
       "   'kind',\n",
       "   'quantifier',\n",
       "   'existential',\n",
       "   'universal',\n",
       "   'usually',\n",
       "   'change',\n",
       "   'mean',\n",
       "   'proposition'],\n",
       "  ['example',\n",
       "   'let',\n",
       "   'return',\n",
       "   'initial',\n",
       "   'confusing',\n",
       "   'statement',\n",
       "   'sentence',\n",
       "   'ambiguous',\n",
       "   'order',\n",
       "   'quantifier',\n",
       "   'unclear'],\n",
       "  ['let', 'set', 'americans', 'let', 'set', 'dream', 'define', 'predicate'],\n",
       "  ['american', 'dream'],\n",
       "  ['sentence', 'could', 'mean', 'single', 'dream', 'american', 'share'],\n",
       "  ['chapter',\n",
       "   'proposition',\n",
       "   'example',\n",
       "   'may',\n",
       "   'american',\n",
       "   'share',\n",
       "   'dream',\n",
       "   'own',\n",
       "   'home'],\n",
       "  ['could', 'mean', 'american', 'personal', 'dream'],\n",
       "  ['example',\n",
       "   'americans',\n",
       "   'may',\n",
       "   'dream',\n",
       "   'peaceful',\n",
       "   'retirement',\n",
       "   'other',\n",
       "   'dream',\n",
       "   'continue',\n",
       "   'practice',\n",
       "   'profession',\n",
       "   'long',\n",
       "   'live',\n",
       "   'still',\n",
       "   'other',\n",
       "   'may',\n",
       "   'dream',\n",
       "   'rich',\n",
       "   'think',\n",
       "   'work'],\n",
       "  ['swap',\n",
       "   'quantifier',\n",
       "   'goldbach',\n",
       "   'conjecture',\n",
       "   'create',\n",
       "   'patently',\n",
       "   'false',\n",
       "   'state',\n",
       "   'ment',\n",
       "   'namely',\n",
       "   'even',\n",
       "   'number',\n",
       "   'sum',\n",
       "   'prime',\n",
       "   'prime',\n",
       "   'even']],\n",
       " [['variable',\n",
       "   'domain',\n",
       "   'variable',\n",
       "   'formula',\n",
       "   'understand',\n",
       "   'take',\n",
       "   'value',\n",
       "   'nonempty_set',\n",
       "   'conventional',\n",
       "   'omit',\n",
       "   'mention'],\n",
       "  ['example', 'instead'],\n",
       "  ['write'],\n",
       "  ['unnamed',\n",
       "   'nonempty_set',\n",
       "   'range',\n",
       "   'call',\n",
       "   'domain',\n",
       "   'discourse',\n",
       "   'plain',\n",
       "   'domain',\n",
       "   'formula'],\n",
       "  ['easy', 'arrange', 'variable_range', 'domain'],\n",
       "  ['exam_ple',\n",
       "   'goldbach',\n",
       "   'conjecture',\n",
       "   'could',\n",
       "   'expressed',\n",
       "   'variable_range',\n",
       "   'domain'],\n",
       "  ['evens', 'imply']],\n",
       " [['negating', 'quantifier', 'simple', 'relationship', 'kind', 'quantifier'],\n",
       "  ['follow', 'sentence', 'mean', 'thing', 'case', 'like', 'snowboard'],\n",
       "  ['exist', 'snowboard'],\n",
       "  ['term',\n",
       "   'logic',\n",
       "   'notation',\n",
       "   'follow',\n",
       "   'general',\n",
       "   'property',\n",
       "   'predicate',\n",
       "   'formu',\n",
       "   'las',\n",
       "   'equivalent',\n",
       "   'similarly',\n",
       "   'sentence',\n",
       "   'mean',\n",
       "   'thing',\n",
       "   'exist',\n",
       "   'like',\n",
       "   'skiing',\n",
       "   'magma'],\n",
       "  ['dislike', 'skiing', 'magma'],\n",
       "  ['express',\n",
       "   'equivalence',\n",
       "   'logic',\n",
       "   'notation',\n",
       "   'way',\n",
       "   'general',\n",
       "   'principle',\n",
       "   'move',\n",
       "   'quantifi',\n",
       "   'change',\n",
       "   'kind',\n",
       "   'quantifier']],\n",
       " [['validity',\n",
       "   'propositional',\n",
       "   'formula',\n",
       "   'call',\n",
       "   'valid',\n",
       "   'evaluate',\n",
       "   'matter',\n",
       "   'truth',\n",
       "   'value',\n",
       "   'assign',\n",
       "   'individual',\n",
       "   'propositional',\n",
       "   'variable'],\n",
       "  ['example', 'propositional', 'version', 'distributive', 'law', 'valid'],\n",
       "  ['verified',\n",
       "   'check',\n",
       "   'truth_table',\n",
       "   'idea',\n",
       "   'extend',\n",
       "   'predicate',\n",
       "   'formula',\n",
       "   'valid',\n",
       "   'formula',\n",
       "   'must',\n",
       "   'evaluate',\n",
       "   'true',\n",
       "   'matter',\n",
       "   'value',\n",
       "   'variable',\n",
       "   'may',\n",
       "   'take',\n",
       "   'unspecified',\n",
       "   'domain',\n",
       "   'matter',\n",
       "   'interpretation',\n",
       "   'predicate',\n",
       "   'variable',\n",
       "   'may',\n",
       "   'give'],\n",
       "  ['example',\n",
       "   'already',\n",
       "   'observe',\n",
       "   'rule',\n",
       "   'negate',\n",
       "   'quantifier',\n",
       "   'capture',\n",
       "   'valid',\n",
       "   'assertion',\n",
       "   'useful',\n",
       "   'example',\n",
       "   'valid',\n",
       "   'assertion',\n",
       "   'explanation',\n",
       "   'valid',\n",
       "   'chapter',\n",
       "   'proposition',\n",
       "   'let',\n",
       "   'domain',\n",
       "   'variable'],\n",
       "  ['need',\n",
       "   'show',\n",
       "   'hold',\n",
       "   'interpretation',\n",
       "   'suppose',\n",
       "   'definition',\n",
       "   'mean',\n",
       "   'true'],\n",
       "  ['give',\n",
       "   'element',\n",
       "   'namely',\n",
       "   'hope',\n",
       "   'helpful',\n",
       "   'explanation',\n",
       "   'purist',\n",
       "   'would',\n",
       "   'really',\n",
       "   'want',\n",
       "   'call',\n",
       "   'proof'],\n",
       "  ['problem', 'basic', 'contrast', 'valid'],\n",
       "  ['prove', 'describe', 'interpretation', 'hypoth', 'esis'],\n",
       "  ['true', 'conclusion'],\n",
       "  ['true'],\n",
       "  ['example', 'let', 'domain', 'integer'],\n",
       "  ['mean'],\n",
       "  ['hypoth',\n",
       "   'esis',\n",
       "   'would',\n",
       "   'true',\n",
       "   'give',\n",
       "   'value',\n",
       "   'could',\n",
       "   'example',\n",
       "   'choose',\n",
       "   'value'],\n",
       "  ['interpretation',\n",
       "   'conclusion',\n",
       "   'assert',\n",
       "   'integer',\n",
       "   'big',\n",
       "   'integer',\n",
       "   'certainly',\n",
       "   'false'],\n",
       "  ['interpretation',\n",
       "   'falsifie',\n",
       "   'assertion',\n",
       "   'call',\n",
       "   'counter',\n",
       "   'model',\n",
       "   'assertion'],\n",
       "  ['predicate', 'depend', 'variable']],\n",
       " [['satisfiability',\n",
       "   'proposition',\n",
       "   'satisfiable',\n",
       "   'setting',\n",
       "   'variable',\n",
       "   'make',\n",
       "   'proposition_true'],\n",
       "  ['example',\n",
       "   'general',\n",
       "   'problem',\n",
       "   'decide',\n",
       "   'proposition',\n",
       "   'satisfiable',\n",
       "   'call',\n",
       "   'sit'],\n",
       "  ['approach', 'sit', 'construct', 'truth_table', 'check', 'ever', 'appear'],\n",
       "  ['approach',\n",
       "   'efficient',\n",
       "   'proposition',\n",
       "   'variable',\n",
       "   'truth_table',\n",
       "   'efficient',\n",
       "   'solution',\n",
       "   'sit',\n",
       "   'particular',\n",
       "   'presum',\n",
       "   'ably',\n",
       "   'ingenious',\n",
       "   'procedure',\n",
       "   'determine',\n",
       "   'number',\n",
       "   'step',\n",
       "   'grow',\n",
       "   'polynomially',\n",
       "   'recently',\n",
       "   'exciting',\n",
       "   'progress',\n",
       "   'sit',\n",
       "   'solver',\n",
       "   'practical',\n",
       "   'applica',\n",
       "   'tion',\n",
       "   'digital',\n",
       "   'circuit',\n",
       "   'verification'],\n",
       "  ['program',\n",
       "   'find',\n",
       "   'satisfy',\n",
       "   'assignment',\n",
       "   'amazing',\n",
       "   'efficiency',\n",
       "   'even',\n",
       "   'formula',\n",
       "   'million',\n",
       "   'variable'],\n",
       "  ['unfortu',\n",
       "   'nately',\n",
       "   'hard',\n",
       "   'predict',\n",
       "   'kind',\n",
       "   'formula',\n",
       "   'amenable',\n",
       "   'sit',\n",
       "   'solver',\n",
       "   'meth',\n",
       "   'ods',\n",
       "   'formula',\n",
       "   'satisfiable',\n",
       "   'sit',\n",
       "   'solver',\n",
       "   'generally',\n",
       "   'take',\n",
       "   'exponen',\n",
       "   'time',\n",
       "   'verify'],\n",
       "  ['good_idea',\n",
       "   'solve',\n",
       "   'sit',\n",
       "   'polynomial',\n",
       "   'time',\n",
       "   'prove',\n",
       "   'do',\n",
       "   'researcher',\n",
       "   'completely',\n",
       "   'stick'],\n",
       "  ['problem', 'determine', 'sit', 'polynomial', 'time', 'solution', 'know'],\n",
       "  ['np', 'problem'],\n",
       "  ['outstanding', 'unanswered', 'question', 'theoretical', 'computer_science'],\n",
       "  ['also']],\n",
       " [['pattern_proof']],\n",
       " [['axiomatic',\n",
       "   'method',\n",
       "   'standard',\n",
       "   'procedure',\n",
       "   'establish',\n",
       "   'truth',\n",
       "   'mathematic',\n",
       "   'invent',\n",
       "   'eu',\n",
       "   'clid',\n",
       "   'mathematician',\n",
       "   'work',\n",
       "   'alexandria',\n",
       "   'egypt',\n",
       "   'bc'],\n",
       "  ['idea',\n",
       "   'begin',\n",
       "   'assumption',\n",
       "   'geometry',\n",
       "   'seem',\n",
       "   'undeniable',\n",
       "   'base',\n",
       "   'direct',\n",
       "   'experience'],\n",
       "  ['example', 'assumption', 'straight', 'line', 'segment', 'pair', 'point'],\n",
       "  ['proposition', 'simply', 'accept', 'true', 'call', 'axiom'],\n",
       "  ['start',\n",
       "   'axiom',\n",
       "   'euclid',\n",
       "   'establish',\n",
       "   'truth',\n",
       "   'many',\n",
       "   'additional',\n",
       "   'propo',\n",
       "   'sition',\n",
       "   'provide',\n",
       "   'proof'],\n",
       "  ['proof',\n",
       "   'sequence',\n",
       "   'logical_deduction',\n",
       "   'axiom',\n",
       "   'previously',\n",
       "   'prove',\n",
       "   'statement',\n",
       "   'conclude',\n",
       "   'proposition',\n",
       "   'question'],\n",
       "  ['probably',\n",
       "   'write',\n",
       "   'many',\n",
       "   'proofs',\n",
       "   'high',\n",
       "   'school',\n",
       "   'geometry',\n",
       "   'class',\n",
       "   'see',\n",
       "   'lot',\n",
       "   'course'],\n",
       "  ['several', 'common', 'term', 'proposition', 'prove'],\n",
       "  ['different',\n",
       "   'term',\n",
       "   'hint',\n",
       "   'role',\n",
       "   'proposition',\n",
       "   'large',\n",
       "   'body',\n",
       "   'work'],\n",
       "  ['important', 'proposition', 'call', 'theorem'],\n",
       "  ['lemma',\n",
       "   'preliminary',\n",
       "   'proposition',\n",
       "   'useful',\n",
       "   'prove',\n",
       "   'later',\n",
       "   'proposition'],\n",
       "  ['corollary',\n",
       "   'proposition',\n",
       "   'follow',\n",
       "   'logical',\n",
       "   'step',\n",
       "   'lemma',\n",
       "   'theorem'],\n",
       "  ['definition', 'precise'],\n",
       "  ['fact',\n",
       "   'sometimes',\n",
       "   'good',\n",
       "   'lemma',\n",
       "   'turn',\n",
       "   'far',\n",
       "   'important',\n",
       "   'theorem',\n",
       "   'originally',\n",
       "   'use',\n",
       "   'prove'],\n",
       "  ['euclid',\n",
       "   'axiom',\n",
       "   'proof',\n",
       "   'approach',\n",
       "   'call',\n",
       "   'axiomatic',\n",
       "   'method',\n",
       "   'foundation',\n",
       "   'mathematic',\n",
       "   'today'],\n",
       "  ['fact',\n",
       "   'handful',\n",
       "   'axiom',\n",
       "   'collectively',\n",
       "   'call',\n",
       "   'zermelo',\n",
       "   'frankel',\n",
       "   'set',\n",
       "   'theory',\n",
       "   'choice',\n",
       "   'zfc',\n",
       "   'together',\n",
       "   'logical_deduction',\n",
       "   'rule',\n",
       "   'appear',\n",
       "   'sufficient',\n",
       "   'derive',\n",
       "   'essentially',\n",
       "   'mathematic']],\n",
       " [['axiom',\n",
       "   'zfc',\n",
       "   'axiom',\n",
       "   'important',\n",
       "   'study',\n",
       "   'justify',\n",
       "   'foundation',\n",
       "   'math',\n",
       "   'ematic',\n",
       "   'practical',\n",
       "   'purpose',\n",
       "   'much',\n",
       "   'primitive'],\n",
       "  ['proving',\n",
       "   'theorem',\n",
       "   'zfc',\n",
       "   'little',\n",
       "   'writing',\n",
       "   'program',\n",
       "   'byte',\n",
       "   'code',\n",
       "   'instead',\n",
       "   'full',\n",
       "   'fledge',\n",
       "   'pro',\n",
       "   'gramming',\n",
       "   'language',\n",
       "   'reckon',\n",
       "   'formal',\n",
       "   'proof',\n",
       "   'zfc',\n",
       "   'require',\n",
       "   'step',\n",
       "   'instead',\n",
       "   'start',\n",
       "   'zfc',\n",
       "   'go',\n",
       "   'chapter_pattern',\n",
       "   'proof',\n",
       "   'take',\n",
       "   'huge',\n",
       "   'set',\n",
       "   'axiom',\n",
       "   'foundation',\n",
       "   'accept',\n",
       "   'familiar',\n",
       "   'fact',\n",
       "   'high',\n",
       "   'school',\n",
       "   'math',\n",
       "   'give',\n",
       "   'quick',\n",
       "   'launch',\n",
       "   'may',\n",
       "   'find',\n",
       "   'imprecise',\n",
       "   'specification',\n",
       "   'axiom',\n",
       "   'troubling',\n",
       "   'time'],\n",
       "  ['example',\n",
       "   'midst',\n",
       "   'proof',\n",
       "   'may',\n",
       "   'find',\n",
       "   'wondering',\n",
       "   'must',\n",
       "   'prove',\n",
       "   'little',\n",
       "   'fact',\n",
       "   'take',\n",
       "   'axiom',\n",
       "   'feel',\n",
       "   'free',\n",
       "   'ask',\n",
       "   'guidance',\n",
       "   'really',\n",
       "   'absolute',\n",
       "   'answer'],\n",
       "  ['front',\n",
       "   'assume',\n",
       "   'try',\n",
       "   'evade',\n",
       "   'homework',\n",
       "   'exam',\n",
       "   'problem',\n",
       "   'declare',\n",
       "   'axiom']],\n",
       " [['logical_deduction',\n",
       "   'logical_deduction',\n",
       "   'inference_rule',\n",
       "   'use',\n",
       "   'prove',\n",
       "   'new',\n",
       "   'proposition',\n",
       "   'use',\n",
       "   'previously',\n",
       "   'prove',\n",
       "   'one'],\n",
       "  ['fundamental', 'inference_rule', 'ponens'],\n",
       "  ['rule',\n",
       "   'say',\n",
       "   'proof',\n",
       "   'together',\n",
       "   'proof',\n",
       "   'imply',\n",
       "   'inference_rule',\n",
       "   'sometimes',\n",
       "   'write',\n",
       "   'funny',\n",
       "   'notation'],\n",
       "  ['example', 'modus', 'ponens', 'write', 'rule'],\n",
       "  ['imply',\n",
       "   'statement',\n",
       "   'line',\n",
       "   'call',\n",
       "   'antecedent',\n",
       "   'prove',\n",
       "   'consider',\n",
       "   'statement',\n",
       "   'line',\n",
       "   'call',\n",
       "   'conclusion',\n",
       "   'consequent',\n",
       "   'also',\n",
       "   'prove'],\n",
       "  ['key',\n",
       "   'requirement',\n",
       "   'inference_rule',\n",
       "   'must',\n",
       "   'sound',\n",
       "   'assignment',\n",
       "   'truth',\n",
       "   'value',\n",
       "   'make',\n",
       "   'antecedent',\n",
       "   'true',\n",
       "   'must_also',\n",
       "   'make',\n",
       "   'consequent',\n",
       "   'true'],\n",
       "  ['start',\n",
       "   'true',\n",
       "   'axiom',\n",
       "   'apply',\n",
       "   'sound',\n",
       "   'inference_rule',\n",
       "   'prove',\n",
       "   'also',\n",
       "   'true'],\n",
       "  ['see',\n",
       "   'ponens',\n",
       "   'sound',\n",
       "   'inference_rule',\n",
       "   'check',\n",
       "   'truth_table',\n",
       "   'imply_imply',\n",
       "   'qp',\n",
       "   'many',\n",
       "   'natural',\n",
       "   'sound',\n",
       "   'inference_rule',\n",
       "   'example',\n",
       "   'rule'],\n",
       "  ['imply_imply', 'imply', 'rule'],\n",
       "  ['imply', 'rule'],\n",
       "  ['imply', 'hand', 'non', 'rule'],\n",
       "  ['imply', 'sound', 'assign', 'assign', 'antecedent', 'true', 'consequent'],\n",
       "  ['note',\n",
       "   'propositional',\n",
       "   'inference_rule',\n",
       "   'sound',\n",
       "   'precisely',\n",
       "   'conjunction',\n",
       "   'antecedent',\n",
       "   'imply',\n",
       "   'consequent'],\n",
       "  ['axiom', 'formal', 'set', 'legal', 'inference_rule'],\n",
       "  ['step',\n",
       "   'proof',\n",
       "   'clear',\n",
       "   'logical',\n",
       "   'particular',\n",
       "   'state',\n",
       "   'previously',\n",
       "   'prove',\n",
       "   'fact',\n",
       "   'use',\n",
       "   'derive',\n",
       "   'new',\n",
       "   'conclusion']],\n",
       " [['proof',\n",
       "   'template',\n",
       "   'principle',\n",
       "   'proof',\n",
       "   'sequence',\n",
       "   'logical_deduction',\n",
       "   'axiom',\n",
       "   'previously',\n",
       "   'prove',\n",
       "   'statement',\n",
       "   'conclude',\n",
       "   'proposition',\n",
       "   'question'],\n",
       "  ['freedom', 'construct', 'proof', 'seem', 'overwhelm', 'first'],\n",
       "  ['even',\n",
       "   'start',\n",
       "   'proof',\n",
       "   'good_news',\n",
       "   'many',\n",
       "   'proof',\n",
       "   'follow',\n",
       "   'handful',\n",
       "   'standard',\n",
       "   'tem',\n",
       "   'plate'],\n",
       "  ['proof',\n",
       "   'detail',\n",
       "   'course',\n",
       "   'template',\n",
       "   'least',\n",
       "   'provide',\n",
       "   'outline',\n",
       "   'fill'],\n",
       "  ['remainder',\n",
       "   'chapter',\n",
       "   'go',\n",
       "   'several',\n",
       "   'standard',\n",
       "   'pattern',\n",
       "   'point',\n",
       "   'basic',\n",
       "   'idea',\n",
       "   'common',\n",
       "   'pitfall',\n",
       "   'give',\n",
       "   'example'],\n",
       "  ['many',\n",
       "   'template',\n",
       "   'fit',\n",
       "   'together',\n",
       "   'may',\n",
       "   'give',\n",
       "   'top',\n",
       "   'level',\n",
       "   'outline',\n",
       "   'other',\n",
       "   'help',\n",
       "   'next',\n",
       "   'level',\n",
       "   'detail'],\n",
       "  ['show',\n",
       "   'sophisticated',\n",
       "   'proof',\n",
       "   'technique',\n",
       "   'chapter',\n",
       "   'recipe',\n",
       "   'follow',\n",
       "   'specific',\n",
       "   'time',\n",
       "   'tell',\n",
       "   'exactly',\n",
       "   'word',\n",
       "   'write',\n",
       "   'piece',\n",
       "   'paper'],\n",
       "  ['certainly',\n",
       "   'free',\n",
       "   'say',\n",
       "   'thing',\n",
       "   'way',\n",
       "   'instead',\n",
       "   'give',\n",
       "   'could',\n",
       "   'say',\n",
       "   'never',\n",
       "   'complete',\n",
       "   'loss'],\n",
       "  ['chapter_pattern', 'proof']],\n",
       " [['proof',\n",
       "   'case',\n",
       "   'break',\n",
       "   'complicated',\n",
       "   'proof',\n",
       "   'case',\n",
       "   'prove',\n",
       "   'case',\n",
       "   'separately',\n",
       "   'use',\n",
       "   'ful',\n",
       "   'common',\n",
       "   'proof',\n",
       "   'strategy'],\n",
       "  ['fact',\n",
       "   'already',\n",
       "   'implicitly',\n",
       "   'use',\n",
       "   'strategy',\n",
       "   'use',\n",
       "   'truth_table',\n",
       "   'show',\n",
       "   'certain',\n",
       "   'proposition_true',\n",
       "   'valid'],\n",
       "  ['example', 'section', 'imply_imply', 'imply', 'true', 'true'],\n",
       "  ['exam_ple',\n",
       "   'imply_imply',\n",
       "   'imply',\n",
       "   'iff',\n",
       "   'imply',\n",
       "   'proof',\n",
       "   'case',\n",
       "   'work',\n",
       "   'much',\n",
       "   'general',\n",
       "   'environment',\n",
       "   'proposition',\n",
       "   'volve',\n",
       "   'boolean',\n",
       "   'variable'],\n",
       "  ['follow', 'use', 'approach', 'prove', 'simple', 'fact', 'acquaintance'],\n",
       "  ['background', 'assume', 'pair', 'people_meet'],\n",
       "  ['pair_people', 'group', 'meet', 'call', 'group', 'club'],\n",
       "  ['pair_people', 'group', 'meet', 'call', 'group', 'stranger'],\n",
       "  ['theorem'],\n",
       "  ['collection', 'people', 'include', 'club', 'people', 'group', 'stranger'],\n",
       "  ['proof'],\n",
       "  ['proof', 'case', 'analysis', 'people', 'least', 'meet'],\n",
       "  ['people', 'least', 'meet'],\n",
       "  ['least',\n",
       "   'case',\n",
       "   'must',\n",
       "   'hold',\n",
       "   'easy',\n",
       "   'split',\n",
       "   'people',\n",
       "   'group',\n",
       "   'shake',\n",
       "   'hand',\n",
       "   'group',\n",
       "   'must',\n",
       "   'least',\n",
       "   'half',\n",
       "   'people'],\n",
       "  ['case', 'suppose', 'least', 'people_meet'],\n",
       "  ['case',\n",
       "   'split',\n",
       "   'subcase',\n",
       "   'describe',\n",
       "   'approach',\n",
       "   'outset',\n",
       "   'help',\n",
       "   'orient',\n",
       "   'reader'],\n",
       "  ['try', 'remember', 'always'],\n",
       "  ['part', 'case', 'analysis', 'argument', 'show', 'cover', 'case'],\n",
       "  ['often', 'obvious', 'case', 'form'],\n",
       "  ['however', 'situation', 'state', 'quite', 'simply'],\n",
       "  ['case'],\n",
       "  ['people_meet', 'none', 'meet'],\n",
       "  ['people_meet', 'group', 'least', 'stranger'],\n",
       "  ['theorem', 'hold', 'subcase'],\n",
       "  ['case'],\n",
       "  ['people_meet', 'pair', 'meet'],\n",
       "  ['pair', 'together', 'form', 'club', 'people'],\n",
       "  ['theorem', 'hold', 'subcase'],\n",
       "  ['imply', 'theorem', 'hold', 'case'],\n",
       "  ['case', 'suppose', 'least', 'people_meet'],\n",
       "  ['case', 'also', 'split', 'subcase', 'case'],\n",
       "  ['people_meet', 'pair', 'meet'],\n",
       "  ['people_meet', 'club', 'least', 'people'],\n",
       "  ['theorem', 'hold', 'subcase'],\n",
       "  ['case'],\n",
       "  ['people_meet', 'pair', 'meet'],\n",
       "  ['pair', 'together', 'form', 'group', 'least', 'stranger'],\n",
       "  ['theorem', 'hold', 'subcase'],\n",
       "  ['imply', 'theorem', 'also', 'hold', 'case', 'therefore', 'hold', 'case']],\n",
       " [['prove', 'implication', 'proposition', 'form', 'call', 'implication'],\n",
       "  ['implication',\n",
       "   'often',\n",
       "   'rephrase',\n",
       "   'imply',\n",
       "   'example',\n",
       "   'implication',\n",
       "   'couple',\n",
       "   'standard',\n",
       "   'method',\n",
       "   'prove',\n",
       "   'implication'],\n",
       "  ['chapter_pattern', 'proof']],\n",
       " [['method',\n",
       "   'assume',\n",
       "   'true',\n",
       "   'proving',\n",
       "   'imply_imply',\n",
       "   'imply',\n",
       "   'write',\n",
       "   'assume'],\n",
       "  ['show', 'logically', 'follow'],\n",
       "  ['example', 'use', 'method', 'prove_theorem'],\n",
       "  ['write', 'proof_theorem', 'scratchwork', 'figure', 'true'],\n",
       "  ['inequality', 'certainly', 'hold', 'leave_side', 'equal'],\n",
       "  ['grow', 'term', 'positive', 'initially', 'seem', 'great', 'far', 'good'],\n",
       "  ['still', 'replace', 'seem', 'phrase', 'solid', 'logical', 'argument'],\n",
       "  ['better', 'handle', 'critical', 'aha', 'term', 'right_side', 'nonnegative'],\n",
       "  ['product', 'nonnegative', 'term', 'also', 'nonnegative'],\n",
       "  ['let', 'organize', 'blizzard', 'observation', 'clean', 'proof'],\n",
       "  ['proof'],\n",
       "  ['assume'],\n",
       "  ['cx', 'nonnegative'],\n",
       "  ['therefore', 'product', 'term', 'also', 'nonnegative'],\n",
       "  ['add', 'product', 'give', 'positive', 'number'],\n",
       "  ['multiplying', 'leave_side', 'prof', 'claim'],\n",
       "  ['couple',\n",
       "   'point',\n",
       "   'apply',\n",
       "   'proof',\n",
       "   'often',\n",
       "   'need',\n",
       "   'scratchwork',\n",
       "   'try',\n",
       "   'figure',\n",
       "   'logical',\n",
       "   'step',\n",
       "   'proof'],\n",
       "  ['scratchwork',\n",
       "   'disorganize',\n",
       "   'full',\n",
       "   'dead',\n",
       "   'end',\n",
       "   'strange',\n",
       "   'diagram',\n",
       "   'obscene',\n",
       "   'word'],\n",
       "  ['keep', 'scratchwork', 'separate', 'final', 'proof', 'clear', 'concise'],\n",
       "  ['proofs',\n",
       "   'typically',\n",
       "   'begin',\n",
       "   'word',\n",
       "   'proof',\n",
       "   'end',\n",
       "   'sort',\n",
       "   'doohickey'],\n",
       "  ['purpose', 'convention', 'clarify', 'proof', 'begin_end'],\n",
       "  ['potential',\n",
       "   'pitfall',\n",
       "   'purpose',\n",
       "   'prove',\n",
       "   'implication',\n",
       "   'imply',\n",
       "   'hold',\n",
       "   'example',\n",
       "   'theorem',\n",
       "   'form']],\n",
       " [['method',\n",
       "   'prove',\n",
       "   'contrapositive',\n",
       "   'already',\n",
       "   'see',\n",
       "   'implication',\n",
       "   'imply',\n",
       "   'prove',\n",
       "   'good',\n",
       "   'proving',\n",
       "   'prove',\n",
       "   'contrapositive',\n",
       "   'time',\n",
       "   'easy',\n",
       "   'prove',\n",
       "   'original',\n",
       "   'statement'],\n",
       "  ['hence',\n",
       "   'proceed',\n",
       "   'fol',\n",
       "   'low',\n",
       "   'write',\n",
       "   'prove',\n",
       "   'contrapositive',\n",
       "   'state',\n",
       "   'contrapositive'],\n",
       "  ['proceed', 'method'],\n",
       "  ['example', 'use', 'approach', 'prove_theorem'],\n",
       "  ['irrational', 'also', 'irrational'],\n",
       "  ['recall',\n",
       "   'rational_number',\n",
       "   'equal',\n",
       "   'ratio',\n",
       "   'integer',\n",
       "   'irrational',\n",
       "   'num_ber'],\n",
       "  ['must', 'show', 'ratio', 'integer', 'also', 'ratio', 'integer'],\n",
       "  ['pretty',\n",
       "   'convoluted',\n",
       "   'eliminate',\n",
       "   'make',\n",
       "   'proof',\n",
       "   'straightforward',\n",
       "   'consider',\n",
       "   'contrapositive',\n",
       "   'instead']],\n",
       " [['prove',\n",
       "   'many',\n",
       "   'mathematical',\n",
       "   'theorem',\n",
       "   'assert',\n",
       "   'statement',\n",
       "   'logically',\n",
       "   'equivalent',\n",
       "   'hold'],\n",
       "  ['example',\n",
       "   'know',\n",
       "   'several',\n",
       "   'year',\n",
       "   'triangle',\n",
       "   'side',\n",
       "   'length',\n",
       "   'side',\n",
       "   'length',\n",
       "   'angle',\n",
       "   'side',\n",
       "   'triangle'],\n",
       "  ['phrase', 'come', 'often', 'often', 'abbreviate', 'iff']],\n",
       " [['method',\n",
       "   'prove',\n",
       "   'statement',\n",
       "   'imply',\n",
       "   'statement',\n",
       "   'iff',\n",
       "   'imply_imply',\n",
       "   'write',\n",
       "   'prove',\n",
       "   'imply',\n",
       "   'vice'],\n",
       "  ['write', 'first', 'show', 'imply'],\n",
       "  ['method', 'section', 'write', 'show', 'imply'],\n",
       "  ['method', 'section']],\n",
       " [['method',\n",
       "   'construct',\n",
       "   'chain',\n",
       "   'iff',\n",
       "   'order',\n",
       "   'prove',\n",
       "   'true',\n",
       "   'iff',\n",
       "   'true',\n",
       "   'write',\n",
       "   'construct',\n",
       "   'chain',\n",
       "   'implication'],\n",
       "  ['prove',\n",
       "   'equivalent',\n",
       "   'second',\n",
       "   'statement',\n",
       "   'equivalent',\n",
       "   'third',\n",
       "   'statement',\n",
       "   'forth',\n",
       "   'reach'],\n",
       "  ['method',\n",
       "   'sometimes',\n",
       "   'require',\n",
       "   'ingenuity',\n",
       "   'first',\n",
       "   'result',\n",
       "   'short',\n",
       "   'elegant',\n",
       "   'proof',\n",
       "   'see',\n",
       "   'follow',\n",
       "   'example'],\n",
       "  ['theorem'],\n",
       "  ['standard_deviation', 'sequence', 'value', 'definition'],\n",
       "  ['standard_deviation',\n",
       "   'sequence',\n",
       "   'value',\n",
       "   'example',\n",
       "   'theorem',\n",
       "   'say',\n",
       "   'standard_deviation',\n",
       "   'test',\n",
       "   'score',\n",
       "   'score',\n",
       "   'exactly',\n",
       "   'class',\n",
       "   'average'],\n",
       "  ['talk', 'lot', 'mean', 'standard_deviation', 'part', 'iv', 'book'],\n",
       "  ['proof'],\n",
       "  ['construct',\n",
       "   'chain',\n",
       "   'iff',\n",
       "   'implication',\n",
       "   'start',\n",
       "   'statement',\n",
       "   'standard_deviation',\n",
       "   'number',\n",
       "   'square',\n",
       "   'root',\n",
       "   'equation',\n",
       "   'square',\n",
       "   'real_number',\n",
       "   'always',\n",
       "   'nonnegative',\n",
       "   'term',\n",
       "   'leave_hand',\n",
       "   'side_equation',\n",
       "   'term',\n",
       "   'leave_hand',\n",
       "   'side',\n",
       "   'term'],\n",
       "  ['chapter_pattern', 'proof']],\n",
       " [['proof_contradiction',\n",
       "   'proof_contradiction',\n",
       "   'indirect',\n",
       "   'proof',\n",
       "   'show',\n",
       "   'proposition',\n",
       "   'false',\n",
       "   'false',\n",
       "   'fact',\n",
       "   'would',\n",
       "   'true'],\n",
       "  ['false', 'fact', 'true', 'propo', 'sition', 'better', 'false'],\n",
       "  ['proposition', 'really', 'must', 'true'],\n",
       "  ['proof_contradiction', 'always', 'viable', 'approach'],\n",
       "  ['however',\n",
       "   'name',\n",
       "   'sug',\n",
       "   'gests',\n",
       "   'indirect',\n",
       "   'proofs',\n",
       "   'little',\n",
       "   'convolute'],\n",
       "  ['direct', 'proofs', 'generally', 'preferable', 'matter', 'clarity'],\n",
       "  ['method',\n",
       "   'order',\n",
       "   'prove',\n",
       "   'proposition',\n",
       "   'contradiction',\n",
       "   'write',\n",
       "   'use',\n",
       "   'proof_contradiction'],\n",
       "  ['write', 'suppose', 'false'],\n",
       "  ['deduce', 'know', 'false', 'logical', 'contradiction'],\n",
       "  ['write', 'contradiction'],\n",
       "  ['therefore', 'must', 'true'],\n",
       "  ['example', 'use', 'proof_contradiction', 'prove', 'irrational'],\n",
       "  ['recall', 'number', 'rational', 'equal', 'ratio', 'integer'],\n",
       "  ['example', 'rational_number'],\n",
       "  ['integer'],\n",
       "  ['furthermore', 'let', 'take', 'low', 'term', 'number', 'great', 'divide'],\n",
       "  ['square',\n",
       "   'side',\n",
       "   'give',\n",
       "   'numerator',\n",
       "   'denominator',\n",
       "   'common',\n",
       "   'factor',\n",
       "   'contradict',\n",
       "   'fact',\n",
       "   'low',\n",
       "   'term'],\n",
       "  ['must', 'irrational'],\n",
       "  ['potential',\n",
       "   'pitfall',\n",
       "   'proof',\n",
       "   'proposition',\n",
       "   'contradiction',\n",
       "   'really',\n",
       "   'prove',\n",
       "   'impli',\n",
       "   'cation',\n",
       "   'imply_imply',\n",
       "   'imply',\n",
       "   'matter',\n",
       "   'think',\n",
       "   'important',\n",
       "   'remember',\n",
       "   'start',\n",
       "   'assume']],\n",
       " [['proofs', 'set', 'set', 'simple', 'flexible', 'everywhere'],\n",
       "  ['find', 'set', 'mention', 'nearly', 'section', 'text'],\n",
       "  ['fact',\n",
       "   'already',\n",
       "   'talk',\n",
       "   'lot',\n",
       "   'set',\n",
       "   'set',\n",
       "   'integer',\n",
       "   'set',\n",
       "   'real_number',\n",
       "   'set',\n",
       "   'positive',\n",
       "   'even',\n",
       "   'number',\n",
       "   'name'],\n",
       "  ['section', 'see', 'prove', 'basic', 'fact', 'set'],\n",
       "  ['start',\n",
       "   'definition',\n",
       "   'make',\n",
       "   'sure',\n",
       "   'know',\n",
       "   'terminology',\n",
       "   'comfortable',\n",
       "   'working',\n",
       "   'set']],\n",
       " [['definition',\n",
       "   'informally',\n",
       "   'set',\n",
       "   'bunch',\n",
       "   'object',\n",
       "   'call',\n",
       "   'element_set'],\n",
       "  ['element_set', 'number', 'point', 'space', 'even', 'set'],\n",
       "  ['conventional', 'way', 'write', 'set', 'list_element', 'curly', 'brace'],\n",
       "  ['example',\n",
       "   'set',\n",
       "   'falex',\n",
       "   'tippy',\n",
       "   'shell',\n",
       "   'shadowg',\n",
       "   'dead',\n",
       "   'pet',\n",
       "   'fred',\n",
       "   'blue',\n",
       "   'yellowg',\n",
       "   'primary',\n",
       "   'color',\n",
       "   'ffa',\n",
       "   'bg',\n",
       "   'cg',\n",
       "   'fb',\n",
       "   'cgg',\n",
       "   'set',\n",
       "   'set',\n",
       "   'work',\n",
       "   'fine',\n",
       "   'small',\n",
       "   'finite_set'],\n",
       "  ['set',\n",
       "   'may',\n",
       "   'defined',\n",
       "   'indicate',\n",
       "   'generate',\n",
       "   'list',\n",
       "   'power',\n",
       "   'order',\n",
       "   'element',\n",
       "   'significant',\n",
       "   'fx',\n",
       "   'fy',\n",
       "   'xg',\n",
       "   'set',\n",
       "   'write',\n",
       "   'different_way'],\n",
       "  ['also',\n",
       "   'object',\n",
       "   'element',\n",
       "   'give',\n",
       "   'chapter_pattern',\n",
       "   'proof',\n",
       "   'set',\n",
       "   'notion',\n",
       "   'element',\n",
       "   'appear',\n",
       "   'set'],\n",
       "  ['writ', 'ing', 'fx', 'xg', 'indicate', 'thing', 'twice', 'namely', 'set'],\n",
       "  ['particular', 'fx', 'xg', 'fxg'],\n",
       "  ['expression', 'assert', 'element_set'],\n",
       "  ['example', 'blue', 'tailspin', 'yet'],\n",
       "  ['popular',\n",
       "   'set',\n",
       "   'mathematician',\n",
       "   'devise',\n",
       "   'special',\n",
       "   'symbol',\n",
       "   'represent',\n",
       "   'common',\n",
       "   'set'],\n",
       "  ['superscript',\n",
       "   'compare',\n",
       "   'combine',\n",
       "   'set',\n",
       "   'expression',\n",
       "   'indicate',\n",
       "   'set',\n",
       "   'subset',\n",
       "   'set',\n",
       "   'mean',\n",
       "   'element',\n",
       "   'also',\n",
       "   'element',\n",
       "   'could'],\n",
       "  ['example',\n",
       "   'rational_number',\n",
       "   'real_number',\n",
       "   'complex',\n",
       "   'number',\n",
       "   'integer'],\n",
       "  ['memory',\n",
       "   'trick',\n",
       "   'notice',\n",
       "   'point',\n",
       "   'small',\n",
       "   'set',\n",
       "   'sign',\n",
       "   'point',\n",
       "   'small',\n",
       "   'number'],\n",
       "  ['actually', 'connection', 'go', 'little', 'symbol', 'analogous'],\n",
       "  ['thus', 'mean', 'subset', 'equal'],\n",
       "  ['set'],\n",
       "  ['several', 'way', 'combine', 'set'],\n",
       "  ['let',\n",
       "   'define',\n",
       "   'couple',\n",
       "   'set',\n",
       "   'use',\n",
       "   'example',\n",
       "   'wwd',\n",
       "   'wwd',\n",
       "   'union_set',\n",
       "   'denote',\n",
       "   'contain',\n",
       "   'element',\n",
       "   'appear'],\n",
       "  ['thus'],\n",
       "  ['hard',\n",
       "   'develop',\n",
       "   'notion',\n",
       "   'multiset',\n",
       "   'element',\n",
       "   'occur',\n",
       "   'multiset',\n",
       "   'ordinary',\n",
       "   'set'],\n",
       "  ['intersection', 'denote', 'consist', 'element', 'appear'],\n",
       "  ['set', 'difference', 'denote', 'consist', 'element'],\n",
       "  ['therefore'],\n",
       "  ['complement', 'set', 'sometimes', 'focus', 'particular', 'domain'],\n",
       "  ['subset', 'define', 'set', 'element'],\n",
       "  ['wwd'],\n",
       "  ['set', 'call', 'complement'],\n",
       "  ['example',\n",
       "   'domain',\n",
       "   'work',\n",
       "   'real_number',\n",
       "   'com',\n",
       "   'plement',\n",
       "   'positive',\n",
       "   'real_number',\n",
       "   'set',\n",
       "   'negative',\n",
       "   'real_number',\n",
       "   'together'],\n",
       "  ['helpful', 'rephrase', 'propertie', 'set', 'use', 'complement'],\n",
       "  ['example', 'set', 'say', 'disjoint', 'iff', 'element', 'common'],\n",
       "  ['say', 'subset', 'complement'],\n",
       "  ['cardinality', 'cardinality', 'set', 'number', 'element', 'denote', 'jaj'],\n",
       "  ['example', 'jf', 'gj', 'jnj', 'infinite'],\n",
       "  ['power', 'set', 'set', 'subset', 'set', 'call', 'power', 'set'],\n",
       "  ['iff'],\n",
       "  ['example', 'element'],\n",
       "  ['generally',\n",
       "   'element',\n",
       "   'jaj',\n",
       "   'sequence',\n",
       "   'set',\n",
       "   'provide',\n",
       "   'way',\n",
       "   'group',\n",
       "   'collection',\n",
       "   'object'],\n",
       "  ['way', 'quence', 'list', 'object', 'call', 'term', 'component'],\n",
       "  ['short',\n",
       "   'sequences',\n",
       "   'chapter_pattern',\n",
       "   'proof',\n",
       "   'commonly',\n",
       "   'describe',\n",
       "   'list_element',\n",
       "   'parenthese',\n",
       "   'example'],\n",
       "  ['sequence', 'term'],\n",
       "  ['set',\n",
       "   'sequence',\n",
       "   'perform',\n",
       "   'gather',\n",
       "   'role',\n",
       "   'several',\n",
       "   'differ',\n",
       "   'ence'],\n",
       "  ['element_set', 'require', 'distinct', 'term', 'sequence'],\n",
       "  ['thus'],\n",
       "  ['valid', 'sequence', 'length', 'ag', 'set', 'element'],\n",
       "  ['term', 'sequence', 'specify', 'order', 'element_set'],\n",
       "  ['example'],\n",
       "  ['different', 'sequence', 'bg', 'set'],\n",
       "  ['texts',\n",
       "   'differ',\n",
       "   'notation',\n",
       "   'empty',\n",
       "   'sequence',\n",
       "   'use',\n",
       "   'empty',\n",
       "   'sequence',\n",
       "   'empty',\n",
       "   'set'],\n",
       "  ['cross', 'products', 'product', 'operation', 'link', 'set', 'sequence'],\n",
       "  ['product', 'set', 'bg'],\n",
       "  ['product', 'copy', 'set', 'denote']],\n",
       " [['set',\n",
       "   'builder',\n",
       "   'notation',\n",
       "   'important',\n",
       "   'use',\n",
       "   'predicate',\n",
       "   'set',\n",
       "   'builder',\n",
       "   'notation'],\n",
       "  ['often',\n",
       "   'want',\n",
       "   'talk',\n",
       "   'set',\n",
       "   'can',\n",
       "   'describe',\n",
       "   'well',\n",
       "   'list_element',\n",
       "   'explicitly',\n",
       "   'take',\n",
       "   'union',\n",
       "   'intersection'],\n",
       "  ['easily', 'describe', 'set'],\n",
       "  ['set', 'builder', 'notation', 'often', 'come', 'rescue'],\n",
       "  ['idea',\n",
       "   'define',\n",
       "   'set',\n",
       "   'use',\n",
       "   'predicate',\n",
       "   'particular',\n",
       "   'set',\n",
       "   'consist',\n",
       "   'value',\n",
       "   'make',\n",
       "   'predicate',\n",
       "   'true'],\n",
       "  ['example',\n",
       "   'set',\n",
       "   'builder',\n",
       "   'notation',\n",
       "   'wwd',\n",
       "   'fn',\n",
       "   'prime',\n",
       "   'integer',\n",
       "   'kg',\n",
       "   'wwd',\n",
       "   'fx',\n",
       "   'wwd',\n",
       "   'bi',\n",
       "   'set',\n",
       "   'consist',\n",
       "   'nonnegative_integer',\n",
       "   'predicate',\n",
       "   'try',\n",
       "   'indicate',\n",
       "   'set',\n",
       "   'true'],\n",
       "  ['case',\n",
       "   'explicit',\n",
       "   'description',\n",
       "   'set',\n",
       "   'oval',\n",
       "   'shaped',\n",
       "   'region',\n",
       "   'origin',\n",
       "   'complex',\n",
       "   'plane']],\n",
       " [['prove', 'set', 'equality', 'set', 'define', 'equal', 'contain', 'element'],\n",
       "  ['theorem'],\n",
       "  ['distributive', 'law', 'set'],\n",
       "  ['let', 'proof'],\n",
       "  ['equality',\n",
       "   'prove',\n",
       "   'section',\n",
       "   'proposition',\n",
       "   'chapter_pattern',\n",
       "   'proof',\n",
       "   'many',\n",
       "   'set',\n",
       "   'equality',\n",
       "   'derive',\n",
       "   'valid',\n",
       "   'proposition',\n",
       "   'prove',\n",
       "   'analogous',\n",
       "   'manner'],\n",
       "  ['particular',\n",
       "   'proposition',\n",
       "   'place',\n",
       "   'set',\n",
       "   'replace',\n",
       "   'complement',\n",
       "   'example',\n",
       "   'would',\n",
       "   'become',\n",
       "   'iff']],\n",
       " [['russell_paradox',\n",
       "   'logic',\n",
       "   'set',\n",
       "   'reason',\n",
       "   'naively',\n",
       "   'set',\n",
       "   'sometimes',\n",
       "   'tricky'],\n",
       "  ['fact',\n",
       "   'early',\n",
       "   'tempt',\n",
       "   'come',\n",
       "   'precise',\n",
       "   'axiom',\n",
       "   'set',\n",
       "   'late',\n",
       "   'nineteenth',\n",
       "   'century',\n",
       "   'logician',\n",
       "   'name',\n",
       "   'gotlob',\n",
       "   'frege',\n",
       "   'shoot',\n",
       "   'line',\n",
       "   'argument',\n",
       "   'know',\n",
       "   'russell_paradox',\n",
       "   'astonish',\n",
       "   'blow',\n",
       "   'effort',\n",
       "   'provide',\n",
       "   'axiomatic',\n",
       "   'founda',\n",
       "   'tion',\n",
       "   'mathematic'],\n",
       "  ['russell_paradox',\n",
       "   'let',\n",
       "   'variable_range',\n",
       "   'set',\n",
       "   'define',\n",
       "   'wwd',\n",
       "   'fs',\n",
       "   'sg',\n",
       "   'definition',\n",
       "   'set',\n",
       "   'iff',\n",
       "   'particular',\n",
       "   'let',\n",
       "   'obtain',\n",
       "   'contradictory',\n",
       "   'result',\n",
       "   'iff',\n",
       "   'way',\n",
       "   'paradox',\n",
       "   'clear',\n",
       "   'russell',\n",
       "   'others',\n",
       "   'time',\n",
       "   'unjus',\n",
       "   'tifie',\n",
       "   'assume',\n",
       "   'set'],\n",
       "  ['step', 'proof', 'let', 'justification', 'range', 'set', 'may', 'set'],\n",
       "  ['fact',\n",
       "   'paradox',\n",
       "   'imply',\n",
       "   'better',\n",
       "   'set',\n",
       "   'denying',\n",
       "   'set',\n",
       "   'mean',\n",
       "   'must',\n",
       "   'reject',\n",
       "   'natural',\n",
       "   'axiom',\n",
       "   'mathematically',\n",
       "   'well',\n",
       "   'define',\n",
       "   'collection',\n",
       "   'element',\n",
       "   'actually',\n",
       "   'set'],\n",
       "  ['problem',\n",
       "   'face',\n",
       "   'frege',\n",
       "   'russell',\n",
       "   'colleague',\n",
       "   'specify',\n",
       "   'bertrand',\n",
       "   'russell',\n",
       "   'mathematician',\n",
       "   'logician',\n",
       "   'cambridge',\n",
       "   'university',\n",
       "   'turn',\n",
       "   'twen',\n",
       "   'tieth',\n",
       "   'century'],\n",
       "  ['report',\n",
       "   'feel',\n",
       "   'old',\n",
       "   'mathematic',\n",
       "   'begin',\n",
       "   'study',\n",
       "   'write',\n",
       "   'philosophy',\n",
       "   'longer',\n",
       "   'smart',\n",
       "   'enough',\n",
       "   'philosophy',\n",
       "   'begin',\n",
       "   'write',\n",
       "   'politic'],\n",
       "  ['jail', 'conscientious', 'objector', 'world', 'war'],\n",
       "  ['extensive',\n",
       "   'philosophical',\n",
       "   'political',\n",
       "   'writing',\n",
       "   'nobel',\n",
       "   'prize',\n",
       "   'literature'],\n",
       "  ['define', 'collection', 'set'],\n",
       "  ['russell',\n",
       "   'fellow',\n",
       "   'cambridge',\n",
       "   'university',\n",
       "   'col',\n",
       "   'league',\n",
       "   'whitehead',\n",
       "   'immediately',\n",
       "   'go',\n",
       "   'work',\n",
       "   'problem'],\n",
       "  ['spend',\n",
       "   'dozen',\n",
       "   'year',\n",
       "   'develop',\n",
       "   'huge',\n",
       "   'new',\n",
       "   'axiom',\n",
       "   'system',\n",
       "   'even',\n",
       "   'huger',\n",
       "   'monograph',\n",
       "   'call',\n",
       "   'principia',\n",
       "   'mathematica'],\n",
       "  ['time',\n",
       "   'efficient',\n",
       "   'axiom',\n",
       "   'system',\n",
       "   'develop',\n",
       "   'today',\n",
       "   'gen',\n",
       "   'erally',\n",
       "   'agree',\n",
       "   'use',\n",
       "   'simple',\n",
       "   'logical_deduction',\n",
       "   'rule',\n",
       "   'essentially',\n",
       "   'mathematic',\n",
       "   'derive',\n",
       "   'axiom',\n",
       "   'zermelo',\n",
       "   'frankel',\n",
       "   'set',\n",
       "   'theory',\n",
       "   'choice',\n",
       "   'zfc'],\n",
       "  ['go',\n",
       "   'work',\n",
       "   'axiom',\n",
       "   'course',\n",
       "   'case',\n",
       "   'interested',\n",
       "   'include',\n",
       "   'sidebar'],\n",
       "  ['zfc',\n",
       "   'axiom',\n",
       "   'avoid',\n",
       "   'russell_paradox',\n",
       "   'imply',\n",
       "   'set',\n",
       "   'ever',\n",
       "   'member'],\n",
       "  ['unfortunately',\n",
       "   'necessarily',\n",
       "   'mean',\n",
       "   'paradox',\n",
       "   'lurk',\n",
       "   'around',\n",
       "   'wait',\n",
       "   'uncovered',\n",
       "   'future',\n",
       "   'mathematician'],\n",
       "  ['zfc', 'axiom', 'extensionality'],\n",
       "  ['set', 'equal', 'member'],\n",
       "  ['formal', 'log', 'ical', 'notation', 'would', 'state'],\n",
       "  ['iff', 'imply', 'pair'],\n",
       "  ['set', 'iff', 'union'],\n",
       "  ['union'],\n",
       "  ['iff', 'infinity'],\n",
       "  ['infinite_set'],\n",
       "  ['specifically', 'nonempty_set', 'also', 'member', 'subset'],\n",
       "  ['give', 'set'],\n",
       "  ['power', 'set'],\n",
       "  ['subset', 'set', 'form', 'set', 'iff', 'replacement'],\n",
       "  ['suppose', 'formula'],\n",
       "  ['imply', 'chapter_pattern', 'proof', 'image_set'],\n",
       "  ['iff', 'foundation'],\n",
       "  ['can', 'infinite', 'sequence', 'set', 'member', 'previous'],\n",
       "  ['equivalent', 'say', 'nonempty_set', 'member', 'minimal_element'],\n",
       "  ['namely',\n",
       "   'define',\n",
       "   'member',\n",
       "   'minimal',\n",
       "   'foundation',\n",
       "   'axiom',\n",
       "   'imply',\n",
       "   'choice'],\n",
       "  ['give', 'set']],\n",
       " [['good',\n",
       "   'proofs',\n",
       "   'practice',\n",
       "   'purpose',\n",
       "   'proof',\n",
       "   'establish',\n",
       "   'truth',\n",
       "   'assertion',\n",
       "   'absolute',\n",
       "   'cer',\n",
       "   'tainty'],\n",
       "  ['mechanically',\n",
       "   'checkable',\n",
       "   'proofs',\n",
       "   'enormous',\n",
       "   'length',\n",
       "   'complexity',\n",
       "   'complish'],\n",
       "  ['humanly',\n",
       "   'intelligible',\n",
       "   'proofs',\n",
       "   'one',\n",
       "   'help',\n",
       "   'understand',\n",
       "   'subject'],\n",
       "  ['mathematician',\n",
       "   'generally',\n",
       "   'agree',\n",
       "   'important',\n",
       "   'mathemati',\n",
       "   'cal',\n",
       "   'result',\n",
       "   'fully',\n",
       "   'understand',\n",
       "   'proofs',\n",
       "   'understand'],\n",
       "  ['proofs', 'important', 'part', 'curriculum'],\n",
       "  ['understandable',\n",
       "   'helpful',\n",
       "   'require',\n",
       "   'proof',\n",
       "   'logical',\n",
       "   'correctness',\n",
       "   'good',\n",
       "   'proof',\n",
       "   'must_also',\n",
       "   'clear'],\n",
       "  ['correctness',\n",
       "   'clarity',\n",
       "   'usually',\n",
       "   'go',\n",
       "   'together',\n",
       "   'well',\n",
       "   'write',\n",
       "   'proof',\n",
       "   'likely',\n",
       "   'correct',\n",
       "   'proof',\n",
       "   'mistake',\n",
       "   'harder',\n",
       "   'hide'],\n",
       "  ['practice', 'notion', 'proof', 'move', 'target'],\n",
       "  ['proofs',\n",
       "   'professional',\n",
       "   'research',\n",
       "   'journal',\n",
       "   'generally',\n",
       "   'unintelligible',\n",
       "   'expert',\n",
       "   'know',\n",
       "   'terminology',\n",
       "   'prior',\n",
       "   'result',\n",
       "   'use',\n",
       "   'proof'],\n",
       "  ['conversely',\n",
       "   'proofs',\n",
       "   'first',\n",
       "   'week',\n",
       "   'introductory',\n",
       "   'course',\n",
       "   'mathematic',\n",
       "   'computer_science',\n",
       "   'would',\n",
       "   'regard',\n",
       "   'tediously',\n",
       "   'long',\n",
       "   'wind',\n",
       "   'professional',\n",
       "   'mathematician'],\n",
       "  ['fact',\n",
       "   'accept',\n",
       "   'good',\n",
       "   'proof',\n",
       "   'later',\n",
       "   'term',\n",
       "   'different',\n",
       "   'consider',\n",
       "   'good',\n",
       "   'proof',\n",
       "   'first',\n",
       "   'couple',\n",
       "   'week'],\n",
       "  ['even',\n",
       "   'offer',\n",
       "   'general',\n",
       "   'tip',\n",
       "   'write',\n",
       "   'good',\n",
       "   'proofs',\n",
       "   'state',\n",
       "   'game',\n",
       "   'plan'],\n",
       "  ['good', 'proof', 'begin', 'explain', 'general', 'line', 'rea', 'sone'],\n",
       "  ['example', 'use', 'case', 'analysis', 'argue', 'contradiction'],\n",
       "  ['keep', 'linear', 'flow'],\n",
       "  ['sometimes',\n",
       "   'proofs',\n",
       "   'write',\n",
       "   'mathematical',\n",
       "   'mosaic',\n",
       "   'juicy',\n",
       "   'tidbit',\n",
       "   'independent',\n",
       "   'reasoning',\n",
       "   'sprinkle'],\n",
       "  ['good'],\n",
       "  ['step', 'argument', 'follow', 'one', 'intelligible', 'order'],\n",
       "  ['proof', 'essay', 'calculation'],\n",
       "  ['many',\n",
       "   'student',\n",
       "   'initially',\n",
       "   'write',\n",
       "   'proofs',\n",
       "   'way',\n",
       "   'compute',\n",
       "   'integral'],\n",
       "  ['result',\n",
       "   'long',\n",
       "   'sequence',\n",
       "   'expression',\n",
       "   'explanation',\n",
       "   'make',\n",
       "   'hard',\n",
       "   'follow'],\n",
       "  ['bad'],\n",
       "  ['good', 'proof', 'usually', 'look', 'essay', 'equation', 'throw'],\n",
       "  ['use', 'complete', 'sentence'],\n",
       "  ['avoid', 'excessive', 'symbolism'],\n",
       "  ['reader',\n",
       "   'probably',\n",
       "   'good',\n",
       "   'understanding',\n",
       "   'word',\n",
       "   'much',\n",
       "   'less',\n",
       "   'skilled',\n",
       "   'reading',\n",
       "   'arcane',\n",
       "   'mathematical',\n",
       "   'symbol'],\n",
       "  ['use', 'word', 'reasonably'],\n",
       "  ['revise', 'simplify'],\n",
       "  ['reader', 'grateful'],\n",
       "  ['introduce', 'notation', 'thoughtfully'],\n",
       "  ['sometimes',\n",
       "   'argument',\n",
       "   'greatly',\n",
       "   'simpli',\n",
       "   'fie',\n",
       "   'introduce',\n",
       "   'variable',\n",
       "   'devise',\n",
       "   'special',\n",
       "   'notation',\n",
       "   'define',\n",
       "   'new',\n",
       "   'term'],\n",
       "  ['sparingly', 'require', 'reader', 'remember', 'new', 'stuff'],\n",
       "  ['remember',\n",
       "   'actually',\n",
       "   'define',\n",
       "   'meaning',\n",
       "   'new',\n",
       "   'variable',\n",
       "   'term',\n",
       "   'notation',\n",
       "   'start',\n",
       "   'use',\n",
       "   'structure',\n",
       "   'long',\n",
       "   'proofs'],\n",
       "  ['long', 'program', 'usually', 'break', 'hierarchy', 'small', 'procedure'],\n",
       "  ['long', 'proofs', 'much'],\n",
       "  ['fact',\n",
       "   'need',\n",
       "   'proof',\n",
       "   'easily',\n",
       "   'state',\n",
       "   'readily',\n",
       "   'prove',\n",
       "   'best',\n",
       "   'pull',\n",
       "   'prove',\n",
       "   'pre',\n",
       "   'liminary',\n",
       "   'lemmas'],\n",
       "  ['also',\n",
       "   'repeat',\n",
       "   'essentially',\n",
       "   'argument',\n",
       "   'try',\n",
       "   'capture',\n",
       "   'argument',\n",
       "   'general',\n",
       "   'lemma',\n",
       "   'cite',\n",
       "   'repeatedly',\n",
       "   'instead'],\n",
       "  ['wary', 'obvious'],\n",
       "  ['familiar',\n",
       "   'truly',\n",
       "   'obvious',\n",
       "   'fact',\n",
       "   'need',\n",
       "   'proof',\n",
       "   'ok',\n",
       "   'label',\n",
       "   'prove'],\n",
       "  ['remember',\n",
       "   'chapter_pattern',\n",
       "   'proof',\n",
       "   'obvious',\n",
       "   'may',\n",
       "   'typically',\n",
       "   'obvious',\n",
       "   'reader'],\n",
       "  ['especially',\n",
       "   'use',\n",
       "   'phrase',\n",
       "   'clearly',\n",
       "   'obviously',\n",
       "   'attempt',\n",
       "   'bully',\n",
       "   'reader',\n",
       "   'accept',\n",
       "   'trouble',\n",
       "   'prove'],\n",
       "  ['also', 'go', 'alert', 'whenever', 'see', 'phrase', 'else', 'proof'],\n",
       "  ['finish'],\n",
       "  ['point', 'proof', 'establish', 'essential', 'fact', 'need'],\n",
       "  ['resist',\n",
       "   'temptation',\n",
       "   'quit',\n",
       "   'leave',\n",
       "   'reader',\n",
       "   'draw',\n",
       "   'obvious',\n",
       "   'conclusion'],\n",
       "  ['instead', 'tie', 'together', 'explain', 'original', 'claim', 'follow'],\n",
       "  ['analogy', 'good', 'proofs', 'good', 'program', 'extend', 'structure'],\n",
       "  ['rigorous',\n",
       "   'thinking',\n",
       "   'need',\n",
       "   'proofs',\n",
       "   'essential',\n",
       "   'design',\n",
       "   'criti',\n",
       "   'cal',\n",
       "   'computer',\n",
       "   'system'],\n",
       "  ['algorithms',\n",
       "   'protocol',\n",
       "   'mostly',\n",
       "   'work',\n",
       "   'due',\n",
       "   'reliance',\n",
       "   'hand',\n",
       "   'waving',\n",
       "   'argument',\n",
       "   'result',\n",
       "   'range',\n",
       "   'problematic',\n",
       "   'catastrophic'],\n",
       "  ['early',\n",
       "   'example',\n",
       "   'therac',\n",
       "   'machine',\n",
       "   'provide',\n",
       "   'radia',\n",
       "   'tion',\n",
       "   'therapy',\n",
       "   'cancer',\n",
       "   'victim',\n",
       "   'occasionally',\n",
       "   'kill',\n",
       "   'massive',\n",
       "   'overdose',\n",
       "   'due',\n",
       "   'software',\n",
       "   'race',\n",
       "   'condition'],\n",
       "  ['recent',\n",
       "   'august',\n",
       "   'example',\n",
       "   'involve',\n",
       "   'single',\n",
       "   'faulty',\n",
       "   'command',\n",
       "   'computer',\n",
       "   'system',\n",
       "   'use',\n",
       "   'united',\n",
       "   'american',\n",
       "   'airlines',\n",
       "   'ground',\n",
       "   'entire',\n",
       "   'fleet',\n",
       "   'company',\n",
       "   'passenger',\n",
       "   'certainty',\n",
       "   'day',\n",
       "   'mercy',\n",
       "   'critical',\n",
       "   'computer',\n",
       "   'system',\n",
       "   'design',\n",
       "   'classmate'],\n",
       "  ['really',\n",
       "   'hope',\n",
       "   'develop',\n",
       "   'ability',\n",
       "   'formulate',\n",
       "   'rock',\n",
       "   'solid',\n",
       "   'logical',\n",
       "   'argument',\n",
       "   'system',\n",
       "   'actually',\n",
       "   'think']],\n",
       " [['induction',\n",
       "   'understand',\n",
       "   'basic',\n",
       "   'prove',\n",
       "   'proposition_true',\n",
       "   'time',\n",
       "   'equip',\n",
       "   'powerful',\n",
       "   'method',\n",
       "   'establish',\n",
       "   'truth',\n",
       "   'well_order',\n",
       "   'principle',\n",
       "   'induction',\n",
       "   'rule',\n",
       "   'strong_induction'],\n",
       "  ['method',\n",
       "   'especially',\n",
       "   'useful',\n",
       "   'nee',\n",
       "   'prove',\n",
       "   'predicate',\n",
       "   'true',\n",
       "   'natural_number'],\n",
       "  ['method',\n",
       "   'look',\n",
       "   'feel',\n",
       "   'different',\n",
       "   'turn',\n",
       "   'equivalent',\n",
       "   'sense',\n",
       "   'proof',\n",
       "   'use',\n",
       "   'method',\n",
       "   'automat',\n",
       "   'ically',\n",
       "   'reformatte',\n",
       "   'become',\n",
       "   'proof',\n",
       "   'use',\n",
       "   'method'],\n",
       "  ['choice',\n",
       "   'method',\n",
       "   'use',\n",
       "   'typically',\n",
       "   'depend',\n",
       "   'seem',\n",
       "   'easy',\n",
       "   'natural',\n",
       "   'problem',\n",
       "   'hand']],\n",
       " [['order_principle',\n",
       "   'nonempty_set',\n",
       "   'nonnegative_integer',\n",
       "   'small',\n",
       "   'element'],\n",
       "  ['statement', 'know', 'well_order', 'principle'],\n",
       "  ['believe',\n",
       "   'seem',\n",
       "   'sort',\n",
       "   'obvious',\n",
       "   'right',\n",
       "   'notice',\n",
       "   'tight',\n",
       "   'require',\n",
       "   'nonempty_set',\n",
       "   'false',\n",
       "   'empty',\n",
       "   'set',\n",
       "   'small',\n",
       "   'element',\n",
       "   'element',\n",
       "   'require',\n",
       "   'set',\n",
       "   'nonnegative_integer',\n",
       "   'false',\n",
       "   'set',\n",
       "   'negative',\n",
       "   'integer',\n",
       "   'also',\n",
       "   'false',\n",
       "   'set',\n",
       "   'nonnegative',\n",
       "   'rational',\n",
       "   'example',\n",
       "   'set',\n",
       "   'positive',\n",
       "   'rational'],\n",
       "  ['order_principle', 'capture', 'special', 'nonnegative_integer']],\n",
       " [['order',\n",
       "   'proofs',\n",
       "   'well_order',\n",
       "   'principle',\n",
       "   'may_seem',\n",
       "   'obvious',\n",
       "   'hard',\n",
       "   'see',\n",
       "   'offhand',\n",
       "   'useful'],\n",
       "  ['fact', 'provide', 'important', 'proof', 'rule', 'discrete', 'mathematic'],\n",
       "  ['fact',\n",
       "   'look',\n",
       "   'back',\n",
       "   'take',\n",
       "   'well_order',\n",
       "   'principle',\n",
       "   'grant',\n",
       "   'prove',\n",
       "   'irrational'],\n",
       "  ['proof',\n",
       "   'assume',\n",
       "   'positive_integer',\n",
       "   'fraction',\n",
       "   'write',\n",
       "   'low',\n",
       "   'term',\n",
       "   'form',\n",
       "   'way',\n",
       "   'express',\n",
       "   'leave_hand',\n",
       "   'fraction',\n",
       "   'low',\n",
       "   'term',\n",
       "   'would',\n",
       "   'also',\n",
       "   'work',\n",
       "   'fraction',\n",
       "   'definition',\n",
       "   'numerator',\n",
       "   'assumption',\n",
       "   'nonempty',\n",
       "   'lead',\n",
       "   'contradiction',\n",
       "   'follow',\n",
       "   'must',\n",
       "   'empty'],\n",
       "  ['numerator', 'fraction', 'write', 'low', 'term', 'hence', 'fraction'],\n",
       "  ['use_well', 'order_principle', 'sly', 'early']],\n",
       " [['template', 'well_order', 'proof', 'generally', 'prove'],\n",
       "  ['true',\n",
       "   'use_well',\n",
       "   'order_principle',\n",
       "   'take',\n",
       "   'follow',\n",
       "   'step_define',\n",
       "   'set',\n",
       "   'counterexample',\n",
       "   'true'],\n",
       "  ['namely', 'define', 'use', 'proof_contradiction', 'assume', 'nonempty'],\n",
       "  ['order_principle', 'small', 'element'],\n",
       "  ['reach',\n",
       "   'contradiction',\n",
       "   'somehow',\n",
       "   'often',\n",
       "   'show',\n",
       "   'use',\n",
       "   'find',\n",
       "   'member',\n",
       "   'small'],\n",
       "  ['open', 'ended', 'part', 'proof', 'task'],\n",
       "  ['conclude', 'must', 'empty', 'counterexample', 'exist'],\n",
       "  ['qed', 'mean', 'see', 'informal', 'proof_contradiction'],\n",
       "  ['learned', 'section']],\n",
       " [['example', 'let', 'use', 'template', 'prove', 'nonnegative_integer'],\n",
       "  ['first',\n",
       "   'well',\n",
       "   'address',\n",
       "   'couple',\n",
       "   'ambiguous',\n",
       "   'special_case',\n",
       "   'trip',\n",
       "   'term',\n",
       "   'summation',\n",
       "   'term'],\n",
       "  ['mislead',\n",
       "   'appearance',\n",
       "   'suggestion',\n",
       "   'distinct',\n",
       "   'term',\n",
       "   'term',\n",
       "   'summation'],\n",
       "  ['convention', 'sum', 'case'],\n",
       "  ['dot',\n",
       "   'notation',\n",
       "   'convenient',\n",
       "   'watch',\n",
       "   'special_case',\n",
       "   'notation',\n",
       "   'mislead',\n",
       "   'fact',\n",
       "   'whenever',\n",
       "   'see',\n",
       "   'dot',\n",
       "   'lookout',\n",
       "   'sure',\n",
       "   'understand',\n",
       "   'pattern',\n",
       "   'watch',\n",
       "   'begin_end'],\n",
       "  ['could',\n",
       "   'eliminate',\n",
       "   'need',\n",
       "   'guess',\n",
       "   'rewrite',\n",
       "   'left',\n",
       "   'side',\n",
       "   'summation',\n",
       "   'notation',\n",
       "   'would',\n",
       "   'expression',\n",
       "   'denote',\n",
       "   'sum',\n",
       "   'value',\n",
       "   'take',\n",
       "   'expression',\n",
       "   'right',\n",
       "   'sigma',\n",
       "   'variable_range'],\n",
       "  ['expression', 'make', 'clear', 'back', 'proof', 'proof'],\n",
       "  ['contradiction', 'use_well', 'order_principle'],\n",
       "  ['assume', 'theorem', 'false'],\n",
       "  ['nonnegative_integer', 'serve', 'counterexample'],\n",
       "  ['let', 'collect', 'set', 'wwd'],\n",
       "  ['result', 'prove', 'use_well', 'ordering'],\n",
       "  ['useful', 'chapter', 'study', 'number_theory', 'cryptography'],\n",
       "  ['theorem'],\n",
       "  ['natural_number', 'factor', 'product_prime'],\n",
       "  ['proof'],\n",
       "  ['contradiction', 'well_order'],\n",
       "  ['assume',\n",
       "   'theorem',\n",
       "   'false',\n",
       "   'let',\n",
       "   'set',\n",
       "   'integer',\n",
       "   'great',\n",
       "   'can',\n",
       "   'factor',\n",
       "   'product_prime'],\n",
       "  ['assume', 'empty', 'derive', 'contradiction'],\n",
       "  ['empty', 'least', 'element', 'well_order'],\n",
       "  ['prime', 'prime', 'consider', 'length', 'product_prime', 'product'],\n",
       "  ['must', 'product', 'integer'],\n",
       "  ['small', 'small', 'element', 'know'],\n",
       "  ['word', 'write', 'product_prime', 'must', 'therefore', 'false']],\n",
       " [['ordinary_induction',\n",
       "   'induction',\n",
       "   'far',\n",
       "   'powerful',\n",
       "   'commonly_use',\n",
       "   'proof',\n",
       "   'technique',\n",
       "   'dis',\n",
       "   'crete',\n",
       "   'mathematics',\n",
       "   'computer_science'],\n",
       "  ['fact',\n",
       "   'use_induction',\n",
       "   'define',\n",
       "   'characteristic',\n",
       "   'discrete',\n",
       "   'oppose',\n",
       "   'continuous',\n",
       "   'mathematic'],\n",
       "  ['understand',\n",
       "   'work',\n",
       "   'suppose',\n",
       "   'professor',\n",
       "   'bring',\n",
       "   'class',\n",
       "   'bottomless',\n",
       "   'bag',\n",
       "   'assort',\n",
       "   'miniature',\n",
       "   'candy_bar'],\n",
       "  ['offer', 'share', 'candy', 'following', 'way'],\n",
       "  ['first', 'line', 'student', 'order'],\n",
       "  ['next', 'state', 'rule', 'student', 'begin', 'line', 'get_candy_bar'],\n",
       "  ['student_get_candy',\n",
       "   'bar',\n",
       "   'follow',\n",
       "   'student',\n",
       "   'line',\n",
       "   'also',\n",
       "   'get_candy_bar'],\n",
       "  ['let',\n",
       "   'number',\n",
       "   'student',\n",
       "   'order',\n",
       "   'line',\n",
       "   'start',\n",
       "   'count',\n",
       "   'usual',\n",
       "   'computer_science'],\n",
       "  ['understand',\n",
       "   'second',\n",
       "   'rule',\n",
       "   'short',\n",
       "   'description',\n",
       "   'whole',\n",
       "   'sequence',\n",
       "   'statement',\n",
       "   'student_get_candy',\n",
       "   'bar',\n",
       "   'student',\n",
       "   'also',\n",
       "   'get'],\n",
       "  ['student_get_candy', 'bar', 'student', 'also', 'get'],\n",
       "  ['student_get_candy', 'bar', 'student', 'also', 'get'],\n",
       "  ['course',\n",
       "   'sequence',\n",
       "   'concise',\n",
       "   'mathematical',\n",
       "   'description',\n",
       "   'student_get_candy',\n",
       "   'bar',\n",
       "   'student_get_candy',\n",
       "   'bar',\n",
       "   'nonnegative_integer'],\n",
       "  ['suppose', 'student'],\n",
       "  ['rule',\n",
       "   'entitle',\n",
       "   'miniature',\n",
       "   'candy_bar',\n",
       "   'well',\n",
       "   'student_get_candy',\n",
       "   'bar',\n",
       "   'first',\n",
       "   'rule'],\n",
       "  ['therefore',\n",
       "   'second',\n",
       "   'rule',\n",
       "   'student',\n",
       "   'also',\n",
       "   'get',\n",
       "   'mean',\n",
       "   'student',\n",
       "   'get',\n",
       "   'mean',\n",
       "   'student',\n",
       "   'get',\n",
       "   'well'],\n",
       "  ['application',\n",
       "   'professor',\n",
       "   'second',\n",
       "   'rule',\n",
       "   'candy_bar',\n",
       "   'course',\n",
       "   'rule',\n",
       "   'actually',\n",
       "   'guarantee',\n",
       "   'candy_bar',\n",
       "   'student',\n",
       "   'matter',\n",
       "   'far',\n",
       "   'back',\n",
       "   'line',\n",
       "   'may']],\n",
       " [['rule',\n",
       "   'ordinary_induction',\n",
       "   'reasoning',\n",
       "   'lead',\n",
       "   'conclude',\n",
       "   'student_get_candy',\n",
       "   'bar',\n",
       "   'essen',\n",
       "   'tially',\n",
       "   'induction'],\n",
       "  ['chapter_induction', 'principle', 'induction'],\n",
       "  ['let'],\n",
       "  ['predicate'],\n",
       "  ['true'],\n",
       "  ['imply'],\n",
       "  ['true', 'nonnegative_integer'],\n",
       "  ['go',\n",
       "   'consider',\n",
       "   'several',\n",
       "   'useful',\n",
       "   'variant',\n",
       "   'induction',\n",
       "   'later',\n",
       "   'sec',\n",
       "   'tion',\n",
       "   'refer',\n",
       "   'induction',\n",
       "   'method',\n",
       "   'describe',\n",
       "   'ordinary_induction',\n",
       "   'need',\n",
       "   'distinguish'],\n",
       "  ['formulated', 'proof', 'rule', 'would', 'rule'],\n",
       "  ['induction', 'rule'],\n",
       "  ['imply'],\n",
       "  ['general',\n",
       "   'induction',\n",
       "   'rule',\n",
       "   'work',\n",
       "   'intuitive',\n",
       "   'reason',\n",
       "   'stu',\n",
       "   'dent',\n",
       "   'get_candy_bar',\n",
       "   'hope',\n",
       "   'explanation',\n",
       "   'use',\n",
       "   'candy_bar',\n",
       "   'make',\n",
       "   'clear',\n",
       "   'soundness',\n",
       "   'ordinary_induction',\n",
       "   'take',\n",
       "   'grant'],\n",
       "  ['fact',\n",
       "   'rule',\n",
       "   'obvious',\n",
       "   'hard',\n",
       "   'see',\n",
       "   'basic',\n",
       "   'principle',\n",
       "   'could',\n",
       "   'use',\n",
       "   'justify'],\n",
       "  ['obvious', 'much', 'mileage', 'get', 'use']],\n",
       " [['familiar',\n",
       "   'example',\n",
       "   'ordinary_induction',\n",
       "   'often',\n",
       "   'work',\n",
       "   'directly',\n",
       "   'prove',\n",
       "   'statement',\n",
       "   'negative',\n",
       "   'integer',\n",
       "   'hold'],\n",
       "  ['example',\n",
       "   'formula',\n",
       "   'sum',\n",
       "   'nonnegative_integer',\n",
       "   'already',\n",
       "   'prove',\n",
       "   'equation',\n",
       "   'theorem'],\n",
       "  ['time',\n",
       "   'let',\n",
       "   'use_induction',\n",
       "   'principle',\n",
       "   'prove_theorem',\n",
       "   'suppose',\n",
       "   'define',\n",
       "   'predicate'],\n",
       "  ['equation', 'see', 'section'],\n",
       "  ['true'],\n",
       "  ['imply', 'job', 'reduce', 'prove', 'statement'],\n",
       "  ['first', 'true'],\n",
       "  ['assert', 'sum', 'term', 'equal'],\n",
       "  ['true', 'definition'],\n",
       "  ['second', 'statement', 'complicate'],\n",
       "  ['remember',\n",
       "   'basic',\n",
       "   'plan',\n",
       "   'prove',\n",
       "   'validity',\n",
       "   'implication',\n",
       "   'section',\n",
       "   'equation',\n",
       "   'quite',\n",
       "   'similar',\n",
       "   'fact',\n",
       "   'add'],\n",
       "  ['side_equation'],\n",
       "  ['thus'],\n",
       "  ['true'],\n",
       "  ['argument',\n",
       "   'valid',\n",
       "   'non',\n",
       "   'negative',\n",
       "   'integer',\n",
       "   'establish',\n",
       "   'second',\n",
       "   'fact',\n",
       "   'require',\n",
       "   'induction_principle'],\n",
       "  ['therefore', 'induction_principle', 'say', 'predicate'],\n",
       "  ['true', 'nonnegative_integer', 'theorem_prove']],\n",
       " [['template',\n",
       "   'induction_proof',\n",
       "   'proof_theorem',\n",
       "   'relatively',\n",
       "   'simple',\n",
       "   'even',\n",
       "   'complicated',\n",
       "   'induction_proof',\n",
       "   'follow',\n",
       "   'exactly',\n",
       "   'template'],\n",
       "  ['component', 'state', 'proof', 'use_induction'],\n",
       "  ['immediately',\n",
       "   'convey',\n",
       "   'overall',\n",
       "   'structure',\n",
       "   'proof',\n",
       "   'help',\n",
       "   'reader',\n",
       "   'understand',\n",
       "   'argument'],\n",
       "  ['define', 'appropriate', 'predicate'],\n",
       "  ['eventual', 'conclusion', 'duction', 'argument'],\n",
       "  ['true', 'nonnegative'],\n",
       "  ['thus', 'define', 'predicate'],\n",
       "  ['theorem', 'equivalent', 'follow', 'conclusion'],\n",
       "  ['often',\n",
       "   'predicate',\n",
       "   'lift',\n",
       "   'straight',\n",
       "   'proposition',\n",
       "   'try_prove',\n",
       "   'example'],\n",
       "  ['predicate'],\n",
       "  ['call', 'induction_hypothesis'],\n",
       "  ['sometimes',\n",
       "   'induction_hypothesis',\n",
       "   'involve',\n",
       "   'several',\n",
       "   'variable',\n",
       "   'case',\n",
       "   'indicate',\n",
       "   'variable',\n",
       "   'serve'],\n",
       "  ['chapter_induction', 'prove'],\n",
       "  ['true'],\n",
       "  ['usually', 'easy', 'example'],\n",
       "  ['part', 'proof', 'call', 'base_case', 'basis', 'step'],\n",
       "  ['prove'],\n",
       "  ['imply'],\n",
       "  ['nonnegative_integer'],\n",
       "  ['call', 'inductive_step'],\n",
       "  ['basic', 'plan', 'always', 'assume'],\n",
       "  ['true', 'use', 'assumption', 'prove'],\n",
       "  ['nc', 'true'],\n",
       "  ['statement',\n",
       "   'fairly',\n",
       "   'similar',\n",
       "   'bridge',\n",
       "   'gap',\n",
       "   'may',\n",
       "   'require',\n",
       "   'ingenuity'],\n",
       "  ['argument',\n",
       "   'give',\n",
       "   'must',\n",
       "   'valid',\n",
       "   'non',\n",
       "   'negative',\n",
       "   'integer',\n",
       "   'goal',\n",
       "   'prove',\n",
       "   'implication'],\n",
       "  ['invoke', 'induction'],\n",
       "  ['give', 'facts', 'induction_principle', 'allow', 'conclude'],\n",
       "  ['true', 'nonnegative'],\n",
       "  ['logical',\n",
       "   'capstone',\n",
       "   'whole',\n",
       "   'argument',\n",
       "   'standard',\n",
       "   'usual',\n",
       "   'mention',\n",
       "   'explicitly'],\n",
       "  ['always', 'sure', 'explicitly', 'label', 'base_case', 'inductive_step'],\n",
       "  ['make',\n",
       "   'proofs',\n",
       "   'clear',\n",
       "   'decrease',\n",
       "   'chance',\n",
       "   'forget',\n",
       "   'key',\n",
       "   'step',\n",
       "   'checking',\n",
       "   'base_case']],\n",
       " [['clean',\n",
       "   'writeup',\n",
       "   'proof_theorem',\n",
       "   'give',\n",
       "   'perfectly',\n",
       "   'valid',\n",
       "   'however',\n",
       "   'contain',\n",
       "   'lot',\n",
       "   'extraneous',\n",
       "   'explanation',\n",
       "   'usually',\n",
       "   'see',\n",
       "   'induction_proof'],\n",
       "  ['writeup', 'closer', 'may', 'see', 'print', 'prepare', 'produce'],\n",
       "  ['proof_theorem', 'base_case'],\n",
       "  ['true', 'side_equation'],\n",
       "  ['inductive_step_assume'],\n",
       "  ['true', 'nonnegative_integer'],\n",
       "  ['figure'],\n",
       "  ['induction',\n",
       "   'helpful',\n",
       "   'prove',\n",
       "   'correctness',\n",
       "   'summation',\n",
       "   'formula',\n",
       "   'helpful',\n",
       "   'discover',\n",
       "   'first',\n",
       "   'place'],\n",
       "  ['tricks', 'method', 'find', 'formula', 'cover', 'part', 'iii', 'text']],\n",
       " [['challenge',\n",
       "   'example',\n",
       "   'development',\n",
       "   'mit',\n",
       "   'famous',\n",
       "   'stata',\n",
       "   'center',\n",
       "   'cost',\n",
       "   'rise',\n",
       "   'budget',\n",
       "   'radical',\n",
       "   'fundraising',\n",
       "   'idea'],\n",
       "  ['rumor',\n",
       "   'plan',\n",
       "   'install',\n",
       "   'big',\n",
       "   'courtyard',\n",
       "   'dimension',\n",
       "   'occupy',\n",
       "   'statue',\n",
       "   'wealthy',\n",
       "   'potential',\n",
       "   'donor',\n",
       "   'refer',\n",
       "   'bill',\n",
       "   'purpose',\n",
       "   'preserve',\n",
       "   'anonymity'],\n",
       "  ['complication',\n",
       "   'building',\n",
       "   'unconventional',\n",
       "   'architect',\n",
       "   'frank',\n",
       "   'gehry',\n",
       "   'allege',\n",
       "   'require',\n",
       "   'special',\n",
       "   'shaped',\n",
       "   'tile',\n",
       "   'show_figure',\n",
       "   'theorem'],\n",
       "  ['exist', 'tile', 'proof'],\n",
       "  ['doom', 'attempt', 'proof', 'induction'],\n",
       "  ['let'],\n",
       "  ['proposition',\n",
       "   'exist',\n",
       "   'tile',\n",
       "   'special_case',\n",
       "   'whole',\n",
       "   'courtyard',\n",
       "   'consist',\n",
       "   'single',\n",
       "   'central',\n",
       "   'square',\n",
       "   'otherwise',\n",
       "   'central',\n",
       "   'square'],\n",
       "  ['chapter_induction', 'figure'],\n",
       "  ['special', 'shaped', 'tile'],\n",
       "  ['figure'],\n",
       "  ['tile', 'use', 'shaped', 'tile', 'bill', 'center', 'square'],\n",
       "  ['base_case'],\n",
       "  ['true', 'bill', 'fill', 'whole', 'courtyard'],\n",
       "  ['inductive_step_assume', 'tile', 'nc_nc', 'courtyard', 'bill', 'center'],\n",
       "  ['trouble',\n",
       "   'ability',\n",
       "   'tile',\n",
       "   'small',\n",
       "   'courtyard',\n",
       "   'bill',\n",
       "   'center',\n",
       "   'much',\n",
       "   'help',\n",
       "   'tile',\n",
       "   'large',\n",
       "   'courtyard',\n",
       "   'bill',\n",
       "   'center'],\n",
       "  ['figured', 'bridge', 'gap'],\n",
       "  ['go',\n",
       "   'prove_theorem',\n",
       "   'induction',\n",
       "   'go',\n",
       "   'need',\n",
       "   'induction_hypothesis',\n",
       "   'simply',\n",
       "   'statement',\n",
       "   'try_prove'],\n",
       "  ['happen',\n",
       "   'first',\n",
       "   'fallback',\n",
       "   'look',\n",
       "   'strong_induction',\n",
       "   'hypothesis',\n",
       "   'imply',\n",
       "   'previous',\n",
       "   'hypothesis'],\n",
       "  ['example', 'could', 'make'],\n",
       "  ['proposition',\n",
       "   'location',\n",
       "   'bill',\n",
       "   'advice',\n",
       "   'may',\n",
       "   'sound',\n",
       "   'bizarre',\n",
       "   'prove',\n",
       "   'try_prove',\n",
       "   'thing',\n",
       "   'grander',\n",
       "   'induction',\n",
       "   'argument',\n",
       "   'make_sense'],\n",
       "  ['inductive_step', 'prove'],\n",
       "  ['imply', 'proof', 'successful', 'attempt'],\n",
       "  ['proof', 'induction'],\n",
       "  ['let'],\n",
       "  ['proposition', 'location', 'bill', 'base_case'],\n",
       "  ['true', 'bill', 'fill', 'whole', 'courtyard'],\n",
       "  ['inductive_step_assume'],\n",
       "  ['true',\n",
       "   'location',\n",
       "   'bill',\n",
       "   'nc_nc',\n",
       "   'tile',\n",
       "   'quadrant',\n",
       "   'induction',\n",
       "   'assumption'],\n",
       "  ['replac',\n",
       "   'e',\n",
       "   'temporary',\n",
       "   'bill',\n",
       "   'single',\n",
       "   'shaped',\n",
       "   'tile',\n",
       "   'complete',\n",
       "   'job'],\n",
       "  ['prove'],\n",
       "  ['imply'],\n",
       "  ['thus'],\n",
       "  ['true',\n",
       "   'theorem',\n",
       "   'follow',\n",
       "   'special_case',\n",
       "   'put',\n",
       "   'bill',\n",
       "   'central',\n",
       "   'square'],\n",
       "  ['proof', 'nice', 'property'],\n",
       "  ['first',\n",
       "   'argument',\n",
       "   'guarantee',\n",
       "   'tiling',\n",
       "   'exist',\n",
       "   'also',\n",
       "   'give',\n",
       "   'algorithm',\n",
       "   'finding',\n",
       "   'tiling'],\n",
       "  ['second',\n",
       "   'strong',\n",
       "   'result',\n",
       "   'bill',\n",
       "   'want',\n",
       "   'statue',\n",
       "   'edge',\n",
       "   'courtyard',\n",
       "   'pigeon',\n",
       "   'could',\n",
       "   'accommodate',\n",
       "   'strengthen',\n",
       "   'induction_hypothesis',\n",
       "   'often',\n",
       "   'good',\n",
       "   'move',\n",
       "   'induction_proof',\n",
       "   'go'],\n",
       "  ['keep',\n",
       "   'mind',\n",
       "   'strong',\n",
       "   'assertion',\n",
       "   'must',\n",
       "   'actually',\n",
       "   'chapter_induction',\n",
       "   'figure'],\n",
       "  ['use',\n",
       "   'strong',\n",
       "   'inductive',\n",
       "   'hypothesis',\n",
       "   'prove_theorem',\n",
       "   'true',\n",
       "   'otherwise',\n",
       "   'much',\n",
       "   'hope',\n",
       "   'construct',\n",
       "   'valid',\n",
       "   'proof',\n",
       "   'sometimes',\n",
       "   'find',\n",
       "   'right',\n",
       "   'induction_hypothesis',\n",
       "   'require',\n",
       "   'trial',\n",
       "   'error',\n",
       "   'insight'],\n",
       "  ['example',\n",
       "   'mathematicians',\n",
       "   'spend',\n",
       "   'almost',\n",
       "   'year',\n",
       "   'try_prove',\n",
       "   'disprove',\n",
       "   'conjecture',\n",
       "   'planar_graph',\n",
       "   'choosable']],\n",
       " [['faulty',\n",
       "   'induction_proof',\n",
       "   'do',\n",
       "   'good',\n",
       "   'job',\n",
       "   'writing',\n",
       "   'text',\n",
       "   'right',\n",
       "   'thinking',\n",
       "   'induction',\n",
       "   'stuff',\n",
       "   'hard',\n",
       "   'show'],\n",
       "  ['true'],\n",
       "  ['imply'],\n",
       "  ['number'],\n",
       "  ['would',\n",
       "   'right',\n",
       "   'sometimes',\n",
       "   'start',\n",
       "   'induction_proof',\n",
       "   'run',\n",
       "   'trouble'],\n",
       "  ['example',\n",
       "   'attempt',\n",
       "   'ruin',\n",
       "   'day',\n",
       "   'use_induction',\n",
       "   'prove',\n",
       "   'horse_color'],\n",
       "  ['thought', 'safe', 'skip', 'class', 'work', 'robot', 'program', 'instead'],\n",
       "  ['bummer', 'false', 'theorem'],\n",
       "  ['horse_color'],\n",
       "  ['notice',\n",
       "   'mention',\n",
       "   'assertion',\n",
       "   'go',\n",
       "   'formulate',\n",
       "   'way_make',\n",
       "   'explicit'],\n",
       "  ['particular',\n",
       "   'falsely',\n",
       "   'prove',\n",
       "   'choosability',\n",
       "   'slight',\n",
       "   'generalization',\n",
       "   'colorability'],\n",
       "  ['planar_graph',\n",
       "   'colorable',\n",
       "   'therefore',\n",
       "   'colorable',\n",
       "   'planar_graph',\n",
       "   'choosable'],\n",
       "  ['sound', 'nonsense', 'panic'],\n",
       "  ['discuss', 'graphs', 'planarity', 'color', 'part', 'ii', 'text'],\n",
       "  ['false', 'theorem'],\n",
       "  ['set', 'horse', 'horse_color'],\n",
       "  ['statement',\n",
       "   'integer',\n",
       "   'rather',\n",
       "   'natural',\n",
       "   'use',\n",
       "   'slight',\n",
       "   'variation',\n",
       "   'induction',\n",
       "   'prove'],\n",
       "  ['base_case', 'prove'],\n",
       "  ['imply'],\n",
       "  ['nc', 'inductive_step'],\n",
       "  ['perfectly', 'valid', 'variant', 'induction', 'problem', 'proof'],\n",
       "  ['bogus', 'proof'],\n",
       "  ['proof', 'induction'],\n",
       "  ['induction_hypothesis'],\n",
       "  ['base_case'],\n",
       "  ['true', 'set', 'horse', 'size', 'horse', 'horse', 'definitely', 'color'],\n",
       "  ['inductive_step_assume'],\n",
       "  ['true'],\n",
       "  ['assume', 'set', 'horse_color'],\n",
       "  ['consider',\n",
       "   'set',\n",
       "   'horse',\n",
       "   'nc',\n",
       "   'assumption',\n",
       "   'first',\n",
       "   'horse_color',\n",
       "   'nc',\n",
       "   'also',\n",
       "   'assumption',\n",
       "   'last',\n",
       "   'horse_color',\n",
       "   'nc_nc',\n",
       "   'nc_nc',\n",
       "   'nc',\n",
       "   'principle',\n",
       "   'induction'],\n",
       "  ['true'],\n",
       "  ['prove', 'false', 'math', 'break', 'become', 'poet', 'proof', 'mistake'],\n",
       "  ['first',\n",
       "   'error',\n",
       "   'argument',\n",
       "   'sentence',\n",
       "   'begin',\n",
       "   'nc',\n",
       "   'notation',\n",
       "   'expression',\n",
       "   'nc_nc',\n",
       "   'nc',\n",
       "   'chapter_induction',\n",
       "   'nc',\n",
       "   'mistake',\n",
       "   'knocks',\n",
       "   'critical',\n",
       "   'link',\n",
       "   'induction',\n",
       "   'argument'],\n",
       "  ['prove'],\n",
       "  ['correctly', 'prove'],\n",
       "  ['fail', 'prove'],\n",
       "  ['fall', 'apart', 'conclude'],\n",
       "  ['true'],\n",
       "  ['course',\n",
       "   'proposition',\n",
       "   'false',\n",
       "   'set',\n",
       "   'non',\n",
       "   'uniformly',\n",
       "   'colored',\n",
       "   'horse'],\n",
       "  ['student', 'sometimes', 'claim', 'mistake', 'proof'],\n",
       "  ['false', 'proof', 'assume', 'false', 'namely'],\n",
       "  ['order', 'prove'],\n",
       "  ['think',\n",
       "   'explain',\n",
       "   'student',\n",
       "   'claim',\n",
       "   'would',\n",
       "   'credit',\n",
       "   'math',\n",
       "   'computer_science',\n",
       "   'exam']],\n",
       " [['induction',\n",
       "   'well_order',\n",
       "   'induction',\n",
       "   'rule',\n",
       "   'look',\n",
       "   'order_principle',\n",
       "   'proof',\n",
       "   'method',\n",
       "   'closely',\n",
       "   'relate'],\n",
       "  ['fact',\n",
       "   'example',\n",
       "   'suggest',\n",
       "   'take',\n",
       "   'well_order',\n",
       "   'proof',\n",
       "   'reformat',\n",
       "   'induction_proof'],\n",
       "  ['conversely',\n",
       "   'equally',\n",
       "   'easy',\n",
       "   'take',\n",
       "   'induction_proof',\n",
       "   'reformat',\n",
       "   'well_order',\n",
       "   'proof'],\n",
       "  ['difference',\n",
       "   'sometimes',\n",
       "   'induction_proof',\n",
       "   'clear',\n",
       "   'resemble',\n",
       "   'recursive',\n",
       "   'procedure',\n",
       "   'reduce',\n",
       "   'handle',\n",
       "   'input',\n",
       "   'size',\n",
       "   'handle',\n",
       "   'size'],\n",
       "  ['hand',\n",
       "   'well_order',\n",
       "   'proof',\n",
       "   'sometimes',\n",
       "   'seem',\n",
       "   'natural',\n",
       "   'also',\n",
       "   'come',\n",
       "   'slightly',\n",
       "   'short'],\n",
       "  ['choice', 'method', 'really', 'matter', 'style']],\n",
       " [['invariant',\n",
       "   'important',\n",
       "   'use_induction',\n",
       "   'computer_science',\n",
       "   'involve',\n",
       "   'prove',\n",
       "   'program',\n",
       "   'process',\n",
       "   'preserve',\n",
       "   'desirable',\n",
       "   'property',\n",
       "   'proceed'],\n",
       "  ['property', 'preserve', 'series', 'operation', 'step', 'know', 'invariant'],\n",
       "  ['example',\n",
       "   'desirable',\n",
       "   'invariant',\n",
       "   'include',\n",
       "   'property',\n",
       "   'variable',\n",
       "   'never',\n",
       "   'exceed',\n",
       "   'certain',\n",
       "   'value',\n",
       "   'altitude',\n",
       "   'plane',\n",
       "   'never',\n",
       "   'drop',\n",
       "   'foot',\n",
       "   'wingflap',\n",
       "   'landing',\n",
       "   'gear',\n",
       "   'deploy',\n",
       "   'temperature',\n",
       "   'nuclear',\n",
       "   'reactor',\n",
       "   'never',\n",
       "   'exceed',\n",
       "   'threshold',\n",
       "   'meltdown'],\n",
       "  ['typically', 'use_induction', 'prove', 'proposition', 'invariant'],\n",
       "  ['particu',\n",
       "   'lar',\n",
       "   'show',\n",
       "   'proposition_true',\n",
       "   'beginning',\n",
       "   'base_case',\n",
       "   'true',\n",
       "   'step',\n",
       "   'take',\n",
       "   'also',\n",
       "   'true',\n",
       "   'step',\n",
       "   'inductive_step'],\n",
       "  ['use_induction',\n",
       "   'principle',\n",
       "   'conclude',\n",
       "   'proposition',\n",
       "   'indeed',\n",
       "   'invariant',\n",
       "   'namely',\n",
       "   'always',\n",
       "   'hold']],\n",
       " [['simple',\n",
       "   'example',\n",
       "   'diagonally',\n",
       "   'move',\n",
       "   'robot',\n",
       "   'invariant',\n",
       "   'useful',\n",
       "   'system',\n",
       "   'start',\n",
       "   'state',\n",
       "   'start',\n",
       "   'configuration',\n",
       "   'well',\n",
       "   'define',\n",
       "   'series',\n",
       "   'step',\n",
       "   'system',\n",
       "   'change',\n",
       "   'state'],\n",
       "  ['example_suppose',\n",
       "   'robot',\n",
       "   'walk',\n",
       "   'diagonal',\n",
       "   'infinite',\n",
       "   'dimensional',\n",
       "   'grid'],\n",
       "  ['robot', 'start', 'position'],\n",
       "  ['step',\n",
       "   'move',\n",
       "   'unit',\n",
       "   'vertically',\n",
       "   'leave_right',\n",
       "   'unit',\n",
       "   'horizontally'],\n",
       "  ['clear',\n",
       "   'robot',\n",
       "   'must',\n",
       "   'move',\n",
       "   'exactly',\n",
       "   'unit',\n",
       "   'dimension',\n",
       "   'step',\n",
       "   'traverse',\n",
       "   'diagonal'],\n",
       "  ['example', 'state', 'robot', 'time', 'specify', 'coordinate', 'pair'],\n",
       "  ['denote', 'robot', 'position'],\n",
       "  ['start', 'state'],\n",
       "  ['give', 'robot', 'start', 'position'],\n",
       "  ['first_step',\n",
       "   'robot',\n",
       "   'could',\n",
       "   'states',\n",
       "   'robot',\n",
       "   'ever',\n",
       "   'reach',\n",
       "   'position'],\n",
       "  ['play',\n",
       "   'robot',\n",
       "   'bit',\n",
       "   'become',\n",
       "   'apparent',\n",
       "   'robot',\n",
       "   'never',\n",
       "   'able',\n",
       "   'reach',\n",
       "   'position'],\n",
       "  ['robot', 'reach', 'position'],\n",
       "  ['even'],\n",
       "  ['crucial', 'observation', 'quickly', 'lead', 'formulation', 'predicate'],\n",
       "  ['ww', 'robot', 'state'],\n",
       "  ['step', 'even', 'prove', 'invariant', 'induction'],\n",
       "  ['theorem'],\n",
       "  ['sum', 'robot', 'coordinate', 'always', 'even'],\n",
       "  ['proof'],\n",
       "  ['prove', 'invariant', 'induction'],\n",
       "  ['true', 'robot', 'start'],\n",
       "  ['even'],\n",
       "  ['assume'],\n",
       "  ['true', 'inductive_step'],\n",
       "  ['let'],\n",
       "  ['position', 'robot', 'step'],\n",
       "  ['assume', 'true', 'know', 'even'],\n",
       "  ['case', 'consider', 'step', 'depend', 'direction', 'robot', 'move'],\n",
       "  ['case', 'robot', 'move'],\n",
       "  ['sum', 'coordinate', 'even'],\n",
       "  ['true'],\n",
       "  ['case', 'robot', 'move'],\n",
       "  ['sum', 'coordinate', 'cy', 'even'],\n",
       "  ['true'],\n",
       "  ['system',\n",
       "   'know',\n",
       "   'state',\n",
       "   'machine',\n",
       "   'study',\n",
       "   'great',\n",
       "   'detail',\n",
       "   'chapter',\n",
       "   'first',\n",
       "   'time',\n",
       "   'prove',\n",
       "   'predicate',\n",
       "   'invariant',\n",
       "   'careful',\n",
       "   'go',\n",
       "   'case',\n",
       "   'gory',\n",
       "   'detail'],\n",
       "  ['become', 'experienced', 'proof', 'likely', 'become', 'brief', 'well'],\n",
       "  ['indeed',\n",
       "   'go',\n",
       "   'proof',\n",
       "   'later',\n",
       "   'point',\n",
       "   'text',\n",
       "   'may',\n",
       "   'simply',\n",
       "   'note',\n",
       "   'sum',\n",
       "   'coordinate',\n",
       "   'step',\n",
       "   'cy',\n",
       "   'cy',\n",
       "   'cy',\n",
       "   'therefore',\n",
       "   'sum',\n",
       "   'even']],\n",
       " [['invariant',\n",
       "   'method',\n",
       "   'summary',\n",
       "   'would',\n",
       "   'prove',\n",
       "   'property',\n",
       "   'nice',\n",
       "   'define'],\n",
       "  ['predicate', 'nice', 'nice', 'show'],\n",
       "  ['imply', 'namely', 'nice']],\n",
       " [['challenge',\n",
       "   'example',\n",
       "   'puzzle',\n",
       "   'late',\n",
       "   'century',\n",
       "   'noyes',\n",
       "   'chapman',\n",
       "   'postmaster',\n",
       "   'canastota',\n",
       "   'new',\n",
       "   'york',\n",
       "   'invent',\n",
       "   'puzzle',\n",
       "   'actually',\n",
       "   'dispute',\n",
       "   'really',\n",
       "   'invent',\n",
       "   'puzzle'],\n",
       "  ['sam',\n",
       "   'lloyd',\n",
       "   'well',\n",
       "   'know',\n",
       "   'puzzle',\n",
       "   'designer',\n",
       "   'claim',\n",
       "   'inventor',\n",
       "   'claim',\n",
       "   'discount'],\n",
       "  ['figure'],\n",
       "  ['puzzle', 'start', 'configuration', 'block', 'move', 'hole'],\n",
       "  ['figure'],\n",
       "  ['desire', 'final', 'configuration', 'puzzle'],\n",
       "  ['achieve',\n",
       "   'move',\n",
       "   'block',\n",
       "   'time',\n",
       "   'adjacent',\n",
       "   'hole',\n",
       "   'get',\n",
       "   'block',\n",
       "   'natural',\n",
       "   'order'],\n",
       "  ['picture',\n",
       "   'puzzle',\n",
       "   'show_figure',\n",
       "   'configuration',\n",
       "   'block',\n",
       "   'move',\n",
       "   'hole'],\n",
       "  ['desire',\n",
       "   'final',\n",
       "   'configuration',\n",
       "   'show_figure',\n",
       "   'puzzle',\n",
       "   'become',\n",
       "   'popular',\n",
       "   'north',\n",
       "   'america',\n",
       "   'europe',\n",
       "   'still',\n",
       "   'sell',\n",
       "   'game',\n",
       "   'puzzle',\n",
       "   'shop',\n",
       "   'today'],\n",
       "  ['prize',\n",
       "   'offer',\n",
       "   'solution',\n",
       "   'doubtful',\n",
       "   'ever',\n",
       "   'award',\n",
       "   'impossible',\n",
       "   'get',\n",
       "   'configuration',\n",
       "   'figure',\n",
       "   'move',\n",
       "   'block',\n",
       "   'time',\n",
       "   'adjacent',\n",
       "   'hole'],\n",
       "  ['proof',\n",
       "   'fact',\n",
       "   'little',\n",
       "   'tricky',\n",
       "   'left',\n",
       "   'figure',\n",
       "   'instead',\n",
       "   'prove',\n",
       "   'analogous',\n",
       "   'task',\n",
       "   'much',\n",
       "   'easy',\n",
       "   'puzzle',\n",
       "   'can',\n",
       "   'perform'],\n",
       "  ['proofs', 'course', 'make', 'use', 'invariant', 'method'],\n",
       "  ['chapter_induction', 'figure'],\n",
       "  ['puzzle', 'initial', 'configuration', 'possible', 'move']],\n",
       " [['puzzle', 'puzzle', 'letter', 'tile', 'blank', 'square', 'arrange', 'grid'],\n",
       "  ['letter', 'tile', 'adjacent', 'blank', 'square', 'slide', 'blank'],\n",
       "  ['example',\n",
       "   'sequence',\n",
       "   'move',\n",
       "   'illustrate_figure',\n",
       "   'initial',\n",
       "   'configuration',\n",
       "   'show_figure',\n",
       "   'theorem'],\n",
       "  ['sequence',\n",
       "   'legal',\n",
       "   'move',\n",
       "   'transform',\n",
       "   'configuration',\n",
       "   'fig_ure',\n",
       "   'build',\n",
       "   'sequence',\n",
       "   'observation',\n",
       "   'state',\n",
       "   'lemmas'],\n",
       "  ['achieve',\n",
       "   'critical',\n",
       "   'mass',\n",
       "   'assemble',\n",
       "   'observation',\n",
       "   'complete',\n",
       "   'proof',\n",
       "   'theo',\n",
       "   'rem',\n",
       "   'define',\n",
       "   'row',\n",
       "   'move',\n",
       "   'move',\n",
       "   'tile',\n",
       "   'slide',\n",
       "   'horizontally',\n",
       "   'column_move',\n",
       "   'tile',\n",
       "   'slide',\n",
       "   'vertically'],\n",
       "  ['assume',\n",
       "   'tile',\n",
       "   'read',\n",
       "   'top',\n",
       "   'bottom',\n",
       "   'leave_right',\n",
       "   'english',\n",
       "   'text',\n",
       "   'natural',\n",
       "   'order',\n",
       "   'define',\n",
       "   'follow',\n",
       "   'say',\n",
       "   'tile',\n",
       "   'order',\n",
       "   'mean',\n",
       "   'large',\n",
       "   'letter',\n",
       "   'precede',\n",
       "   'small',\n",
       "   'letter',\n",
       "   'natural',\n",
       "   'order'],\n",
       "  ['difficulty', 'pair', 'tile', 'order', 'initially'],\n",
       "  ['immediate',\n",
       "   'observation',\n",
       "   'row',\n",
       "   'move',\n",
       "   'alone',\n",
       "   'little',\n",
       "   'value',\n",
       "   'address',\n",
       "   'figure'],\n",
       "  ['desire', 'final', 'configuration', 'puzzle'],\n",
       "  ['problem', 'lemma'],\n",
       "  ['row', 'move', 'change', 'order', 'tile'],\n",
       "  ['proof'],\n",
       "  ['row', 'move', 'move', 'tile', 'cell', 'cell', 'vice', 'versa'],\n",
       "  ['tile', 'change', 'order', 'respect', 'tile'],\n",
       "  ['tile', 'move', 'change', 'order_pair', 'tile'],\n",
       "  ['let', 'turn', 'column_move'],\n",
       "  ['interesting', 'case', 'order', 'change'],\n",
       "  ['example', 'column_move', 'figure', 'change', 'relative', 'order_pair'],\n",
       "  ['lemma'],\n",
       "  ['column_move', 'change', 'relative', 'order', 'exactly', 'pair', 'tile'],\n",
       "  ['proof'],\n",
       "  ['slide', 'tile', 'move', 'next', 'tile', 'order'],\n",
       "  ['slide', 'tile', 'move', 'previous', 'tile', 'order'],\n",
       "  ['way', 'relative', 'order', 'change', 'move', 'tile', 'tile', 'crosse'],\n",
       "  ['relative', 'order_pair', 'tile', 'change'],\n",
       "  ['observation', 'suggest', 'limitation', 'tile', 'swap'],\n",
       "  ['limitation', 'may', 'lead', 'invariant', 'need'],\n",
       "  ['order',\n",
       "   'reason',\n",
       "   'swap',\n",
       "   'precisely',\n",
       "   'let',\n",
       "   'define',\n",
       "   'term',\n",
       "   'refer',\n",
       "   'pair',\n",
       "   'item',\n",
       "   'order',\n",
       "   'chapter_induction',\n",
       "   'figure'],\n",
       "  ['example', 'column_move', 'tile', 'move', 'adjacent', 'hole'],\n",
       "  ['case', 'change', 'order'],\n",
       "  ['definition'],\n",
       "  ['pair', 'letter', 'example', 'puzzle', 'inversion'],\n",
       "  ['exactly', 'inversion'],\n",
       "  ['start',\n",
       "   'state',\n",
       "   'inversion',\n",
       "   'end',\n",
       "   'state',\n",
       "   'let',\n",
       "   'work',\n",
       "   'effect',\n",
       "   'row',\n",
       "   'column_move',\n",
       "   'term',\n",
       "   'inversion'],\n",
       "  ['lemma'],\n",
       "  ['move', 'number', 'inversion', 'increase', 'decrease', 'remain'],\n",
       "  ['proof'],\n",
       "  ['lemma_lemma', 'large'],\n",
       "  ['almost'],\n",
       "  ['number',\n",
       "   'inversion',\n",
       "   'change',\n",
       "   'parity',\n",
       "   'number',\n",
       "   'inversion',\n",
       "   'parity',\n",
       "   'number',\n",
       "   'refer',\n",
       "   'number',\n",
       "   'even',\n",
       "   'odd'],\n",
       "  ['example', 'odd', 'parity', 'even', 'parity'],\n",
       "  ['add',\n",
       "   'subtract',\n",
       "   'number',\n",
       "   'change',\n",
       "   'parity',\n",
       "   'follow',\n",
       "   'corollary',\n",
       "   'lemma',\n",
       "   'corollary'],\n",
       "  ['row',\n",
       "   'move',\n",
       "   'column_move',\n",
       "   'ever',\n",
       "   'change',\n",
       "   'parity',\n",
       "   'number',\n",
       "   'inversion'],\n",
       "  ['bundle',\n",
       "   'observations',\n",
       "   'state',\n",
       "   'invariant',\n",
       "   'property',\n",
       "   'puzzle',\n",
       "   'never',\n",
       "   'change',\n",
       "   'matter',\n",
       "   'slide',\n",
       "   'tile'],\n",
       "  ['lemma'],\n",
       "  ['configuration', 'reachable', 'configuration', 'show_figure', 'proof'],\n",
       "  ['target', 'configuration', 'right', 'total_number', 'inversion', 'even'],\n",
       "  ['therefore', 'lemma', 'reachable']],\n",
       " [['strong_induction',\n",
       "   'strong_induction',\n",
       "   'variation',\n",
       "   'ordinary_induction',\n",
       "   'useful',\n",
       "   'pre',\n",
       "   'icate'],\n",
       "  ['naturally', 'depend'],\n",
       "  ['value'],\n",
       "  ['ordinary_induction', 'strong_induction', 'useful', 'prove', 'predicate'],\n",
       "  ['true']],\n",
       " [['rule', 'strong_induction', 'principle', 'strong_induction'],\n",
       "  ['let'],\n",
       "  ['predicate'],\n",
       "  ['true'],\n",
       "  ['together', 'imply'],\n",
       "  ['true'],\n",
       "  ['change',\n",
       "   'ordinary_induction',\n",
       "   'principle',\n",
       "   'strong_induction',\n",
       "   'allow',\n",
       "   'assume',\n",
       "   'stuff',\n",
       "   'inductive_step',\n",
       "   'proof',\n",
       "   'ordinary_induction',\n",
       "   'argument',\n",
       "   'assume'],\n",
       "  ['true', 'try_prove'],\n",
       "  ['also', 'true'],\n",
       "  ['strong_induction', 'argument', 'may', 'assume'],\n",
       "  ['true', 'go', 'prove'],\n",
       "  ['extra', 'assumption', 'make', 'job', 'easy'],\n",
       "  ['hence', 'name', 'strong_induction'],\n",
       "  ['formulated', 'proof', 'rule', 'strong_induction', 'rule'],\n",
       "  ['strong_induction',\n",
       "   'rule',\n",
       "   'template',\n",
       "   'strong_induction',\n",
       "   'proof',\n",
       "   'identical',\n",
       "   'template',\n",
       "   'give',\n",
       "   'section',\n",
       "   'ordinary_induction',\n",
       "   'thing',\n",
       "   'state',\n",
       "   'proof',\n",
       "   'strong_induction',\n",
       "   'assume'],\n",
       "  ['true', 'instead'],\n",
       "  ['inductive_step']],\n",
       " [['examples',\n",
       "   'product_prime',\n",
       "   'first',\n",
       "   'example',\n",
       "   'use_strong_induction',\n",
       "   'prove_theorem',\n",
       "   'previously',\n",
       "   'prove',\n",
       "   'use_well',\n",
       "   'ordering'],\n",
       "  ['lemma'],\n",
       "  ['integer', 'great', 'product_prime'],\n",
       "  ['proof'],\n",
       "  ['prove', 'lemma', 'strong_induction', 'let', 'induction', 'hy', 'pothesis'],\n",
       "  ['product_prime', 'lemma', 'follow', 'prove'],\n",
       "  ['holds'],\n",
       "  ['chapter_induction', 'base_case'],\n",
       "  ['true', 'prime', 'length', 'product_prime', 'convention'],\n",
       "  ['inductive_step', 'suppose', 'product_prime', 'integer'],\n",
       "  ['must', 'show'],\n",
       "  ['holds', 'namely', 'also', 'product_prime'],\n",
       "  ['argue', 'cases', 'prime', 'length', 'product_prime', 'convention'],\n",
       "  ['holds', 'case'],\n",
       "  ['otherwise', 'prime', 'definition', 'mean', 'km', 'integer'],\n",
       "  ['strong_induction', 'hypothesis', 'know', 'product_prime'],\n",
       "  ['likewise', 'product_prime'],\n",
       "  ['follow', 'immediately', 'also', 'product_prime'],\n",
       "  ['therefore'],\n",
       "  ['hold', 'case', 'well'],\n",
       "  ['hold', 'case', 'complete', 'proof', 'strong_induction'],\n",
       "  ['holds'],\n",
       "  ['make_change',\n",
       "   'country',\n",
       "   'inductia',\n",
       "   'unit',\n",
       "   'currency',\n",
       "   'strong',\n",
       "   'coin',\n",
       "   'worth',\n",
       "   'sg',\n",
       "   'strongs'],\n",
       "  ['inductians',\n",
       "   'trouble',\n",
       "   'make',\n",
       "   'small',\n",
       "   'change',\n",
       "   'sg',\n",
       "   'sg',\n",
       "   'turn',\n",
       "   'collect',\n",
       "   'coin',\n",
       "   'make_change',\n",
       "   'number',\n",
       "   'least',\n",
       "   'strong'],\n",
       "  ['strong_induction', 'make', 'easy', 'prove'],\n",
       "  ['strong_induction',\n",
       "   'inductians',\n",
       "   'make_change',\n",
       "   'exactly',\n",
       "   'detail',\n",
       "   'writeup',\n",
       "   'use',\n",
       "   'official',\n",
       "   'format',\n",
       "   'proof'],\n",
       "  ['prove',\n",
       "   'strong_induction',\n",
       "   'inductians',\n",
       "   'make_change',\n",
       "   'amount',\n",
       "   'least',\n",
       "   'sg'],\n",
       "  ['induction_hypothesis'],\n",
       "  ['collection', 'coin', 'value', 'strong'],\n",
       "  ['base_case'],\n",
       "  ['true', 'sg', 'coin', 'together', 'sg', 'coin', 'make'],\n",
       "  ['inductive_step_assume'],\n",
       "  ['hold', 'prove'],\n",
       "  ['holds'],\n",
       "  ['argue', 'case', 'case', 'make'],\n",
       "  ['sg'],\n",
       "  ['use', 'sg', 'coin'],\n",
       "  ['case', 'make'],\n",
       "  ['sg'],\n",
       "  ['use', 'sg', 'coin'],\n",
       "  ['figure'],\n",
       "  ['example', 'stack', 'game', 'box'],\n",
       "  ['line', 'underline', 'stack', 'divide', 'next', 'step'],\n",
       "  ['case',\n",
       "   'strong_induction',\n",
       "   'hypothesis',\n",
       "   'inductians',\n",
       "   'make_change',\n",
       "   'strong'],\n",
       "  ['add', 'sg', 'coin', 'make_change'],\n",
       "  ['sg'],\n",
       "  ['know', 'thus', 'case', 'cover', 'possibility'],\n",
       "  ['true',\n",
       "   'case',\n",
       "   'conclude',\n",
       "   'strong_induction',\n",
       "   'inductian',\n",
       "   'make_change',\n",
       "   'strong'],\n",
       "  ['make_change', 'number', 'strong'],\n",
       "  ['stack',\n",
       "   'game',\n",
       "   'exciting',\n",
       "   'game',\n",
       "   'surely',\n",
       "   'sweep',\n",
       "   'nation',\n",
       "   'begin',\n",
       "   'stack',\n",
       "   'box'],\n",
       "  ['make', 'sequence', 'move'],\n",
       "  ['move', 'divide', 'stack', 'box', 'nonempty', 'stack'],\n",
       "  ['game', 'end', 'stack', 'contain', 'single', 'box'],\n",
       "  ['earn',\n",
       "   'point',\n",
       "   'move',\n",
       "   'particular',\n",
       "   'divide',\n",
       "   'stack',\n",
       "   'height',\n",
       "   'stacks',\n",
       "   'height',\n",
       "   'score',\n",
       "   'ab',\n",
       "   'point',\n",
       "   'move'],\n",
       "  ['overall', 'score', 'sum', 'point', 'earn', 'move'],\n",
       "  ['strategy',\n",
       "   'use',\n",
       "   'maximize',\n",
       "   'total',\n",
       "   'score',\n",
       "   'example_suppose',\n",
       "   'begin',\n",
       "   'stack',\n",
       "   'box'],\n",
       "  ['game',\n",
       "   'may',\n",
       "   'proceed',\n",
       "   'show_figure',\n",
       "   'let',\n",
       "   'use_strong_induction',\n",
       "   'analyze',\n",
       "   'unstacking',\n",
       "   'game'],\n",
       "  ['prove',\n",
       "   'score',\n",
       "   'determine',\n",
       "   'entirely',\n",
       "   'number',\n",
       "   'box',\n",
       "   'strategy',\n",
       "   'irrelevant',\n",
       "   'chapter_induction',\n",
       "   'theorem'],\n",
       "  ['way', 'unstacke', 'block', 'give', 'score'],\n",
       "  ['point'],\n",
       "  ['couple',\n",
       "   'technical',\n",
       "   'point',\n",
       "   'notice',\n",
       "   'proof',\n",
       "   'template',\n",
       "   'strong_induction',\n",
       "   'proof',\n",
       "   'mirror',\n",
       "   'template',\n",
       "   'ordinary_induction'],\n",
       "  ['ordinary_induction', 'freedom', 'adjust', 'indice'],\n",
       "  ['case', 'prove'],\n",
       "  ['base_case', 'prove'],\n",
       "  ['imply'],\n",
       "  ['inductive_step'],\n",
       "  ['proof'],\n",
       "  ['proof', 'strong_induction'],\n",
       "  ['let'],\n",
       "  ['proposition', 'way', 'unstacke', 'block', 'give', 'score'],\n",
       "  ['base_case', 'block'],\n",
       "  ['move', 'possible', 'total', 'score', 'game'],\n",
       "  ['therefore'],\n",
       "  ['true'],\n",
       "  ['inductive_step', 'must', 'show'],\n",
       "  ['imply'],\n",
       "  ['assume'],\n",
       "  ['true', 'stack_block'],\n",
       "  ['first', 'move', 'must', 'split', 'stack', 'substack', 'positive', 'size'],\n",
       "  ['total',\n",
       "   'score',\n",
       "   'game',\n",
       "   'sum',\n",
       "   'point',\n",
       "   'first',\n",
       "   'move',\n",
       "   'point',\n",
       "   'obtain',\n",
       "   'unstacke']],\n",
       " [['strong_induction',\n",
       "   'induction',\n",
       "   'strong_induction',\n",
       "   'really',\n",
       "   'strong',\n",
       "   'ordinary_induction',\n",
       "   'certainly',\n",
       "   'look',\n",
       "   'way'],\n",
       "  ['assume', 'lot', 'prove', 'induction', 'step'],\n",
       "  ['actually',\n",
       "   'proof',\n",
       "   'use_strong_induction',\n",
       "   'reformatte',\n",
       "   'proof',\n",
       "   'use',\n",
       "   'ordinary_induction',\n",
       "   'need',\n",
       "   'use_strong_induction',\n",
       "   'hypothesis'],\n",
       "  ['method', 'use', 'find', 'easy'],\n",
       "  ['method',\n",
       "   'choose',\n",
       "   'sure',\n",
       "   'state',\n",
       "   'method',\n",
       "   'front',\n",
       "   'reader',\n",
       "   'understand',\n",
       "   'easily',\n",
       "   'verify',\n",
       "   'proof']],\n",
       " [['structural_induction', 'focusse', 'induction', 'natural_number'],\n",
       "  ['idea',\n",
       "   'induction',\n",
       "   'far',\n",
       "   'general',\n",
       "   'apply',\n",
       "   'much',\n",
       "   'rich',\n",
       "   'class',\n",
       "   'set'],\n",
       "  ['particular',\n",
       "   'especially',\n",
       "   'useful',\n",
       "   'connection',\n",
       "   'set',\n",
       "   'data_type',\n",
       "   'define_recursively']],\n",
       " [['recursive',\n",
       "   'data_type',\n",
       "   'recursive',\n",
       "   'data_type',\n",
       "   'play',\n",
       "   'central',\n",
       "   'role',\n",
       "   'programming'],\n",
       "  ['specify', 'recursive_definition', 'say', 'build', 'part'],\n",
       "  ['recursive_definition', 'part', 'base_case', 'depend', 'else'],\n",
       "  ['constructor_case', 'depend', 'previous', 'case'],\n",
       "  ['let_see',\n",
       "   'work',\n",
       "   'couple',\n",
       "   'example',\n",
       "   'string',\n",
       "   'bracket',\n",
       "   'expre',\n",
       "   'sion',\n",
       "   'evaluation'],\n",
       "  ['example',\n",
       "   'string',\n",
       "   'bracket',\n",
       "   'let',\n",
       "   'brkts',\n",
       "   'set',\n",
       "   'sequence',\n",
       "   'string',\n",
       "   'square',\n",
       "   'bracket'],\n",
       "  ['example', 'follow', 'string', 'brkts', 'definition'],\n",
       "  ['set',\n",
       "   'brkts',\n",
       "   'strings',\n",
       "   'bracket',\n",
       "   'define_recursively',\n",
       "   'follow',\n",
       "   'base_case',\n",
       "   'empty',\n",
       "   'string',\n",
       "   'brkts'],\n",
       "  ['constructor_case',\n",
       "   'brkts',\n",
       "   'writing',\n",
       "   'string',\n",
       "   'brkts',\n",
       "   'call',\n",
       "   'matched',\n",
       "   'string',\n",
       "   'bracket',\n",
       "   'match',\n",
       "   'usual',\n",
       "   'way'],\n",
       "  ['example',\n",
       "   'leave_hand',\n",
       "   'string',\n",
       "   'match',\n",
       "   'second',\n",
       "   'right',\n",
       "   'bracket',\n",
       "   'match',\n",
       "   'left',\n",
       "   'bracket'],\n",
       "  ['stre', 'right', 'match'],\n",
       "  ['set', 'match', 'string', 'define_recursively', 'follow'],\n",
       "  ['chapter_induction', 'definition'],\n",
       "  ['recursively_define',\n",
       "   'set',\n",
       "   'recmatch',\n",
       "   'string',\n",
       "   'follow',\n",
       "   'base_case',\n",
       "   'recmatch'],\n",
       "  ['constructor_case',\n",
       "   'recmatch',\n",
       "   'recmatch',\n",
       "   'writing',\n",
       "   'use',\n",
       "   'definition',\n",
       "   'see',\n",
       "   'recmatch',\n",
       "   'base_case',\n",
       "   'recmatch',\n",
       "   'constructor_case'],\n",
       "  ['also', 'string', 'recmatch', 'repeat', 'application', 'constructor_case'],\n",
       "  ['general',\n",
       "   'recmatch',\n",
       "   'contain',\n",
       "   'precisely',\n",
       "   'string',\n",
       "   'match',\n",
       "   'brack',\n",
       "   'et'],\n",
       "  ['constructor_case',\n",
       "   'effect',\n",
       "   'identify',\n",
       "   'bracket',\n",
       "   'match',\n",
       "   'leftmost',\n",
       "   'bracket',\n",
       "   'string'],\n",
       "  ['match',\n",
       "   'bracket',\n",
       "   'unique',\n",
       "   'method',\n",
       "   'constructing',\n",
       "   'recmatch',\n",
       "   'give',\n",
       "   'unique',\n",
       "   'way',\n",
       "   'construct',\n",
       "   'string',\n",
       "   'match',\n",
       "   'bracket'],\n",
       "  ['turn', 'important', 'later', 'talk', 'ambiguity'],\n",
       "  ['string', 'match', 'bracket', 'arise', 'area', 'expression', 'parse'],\n",
       "  ['brief', 'history', 'advance', 'field', 'provide', 'box', 'next', 'page'],\n",
       "  ['example',\n",
       "   'arithmetic',\n",
       "   'expression',\n",
       "   'expression',\n",
       "   'evaluation',\n",
       "   'key',\n",
       "   'feature',\n",
       "   'programming',\n",
       "   'language',\n",
       "   'recognition',\n",
       "   'expression',\n",
       "   'recursive',\n",
       "   'datum_type',\n",
       "   'key',\n",
       "   'understanding',\n",
       "   'process'],\n",
       "  ['illustrate',\n",
       "   'approach',\n",
       "   'work',\n",
       "   'toy',\n",
       "   'example',\n",
       "   'arithmetic',\n",
       "   'expression',\n",
       "   'definition'],\n",
       "  ['set',\n",
       "   'aexp',\n",
       "   'define_recursively',\n",
       "   'follow',\n",
       "   'base_case',\n",
       "   'expression',\n",
       "   'parse',\n",
       "   'early',\n",
       "   'development',\n",
       "   'computer_science',\n",
       "   'creation',\n",
       "   'effective',\n",
       "   'programming',\n",
       "   'language',\n",
       "   'compiler',\n",
       "   'central',\n",
       "   'concern'],\n",
       "  ['key',\n",
       "   'aspect',\n",
       "   'processing',\n",
       "   'program',\n",
       "   'compilation',\n",
       "   'expression',\n",
       "   'parse'],\n",
       "  ['problem', 'take', 'expression', 'put', 'bracket', 'determine', 'evaluate'],\n",
       "  ['turing',\n",
       "   'award',\n",
       "   'nobel',\n",
       "   'prize',\n",
       "   'computer_science',\n",
       "   'ultimately',\n",
       "   'stow',\n",
       "   'robert',\n",
       "   'floyd',\n",
       "   'thing',\n",
       "   'discoverer',\n",
       "   'simple',\n",
       "   'program',\n",
       "   'would',\n",
       "   'insert',\n",
       "   'bracket',\n",
       "   'properly'],\n",
       "  ['parse',\n",
       "   'technology',\n",
       "   'package',\n",
       "   'high',\n",
       "   'level',\n",
       "   'compiler',\n",
       "   'compiler',\n",
       "   'automatically',\n",
       "   'generate',\n",
       "   'parser',\n",
       "   'expression',\n",
       "   'gram',\n",
       "   'mars'],\n",
       "  ['automation',\n",
       "   'parse',\n",
       "   'effective',\n",
       "   'subject',\n",
       "   'stop',\n",
       "   'de',\n",
       "   'manding',\n",
       "   'attention',\n",
       "   'largely',\n",
       "   'disappear',\n",
       "   'computer_science',\n",
       "   'curriculum'],\n",
       "  ['chapter_induction', 'variable', 'aexp'],\n",
       "  ['arabic', 'numeral', 'nonnegative_integer', 'aexp'],\n",
       "  ['constructor_case', 'aexp'],\n",
       "  ['aexp'],\n",
       "  ['expression'],\n",
       "  ['call', 'sum'],\n",
       "  ['aexp', 'call', 'components', 'sum', 'also', 'call', 'summand'],\n",
       "  ['aexp'],\n",
       "  ['expression'],\n",
       "  ['call', 'product'],\n",
       "  ['aexp',\n",
       "   'call',\n",
       "   'component',\n",
       "   'product',\n",
       "   'also',\n",
       "   'call',\n",
       "   'multipli',\n",
       "   'multiplicand'],\n",
       "  ['aexp'],\n",
       "  ['expression'],\n",
       "  ['call', 'negative'],\n",
       "  ['notice', 'aexp', 'fully', 'parenthesize', 'exponent', 'allow'],\n",
       "  ['aexp',\n",
       "   'version',\n",
       "   'polynomial',\n",
       "   'expression',\n",
       "   'parenthese',\n",
       "   'clutter',\n",
       "   'example',\n",
       "   'often',\n",
       "   'use',\n",
       "   'simple',\n",
       "   'expre',\n",
       "   'sion']],\n",
       " [['structural_induction',\n",
       "   'recursive',\n",
       "   'data_type',\n",
       "   'structural_induction',\n",
       "   'method',\n",
       "   'prove',\n",
       "   'property',\n",
       "   'hold',\n",
       "   'element',\n",
       "   'recursively_define',\n",
       "   'datum_type'],\n",
       "  ['proof', 'consist', 'step', 'prove', 'base_case', 'definition'],\n",
       "  ['prove',\n",
       "   'constructor_case',\n",
       "   'definition',\n",
       "   'assume',\n",
       "   'true',\n",
       "   'component',\n",
       "   'datum',\n",
       "   'item'],\n",
       "  ['simple',\n",
       "   'application',\n",
       "   'structural_induction',\n",
       "   'prove',\n",
       "   'recursively_define',\n",
       "   'match',\n",
       "   'string',\n",
       "   'always',\n",
       "   'equal_number',\n",
       "   'leave_right',\n",
       "   'bracket'],\n",
       "  ['define', 'predicate', 'strings', 'brkts'],\n",
       "  ['wwd', 'equal_number', 'leave_right', 'bracket', 'theorem'],\n",
       "  ['holds', 'recmatch'],\n",
       "  ['proof'],\n",
       "  ['structural_induction', 'definition', 'recmatch', 'use'],\n",
       "  ['induction_hypothesis'],\n",
       "  ['base_case'],\n",
       "  ['hold', 'empty', 'stre', 'leave_right', 'bracket'],\n",
       "  ['constructor_case', 'respective', 'hypothesis'],\n",
       "  ['know', 'number', 'right', 'bracket', 'hold', 'recmatch']],\n",
       " [['function',\n",
       "   'recursively_define',\n",
       "   'data_type',\n",
       "   'quick',\n",
       "   'review',\n",
       "   'function',\n",
       "   'function',\n",
       "   'assign',\n",
       "   'element_set',\n",
       "   'call',\n",
       "   'domain',\n",
       "   'element_set',\n",
       "   'call',\n",
       "   'codomain'],\n",
       "  ['notation', 'indicate', 'function', 'domain', 'codomain'],\n",
       "  ['familiar', 'notation'],\n",
       "  ['indicate', 'assign', 'element'],\n",
       "  ['would', 'call', 'value', 'argument'],\n",
       "  ['function', 'often', 'define', 'formula'],\n",
       "  ['wwd',\n",
       "   'real',\n",
       "   'value',\n",
       "   'variable_range',\n",
       "   'binary',\n",
       "   'string',\n",
       "   'function',\n",
       "   'finite',\n",
       "   'domain',\n",
       "   'could',\n",
       "   'specify',\n",
       "   'table',\n",
       "   'show',\n",
       "   'value',\n",
       "   'function',\n",
       "   'element',\n",
       "   'domain'],\n",
       "  ['example',\n",
       "   'function',\n",
       "   'chapter_induction',\n",
       "   'notice',\n",
       "   'wwd',\n",
       "   'imply',\n",
       "   'function',\n",
       "   'may',\n",
       "   'also',\n",
       "   'define',\n",
       "   'procedure',\n",
       "   'computing',\n",
       "   'value',\n",
       "   'element',\n",
       "   'domain',\n",
       "   'kind',\n",
       "   'specification'],\n",
       "  ['example',\n",
       "   'define',\n",
       "   'length',\n",
       "   'leave_right',\n",
       "   'search',\n",
       "   'bit',\n",
       "   'binary',\n",
       "   'string',\n",
       "   'appear',\n",
       "   'undefined',\n",
       "   'notice',\n",
       "   'often',\n",
       "   'useful',\n",
       "   'find',\n",
       "   'set',\n",
       "   'value',\n",
       "   'function',\n",
       "   'take',\n",
       "   'applied',\n",
       "   'element_set',\n",
       "   'argument'],\n",
       "  ['set', 'value', 'take', 'applied', 'element'],\n",
       "  ['wwd',\n",
       "   'example',\n",
       "   'let',\n",
       "   'example',\n",
       "   'let',\n",
       "   'take',\n",
       "   'search',\n",
       "   'function',\n",
       "   'apply',\n",
       "   'refer',\n",
       "   'image_set',\n",
       "   'value',\n",
       "   'arise',\n",
       "   'apply',\n",
       "   'range'],\n",
       "  ['domain',\n",
       "   'picky',\n",
       "   'distinction',\n",
       "   'function',\n",
       "   'apply',\n",
       "   'elements',\n",
       "   'function',\n",
       "   'apply',\n",
       "   'pointwise',\n",
       "   'subset',\n",
       "   'domain',\n",
       "   'domain',\n",
       "   'pointwise'],\n",
       "  ['usually',\n",
       "   'clear',\n",
       "   'context',\n",
       "   'pointwise',\n",
       "   'mean',\n",
       "   'harm',\n",
       "   'overload',\n",
       "   'symbol',\n",
       "   'way'],\n",
       "  ['recursively_define',\n",
       "   'function',\n",
       "   'function',\n",
       "   'recursively_define',\n",
       "   'data_type',\n",
       "   'define_recursively',\n",
       "   'use',\n",
       "   'case',\n",
       "   'datum_type',\n",
       "   'definition'],\n",
       "  ['namely',\n",
       "   'define_function',\n",
       "   'recur',\n",
       "   'sive',\n",
       "   'datum_type',\n",
       "   'define',\n",
       "   'value',\n",
       "   'base_case',\n",
       "   'datum_type',\n",
       "   'definition',\n",
       "   'define',\n",
       "   'value',\n",
       "   'constructor_case',\n",
       "   'term',\n",
       "   'value',\n",
       "   'component',\n",
       "   'datum',\n",
       "   'item'],\n",
       "  ['example_consider',\n",
       "   'function',\n",
       "   'eval',\n",
       "   'aexp',\n",
       "   'evaluate',\n",
       "   'expression',\n",
       "   'aexp',\n",
       "   'use',\n",
       "   'value'],\n",
       "  ['useful',\n",
       "   'express',\n",
       "   'function',\n",
       "   'recursive_definition',\n",
       "   'follow',\n",
       "   'definition'],\n",
       "  ['evaluation',\n",
       "   'function',\n",
       "   'eval',\n",
       "   'aexp',\n",
       "   'define',\n",
       "   'recur',\n",
       "   'sively',\n",
       "   'expression',\n",
       "   'aexp',\n",
       "   'follow'],\n",
       "  ['let', 'integer'],\n",
       "  ['base_case', 'case', 'eval'],\n",
       "  ['wwd'],\n",
       "  ['case', 'eval'],\n",
       "  ['wwd', 'constructor_case', 'case'],\n",
       "  ['eval'],\n",
       "  ['case'],\n",
       "  ['eval'],\n",
       "  ['case'],\n",
       "  ['eval'],\n",
       "  ['eval'],\n",
       "  ['chapter_induction',\n",
       "   'example',\n",
       "   'recursive_definition',\n",
       "   'eval',\n",
       "   'would',\n",
       "   'arrive',\n",
       "   'value',\n",
       "   'second',\n",
       "   'example_consider',\n",
       "   'function',\n",
       "   'match',\n",
       "   'string',\n",
       "   'specify',\n",
       "   'depth',\n",
       "   'match',\n",
       "   'bracket',\n",
       "   'stre'],\n",
       "  ['function', 'specify', 'recursively', 'fol', 'low', 'definition'],\n",
       "  ['depth'],\n",
       "  ['stre', 'recmatch', 'define_recursively', 'rule'],\n",
       "  ['wwd'],\n",
       "  ['ambiguity',\n",
       "   'recursive_definition',\n",
       "   'datum_type',\n",
       "   'allow',\n",
       "   'element',\n",
       "   'construct',\n",
       "   'way',\n",
       "   'definition',\n",
       "   'say',\n",
       "   'ambiguous'],\n",
       "  ['function',\n",
       "   'define_recursively',\n",
       "   'ambiguous',\n",
       "   'definition',\n",
       "   'datum_type',\n",
       "   'well',\n",
       "   'define',\n",
       "   'value',\n",
       "   'specify',\n",
       "   'different_way',\n",
       "   'construct',\n",
       "   'element',\n",
       "   'agree'],\n",
       "  ['careful',\n",
       "   'choose',\n",
       "   'unambiguous',\n",
       "   'definition',\n",
       "   'recmatch',\n",
       "   'ensure',\n",
       "   'function',\n",
       "   'define_recursively',\n",
       "   'definition',\n",
       "   'would',\n",
       "   'always',\n",
       "   'well',\n",
       "   'define'],\n",
       "  ['example',\n",
       "   'trouble',\n",
       "   'ambiguous',\n",
       "   'definition',\n",
       "   'cause',\n",
       "   'let',\n",
       "   'consider',\n",
       "   'definition',\n",
       "   'match',\n",
       "   'string'],\n",
       "  ['definition'],\n",
       "  ['define',\n",
       "   'set',\n",
       "   'brkts',\n",
       "   'recursively',\n",
       "   'follow',\n",
       "   'base_case',\n",
       "   'constructor_case',\n",
       "   'string',\n",
       "   'use',\n",
       "   'structural_induction',\n",
       "   'possible',\n",
       "   'prove',\n",
       "   'recmatch'],\n",
       "  ['deed',\n",
       "   'definition',\n",
       "   'may',\n",
       "   'even',\n",
       "   'seem',\n",
       "   'natural_way',\n",
       "   'define',\n",
       "   'set',\n",
       "   'match',\n",
       "   'string',\n",
       "   'definition',\n",
       "   'recmatch'],\n",
       "  ['definition',\n",
       "   'biguous',\n",
       "   'perhaps',\n",
       "   'less',\n",
       "   'natural',\n",
       "   'definition',\n",
       "   'recmatch',\n",
       "   'unambiguous'],\n",
       "  ['ambiguity', 'matter'],\n",
       "  ['example_suppose', 'define'],\n",
       "  ['wwd'],\n",
       "  ['st', 'wwd'],\n",
       "  ['st',\n",
       "   'let',\n",
       "   'string',\n",
       "   'wwd',\n",
       "   'aa',\n",
       "   'wwd',\n",
       "   'bb',\n",
       "   'build',\n",
       "   'successive',\n",
       "   'application',\n",
       "   'second',\n",
       "   'constructor',\n",
       "   'start'],\n",
       "  ['alternatively',\n",
       "   'build',\n",
       "   'ba',\n",
       "   'second',\n",
       "   'constructor',\n",
       "   'get',\n",
       "   'use',\n",
       "   'second',\n",
       "   'constructor',\n",
       "   'ba'],\n",
       "  ['apply', 'rule', 'first', 'way', 'construct'],\n",
       "  ['note',\n",
       "   'structural_induction',\n",
       "   'remain',\n",
       "   'sound',\n",
       "   'proof',\n",
       "   'method',\n",
       "   'even',\n",
       "   'ambiguous',\n",
       "   'recursive_definition',\n",
       "   'easy',\n",
       "   'prove',\n",
       "   'recmatch']],\n",
       " [['recursive',\n",
       "   'functions',\n",
       "   'structural_induction',\n",
       "   'ordinary_induction',\n",
       "   'nonnegative_integer',\n",
       "   'understand',\n",
       "   'recursive',\n",
       "   'data_type'],\n",
       "  ['definition'],\n",
       "  ['set', 'datum_type', 'define', 'recursivly', 'base_case'],\n",
       "  ['constructor_case', 'successor'],\n",
       "  ['chapter_induction',\n",
       "   'mean',\n",
       "   'ordinary_induction',\n",
       "   'special_case',\n",
       "   'structural_induction',\n",
       "   'recursive_definition',\n",
       "   'definition',\n",
       "   'also',\n",
       "   'justify',\n",
       "   'familiar',\n",
       "   'recursive_definition',\n",
       "   'function',\n",
       "   'nonnegative_integer'],\n",
       "  ['example'],\n",
       "  ['factorial',\n",
       "   'function',\n",
       "   'factorial',\n",
       "   'function',\n",
       "   'often',\n",
       "   'write',\n",
       "   'base_case',\n",
       "   'fac',\n",
       "   'constructor_case',\n",
       "   'fac',\n",
       "   'fibonacci_number'],\n",
       "  ['fibonacci_number',\n",
       "   'arise',\n",
       "   'effort',\n",
       "   'year_ago',\n",
       "   'model',\n",
       "   'population',\n",
       "   'growth'],\n",
       "  ['study', 'length', 'part', 'iii'],\n",
       "  ['fibonacci_number',\n",
       "   'fib',\n",
       "   'base_case',\n",
       "   'fib',\n",
       "   'constructor_case',\n",
       "   'fib',\n",
       "   'fib',\n",
       "   'recursive',\n",
       "   'step',\n",
       "   'start',\n",
       "   'fib',\n",
       "   'sum',\n",
       "   'notation',\n",
       "   'let'],\n",
       "  ['would'],\n",
       "  ['base_case'],\n",
       "  ['constructor_case'],\n",
       "  ['ill',\n",
       "   'formed',\n",
       "   'function',\n",
       "   'definition',\n",
       "   'blunder',\n",
       "   'watch',\n",
       "   'define_function',\n",
       "   'recursively'],\n",
       "  ['low',\n",
       "   'function',\n",
       "   'specification',\n",
       "   'resemble',\n",
       "   'good',\n",
       "   'definition',\n",
       "   'functions',\n",
       "   'nonnegative_integer'],\n",
       "  ['definition'],\n",
       "  ['definition', 'base_case'],\n",
       "  ['function', 'definition'],\n",
       "  ['definition',\n",
       "   'base_case',\n",
       "   'still',\n",
       "   'uniquely',\n",
       "   'determine',\n",
       "   'typical',\n",
       "   'programming',\n",
       "   'language',\n",
       "   'evaluation',\n",
       "   'definition'],\n",
       "  ['definition',\n",
       "   'inconsistent',\n",
       "   'require',\n",
       "   'mysterious',\n",
       "   'function',\n",
       "   'mathematician',\n",
       "   'wonder',\n",
       "   'follow',\n",
       "   'function',\n",
       "   'specification',\n",
       "   'many',\n",
       "   'year',\n",
       "   'chapter_induction',\n",
       "   'example',\n",
       "   'constant',\n",
       "   'function',\n",
       "   'equal',\n",
       "   'satisfy']],\n",
       " [['number_theory', 'number_theory', 'study', 'integer'],\n",
       "  ['would', 'want', 'study', 'integer', 'immediately', 'obvious'],\n",
       "  ['first', 'know'],\n",
       "  ['understand', 'sec', 'ond', 'practical', 'value', 'mathematician'],\n",
       "  ['hardy',\n",
       "   'express',\n",
       "   'pleasure',\n",
       "   'impracticality',\n",
       "   'write',\n",
       "   'hardy',\n",
       "   'specially',\n",
       "   'concerned',\n",
       "   'number_theory',\n",
       "   'use',\n",
       "   'warfare',\n",
       "   'pacifist'],\n",
       "  ['may',\n",
       "   'applaud',\n",
       "   'sentiment',\n",
       "   'get',\n",
       "   'wrong',\n",
       "   'number_theory',\n",
       "   'underlie',\n",
       "   'modern',\n",
       "   'cryptography',\n",
       "   'make',\n",
       "   'secure',\n",
       "   'online',\n",
       "   'communication',\n",
       "   'possible'],\n",
       "  ['secure',\n",
       "   'communication',\n",
       "   'course',\n",
       "   'crucial',\n",
       "   'war',\n",
       "   'may',\n",
       "   'leave',\n",
       "   'poor',\n",
       "   'hardy',\n",
       "   'spinning',\n",
       "   'grave'],\n",
       "  ['also', 'central', 'online', 'commerce'],\n",
       "  ['time',\n",
       "   'buy',\n",
       "   'book',\n",
       "   'amazon',\n",
       "   'check',\n",
       "   'grade',\n",
       "   'websis',\n",
       "   'use',\n",
       "   'paypal',\n",
       "   'account',\n",
       "   'rely',\n",
       "   'number',\n",
       "   'theoretic',\n",
       "   'algorithm'],\n",
       "  ['number_theory',\n",
       "   'also',\n",
       "   'provide',\n",
       "   'excellent',\n",
       "   'environment',\n",
       "   'practice',\n",
       "   'apply',\n",
       "   'proof',\n",
       "   'technique',\n",
       "   'develop',\n",
       "   'chapter',\n",
       "   'focus',\n",
       "   'property',\n",
       "   'integer',\n",
       "   'adopt',\n",
       "   'default',\n",
       "   'convention',\n",
       "   'chapter',\n",
       "   'variable_range',\n",
       "   'set',\n",
       "   'integer']],\n",
       " [['divisibility',\n",
       "   'nature',\n",
       "   'number_theory',\n",
       "   'emerge',\n",
       "   'soon',\n",
       "   'consider',\n",
       "   'divide',\n",
       "   'relation',\n",
       "   'divide',\n",
       "   'iff',\n",
       "   'ak',\n",
       "   'notation',\n",
       "   'abbreviation',\n",
       "   'divide'],\n",
       "  ['also', 'say', 'multiple'],\n",
       "  ['consequence', 'definition', 'number', 'divide'],\n",
       "  ['seem', 'simple', 'enough', 'let', 'play', 'definition'],\n",
       "  ['pythagoreans',\n",
       "   'ancient',\n",
       "   'sect',\n",
       "   'mathematical',\n",
       "   'mystic',\n",
       "   'say',\n",
       "   'number',\n",
       "   'perfect',\n",
       "   'equal',\n",
       "   'sum',\n",
       "   'positive',\n",
       "   'integral',\n",
       "   'divisor',\n",
       "   'exclude'],\n",
       "  ['example', 'perfect', 'number'],\n",
       "  ['hand', 'perfect', 'perfect'],\n",
       "  ['chapter_number',\n",
       "   'theory',\n",
       "   'euclid',\n",
       "   'characterize',\n",
       "   'even',\n",
       "   'perfect',\n",
       "   'number',\n",
       "   'bc'],\n",
       "  ['odd',\n",
       "   'perfect',\n",
       "   'number',\n",
       "   'year',\n",
       "   'later',\n",
       "   'still',\n",
       "   'know',\n",
       "   'number',\n",
       "   'half',\n",
       "   'page',\n",
       "   'number_theory',\n",
       "   'stray',\n",
       "   'outer',\n",
       "   'limit',\n",
       "   'human',\n",
       "   'knowledge',\n",
       "   'pretty',\n",
       "   'typical',\n",
       "   'number_theory',\n",
       "   'full',\n",
       "   'question',\n",
       "   'easy',\n",
       "   'pose',\n",
       "   'incredibly',\n",
       "   'difficult',\n",
       "   'answer'],\n",
       "  ['example', 'several', 'problem', 'show', 'box', 'follow', 'page'],\n",
       "  ['interestingly',\n",
       "   'see',\n",
       "   'computer',\n",
       "   'scientist',\n",
       "   'find',\n",
       "   'way',\n",
       "   'turn',\n",
       "   'difficulty',\n",
       "   'advantage']],\n",
       " [['fact',\n",
       "   'divisibility',\n",
       "   'lemma',\n",
       "   'state',\n",
       "   'basic',\n",
       "   'fact',\n",
       "   'divisibility',\n",
       "   'difficult',\n",
       "   'prove',\n",
       "   'lemma'],\n",
       "  ['follow', 'statement', 'divisibility', 'hold'],\n",
       "  ['bc'],\n",
       "  ['sb', 'tc'],\n",
       "  ['ca', 'cb'],\n",
       "  ['proof'],\n",
       "  ['prove', 'part'],\n",
       "  ['proofs', 'similar'],\n",
       "  ['proof', 'assume'],\n",
       "  ['exist', 'integer', 'imply']],\n",
       " [['divisibility',\n",
       "   'go',\n",
       "   'bad',\n",
       "   'learn',\n",
       "   'elementary',\n",
       "   'school',\n",
       "   'number',\n",
       "   'evenly',\n",
       "   'divide',\n",
       "   'quotient',\n",
       "   'remainder',\n",
       "   'leave'],\n",
       "  ['precisely', 'theorem'],\n",
       "  ['division', 'theorem'],\n",
       "  ['let', 'integer'],\n",
       "  ['exist',\n",
       "   'unique',\n",
       "   'pair',\n",
       "   'integer',\n",
       "   'panic',\n",
       "   'go',\n",
       "   'stick',\n",
       "   'relatively',\n",
       "   'benign',\n",
       "   'part',\n",
       "   'number_theory'],\n",
       "  ['super',\n",
       "   'hard',\n",
       "   'unsolved',\n",
       "   'problem',\n",
       "   'rarely',\n",
       "   'get',\n",
       "   'put',\n",
       "   'problem',\n",
       "   'set'],\n",
       "  ['theorem',\n",
       "   'often',\n",
       "   'call',\n",
       "   'division',\n",
       "   'algorithm',\n",
       "   'even',\n",
       "   'though',\n",
       "   'would',\n",
       "   'call',\n",
       "   'algorithm'],\n",
       "  ['take', 'familiar', 'result', 'grant', 'proof'],\n",
       "  ['famous',\n",
       "   'conjecture',\n",
       "   'number_theory',\n",
       "   'fermat',\n",
       "   'last',\n",
       "   'theorem',\n",
       "   'positive_integer',\n",
       "   'integer'],\n",
       "  ['book',\n",
       "   'read',\n",
       "   'fermat',\n",
       "   'claim',\n",
       "   'proof',\n",
       "   'enough',\n",
       "   'space',\n",
       "   'margin',\n",
       "   'write'],\n",
       "  ['wiles',\n",
       "   'finally',\n",
       "   'give',\n",
       "   'proof_theorem',\n",
       "   'year',\n",
       "   'work',\n",
       "   'secrecy',\n",
       "   'isolation',\n",
       "   'attic'],\n",
       "  ['proof', 'fit', 'margin'],\n",
       "  ['goldbach',\n",
       "   'conjecture',\n",
       "   'even',\n",
       "   'integ',\n",
       "   'great',\n",
       "   'equal',\n",
       "   'sum',\n",
       "   'prime',\n",
       "   'twin',\n",
       "   'prime',\n",
       "   'conjecture',\n",
       "   'infinitely_many',\n",
       "   'prime',\n",
       "   'also',\n",
       "   'prime'],\n",
       "  ['chen', 'show', 'infinitely_many', 'prime', 'product_prime'],\n",
       "  ['conjecture',\n",
       "   'know',\n",
       "   'almost',\n",
       "   'true',\n",
       "   'primality',\n",
       "   'testing',\n",
       "   'efficient',\n",
       "   'way',\n",
       "   'determine',\n",
       "   'number',\n",
       "   'prime'],\n",
       "  ['naive',\n",
       "   'search',\n",
       "   'factor',\n",
       "   'integer',\n",
       "   'take',\n",
       "   'number',\n",
       "   'step',\n",
       "   'proportional',\n",
       "   'exponential',\n",
       "   'size',\n",
       "   'decimal',\n",
       "   'bi',\n",
       "   'nary',\n",
       "   'notation'],\n",
       "  ['know', 'procedure', 'prime', 'check', 'blow', 'various', 'input'],\n",
       "  ['finally',\n",
       "   'amazingly',\n",
       "   'simple',\n",
       "   'new',\n",
       "   'method',\n",
       "   'discover',\n",
       "   'agrawal',\n",
       "   'kayal',\n",
       "   'saxena',\n",
       "   'show',\n",
       "   'prime',\n",
       "   'test',\n",
       "   'ing',\n",
       "   'require',\n",
       "   'polynomial',\n",
       "   'number',\n",
       "   'step'],\n",
       "  ['paper',\n",
       "   'begin',\n",
       "   'gauss',\n",
       "   'emphasizing',\n",
       "   'importance',\n",
       "   'antiquity',\n",
       "   'prob',\n",
       "   'lem',\n",
       "   'even',\n",
       "   'time',\n",
       "   'century',\n",
       "   'ago'],\n",
       "  ['prime',\n",
       "   'testing',\n",
       "   'definitely',\n",
       "   'category',\n",
       "   'infeasible',\n",
       "   'problem',\n",
       "   'require',\n",
       "   'exponentially',\n",
       "   'grow',\n",
       "   'number',\n",
       "   'step',\n",
       "   'bad',\n",
       "   'case'],\n",
       "  ['factor',\n",
       "   'give',\n",
       "   'product',\n",
       "   'large',\n",
       "   'prime',\n",
       "   'pq',\n",
       "   'efficient',\n",
       "   'way',\n",
       "   'recover',\n",
       "   'prime'],\n",
       "  ['best',\n",
       "   'know',\n",
       "   'algorithm',\n",
       "   'num_ber',\n",
       "   'field',\n",
       "   'sieve',\n",
       "   'run_time',\n",
       "   'proportional'],\n",
       "  ['ln', 'infeasible', 'digit'],\n",
       "  ['chapter_number',\n",
       "   'theory',\n",
       "   'number',\n",
       "   'call',\n",
       "   'quotient',\n",
       "   'number',\n",
       "   'call',\n",
       "   'remainder',\n",
       "   'divide'],\n",
       "  ['use', 'notation', 'qcnt'],\n",
       "  ['quotient', 'rem'],\n",
       "  ['remainder'],\n",
       "  ['example', 'qcnt'],\n",
       "  ['rem'],\n",
       "  ['similarly', 'rem'],\n",
       "  ['remainder', 'operator', 'build', 'many', 'programming', 'language'],\n",
       "  ['example', 'expression', 'evaluate', 'java'],\n",
       "  ['however', 'language', 'treat', 'negative', 'number', 'strangely']],\n",
       " [['die_hard', 'simon', 'fountain', 'jug', 'see', 'gallon', 'gallon'],\n",
       "  ['fill',\n",
       "   'jug',\n",
       "   'exactly',\n",
       "   'gallon',\n",
       "   'water',\n",
       "   'place',\n",
       "   'scale',\n",
       "   'timer',\n",
       "   'stop'],\n",
       "  ['must', 'precise', 'ounce', 'less', 'result', 'detonation'],\n",
       "  ['still', 'alive', 'minute', 'speak'],\n",
       "  ['bruce', 'wait', 'wait', 'second'],\n",
       "  ['samuel'],\n",
       "  ['bruce', 'get', 'jug'],\n",
       "  ['obviously', 'fill', 'gallon_jug', 'gallon', 'water'],\n",
       "  ['samuel', 'obviously'],\n",
       "  ['bruce', 'right'],\n",
       "  ['know', 'go'],\n",
       "  ['fill', 'gallon_jug', 'exactly', 'top', 'right', 'samuel'],\n",
       "  ['bruce',\n",
       "   'pour',\n",
       "   'gallon',\n",
       "   'gallon_jug',\n",
       "   'give',\n",
       "   'exactly',\n",
       "   'gallon',\n",
       "   'gallon_jug',\n",
       "   'right',\n",
       "   'samuel',\n",
       "   'right',\n",
       "   'bruce',\n",
       "   'right'],\n",
       "  ['take', 'gallon_jug', 'fill', 'third', 'way'],\n",
       "  ['samuel', 'say', 'precise'],\n",
       "  ['exactly', 'gallon'],\n",
       "  ['bruce', 'sh'],\n",
       "  ['cop', 'mile', 'run', 'play', 'kid', 'games', 'park'],\n",
       "  ['samuel',\n",
       "   'want',\n",
       "   'focus',\n",
       "   'problem',\n",
       "   'hand',\n",
       "   'precede',\n",
       "   'script',\n",
       "   'movie',\n",
       "   'die_hard',\n",
       "   'vengeance'],\n",
       "  ['movie', 'samuel'],\n",
       "  ['jackson',\n",
       "   'bruce',\n",
       "   'willis',\n",
       "   'disarm',\n",
       "   'bomb',\n",
       "   'plant',\n",
       "   'diabolical',\n",
       "   'simon',\n",
       "   'gruber'],\n",
       "  ['fortunately', 'find', 'solution', 'nick', 'time'],\n",
       "  ['doubt', 'reading', 'script', 'help'],\n",
       "  ['surface',\n",
       "   'die_hard',\n",
       "   'grade',\n",
       "   'action',\n",
       "   'movie',\n",
       "   'however',\n",
       "   'think',\n",
       "   'inner',\n",
       "   'message',\n",
       "   'film',\n",
       "   'learn',\n",
       "   'least',\n",
       "   'little',\n",
       "   'number_theory'],\n",
       "  ['unfortunately', 'hollywood', 'never', 'let', 'go', 'gimmick'],\n",
       "  ['water_jug',\n",
       "   'test',\n",
       "   'die_hard',\n",
       "   'live',\n",
       "   'free',\n",
       "   'die_hard',\n",
       "   'rumor',\n",
       "   'jug',\n",
       "   'return',\n",
       "   'future',\n",
       "   'sequel',\n",
       "   'die_hard',\n",
       "   'die_hard',\n",
       "   'bruce',\n",
       "   'go',\n",
       "   'vacation',\n",
       "   'shockingly',\n",
       "   'happen',\n",
       "   'terrorist',\n",
       "   'plot'],\n",
       "  ['save', 'day', 'must', 'make', 'gallon_use', 'gallon_jug'],\n",
       "  ['die_hard',\n",
       "   'die',\n",
       "   'old',\n",
       "   'age',\n",
       "   'bruce',\n",
       "   'must',\n",
       "   'save',\n",
       "   'assist',\n",
       "   'living',\n",
       "   'facility',\n",
       "   'criminal',\n",
       "   'mastermind',\n",
       "   'form',\n",
       "   'gallon',\n",
       "   'gallon_jug'],\n",
       "  ['die_hard', 'die', 'bruce', 'make', 'gallon_use', 'gallon_jug'],\n",
       "  ['would', 'nice', 'could', 'solve', 'silly', 'water_jug', 'question'],\n",
       "  ['particular',\n",
       "   'form',\n",
       "   'gallon_use',\n",
       "   'jug',\n",
       "   'capacitie',\n",
       "   'number_theory',\n",
       "   'come',\n",
       "   'handy'],\n",
       "  ['find', 'invariant', 'property', 'suppose', 'water_jug', 'capacity'],\n",
       "  ['state', 'system', 'describe', 'pair', 'number'],\n",
       "  ['amount_water', 'jug_capacity', 'amount', 'jug_capacity'],\n",
       "  ['let',\n",
       "   'carry',\n",
       "   'sample',\n",
       "   'operation',\n",
       "   'see',\n",
       "   'happen',\n",
       "   'assume',\n",
       "   'jug',\n",
       "   'big',\n",
       "   'enough',\n",
       "   'leap',\n",
       "   'step',\n",
       "   'amount_water_jug',\n",
       "   'form',\n",
       "   'integer'],\n",
       "  ['expression', 'form', 'lemma'],\n",
       "  ['suppose', 'water_jug', 'capacity'],\n",
       "  ['amount_water_jug', 'always', 'linear_combination'],\n",
       "  ['chapter_number',\n",
       "   'theory',\n",
       "   'lemma',\n",
       "   'easy',\n",
       "   'prove',\n",
       "   'induction',\n",
       "   'number',\n",
       "   'pouring'],\n",
       "  ['proof'],\n",
       "  ['induction_hypothesis'],\n",
       "  ['proposition', 'step', 'amount_water_jug', 'linear_combination'],\n",
       "  ['base_case'],\n",
       "  ['true', 'jug', 'initially', 'empty'],\n",
       "  ['inductive_step'],\n",
       "  ['assume',\n",
       "   'induction_hypothesis',\n",
       "   'step',\n",
       "   'amount_water_jug',\n",
       "   'linear_combination'],\n",
       "  ['case',\n",
       "   'fill',\n",
       "   'jug',\n",
       "   'fountain',\n",
       "   'empty',\n",
       "   'jug',\n",
       "   'fountain',\n",
       "   'jug',\n",
       "   'empty',\n",
       "   'full'],\n",
       "  ['amount', 'jug', 'remain', 'linear_combination'],\n",
       "  ['holds'],\n",
       "  ['otherwise', 'pour', 'water_jug', 'one', 'empty', 'full'],\n",
       "  ['assumption',\n",
       "   'amount',\n",
       "   'jug',\n",
       "   'linear',\n",
       "   'combina',\n",
       "   'tion',\n",
       "   'begin',\n",
       "   'pour',\n",
       "   'pour',\n",
       "   'jug',\n",
       "   'empty',\n",
       "   'contain',\n",
       "   'gallon',\n",
       "   'full',\n",
       "   'contain',\n",
       "   'establish',\n",
       "   'jug',\n",
       "   'problem',\n",
       "   'invariant',\n",
       "   'property',\n",
       "   'namely',\n",
       "   'amount_water_jug',\n",
       "   'always',\n",
       "   'linear_combination',\n",
       "   'capacitie',\n",
       "   'jug'],\n",
       "  ['lemma', 'important', 'corollary', 'corollary'],\n",
       "  ['bruce', 'die'],\n",
       "  ['proof'],\n",
       "  ['die_hard',\n",
       "   'bruce',\n",
       "   'water_jug',\n",
       "   'capacity',\n",
       "   'must',\n",
       "   'form',\n",
       "   'gallon',\n",
       "   'water'],\n",
       "  ['however',\n",
       "   'amount',\n",
       "   'jug',\n",
       "   'always',\n",
       "   'form',\n",
       "   'lemma_lemma',\n",
       "   'can',\n",
       "   'measure',\n",
       "   'gallon'],\n",
       "  ['lemma', 'satisfying'],\n",
       "  ['manage',\n",
       "   'recast',\n",
       "   'pretty',\n",
       "   'understandable',\n",
       "   'question',\n",
       "   'water_jug',\n",
       "   'complicate',\n",
       "   'question',\n",
       "   'linear_combination'],\n",
       "  ['may_seem', 'lot', 'progress'],\n",
       "  ['fortunately',\n",
       "   'linear',\n",
       "   'com',\n",
       "   'bination',\n",
       "   'closely',\n",
       "   'relate',\n",
       "   'familiar',\n",
       "   'namely',\n",
       "   'great_common_divisor',\n",
       "   'help',\n",
       "   'solve',\n",
       "   'water_jug',\n",
       "   'problem']],\n",
       " [['great_common_divisor',\n",
       "   'great_common_divisor',\n",
       "   'exactly',\n",
       "   'guess',\n",
       "   'large_number',\n",
       "   'divisor'],\n",
       "  ['denote', 'gcd'],\n",
       "  ['example', 'gcd'],\n",
       "  ['great_common_divisor',\n",
       "   'turn',\n",
       "   'valuable',\n",
       "   'piece',\n",
       "   'information',\n",
       "   'relationship',\n",
       "   'reasoning',\n",
       "   'integer',\n",
       "   'general'],\n",
       "  ['make', 'lot', 'argument', 'great_common_divisor', 'follow']],\n",
       " [['linear_combination',\n",
       "   'gcd',\n",
       "   'theorem',\n",
       "   'relate',\n",
       "   'great_common_divisor',\n",
       "   'linear_combination'],\n",
       "  ['theorem', 'useful', 'take', 'time', 'understand', 'remember', 'theorem'],\n",
       "  ['great_common_divisor',\n",
       "   'equal',\n",
       "   'smallest',\n",
       "   'positive',\n",
       "   'linear_combination'],\n",
       "  ['example', 'great_common_divisor'],\n",
       "  ['sure_enough', 'linear_combination'],\n",
       "  ['furthermore', 'linear_combination', 'equal', 'small', 'positive_integer'],\n",
       "  ['proof_theorem', 'first', 'show', 'gcd'],\n",
       "  ['common_divisor', 'divide', 'sa_tb', 'therefore', 'also', 'sa_tb'],\n",
       "  ['gcd'],\n",
       "  ['definition', 'common_divisor'],\n",
       "  ['particular', 'gcd'],\n",
       "  ['imply', 'gcd'],\n",
       "  ['show', 'gcd'],\n",
       "  ['show'],\n",
       "  ['symmetric', 'argument', 'show', 'mean', 'common_divisor'],\n",
       "  ['thus', 'must', 'less', 'equal', 'great_common_divisor'],\n",
       "  ['remain', 'show'],\n",
       "  ['division',\n",
       "   'algorithm',\n",
       "   'exist',\n",
       "   'quotient',\n",
       "   'remainder',\n",
       "   'chapter_number',\n",
       "   'theory',\n",
       "   'recall',\n",
       "   'sa_tb',\n",
       "   'integer'],\n",
       "  ['substituting', 'give'],\n",
       "  ['sa_tb'],\n",
       "  ['qs'],\n",
       "  ['express', 'linear_combination'],\n",
       "  ['however', 'small', 'positive', 'linear_combination'],\n",
       "  ['possibility', 'remainder', 'positive'],\n",
       "  ['imply'],\n",
       "  ['corollary'],\n",
       "  ['integer', 'linear_combination', 'iff', 'multiple', 'gcd'],\n",
       "  ['proof'],\n",
       "  ['gcd'],\n",
       "  ['restate',\n",
       "   'water_jug',\n",
       "   'lemma',\n",
       "   'term',\n",
       "   'greatest',\n",
       "   'common',\n",
       "   'divi',\n",
       "   'sor',\n",
       "   'corollary'],\n",
       "  ['suppose', 'water_jug', 'capacity'],\n",
       "  ['amount_water_jug', 'always', 'multiple', 'gcd'],\n",
       "  ['example',\n",
       "   'way',\n",
       "   'form',\n",
       "   'gallon_use',\n",
       "   'gallon_jug',\n",
       "   'cause',\n",
       "   'multiple',\n",
       "   'gcd']],\n",
       " [['property',\n",
       "   'greatest',\n",
       "   'common_divisor',\n",
       "   'often',\n",
       "   'make',\n",
       "   'use',\n",
       "   'basic',\n",
       "   'gcd',\n",
       "   'fact',\n",
       "   'lemma'],\n",
       "  ['follow',\n",
       "   'statement',\n",
       "   'greatest',\n",
       "   'common_divisor',\n",
       "   'hold',\n",
       "   'common_divisor',\n",
       "   'divide',\n",
       "   'gcd'],\n",
       "  ['gcd'],\n",
       "  ['ka', 'kb'],\n",
       "  ['gcd'],\n",
       "  ['gcd'],\n",
       "  ['gcd'],\n",
       "  ['bc'],\n",
       "  ['bc', 'gcd'],\n",
       "  ['gcd'],\n",
       "  ['gcd'],\n",
       "  ['rem'],\n",
       "  ['trick',\n",
       "   'proving',\n",
       "   'statement',\n",
       "   'translate',\n",
       "   'gcd',\n",
       "   'world',\n",
       "   'linear_combination',\n",
       "   'world',\n",
       "   'use',\n",
       "   'theorem'],\n",
       "  ['proof'],\n",
       "  ['prove',\n",
       "   'part',\n",
       "   'proof',\n",
       "   'imply',\n",
       "   'exist',\n",
       "   'integer',\n",
       "   'sa_tb',\n",
       "   'ua',\n",
       "   'vc',\n",
       "   'multiply',\n",
       "   'equation',\n",
       "   'give',\n",
       "   'leave_side',\n",
       "   'rewrite'],\n",
       "  ['asu', 'btu', 'csv', 'bc'],\n",
       "  ['tv'],\n",
       "  ['linear_combination', 'bc', 'equal', 'gcd'],\n",
       "  ['bc', 'theorem', 'proof', 'say', 'gcd'],\n",
       "  ['bc', 'equal', 'linear_combination', 'bc'],\n",
       "  ['ac', 'trivially', 'bc', 'assumption'],\n",
       "  ['therefore', 'divide', 'linear_combination', 'bc'],\n",
       "  ['particular', 'divide', 'gcd'],\n",
       "  ['bc', 'gcd'],\n",
       "  ['first', 'equality', 'use', 'part', 'second', 'use', 'assumption', 'gcd']],\n",
       " [['euclid_algorithm',\n",
       "   'part',\n",
       "   'lemma',\n",
       "   'useful',\n",
       "   'quickly',\n",
       "   'compute',\n",
       "   'great_common',\n",
       "   'divi',\n",
       "   'sor',\n",
       "   'number'],\n",
       "  ['example',\n",
       "   'could',\n",
       "   'compute',\n",
       "   'great_common_divisor',\n",
       "   'repeatedly',\n",
       "   'apply',\n",
       "   'part',\n",
       "   'gcd'],\n",
       "  ['gcd_rem'],\n",
       "  ['gcd_rem'],\n",
       "  ['gcd_rem'],\n",
       "  ['gcd_rem'],\n",
       "  ['gcd_rem'],\n",
       "  ['gcd_rem'],\n",
       "  ['gcd'],\n",
       "  ['chapter_number',\n",
       "   'theory',\n",
       "   'last',\n",
       "   'equation',\n",
       "   'may',\n",
       "   'look',\n",
       "   'wrong',\n",
       "   'divisor',\n",
       "   'integer',\n",
       "   'divide'],\n",
       "  ['process', 'call', 'euclid_algorithm', 'discover', 'greeks', 'year_ago'],\n",
       "  ['prove',\n",
       "   'algorithm',\n",
       "   'always',\n",
       "   'eventually',\n",
       "   'terminate',\n",
       "   'use_induction',\n",
       "   'fact',\n",
       "   'number',\n",
       "   'step',\n",
       "   'keep',\n",
       "   'get',\n",
       "   'small',\n",
       "   'remainder',\n",
       "   'whereupon',\n",
       "   'compute',\n",
       "   'gcd'],\n",
       "  ['fact',\n",
       "   'number',\n",
       "   'get',\n",
       "   'small',\n",
       "   'quickly',\n",
       "   'least',\n",
       "   'factor',\n",
       "   'step',\n",
       "   'eul',\n",
       "   'algorithm',\n",
       "   'quite',\n",
       "   'fast'],\n",
       "  ['fact',\n",
       "   'euclid_algorithm',\n",
       "   'actually',\n",
       "   'produce',\n",
       "   'gcd',\n",
       "   'different',\n",
       "   'also',\n",
       "   'prove',\n",
       "   'inductive',\n",
       "   'invariant',\n",
       "   'argument'],\n",
       "  ['calculation', 'gcd'],\n",
       "  ['together',\n",
       "   'corollary',\n",
       "   'imply',\n",
       "   'way',\n",
       "   'measure',\n",
       "   'gallon',\n",
       "   'water',\n",
       "   'use',\n",
       "   'jug_capacity',\n",
       "   'obtain',\n",
       "   'multiple',\n",
       "   'gallon_jug'],\n",
       "  ['good_news',\n",
       "   'bruce',\n",
       "   'even',\n",
       "   'survive',\n",
       "   'die_hard',\n",
       "   'die_hard',\n",
       "   'possible',\n",
       "   'bruce',\n",
       "   'make',\n",
       "   'gallon_use',\n",
       "   'gallon_jug',\n",
       "   'use',\n",
       "   'euclid_algorithm',\n",
       "   'gcd'],\n",
       "  ['gcd'],\n",
       "  ['gcd'],\n",
       "  ['multiple', 'rule', 'possibility', 'gallon', 'form'],\n",
       "  ['hand', 'know', 'do', 'either'],\n",
       "  ['resolve', 'matter', 'need', 'number_theory']],\n",
       " [['solution',\n",
       "   'water_jug',\n",
       "   'problem',\n",
       "   'corollary',\n",
       "   'say',\n",
       "   'write',\n",
       "   'linear_combination',\n",
       "   'multiple',\n",
       "   'gcd'],\n",
       "  ['word', 'exist', 'integer', 'know', 'coefficient', 'know', 'exist'],\n",
       "  ['coefficient', 'could', 'positive', 'negative'],\n",
       "  ['however',\n",
       "   'readily',\n",
       "   'transform',\n",
       "   'linear_combination',\n",
       "   'equivalent',\n",
       "   'linear_combination',\n",
       "   'coefficient',\n",
       "   'form',\n",
       "   'gallon_use',\n",
       "   'jug_capacity',\n",
       "   'simply',\n",
       "   'repeat',\n",
       "   'follow',\n",
       "   'step',\n",
       "   'fill',\n",
       "   'gallon_jug'],\n",
       "  ['pour', 'water', 'gallon_jug', 'gallon_jug'],\n",
       "  ['time',\n",
       "   'gallon_jug',\n",
       "   'become',\n",
       "   'full',\n",
       "   'empty',\n",
       "   'continue',\n",
       "   'pour',\n",
       "   'gallon_jug',\n",
       "   'gallon_jug'],\n",
       "  ['end', 'process', 'must', 'empty', 'gallon_jug', 'exactly', 'jt', 'times'],\n",
       "  ['take',\n",
       "   'time',\n",
       "   'equation',\n",
       "   'remarkably',\n",
       "   'even',\n",
       "   'need',\n",
       "   'know',\n",
       "   'coefficient',\n",
       "   'chapter_number',\n",
       "   'theory',\n",
       "   'approach',\n",
       "   'work',\n",
       "   'regardless',\n",
       "   'jug_capacity',\n",
       "   'even',\n",
       "   'regardless',\n",
       "   'amount',\n",
       "   'try',\n",
       "   'produce',\n",
       "   'simply',\n",
       "   'repeat',\n",
       "   'step',\n",
       "   'desire',\n",
       "   'amount_water',\n",
       "   'obtain',\n",
       "   'fill',\n",
       "   'small',\n",
       "   'jug'],\n",
       "  ['pour', 'water', 'small', 'jug', 'large', 'jug'],\n",
       "  ['time',\n",
       "   'large',\n",
       "   'jug',\n",
       "   'become',\n",
       "   'full',\n",
       "   'empty',\n",
       "   'continue',\n",
       "   'pour',\n",
       "   'small',\n",
       "   'jug',\n",
       "   'large',\n",
       "   'jug'],\n",
       "  ['reasoning',\n",
       "   'method',\n",
       "   'eventually',\n",
       "   'generate',\n",
       "   'multiple',\n",
       "   'great_common_divisor',\n",
       "   'jug',\n",
       "   'capacitie',\n",
       "   'quantity',\n",
       "   'possibly',\n",
       "   'produce'],\n",
       "  ['ingenuity', 'need']],\n",
       " [['pulverizer',\n",
       "   'show',\n",
       "   'matter',\n",
       "   'pair',\n",
       "   'number',\n",
       "   'give',\n",
       "   'always',\n",
       "   'pair',\n",
       "   'integer',\n",
       "   'coefficient'],\n",
       "  ['sa_tb',\n",
       "   'unfortunately',\n",
       "   'proof',\n",
       "   'nonconstructive',\n",
       "   'suggest',\n",
       "   'way',\n",
       "   'find'],\n",
       "  ['job',\n",
       "   'tackle',\n",
       "   'mathematical',\n",
       "   'tool',\n",
       "   'date',\n",
       "   'sixth',\n",
       "   'century',\n",
       "   'india',\n",
       "   'call',\n",
       "   'kuttak',\n",
       "   'mean',\n",
       "   'pulverizer'],\n",
       "  ['today',\n",
       "   'pul',\n",
       "   'verizer',\n",
       "   'commonly',\n",
       "   'know',\n",
       "   'extended',\n",
       "   'euclidean',\n",
       "   'gcd',\n",
       "   'algorithm',\n",
       "   'close',\n",
       "   'euclid_algorithm'],\n",
       "  ['euclid_algorithm',\n",
       "   'find',\n",
       "   'gcd',\n",
       "   'number',\n",
       "   'rely',\n",
       "   'repeat',\n",
       "   'ap',\n",
       "   'plication',\n",
       "   'equation',\n",
       "   'gcd'],\n",
       "  ['gcd'],\n",
       "  ['rem'],\n",
       "  ['example', 'compute', 'gcd', 'follow', 'gcd'],\n",
       "  ['gcd'],\n",
       "  ['gcd'],\n",
       "  ['gcd'],\n",
       "  ['gcd'],\n",
       "  ['rem'],\n",
       "  ['rem'],\n",
       "  ['rem'],\n",
       "  ['rem'],\n",
       "  ['pulverizer',\n",
       "   'go',\n",
       "   'step',\n",
       "   'require',\n",
       "   'extra',\n",
       "   'bookkeeping',\n",
       "   'way',\n",
       "   'compute',\n",
       "   'gcd'],\n",
       "  ['keep',\n",
       "   'track',\n",
       "   'write',\n",
       "   'remainder',\n",
       "   'example',\n",
       "   'linear_combination',\n",
       "   'worthwhile',\n",
       "   'objective',\n",
       "   'write',\n",
       "   'last',\n",
       "   'nonzero',\n",
       "   'remainder',\n",
       "   'gcd',\n",
       "   'linear_combination'],\n",
       "  ['example', 'extra', 'bookkeeping', 'begin', 'initialize', 'variable'],\n",
       "  ['first', 'column', 'carry', 'euclid_algorithm'],\n",
       "  ['step_compute', 'rem'],\n",
       "  ['write', 'form'],\n",
       "  ['remember', 'division', 'algorithm', 'say', 'remainder'],\n",
       "  ['rearranging', 'term'],\n",
       "  ['replace',\n",
       "   'equation',\n",
       "   'equivalent',\n",
       "   'linear',\n",
       "   'combina',\n",
       "   'tion',\n",
       "   'already',\n",
       "   'compute'],\n",
       "  ['simplify',\n",
       "   'left',\n",
       "   'chapter_number',\n",
       "   'theory',\n",
       "   'linear_combination',\n",
       "   'equal',\n",
       "   'remainder',\n",
       "   'desire'],\n",
       "  ['final', 'solution', 'box'],\n",
       "  ['prove', 'pulverizer', 'always', 'work', 'terminate', 'use_induction'],\n",
       "  ['indeed', 'pulverize', 'large_number', 'quickly', 'use', 'algorithm'],\n",
       "  ['soon',\n",
       "   'see',\n",
       "   'speed',\n",
       "   'make',\n",
       "   'pulverizer',\n",
       "   'useful',\n",
       "   'tool',\n",
       "   'field',\n",
       "   'cryptography']],\n",
       " [['fundamental_theorem',\n",
       "   'arithmetic',\n",
       "   'almost',\n",
       "   'enough',\n",
       "   'tool',\n",
       "   'prove',\n",
       "   'probably',\n",
       "   'already_know'],\n",
       "  ['theorem'],\n",
       "  ['fundamental_theorem', 'arithmetic'],\n",
       "  ['positive_integer',\n",
       "   'write',\n",
       "   'unique',\n",
       "   'way',\n",
       "   'product_prime',\n",
       "   'notice',\n",
       "   'theorem',\n",
       "   'would',\n",
       "   'false',\n",
       "   'consider',\n",
       "   'prime',\n",
       "   'example',\n",
       "   'could',\n",
       "   'written',\n",
       "   'certain',\n",
       "   'wonder',\n",
       "   'fundamental_theorem',\n",
       "   'even',\n",
       "   'know',\n",
       "   'crib'],\n",
       "  ['prime', 'show', 'erratically', 'sequence', 'integer'],\n",
       "  ['fact',\n",
       "   'distribution',\n",
       "   'seem',\n",
       "   'almost',\n",
       "   'random',\n",
       "   'basic',\n",
       "   'question',\n",
       "   'sequence',\n",
       "   'stump',\n",
       "   'humanity',\n",
       "   'century'],\n",
       "  ['know', 'natural_number', 'build', 'prime', 'exactly', 'way'],\n",
       "  ['quirky', 'number', 'building', 'block', 'integer'],\n",
       "  ['fundamental_theorem',\n",
       "   'hard',\n",
       "   'prove',\n",
       "   'need',\n",
       "   'couple',\n",
       "   'pre',\n",
       "   'liminary',\n",
       "   'fact'],\n",
       "  ['lemma'],\n",
       "  ['prime', 'ab'],\n",
       "  ['proof'],\n",
       "  ['great_common_divisor', 'must', 'positive', 'divisor'],\n",
       "  ['gcd'],\n",
       "  ['claim', 'hold', 'cause', 'multiple'],\n",
       "  ['otherwise', 'gcd'],\n",
       "  ['part',\n",
       "   'lemma',\n",
       "   'prime_number',\n",
       "   'theorem',\n",
       "   'let',\n",
       "   'lim',\n",
       "   'thus',\n",
       "   'prime',\n",
       "   'gradually',\n",
       "   'taper'],\n",
       "  ['rule_thumb', 'integer', 'ln', 'vicinity', 'prime'],\n",
       "  ['prime_number',\n",
       "   'theorem',\n",
       "   'conjecture',\n",
       "   'legendre',\n",
       "   'prove',\n",
       "   'century',\n",
       "   'later',\n",
       "   'de',\n",
       "   'la',\n",
       "   'vallee',\n",
       "   'poussin',\n",
       "   'hadamard'],\n",
       "  ['however',\n",
       "   'death',\n",
       "   'notebook',\n",
       "   'gauss',\n",
       "   'find',\n",
       "   'contain',\n",
       "   'conjecture',\n",
       "   'apparently',\n",
       "   'make',\n",
       "   'age'],\n",
       "  ['sort',\n",
       "   'feel',\n",
       "   'sorry',\n",
       "   'oth',\n",
       "   'erwise',\n",
       "   'great',\n",
       "   'mathematicians',\n",
       "   'misfortune',\n",
       "   'contemporaries',\n",
       "   'gauss'],\n",
       "  ['late',\n",
       "   'billboard',\n",
       "   'appear',\n",
       "   'various',\n",
       "   'location',\n",
       "   'country',\n",
       "   'first',\n",
       "   'digit',\n",
       "   'prime',\n",
       "   'find',\n",
       "   'consecutive',\n",
       "   'digit',\n",
       "   'substitute',\n",
       "   'correct',\n",
       "   'number',\n",
       "   'expression',\n",
       "   'curly',\n",
       "   'brace',\n",
       "   'produce',\n",
       "   'url',\n",
       "   'google',\n",
       "   'employment',\n",
       "   'page'],\n",
       "  ['idea',\n",
       "   'google',\n",
       "   'interested',\n",
       "   'hire',\n",
       "   'sort',\n",
       "   'people',\n",
       "   'could',\n",
       "   'would',\n",
       "   'solve_problem'],\n",
       "  ['hard',\n",
       "   'problem',\n",
       "   'would',\n",
       "   'look',\n",
       "   'thousand',\n",
       "   'million',\n",
       "   'billion',\n",
       "   'digit',\n",
       "   'find',\n",
       "   'digit',\n",
       "   'prime',\n",
       "   'rule_thumb',\n",
       "   'derive',\n",
       "   'prime_number',\n",
       "   'theorem',\n",
       "   'say',\n",
       "   'digit',\n",
       "   'number',\n",
       "   'ln',\n",
       "   'prime'],\n",
       "  ['suggest',\n",
       "   'problem',\n",
       "   'really',\n",
       "   'hard',\n",
       "   'sure_enough',\n",
       "   'first',\n",
       "   'digit',\n",
       "   'prime',\n",
       "   'consecutive',\n",
       "   'digit',\n",
       "   'appear',\n",
       "   'quite',\n",
       "   'early',\n",
       "   'chapter_number',\n",
       "   'theory',\n",
       "   'routine',\n",
       "   'induction',\n",
       "   'argument',\n",
       "   'extend',\n",
       "   'statement',\n",
       "   'lemma'],\n",
       "  ['let', 'prime'],\n",
       "  ['ready', 'prove', 'fundamental_theorem', 'arithmetic'],\n",
       "  ['proof'],\n",
       "  ['theorem',\n",
       "   'show',\n",
       "   'use_well',\n",
       "   'order_principle',\n",
       "   'posi',\n",
       "   'tive',\n",
       "   'integer',\n",
       "   'express',\n",
       "   'product_prime'],\n",
       "  ['prove', 'expression', 'unique'],\n",
       "  ['use_well', 'order', 'prove'],\n",
       "  ['proof_contradiction',\n",
       "   'assume',\n",
       "   'contrary',\n",
       "   'claim',\n",
       "   'exist',\n",
       "   'positive_integer',\n",
       "   'write',\n",
       "   'product',\n",
       "   'primes',\n",
       "   'way'],\n",
       "  ['order_principle', 'small', 'integer', 'property'],\n",
       "  ['call', 'integer', 'let', 'possibly', 'many_way', 'write', 'product_prime'],\n",
       "  ['imply', 'definition', 'smallest', 'positive_integer']],\n",
       " [['alan',\n",
       "   'turing',\n",
       "   'man',\n",
       "   'picture',\n",
       "   'figure',\n",
       "   'alan_ture',\n",
       "   'important',\n",
       "   'figure',\n",
       "   'history',\n",
       "   'computer_science'],\n",
       "  ['decade',\n",
       "   'fascinating',\n",
       "   'life',\n",
       "   'story',\n",
       "   'shroud',\n",
       "   'government',\n",
       "   'secrecy',\n",
       "   'societal',\n",
       "   'taboo',\n",
       "   'even',\n",
       "   'deception'],\n",
       "  ['age',\n",
       "   'ture',\n",
       "   'write',\n",
       "   'paper',\n",
       "   'entitle',\n",
       "   'computable',\n",
       "   'number',\n",
       "   'ap',\n",
       "   'plication'],\n",
       "  ['crux',\n",
       "   'paper',\n",
       "   'elegant',\n",
       "   'way',\n",
       "   'model',\n",
       "   'computer',\n",
       "   'mathematical',\n",
       "   'term'],\n",
       "  ['breakthrough',\n",
       "   'allow',\n",
       "   'tool',\n",
       "   'mathematic',\n",
       "   'bring',\n",
       "   'bear',\n",
       "   'question',\n",
       "   'computation'],\n",
       "  ['example',\n",
       "   'model',\n",
       "   'hand',\n",
       "   'ture',\n",
       "   'immediately',\n",
       "   'prove',\n",
       "   'exist',\n",
       "   'problem',\n",
       "   'computer',\n",
       "   'solve',\n",
       "   'matter',\n",
       "   'ingenious',\n",
       "   'programmer'],\n",
       "  ['ture',\n",
       "   'paper',\n",
       "   'remarkable',\n",
       "   'write',\n",
       "   'full',\n",
       "   'decade',\n",
       "   'electronic',\n",
       "   'computer',\n",
       "   'actually',\n",
       "   'exist'],\n",
       "  ['word',\n",
       "   'title',\n",
       "   'refer',\n",
       "   'mathemat',\n",
       "   'ical',\n",
       "   'problem',\n",
       "   'pose',\n",
       "   'david',\n",
       "   'hilbert',\n",
       "   'challenge',\n",
       "   'mathematicians'],\n",
       "  ['alan',\n",
       "   'turing',\n",
       "   'photograph',\n",
       "   'alan_ture',\n",
       "   'remove',\n",
       "   'due',\n",
       "   'copyright',\n",
       "   'restriction'],\n",
       "  ['see', 'th', 'century'],\n",
       "  ['ture', 'knock', 'paper'],\n",
       "  ['perhaps', 'hear', 'church', 'ture', 'thesis', 'paper'],\n",
       "  ['ture',\n",
       "   'obviously',\n",
       "   'brilliant',\n",
       "   'guy',\n",
       "   'generate',\n",
       "   'lot',\n",
       "   'amazing',\n",
       "   'idea'],\n",
       "  ['lecture', 'ture', 'less', 'amazing', 'idea'],\n",
       "  ['involved', 'code'],\n",
       "  ['involved', 'number_theory'],\n",
       "  ['sort', 'stupid'],\n",
       "  ['let_look', 'back', 'fall'],\n",
       "  ['nazi',\n",
       "   'germany',\n",
       "   'rearm',\n",
       "   'adolf',\n",
       "   'hitler',\n",
       "   'world',\n",
       "   'shatter',\n",
       "   'war',\n",
       "   'look',\n",
       "   'imminent',\n",
       "   'alan_ture',\n",
       "   'pon',\n",
       "   'dere',\n",
       "   'usefulness',\n",
       "   'number_theory'],\n",
       "  ['foresaw',\n",
       "   'preserve',\n",
       "   'military',\n",
       "   'secret',\n",
       "   'would',\n",
       "   'vital',\n",
       "   'come',\n",
       "   'conflict',\n",
       "   'propose',\n",
       "   'way',\n",
       "   'encrypt',\n",
       "   'communica',\n",
       "   'tion',\n",
       "   'use',\n",
       "   'number_theory'],\n",
       "  ['idea', 'ricochet', 'time'],\n",
       "  ['today',\n",
       "   'number_theory',\n",
       "   'basis',\n",
       "   'numerous',\n",
       "   'public_key',\n",
       "   'cryptosystem',\n",
       "   'digital',\n",
       "   'signature',\n",
       "   'scheme',\n",
       "   'cryptographic',\n",
       "   'hash',\n",
       "   'function',\n",
       "   'electronic',\n",
       "   'payment',\n",
       "   'system'],\n",
       "  ['furthermore',\n",
       "   'military',\n",
       "   'funding',\n",
       "   'agency',\n",
       "   'big',\n",
       "   'investor',\n",
       "   'crypto',\n",
       "   'graphic',\n",
       "   'research'],\n",
       "  ['soon',\n",
       "   'devise',\n",
       "   'code',\n",
       "   'ture',\n",
       "   'disappear',\n",
       "   'public',\n",
       "   'view',\n",
       "   'half',\n",
       "   'century',\n",
       "   'would',\n",
       "   'pass',\n",
       "   'world',\n",
       "   'learn',\n",
       "   'full',\n",
       "   'story',\n",
       "   'go'],\n",
       "  ['come',\n",
       "   'back',\n",
       "   'ture',\n",
       "   'life',\n",
       "   'little',\n",
       "   'let',\n",
       "   'investigate',\n",
       "   'code',\n",
       "   'turing',\n",
       "   'leave',\n",
       "   'behind'],\n",
       "  ['detail',\n",
       "   'uncertain',\n",
       "   'never',\n",
       "   'formally',\n",
       "   'publish',\n",
       "   'idea',\n",
       "   'consider',\n",
       "   'couple',\n",
       "   'possibility'],\n",
       "  ['chapter_number', 'theory']],\n",
       " [['ture_code', 'version'],\n",
       "  ['first',\n",
       "   'challenge',\n",
       "   'translate',\n",
       "   'text',\n",
       "   'message',\n",
       "   'integer',\n",
       "   'perform',\n",
       "   'mathematical',\n",
       "   'operation'],\n",
       "  ['step', 'intend', 'make', 'message', 'hard', 'read', 'detail', 'important'],\n",
       "  ['approach', 'replace', 'letter', 'message', 'digit'],\n",
       "  ['stre', 'digit', 'together', 'form', 'huge', 'number'],\n",
       "  ['example',\n",
       "   'message',\n",
       "   'victory',\n",
       "   'could',\n",
       "   'translate',\n",
       "   'way',\n",
       "   'ture_code',\n",
       "   'require',\n",
       "   'message',\n",
       "   'prime_number',\n",
       "   'may',\n",
       "   'need',\n",
       "   'pad',\n",
       "   'result',\n",
       "   'digit',\n",
       "   'make',\n",
       "   'prime'],\n",
       "  ['case', 'append', 'digits', 'give', 'number', 'prime'],\n",
       "  ['encryption', 'process', 'work'],\n",
       "  ['description',\n",
       "   'unencoded',\n",
       "   'message',\n",
       "   'want',\n",
       "   'keep',\n",
       "   'secret',\n",
       "   'encrypt_message',\n",
       "   'nazi',\n",
       "   'may',\n",
       "   'intercept',\n",
       "   'key'],\n",
       "  ['beforehand',\n",
       "   'sender',\n",
       "   'receiver',\n",
       "   'agree',\n",
       "   'secret_key',\n",
       "   'large',\n",
       "   'prime',\n",
       "   'encryption',\n",
       "   'sender',\n",
       "   'encrypt_message',\n",
       "   'compute',\n",
       "   'decryption',\n",
       "   'receiver',\n",
       "   'decrypt',\n",
       "   'compute',\n",
       "   'example_suppose',\n",
       "   'secret_key',\n",
       "   'prime_number',\n",
       "   'message',\n",
       "   'victory'],\n",
       "  ['encrypt_message',\n",
       "   'couple',\n",
       "   'question',\n",
       "   'may',\n",
       "   'naturally',\n",
       "   'ask',\n",
       "   'ture_code'],\n",
       "  ['sender',\n",
       "   'receiver',\n",
       "   'ensure',\n",
       "   'prime_number',\n",
       "   'require',\n",
       "   'general',\n",
       "   'problem',\n",
       "   'determine',\n",
       "   'large_number',\n",
       "   'prime',\n",
       "   'com',\n",
       "   'posite',\n",
       "   'study',\n",
       "   'century',\n",
       "   'reasonably',\n",
       "   'good',\n",
       "   'primality',\n",
       "   'test',\n",
       "   'know',\n",
       "   'even',\n",
       "   'ture',\n",
       "   'time'],\n",
       "  ['manindra',\n",
       "   'agrawal',\n",
       "   'neeraj',\n",
       "   'kayal',\n",
       "   'nitin',\n",
       "   'saxena',\n",
       "   'announce',\n",
       "   'primality',\n",
       "   'test',\n",
       "   'guarantee',\n",
       "   'work',\n",
       "   'number'],\n",
       "  ['log',\n",
       "   'course',\n",
       "   'twelfth',\n",
       "   'degree',\n",
       "   'polynomial',\n",
       "   'grow',\n",
       "   'pretty',\n",
       "   'fast',\n",
       "   'agrawal',\n",
       "   'al'],\n",
       "  ['procedure', 'practical', 'use'],\n",
       "  ['still',\n",
       "   'good_idea',\n",
       "   'way',\n",
       "   'breed',\n",
       "   'good_idea',\n",
       "   'certainly',\n",
       "   'hope',\n",
       "   'improvement',\n",
       "   'lead',\n",
       "   'procedure',\n",
       "   'useful',\n",
       "   'practice'],\n",
       "  ['truth',\n",
       "   'practical',\n",
       "   'nee',\n",
       "   'improve',\n",
       "   'efficient',\n",
       "   'probabilistic',\n",
       "   'procedure',\n",
       "   'prime',\n",
       "   'testing',\n",
       "   'know',\n",
       "   'early'],\n",
       "  ['procedure',\n",
       "   'probability',\n",
       "   'give',\n",
       "   'wrong',\n",
       "   'answer',\n",
       "   'probability',\n",
       "   'wrong',\n",
       "   'tiny',\n",
       "   'relying',\n",
       "   'answer',\n",
       "   'best',\n",
       "   'bet',\n",
       "   'ever',\n",
       "   'make'],\n",
       "  ['ture_code',\n",
       "   'secure',\n",
       "   'nazis',\n",
       "   'see',\n",
       "   'encrypt_message',\n",
       "   'recover',\n",
       "   'original',\n",
       "   'message',\n",
       "   'require',\n",
       "   'factor'],\n",
       "  ['immense',\n",
       "   'effort',\n",
       "   'ally',\n",
       "   'efficient',\n",
       "   'factoring',\n",
       "   'algorithm',\n",
       "   'ever',\n",
       "   'find'],\n",
       "  ['appear',\n",
       "   'fundamentally',\n",
       "   'difficult',\n",
       "   'problem',\n",
       "   'breakthrough',\n",
       "   'someday',\n",
       "   'be',\n",
       "   'possible'],\n",
       "  ['effect',\n",
       "   'ture_code',\n",
       "   'put',\n",
       "   'practical',\n",
       "   'use',\n",
       "   'discovery',\n",
       "   'limit',\n",
       "   'power',\n",
       "   'computation'],\n",
       "  ['thus',\n",
       "   'provide',\n",
       "   'sufficiently',\n",
       "   'large',\n",
       "   'nazi',\n",
       "   'seem',\n",
       "   'luck',\n",
       "   'sound',\n",
       "   'promise',\n",
       "   'major',\n",
       "   'flaw',\n",
       "   'ture_code']],\n",
       " [['break',\n",
       "   'ture_code',\n",
       "   'let',\n",
       "   'consider',\n",
       "   'happen',\n",
       "   'sender',\n",
       "   'transmit',\n",
       "   'second',\n",
       "   'message',\n",
       "   'use',\n",
       "   'ture_code',\n",
       "   'key'],\n",
       "  ['give',\n",
       "   'nazis',\n",
       "   'encrypt_message',\n",
       "   'look',\n",
       "   'greatest',\n",
       "   'common_divisor',\n",
       "   'encrypt_message',\n",
       "   'chapter_number',\n",
       "   'theory',\n",
       "   'difficult',\n",
       "   'believe',\n",
       "   'mathematician',\n",
       "   'brilliant',\n",
       "   'turing',\n",
       "   'could',\n",
       "   'overlook',\n",
       "   'glaring',\n",
       "   'problem'],\n",
       "  ['possible',\n",
       "   'explanation',\n",
       "   'slightly',\n",
       "   'different',\n",
       "   'system',\n",
       "   'mind',\n",
       "   'base',\n",
       "   'modular',\n",
       "   'arithmetic']],\n",
       " [['modular',\n",
       "   'arithmetic',\n",
       "   'page',\n",
       "   'masterpiece',\n",
       "   'number_theory',\n",
       "   'disquisitione',\n",
       "   'arithmeticae',\n",
       "   'gauss',\n",
       "   'introduce',\n",
       "   'notion',\n",
       "   'congruence'],\n",
       "  ['gauss', 'guy', 'manage', 'cough', 'decent', 'idea', 'let', 'take', 'look'],\n",
       "  ['close', 'connection', 'congruence', 'remainder', 'lemma'],\n",
       "  ['congruence', 'remainder'],\n",
       "  ['mod', 'iff', 'rem'],\n",
       "  ['rem'],\n",
       "  ['proof'],\n",
       "  ['division',\n",
       "   'theorem',\n",
       "   'exist',\n",
       "   'unique',\n",
       "   'pair',\n",
       "   'integer',\n",
       "   'subtract',\n",
       "   'second',\n",
       "   'equation',\n",
       "   'first',\n",
       "   'give'],\n",
       "  ['mod', 'divide', 'left', 'side'],\n",
       "  ['true', 'divide', 'right_side', 'hold', 'rem'],\n",
       "  ['rem'],\n",
       "  ['also', 'see'],\n",
       "  ['mod', 'rem'],\n",
       "  ['rem'],\n",
       "  ['formulation',\n",
       "   'explain',\n",
       "   'congruence',\n",
       "   'relation',\n",
       "   'property',\n",
       "   'equal',\n",
       "   'ity',\n",
       "   'relation'],\n",
       "  ['notice',\n",
       "   'even',\n",
       "   'mod',\n",
       "   'appear',\n",
       "   'right_side',\n",
       "   'symbol',\n",
       "   'strongly',\n",
       "   'associate'],\n",
       "  ['would',\n",
       "   'really',\n",
       "   'clearer',\n",
       "   'write',\n",
       "   'mod',\n",
       "   'make',\n",
       "   'frequent',\n",
       "   'use',\n",
       "   'follow',\n",
       "   'immediate',\n",
       "   'corollary',\n",
       "   'lemma',\n",
       "   'corollary'],\n",
       "  ['rem'],\n",
       "  ['still',\n",
       "   'way',\n",
       "   'think',\n",
       "   'congruence',\n",
       "   'modulo',\n",
       "   'define',\n",
       "   'partition',\n",
       "   'integer',\n",
       "   'set',\n",
       "   'congruent',\n",
       "   'number',\n",
       "   'set'],\n",
       "  ['example_suppose', 'work_modulo'],\n",
       "  ['partition', 'integer', 'set', 'follow', 'accord', 'remainder', 'division'],\n",
       "  ['upshot',\n",
       "   'arithmetic',\n",
       "   'do',\n",
       "   'modulo',\n",
       "   'really',\n",
       "   'different',\n",
       "   'kind',\n",
       "   'number',\n",
       "   'worry',\n",
       "   'possible',\n",
       "   'remainder'],\n",
       "  ['sense',\n",
       "   'modular',\n",
       "   'arithmetic',\n",
       "   'simplification',\n",
       "   'ordinary',\n",
       "   'arithmetic',\n",
       "   'thus',\n",
       "   'good',\n",
       "   'reasoning',\n",
       "   'tool'],\n",
       "  ['many', 'useful', 'fact', 'congruence', 'list', 'lemma'],\n",
       "  ['overall',\n",
       "   'theme',\n",
       "   'congruence',\n",
       "   'work',\n",
       "   'lot',\n",
       "   'equation',\n",
       "   'couple',\n",
       "   'exception'],\n",
       "  ['lemma'],\n",
       "  ['fact', 'congruence'],\n",
       "  ['follow', 'hold'],\n",
       "  ['mod'],\n",
       "  ['mod_imply'],\n",
       "  ['mod'],\n",
       "  ['mod'],\n",
       "  ['mod_imply'],\n",
       "  ['mod'],\n",
       "  ['mod_imply'],\n",
       "  ['mod'],\n",
       "  ['mod_imply', 'ac', 'bc'],\n",
       "  ['mod'],\n",
       "  ['mod'],\n",
       "  ['mod_imply'],\n",
       "  ['mod'],\n",
       "  ['mod'],\n",
       "  ['mod_imply', 'bd'],\n",
       "  ['mod', 'chapter_number', 'theory', 'proof'],\n",
       "  ['part'],\n",
       "  ['follow', 'immediately', 'lemma', 'part'],\n",
       "  ['follow', 'imme'],\n",
       "  ['likewise', 'part'],\n",
       "  ['bc'],\n",
       "  ['prove', 'part'],\n",
       "  ['part', 'similar', 'proof']],\n",
       " [['ture_code', 'version'],\n",
       "  ['france',\n",
       "   'fall',\n",
       "   'hitler',\n",
       "   'army',\n",
       "   'britain',\n",
       "   'stand',\n",
       "   'alone',\n",
       "   'nazis',\n",
       "   'western',\n",
       "   'europe'],\n",
       "  ['british',\n",
       "   'resistance',\n",
       "   'depend',\n",
       "   'steady',\n",
       "   'flow',\n",
       "   'sup',\n",
       "   'ply',\n",
       "   'bring',\n",
       "   'north',\n",
       "   'atlantic',\n",
       "   'united',\n",
       "   'states',\n",
       "   'convoys',\n",
       "   'ship'],\n",
       "  ['convoy',\n",
       "   'engage',\n",
       "   'cat',\n",
       "   'mouse',\n",
       "   'game',\n",
       "   'german',\n",
       "   'boat',\n",
       "   'submarine',\n",
       "   'prowl',\n",
       "   'atlantic',\n",
       "   'try',\n",
       "   'sink',\n",
       "   'supply',\n",
       "   'ship',\n",
       "   'starve',\n",
       "   'britain',\n",
       "   'submission'],\n",
       "  ['outcome',\n",
       "   'struggle',\n",
       "   'pivot',\n",
       "   'balance',\n",
       "   'formation',\n",
       "   'could',\n",
       "   'germans',\n",
       "   'locate',\n",
       "   'convoy',\n",
       "   'well',\n",
       "   'ally',\n",
       "   'could',\n",
       "   'locate',\n",
       "   'boat',\n",
       "   'vice',\n",
       "   'germany',\n",
       "   'lose'],\n",
       "  ['critical',\n",
       "   'reason',\n",
       "   'germany',\n",
       "   'loss',\n",
       "   'make',\n",
       "   'public',\n",
       "   'ger',\n",
       "   'many',\n",
       "   'naval',\n",
       "   'code',\n",
       "   'enigma',\n",
       "   'break',\n",
       "   'secret',\n",
       "   'turn',\n",
       "   'british',\n",
       "   'week',\n",
       "   'nazi',\n",
       "   'invasion',\n",
       "   'poland'],\n",
       "  ['much',\n",
       "   'war',\n",
       "   'ally',\n",
       "   'able',\n",
       "   'route',\n",
       "   'con',\n",
       "   'voy',\n",
       "   'german',\n",
       "   'submarine',\n",
       "   'listen',\n",
       "   'german',\n",
       "   'communication'],\n",
       "  ['british', 'government', 'explain', 'enigma', 'broken'],\n",
       "  ['finally',\n",
       "   'release',\n",
       "   'story',\n",
       "   'reveal',\n",
       "   'alan_ture',\n",
       "   'join',\n",
       "   'secret',\n",
       "   'british',\n",
       "   'codebreaking',\n",
       "   'effort',\n",
       "   'bletchley',\n",
       "   'park',\n",
       "   'become',\n",
       "   'lead',\n",
       "   'developer',\n",
       "   'method',\n",
       "   'rapid',\n",
       "   'bulk',\n",
       "   'decryption',\n",
       "   'german',\n",
       "   'enigma',\n",
       "   'message'],\n",
       "  ['ture',\n",
       "   'enigma',\n",
       "   'decipher',\n",
       "   'invaluable',\n",
       "   'contribution',\n",
       "   'ally',\n",
       "   'victory',\n",
       "   'hitler'],\n",
       "  ['government',\n",
       "   'always',\n",
       "   'tight',\n",
       "   'lip',\n",
       "   'cryptography',\n",
       "   'half',\n",
       "   'century',\n",
       "   'official',\n",
       "   'silence',\n",
       "   'ture',\n",
       "   'role',\n",
       "   'break',\n",
       "   'enigma',\n",
       "   'save',\n",
       "   'britain',\n",
       "   'may',\n",
       "   'relate',\n",
       "   'disturbing',\n",
       "   'event',\n",
       "   'war'],\n",
       "  ['later'],\n",
       "  ['let',\n",
       "   'back',\n",
       "   'number_theory',\n",
       "   'consider',\n",
       "   'alternative',\n",
       "   'interpretation',\n",
       "   'ture_code'],\n",
       "  ['perhaps',\n",
       "   'basic',\n",
       "   'idea',\n",
       "   'multiply',\n",
       "   'message',\n",
       "   'key',\n",
       "   'err',\n",
       "   'use',\n",
       "   'conventional',\n",
       "   'arithmetic',\n",
       "   'instead',\n",
       "   'modular',\n",
       "   'arithmetic'],\n",
       "  ['maybe',\n",
       "   'ture',\n",
       "   'mean',\n",
       "   'beforehand',\n",
       "   'sender',\n",
       "   'receiver',\n",
       "   'agree',\n",
       "   'large',\n",
       "   'prime',\n",
       "   'may',\n",
       "   'make',\n",
       "   'public'],\n",
       "  ['modulus', 'arithmetic'],\n",
       "  ['also', 'agree', 'secret_key'],\n",
       "  ['encryption',\n",
       "   'message',\n",
       "   'integer',\n",
       "   'set',\n",
       "   'particular',\n",
       "   'message',\n",
       "   'longer',\n",
       "   'require',\n",
       "   'prime'],\n",
       "  ['sender', 'crypts', 'message', 'produce', 'compute', 'rem'],\n",
       "  ['mk', 'decryption'],\n",
       "  ['decryption', 'step', 'problem'],\n",
       "  ['may', 'hope', 'decrypt', 'way', 'divide', 'encrypt_message', 'key'],\n",
       "  ['difficulty', 'remainder', 'mk', 'divide'],\n",
       "  ['divide',\n",
       "   'may',\n",
       "   'even',\n",
       "   'give',\n",
       "   'integer',\n",
       "   'decode',\n",
       "   'difficulty',\n",
       "   'overcome',\n",
       "   'better',\n",
       "   'understanding',\n",
       "   'arith',\n",
       "   'metic',\n",
       "   'modulo_prime']],\n",
       " [['arithmetic', 'prime', 'modulus']],\n",
       " [['multiplicative_inverse',\n",
       "   'multiplicative_inverse',\n",
       "   'number',\n",
       "   'number',\n",
       "   'generally',\n",
       "   'multiplicative_inverse',\n",
       "   'exist',\n",
       "   'real_number'],\n",
       "  ['example', 'multiplicative_inverse', 'sole', 'exception', 'inverse'],\n",
       "  ['chapter_number',\n",
       "   'theory',\n",
       "   'hand',\n",
       "   'inverse',\n",
       "   'generally',\n",
       "   'exist',\n",
       "   'integer'],\n",
       "  ['example', 'multiply', 'integer', 'give'],\n",
       "  ['surprisingly',\n",
       "   'multiplicative_inverse',\n",
       "   'exist',\n",
       "   'work_modulo',\n",
       "   'prime_number'],\n",
       "  ['example', 'work_modulo', 'multiplicative_inverse', 'lemma'],\n",
       "  ['prime', 'multiple', 'multiplicative_inverse', 'modulo'],\n",
       "  ['proof'],\n",
       "  ['prime', 'divisor'],\n",
       "  ['tiple', 'must', 'gcd'],\n",
       "  ['therefore',\n",
       "   'linear_combination',\n",
       "   'equal',\n",
       "   'sp',\n",
       "   'tk',\n",
       "   'rearranging',\n",
       "   'term',\n",
       "   'give',\n",
       "   'sp',\n",
       "   'tk',\n",
       "   'imply'],\n",
       "  ['tk', 'definition', 'divisibility', 'therefore', 'tk'],\n",
       "  ['multiplicative_inverse', 'key', 'decryption', 'ture_code'],\n",
       "  ['specifically',\n",
       "   'recover',\n",
       "   'original',\n",
       "   'message',\n",
       "   'multiplying',\n",
       "   'encode',\n",
       "   'message',\n",
       "   'inverse',\n",
       "   'key',\n",
       "   'rem'],\n",
       "  ['mk'],\n",
       "  ['mod', 'show', 'rem'],\n",
       "  ['need', 'decrypt', 'message', 'find', 'value']],\n",
       " [['cancellation',\n",
       "   'sense',\n",
       "   'real_number',\n",
       "   'nice',\n",
       "   'cancel',\n",
       "   'multiplicative',\n",
       "   'term'],\n",
       "  ['word',\n",
       "   'know',\n",
       "   'cancel',\n",
       "   'conclude',\n",
       "   'cancel',\n",
       "   'lead',\n",
       "   'false',\n",
       "   'conclusion'],\n",
       "  ['mod', 'lemma'],\n",
       "  ['suppose', 'prime', 'multiple'],\n",
       "  ['ak', 'bk'],\n",
       "  ['mod_imply'],\n",
       "  ['mod', 'proof'],\n",
       "  ['multiply',\n",
       "   'side',\n",
       "   'congruence',\n",
       "   'use',\n",
       "   'lemma',\n",
       "   'get',\n",
       "   'bit',\n",
       "   'insight',\n",
       "   'ture_code',\n",
       "   'work'],\n",
       "  ['particular',\n",
       "   'encryption',\n",
       "   'operation',\n",
       "   'ture_code',\n",
       "   'permute',\n",
       "   'set',\n",
       "   'possible',\n",
       "   'message'],\n",
       "  ['state', 'precisely', 'follow', 'corollary'],\n",
       "  ['corollary'],\n",
       "  ['suppose', 'prime', 'multiple'],\n",
       "  ['sequence', 'rem'],\n",
       "  ['rem'],\n",
       "  ['rem'],\n",
       "  ['permutation', 'sequence'],\n",
       "  ['proof'],\n",
       "  ['sequence', 'remainder', 'contain', 'number'],\n",
       "  ['divisible', 'remainder', 'range', 'definition', 'remainder'],\n",
       "  ['furthermore',\n",
       "   'remainder',\n",
       "   'different',\n",
       "   'number',\n",
       "   'range',\n",
       "   'congruent',\n",
       "   'modulo',\n",
       "   'lemma',\n",
       "   'remainder',\n",
       "   'must',\n",
       "   'contain',\n",
       "   'number',\n",
       "   'order'],\n",
       "  ['permutation', 'sequence', 'element', 'reorder', 'element'],\n",
       "  ['chapter_number', 'theory', 'example_suppose', 'permutation'],\n",
       "  ['long', 'nazis', 'know', 'secret_key']],\n",
       " [['fermat',\n",
       "   'little',\n",
       "   'theorem',\n",
       "   'alternative',\n",
       "   'approach',\n",
       "   'find',\n",
       "   'inverse',\n",
       "   'secret_key',\n",
       "   'theorem'],\n",
       "  ['fermat', 'little', 'theorem'],\n",
       "  ['suppose'],\n",
       "  ['mod', 'proof'],\n",
       "  ['reason', 'follow', 'wwd', 'rem', 'rem'],\n",
       "  ['mod',\n",
       "   'mod',\n",
       "   'multiple',\n",
       "   'prime',\n",
       "   'factorization',\n",
       "   'contain',\n",
       "   'prime',\n",
       "   'small',\n",
       "   'cancel',\n",
       "   'first',\n",
       "   'last',\n",
       "   'expression',\n",
       "   'prove',\n",
       "   'claim'],\n",
       "  ['find', 'inverse', 'use', 'fermat', 'theorem'],\n",
       "  ['suppose', 'mod', 'therefore', 'hold', 'modulo'],\n",
       "  ['therefore', 'rem'],\n",
       "  ['general',\n",
       "   'work_modulo',\n",
       "   'prime',\n",
       "   'find',\n",
       "   'multiplicative',\n",
       "   'verse',\n",
       "   'try',\n",
       "   'value',\n",
       "   'would',\n",
       "   'require',\n",
       "   'operation'],\n",
       "  ['however',\n",
       "   'approach',\n",
       "   'require',\n",
       "   'log',\n",
       "   'operation',\n",
       "   'far',\n",
       "   'better',\n",
       "   'large']],\n",
       " [['break',\n",
       "   'ture_code',\n",
       "   'german',\n",
       "   'bother',\n",
       "   'encrypt',\n",
       "   'weather',\n",
       "   'report',\n",
       "   'highly',\n",
       "   'secure',\n",
       "   'enigma',\n",
       "   'system'],\n",
       "  ['ally',\n",
       "   'learn',\n",
       "   'rain',\n",
       "   'south',\n",
       "   'coast',\n",
       "   'iceland',\n",
       "   'amazingly',\n",
       "   'practice',\n",
       "   'provide',\n",
       "   'british',\n",
       "   'critical',\n",
       "   'edge',\n",
       "   'atlantic',\n",
       "   'naval',\n",
       "   'battle'],\n",
       "  ['problem',\n",
       "   'weather',\n",
       "   'report',\n",
       "   'originally',\n",
       "   'tran',\n",
       "   'mitte',\n",
       "   'use',\n",
       "   'enigma',\n",
       "   'boat',\n",
       "   'atlantic'],\n",
       "  ['thus',\n",
       "   'british',\n",
       "   'obtain',\n",
       "   'unencrypted',\n",
       "   'report',\n",
       "   'report',\n",
       "   'encrypt',\n",
       "   'enigma'],\n",
       "  ['com',\n",
       "   'pare',\n",
       "   'british',\n",
       "   'able',\n",
       "   'determine',\n",
       "   'key',\n",
       "   'germans',\n",
       "   'use',\n",
       "   'day',\n",
       "   'could',\n",
       "   'read',\n",
       "   'enigma',\n",
       "   'encode',\n",
       "   'traffic'],\n",
       "  ['today', 'would', 'call', 'known', 'plaintext', 'attack'],\n",
       "  ['let_see', 'know', 'plaintext', 'attack', 'would', 'work', 'ture_code'],\n",
       "  ['sup', 'pose', 'nazis', 'know'],\n",
       "  ['mod', 'compute', 'rem'],\n",
       "  ['mk'],\n",
       "  ['mod',\n",
       "   'nazis',\n",
       "   'secret_key',\n",
       "   'decrypt',\n",
       "   'message',\n",
       "   'chapter_number',\n",
       "   'theory',\n",
       "   'huge',\n",
       "   'vulnerability',\n",
       "   'ture_code',\n",
       "   'practical',\n",
       "   'value'],\n",
       "  ['fortunately',\n",
       "   'ture',\n",
       "   'get',\n",
       "   'well',\n",
       "   'cryptography',\n",
       "   'devising',\n",
       "   'code',\n",
       "   'subsequent',\n",
       "   'decipher',\n",
       "   'ing',\n",
       "   'enigma',\n",
       "   'message',\n",
       "   'surely',\n",
       "   'save',\n",
       "   'thousand',\n",
       "   'live',\n",
       "   'whole',\n",
       "   'britain']],\n",
       " [['ture', 'postscript', 'year', 'war', 'ture', 'home', 'rob'],\n",
       "  ['detective',\n",
       "   'soon',\n",
       "   'determine',\n",
       "   'former',\n",
       "   'homosexual',\n",
       "   'lover',\n",
       "   'ture',\n",
       "   'conspire',\n",
       "   'robbery'],\n",
       "  ['arrest',\n",
       "   'arrest',\n",
       "   'alan_ture',\n",
       "   'homosexuality',\n",
       "   'british',\n",
       "   'crime',\n",
       "   'punishable',\n",
       "   'year',\n",
       "   'prison',\n",
       "   'time'],\n",
       "  ['ture',\n",
       "   'sentence',\n",
       "   'hormonal',\n",
       "   'treatment',\n",
       "   'homosexuality',\n",
       "   'give',\n",
       "   'estrogen',\n",
       "   'injection'],\n",
       "  ['begin', 'develop', 'breast'],\n",
       "  ['year', 'later', 'alan_ture', 'founder', 'computer_science', 'dead'],\n",
       "  ['mother', 'explain', 'happen', 'biography', 'son'],\n",
       "  ['peated', 'warning', 'ture', 'carry', 'chemistry', 'experiment', 'home'],\n",
       "  ['ap',\n",
       "   'parently',\n",
       "   'bad',\n",
       "   'fear',\n",
       "   'realize',\n",
       "   'work',\n",
       "   'potassium',\n",
       "   'cyanide',\n",
       "   'eat',\n",
       "   'apple',\n",
       "   'poison'],\n",
       "  ['however', 'ture', 'remain', 'puzzle', 'end'],\n",
       "  ['mother', 'devoutly', 'religious', 'woman', 'consider', 'suicide', 'sin'],\n",
       "  ['biographer',\n",
       "   'point',\n",
       "   'ture',\n",
       "   'previously',\n",
       "   'discuss',\n",
       "   'commit',\n",
       "   'suicide',\n",
       "   'eating',\n",
       "   'poison',\n",
       "   'ap',\n",
       "   'ple'],\n",
       "  ['evidently',\n",
       "   'alan_ture',\n",
       "   'found',\n",
       "   'computer_science',\n",
       "   'save',\n",
       "   'country',\n",
       "   'take',\n",
       "   'life',\n",
       "   'end',\n",
       "   'way',\n",
       "   'mother',\n",
       "   'could',\n",
       "   'believe',\n",
       "   'accident'],\n",
       "  ['ture',\n",
       "   'last',\n",
       "   'project',\n",
       "   'disappear',\n",
       "   'public',\n",
       "   'view',\n",
       "   'involve',\n",
       "   'construction',\n",
       "   'elaborate',\n",
       "   'mechanical',\n",
       "   'device',\n",
       "   'test',\n",
       "   'mathematical',\n",
       "   'conjecture',\n",
       "   'call',\n",
       "   'riemann',\n",
       "   'hypothesis'],\n",
       "  ['conjecture',\n",
       "   'first',\n",
       "   'appear',\n",
       "   'sketchy',\n",
       "   'paper',\n",
       "   'bernhard',\n",
       "   'riemann',\n",
       "   'famous',\n",
       "   'unsolved',\n",
       "   'problem',\n",
       "   'mathematic']],\n",
       " [['arithmetic', 'arbitrary', 'modulus', 'ture_code', 'work', 'hope'],\n",
       "  ['however',\n",
       "   'essential',\n",
       "   'idea',\n",
       "   'use',\n",
       "   'num_ber',\n",
       "   'theory',\n",
       "   'basis',\n",
       "   'cryptography',\n",
       "   'succeed',\n",
       "   'spectacularly',\n",
       "   'decade',\n",
       "   'death'],\n",
       "  ['ronald',\n",
       "   'rivest',\n",
       "   'adi',\n",
       "   'shamir',\n",
       "   'leonard',\n",
       "   'adleman',\n",
       "   'mit',\n",
       "   'propose',\n",
       "   'highly',\n",
       "   'secure',\n",
       "   'cryptosystem',\n",
       "   'call',\n",
       "   'rsa',\n",
       "   'base',\n",
       "   'number_theory'],\n",
       "  ['decade', 'attack', 'significant', 'weakness', 'find'],\n",
       "  ['moreover',\n",
       "   'rsa',\n",
       "   'major',\n",
       "   'advantage',\n",
       "   'traditional',\n",
       "   'code',\n",
       "   'sender',\n",
       "   'receiver',\n",
       "   'encrypt',\n",
       "   'mes',\n",
       "   'riemann',\n",
       "   'hypothesis',\n",
       "   'formula',\n",
       "   'sum',\n",
       "   'infinite',\n",
       "   'geometric_series',\n",
       "   'say',\n",
       "   'substitute'],\n",
       "  ['multiply',\n",
       "   'together',\n",
       "   'leave_side',\n",
       "   'right_side',\n",
       "   'give',\n",
       "   'sum',\n",
       "   'leave',\n",
       "   'obtain',\n",
       "   'multiply',\n",
       "   'infinite',\n",
       "   'series',\n",
       "   'ap',\n",
       "   'ply',\n",
       "   'fundamental_theorem',\n",
       "   'arithmetic'],\n",
       "  ['example', 'term', 'definition'],\n",
       "  ['riemann', 'hypothesis', 'nontrivial', 'zeta', 'func_tion'],\n",
       "  ['lie', 'line', 'ci', 'complex', 'plane'],\n",
       "  ['proof',\n",
       "   'would',\n",
       "   'immediately',\n",
       "   'imply',\n",
       "   'thing',\n",
       "   'strong',\n",
       "   'form',\n",
       "   'prime_number',\n",
       "   'theorem'],\n",
       "  ['researcher',\n",
       "   'continue',\n",
       "   'work',\n",
       "   'intensely',\n",
       "   'settle',\n",
       "   'conjecture',\n",
       "   'century'],\n",
       "  ['solver', 'earn', 'clay', 'institute'],\n",
       "  ['chapter_number',\n",
       "   'theory',\n",
       "   'sage',\n",
       "   'nee',\n",
       "   'meet',\n",
       "   'beforehand',\n",
       "   'agree',\n",
       "   'secret_key'],\n",
       "  ['rather',\n",
       "   'receiver',\n",
       "   'secret_key',\n",
       "   'guard',\n",
       "   'closely',\n",
       "   'public_key',\n",
       "   'distribute',\n",
       "   'widely',\n",
       "   'possible'],\n",
       "  ['sender',\n",
       "   'encrypts',\n",
       "   'message',\n",
       "   'use',\n",
       "   'widely',\n",
       "   'distribute',\n",
       "   'public_key'],\n",
       "  ['decrypt',\n",
       "   'receive',\n",
       "   'message',\n",
       "   'use',\n",
       "   'closely',\n",
       "   'hold',\n",
       "   'private',\n",
       "   'key'],\n",
       "  ['use',\n",
       "   'public_key',\n",
       "   'cryptography',\n",
       "   'system',\n",
       "   'allow',\n",
       "   'amazon',\n",
       "   'example',\n",
       "   'engage',\n",
       "   'secure',\n",
       "   'transaction',\n",
       "   'meet',\n",
       "   'beforehand',\n",
       "   'dark',\n",
       "   'alley',\n",
       "   'exchange',\n",
       "   'key'],\n",
       "  ['interestingly',\n",
       "   'rsa',\n",
       "   'operate',\n",
       "   'modulo_prime',\n",
       "   'ture',\n",
       "   'scheme',\n",
       "   'may',\n",
       "   'rather',\n",
       "   'modulo',\n",
       "   'product',\n",
       "   'large',\n",
       "   'prime'],\n",
       "  ['thus',\n",
       "   'need',\n",
       "   'know',\n",
       "   'bit',\n",
       "   'arithmetic',\n",
       "   'works',\n",
       "   'modulo',\n",
       "   'composite',\n",
       "   'number',\n",
       "   'order',\n",
       "   'understand',\n",
       "   'rsa'],\n",
       "  ['arithmetic',\n",
       "   'modulo',\n",
       "   'arbitrary',\n",
       "   'positive_integer',\n",
       "   'really',\n",
       "   'little',\n",
       "   'painful',\n",
       "   'work_modulo',\n",
       "   'prime',\n",
       "   'though',\n",
       "   'may_think',\n",
       "   'doctor',\n",
       "   'say',\n",
       "   'go',\n",
       "   'hurt',\n",
       "   'little',\n",
       "   'jam',\n",
       "   'big',\n",
       "   'needle',\n",
       "   'arm']],\n",
       " [['relative', 'primality', 'first', 'need', 'new', 'definition'],\n",
       "  ['integer', 'relatively_prime', 'iff', 'gcd'],\n",
       "  ['example', 'relatively_prime', 'gcd'],\n",
       "  ['note', 'multiple', 'integer', 'relatively_prime', 'prime_number'],\n",
       "  ['next',\n",
       "   'need',\n",
       "   'generalize',\n",
       "   'know',\n",
       "   'arithmetic',\n",
       "   'modulo_prime',\n",
       "   'work_modulo',\n",
       "   'arbitrary',\n",
       "   'positive_integer'],\n",
       "  ['basic',\n",
       "   'theme',\n",
       "   'arithmetic',\n",
       "   'modulo',\n",
       "   'may',\n",
       "   'complicated',\n",
       "   'integer',\n",
       "   'relatively_prime',\n",
       "   'remain',\n",
       "   'fairly',\n",
       "   'well',\n",
       "   'behave'],\n",
       "  ['example',\n",
       "   'proof',\n",
       "   'lemma',\n",
       "   'inverse',\n",
       "   'modulo',\n",
       "   'extend',\n",
       "   'inverse',\n",
       "   'relatively_prime',\n",
       "   'lemma'],\n",
       "  ['let', 'positive_integer'],\n",
       "  ['relatively_prime', 'exist', 'integer'],\n",
       "  ['mod',\n",
       "   'consequence',\n",
       "   'lemma',\n",
       "   'cancel',\n",
       "   'multiplicative',\n",
       "   'term',\n",
       "   'side',\n",
       "   'congruence',\n",
       "   'term',\n",
       "   'relatively_prime',\n",
       "   'modulus',\n",
       "   'corollary'],\n",
       "  ['suppose', 'positive_integer', 'relatively_prime'],\n",
       "  ['ak', 'bk'],\n",
       "  ['mod'],\n",
       "  ['mod',\n",
       "   'hold',\n",
       "   'multiply',\n",
       "   'side',\n",
       "   'first',\n",
       "   'congruence',\n",
       "   'follow',\n",
       "   'lemma',\n",
       "   'natural',\n",
       "   'generalization',\n",
       "   'corollary',\n",
       "   'lemma'],\n",
       "  ['suppose',\n",
       "   'denote',\n",
       "   'integer',\n",
       "   'relatively_prime',\n",
       "   'range',\n",
       "   'sequence',\n",
       "   'rem',\n",
       "   'rem',\n",
       "   'permutation',\n",
       "   'sequence',\n",
       "   'proof'],\n",
       "  ['show',\n",
       "   'remainder',\n",
       "   'first',\n",
       "   'sequence',\n",
       "   'distinct',\n",
       "   'equal',\n",
       "   'member',\n",
       "   'sequence',\n",
       "   'first',\n",
       "   'show',\n",
       "   'remainder',\n",
       "   'first',\n",
       "   'sequence',\n",
       "   'distinct'],\n",
       "  ['suppose', 'rem'],\n",
       "  ['mod',\n",
       "   'mod',\n",
       "   'next',\n",
       "   'show',\n",
       "   'remainder',\n",
       "   'first',\n",
       "   'sequence',\n",
       "   'equal',\n",
       "   'gcd_rem',\n",
       "   'definition',\n",
       "   'remainder',\n",
       "   'relatively_prime']],\n",
       " [['euler',\n",
       "   'theorem',\n",
       "   'rsa',\n",
       "   'rely',\n",
       "   'heavily',\n",
       "   'generalization',\n",
       "   'fermat',\n",
       "   'theorem',\n",
       "   'know',\n",
       "   'eul',\n",
       "   'orem'],\n",
       "  ['theorems', 'exponent', 'denote', 'recall', 'gcd'],\n",
       "  ['never', 'relatively_prime'],\n",
       "  ['chapter_number', 'theory', 'composite', 'theorem'],\n",
       "  ['number', 'example', 'corollary'],\n",
       "  ['let',\n",
       "   'corollary',\n",
       "   'follow',\n",
       "   'easily',\n",
       "   'theorem',\n",
       "   'important',\n",
       "   'rsa',\n",
       "   'provide',\n",
       "   'proof_theorem',\n",
       "   'follow'],\n",
       "  ['proof', 'corollary', 'pq'],\n",
       "  ['claim'],\n",
       "  ['prove',\n",
       "   'euler',\n",
       "   'theorem',\n",
       "   'proof',\n",
       "   'provide',\n",
       "   'brief',\n",
       "   'preview',\n",
       "   'kind',\n",
       "   'count',\n",
       "   'argument',\n",
       "   'explore',\n",
       "   'fully',\n",
       "   'part'],\n",
       "  ['theorem'],\n",
       "  ['euler', 'theorem'],\n",
       "  ['suppose', 'positive_integer', 'rela', 'tively', 'prime'],\n",
       "  ['proof'],\n",
       "  ['let', 'part', 'prove', 'claim'],\n",
       "  ['find',\n",
       "   'multiplicative_inverse',\n",
       "   'use',\n",
       "   'eul',\n",
       "   'theorem',\n",
       "   'fer',\n",
       "   'mat',\n",
       "   'theorem',\n",
       "   'relatively_prime']],\n",
       " [['rsa',\n",
       "   'algorithm',\n",
       "   'finally',\n",
       "   'ready',\n",
       "   'rsa',\n",
       "   'public_key',\n",
       "   'encryption',\n",
       "   'scheme',\n",
       "   'work'],\n",
       "  ['detail', 'box', 'next', 'page'],\n",
       "  ['immediately',\n",
       "   'clear',\n",
       "   'description',\n",
       "   'rsa',\n",
       "   'cryptosystem',\n",
       "   'decode',\n",
       "   'encrypt_message',\n",
       "   'fact',\n",
       "   'original',\n",
       "   'unencrypted',\n",
       "   'mes',\n",
       "   'sage'],\n",
       "  ['order', 'check', 'case', 'need', 'show', 'decryption', 'rem'],\n",
       "  ['raise',\n",
       "   'side',\n",
       "   'power',\n",
       "   'obtain',\n",
       "   'congruence',\n",
       "   'chapter_number',\n",
       "   'theory',\n",
       "   'rsa',\n",
       "   'cryptosystem',\n",
       "   'beforehand',\n",
       "   'receiver',\n",
       "   'create',\n",
       "   'public_key',\n",
       "   'secret_key',\n",
       "   'follow'],\n",
       "  ['generate', 'distinct', 'prime'],\n",
       "  ['use', 'generate', 'secret_key', 'must', 'kept', 'hide'],\n",
       "  ['let'],\n",
       "  ['secret_key', 'pair'],\n",
       "  ['keep',\n",
       "   'hide',\n",
       "   'encode',\n",
       "   'give',\n",
       "   'message',\n",
       "   'sender',\n",
       "   'first',\n",
       "   'check',\n",
       "   'gcd'],\n",
       "  ['sender',\n",
       "   'encrypts',\n",
       "   'message',\n",
       "   'produce',\n",
       "   'decode',\n",
       "   'receiver',\n",
       "   'decrypt',\n",
       "   'message',\n",
       "   'rem'],\n",
       "  ['would', 'bad', 'gcd'],\n",
       "  ['equal',\n",
       "   'would',\n",
       "   'easy',\n",
       "   'use',\n",
       "   'encode',\n",
       "   'message',\n",
       "   'compute',\n",
       "   'secret_key',\n",
       "   'gcd'],\n",
       "  ['encode', 'message', 'would', 'fairly', 'useless'],\n",
       "  ['large', 'value', 'extremely', 'unlikely', 'gcd'],\n",
       "  ['happen',\n",
       "   'new',\n",
       "   'set',\n",
       "   'key',\n",
       "   'least',\n",
       "   'add',\n",
       "   'bit',\n",
       "   'result',\n",
       "   'message',\n",
       "   'relatively_prime'],\n",
       "  ['encryption',\n",
       "   'exponent',\n",
       "   'decryption',\n",
       "   'exponent',\n",
       "   'choose',\n",
       "   'hence',\n",
       "   'decryption',\n",
       "   'process',\n",
       "   'indeed',\n",
       "   'reproduce',\n",
       "   'original',\n",
       "   'message'],\n",
       "  ['hard',\n",
       "   'secret_key',\n",
       "   'decrypt',\n",
       "   'message',\n",
       "   'one',\n",
       "   'know',\n",
       "   'sure',\n",
       "   'generally',\n",
       "   'believe',\n",
       "   'large_number',\n",
       "   'say',\n",
       "   'digit',\n",
       "   'difficult',\n",
       "   'reverse',\n",
       "   'engineer'],\n",
       "  ['course',\n",
       "   'easy',\n",
       "   'compute',\n",
       "   'know',\n",
       "   'use',\n",
       "   'pulverizer',\n",
       "   'know',\n",
       "   'quickly',\n",
       "   'factor',\n",
       "   'large'],\n",
       "  ['maybe', 'little', 'study', 'number_theory', 'first', 'figure'],\n",
       "  ['warn', 'gauss', 'work', 'year', 'lot', 'show', 'effort'],\n",
       "  ['figure',\n",
       "   'may',\n",
       "   'wind',\n",
       "   'meet',\n",
       "   'serious',\n",
       "   'looking',\n",
       "   'fellow',\n",
       "   'black',\n",
       "   'suit'],\n",
       "  ['ii',\n",
       "   'structure',\n",
       "   'introduction',\n",
       "   'structure',\n",
       "   'fundamental',\n",
       "   'computer_science'],\n",
       "  ['write',\n",
       "   'code',\n",
       "   'solv',\n",
       "   'e',\n",
       "   'optimization',\n",
       "   'problem',\n",
       "   'design',\n",
       "   'network',\n",
       "   'deal',\n",
       "   'structure'],\n",
       "  ['better', 'understand', 'structure', 'well', 'result'],\n",
       "  ['reason',\n",
       "   'structure',\n",
       "   'good',\n",
       "   'position',\n",
       "   'convince',\n",
       "   'other',\n",
       "   'result',\n",
       "   'worthy'],\n",
       "  ['important',\n",
       "   'structure',\n",
       "   'computer_science',\n",
       "   'graph',\n",
       "   'also',\n",
       "   'know',\n",
       "   'net',\n",
       "   'work'],\n",
       "  ['graph',\n",
       "   'provide',\n",
       "   'excellent',\n",
       "   'mechanism',\n",
       "   'modeling',\n",
       "   'association',\n",
       "   'pair',\n",
       "   'object',\n",
       "   'example',\n",
       "   'exam',\n",
       "   'can',\n",
       "   'give',\n",
       "   'time',\n",
       "   'people',\n",
       "   'subroutine',\n",
       "   'run',\n",
       "   'independently'],\n",
       "  ['chapter',\n",
       "   'chapter',\n",
       "   'conclude',\n",
       "   'chapter',\n",
       "   'discussion',\n",
       "   'state',\n",
       "   'machine'],\n",
       "  ['state',\n",
       "   'machine',\n",
       "   'use',\n",
       "   'model',\n",
       "   'variety',\n",
       "   'process',\n",
       "   'fundamental',\n",
       "   'tool',\n",
       "   'prove',\n",
       "   'algorithm',\n",
       "   'terminate',\n",
       "   'produce',\n",
       "   'correct',\n",
       "   'output']],\n",
       " [['graph_theory',\n",
       "   'informally',\n",
       "   'graph',\n",
       "   'bunch',\n",
       "   'dot',\n",
       "   'line',\n",
       "   'line',\n",
       "   'connect_pair',\n",
       "   'dot'],\n",
       "  ['example', 'show_figure', 'figure'],\n",
       "  ['example', 'graph', 'node', 'edge'],\n",
       "  ['graphs',\n",
       "   'ubiquitous',\n",
       "   'computer_science',\n",
       "   'provide',\n",
       "   'handy',\n",
       "   'way',\n",
       "   'represent',\n",
       "   'relationship',\n",
       "   'pair',\n",
       "   'object'],\n",
       "  ['object',\n",
       "   'represent',\n",
       "   'item',\n",
       "   'interest',\n",
       "   'program',\n",
       "   'people',\n",
       "   'city',\n",
       "   'web',\n",
       "   'page',\n",
       "   'place',\n",
       "   'edge',\n",
       "   'pair_node',\n",
       "   'relate',\n",
       "   'certain',\n",
       "   'way'],\n",
       "  ['example',\n",
       "   'edge',\n",
       "   'pair_people',\n",
       "   'may',\n",
       "   'indicate',\n",
       "   'alternate',\n",
       "   'scenario'],\n",
       "  ['edge', 'pair', 'course', 'may', 'indicate', 'need', 'take'],\n",
       "  ['chapter',\n",
       "   'focus',\n",
       "   'attention',\n",
       "   'simple',\n",
       "   'graphs',\n",
       "   'relation',\n",
       "   'ship',\n",
       "   'denote',\n",
       "   'edge',\n",
       "   'symmetric'],\n",
       "  ['afterward', 'chapter']],\n",
       " [['definition']],\n",
       " [['simple', 'graphs', 'definition'],\n",
       "  ['simple',\n",
       "   'graph',\n",
       "   'consist',\n",
       "   'nonempty_set',\n",
       "   'call',\n",
       "   'ver',\n",
       "   'tice',\n",
       "   'aka',\n",
       "   'node',\n",
       "   'stanford',\n",
       "   'student',\n",
       "   'analyze',\n",
       "   'graph',\n",
       "   'become'],\n",
       "  ['pay',\n",
       "   'attention',\n",
       "   'graph_theory',\n",
       "   'know',\n",
       "   'may',\n",
       "   'happen',\n",
       "   'use',\n",
       "   'term',\n",
       "   'vertex',\n",
       "   'node',\n",
       "   'interchangeably'],\n",
       "  ['chapter_graph',\n",
       "   'theory',\n",
       "   'vertice',\n",
       "   'correspond',\n",
       "   'dot',\n",
       "   'figure',\n",
       "   'express',\n",
       "   'mathematically'],\n",
       "  ['fa',\n",
       "   'ig',\n",
       "   'cg',\n",
       "   'fb',\n",
       "   'fc',\n",
       "   'fc',\n",
       "   'eg',\n",
       "   'fe',\n",
       "   'fe',\n",
       "   'gg',\n",
       "   'fh',\n",
       "   'ig',\n",
       "   'note',\n",
       "   'fb',\n",
       "   'ag',\n",
       "   'different',\n",
       "   'description',\n",
       "   'edge',\n",
       "   'set',\n",
       "   'unordere'],\n",
       "  ['case', 'graph'],\n",
       "  ['nodes', 'edges'],\n",
       "  ['definition'],\n",
       "  ['vertex',\n",
       "   'simple',\n",
       "   'graph',\n",
       "   'say',\n",
       "   'adjacent',\n",
       "   'join',\n",
       "   'edge',\n",
       "   'edge',\n",
       "   'say',\n",
       "   'incident_vertex',\n",
       "   'join'],\n",
       "  ['number_edge', 'incident_vertex', 'call', 'degree_vertex', 'denote', 'deg'],\n",
       "  ['equivalently', 'degree_vertex', 'equal_number', 'vertex_adjacent'],\n",
       "  ['example',\n",
       "   'simple',\n",
       "   'graph_show',\n",
       "   'figure',\n",
       "   'note',\n",
       "   'simple',\n",
       "   'graphs',\n",
       "   'self',\n",
       "   'loop',\n",
       "   'edge',\n",
       "   'form',\n",
       "   'edge',\n",
       "   'define',\n",
       "   'set',\n",
       "   'vertex'],\n",
       "  ['addition', 'edge', 'pair_vertex', 'simple', 'graph'],\n",
       "  ['word', 'simple', 'graph_contain', 'multiedge', 'multiple', 'edge'],\n",
       "  ['set'],\n",
       "  ['lastly',\n",
       "   'importantly',\n",
       "   'simple',\n",
       "   'graphs',\n",
       "   'contain',\n",
       "   'direct_edge',\n",
       "   'edge',\n",
       "   'form'],\n",
       "  ['instead', 'bg'],\n",
       "  ['harm',\n",
       "   'relax',\n",
       "   'condition',\n",
       "   'author',\n",
       "   'need',\n",
       "   'self',\n",
       "   'loop',\n",
       "   'multiple',\n",
       "   'edge',\n",
       "   'vertex',\n",
       "   'graphs',\n",
       "   'vertex',\n",
       "   'simple',\n",
       "   'around'],\n",
       "  ['consider',\n",
       "   'graphs',\n",
       "   'recte',\n",
       "   'edge',\n",
       "   'call',\n",
       "   'direct_graphs',\n",
       "   'digraphs',\n",
       "   'length',\n",
       "   'chapter']],\n",
       " [['common', 'graphs', 'graph', 'come', 'frequently', 'name'],\n",
       "  ['complete', 'graph_vertex', 'denote', 'edge'],\n",
       "  ['example', 'empty', 'graph', 'edge'],\n",
       "  ['example',\n",
       "   'empty',\n",
       "   'graph',\n",
       "   'node',\n",
       "   'show_figure',\n",
       "   'cardinality',\n",
       "   'jej',\n",
       "   'set',\n",
       "   'number',\n",
       "   'element'],\n",
       "  ['figure'],\n",
       "  ['complete', 'graph', 'node', 'figure'],\n",
       "  ['empty', 'graph', 'node'],\n",
       "  ['node_graph',\n",
       "   'contain',\n",
       "   'edge',\n",
       "   'sequence',\n",
       "   'know',\n",
       "   'line',\n",
       "   'graph',\n",
       "   'fv_fv',\n",
       "   'fv_fv',\n",
       "   'example',\n",
       "   'add_edge',\n",
       "   'fv',\n",
       "   'line',\n",
       "   'graph_figure'],\n",
       "  ['node', 'line', 'graph', 'chapter_graph', 'theory_figure'],\n",
       "  ['node', 'cycle', 'graph_figure'],\n",
       "  ['graph_isomorphic']],\n",
       " [['isomorphism',\n",
       "   'graph',\n",
       "   'look',\n",
       "   'may',\n",
       "   'actually',\n",
       "   'different',\n",
       "   'formal',\n",
       "   'sense'],\n",
       "  ['example',\n",
       "   'graph_figure',\n",
       "   'simple',\n",
       "   'cycle',\n",
       "   'vertice',\n",
       "   'graph_vertex',\n",
       "   'set',\n",
       "   'fa',\n",
       "   'vertex',\n",
       "   'set'],\n",
       "  ['strictly',\n",
       "   'speak',\n",
       "   'graphs',\n",
       "   'different',\n",
       "   'mathematical',\n",
       "   'object',\n",
       "   'frustrating',\n",
       "   'distinction',\n",
       "   'graph',\n",
       "   'look',\n",
       "   'fortunately',\n",
       "   'neatly',\n",
       "   'capture',\n",
       "   'idea',\n",
       "   'look',\n",
       "   'tion',\n",
       "   'graph',\n",
       "   'isomorphism'],\n",
       "  ['definition'],\n",
       "  ['fu',\n",
       "   'function',\n",
       "   'call',\n",
       "   'isomorphism',\n",
       "   'word',\n",
       "   'graph_isomorphic',\n",
       "   'relabele',\n",
       "   'vertex'],\n",
       "  ['example', 'isomorphism', 'vertice', 'bijection', 'figure'],\n",
       "  ['way',\n",
       "   'draw',\n",
       "   'graph_show',\n",
       "   'figure',\n",
       "   'correspond',\n",
       "   'correspond',\n",
       "   'correspond',\n",
       "   'correspond',\n",
       "   'check',\n",
       "   'edge',\n",
       "   'vertex_graph',\n",
       "   'leave',\n",
       "   'edge',\n",
       "   'corresponding',\n",
       "   'vertex_graph',\n",
       "   'right'],\n",
       "  ['isomorphic', 'graph', 'may', 'draw', 'differently'],\n",
       "  ['example',\n",
       "   'show',\n",
       "   'different_way',\n",
       "   'draw',\n",
       "   'isomorphism',\n",
       "   'preserve',\n",
       "   'connection',\n",
       "   'propertie',\n",
       "   'graph',\n",
       "   'abstracting',\n",
       "   'vertex',\n",
       "   'call',\n",
       "   'make',\n",
       "   'appear',\n",
       "   'draw',\n",
       "   'graph'],\n",
       "  ['precisely',\n",
       "   'property',\n",
       "   'graph',\n",
       "   'say',\n",
       "   'preserve',\n",
       "   'isomorphism',\n",
       "   'whenever',\n",
       "   'property',\n",
       "   'graph_isomorphic',\n",
       "   'also',\n",
       "   'property'],\n",
       "  ['example', 'isomorphic', 'graph', 'must', 'number', 'vertex'],\n",
       "  ['graph', 'isomorphism', 'map', 'vertex_graph', 'vertex'],\n",
       "  ['isomorphic',\n",
       "   'graph',\n",
       "   'definition',\n",
       "   'isomor',\n",
       "   'phism',\n",
       "   'vertex_adjacent',\n",
       "   'first',\n",
       "   'graph',\n",
       "   'map',\n",
       "   'vertex_adjacent'],\n",
       "  ['isomorphic', 'graph'],\n",
       "  ['means'],\n",
       "  ['degree'],\n",
       "  ['graph_vertex', 'degree', 'isomorphic'],\n",
       "  ['fact', 'isomorphic', 'number', 'degree_vertex', 'graph'],\n",
       "  ['look',\n",
       "   'preserve',\n",
       "   'property',\n",
       "   'make',\n",
       "   'easy',\n",
       "   'determine',\n",
       "   'graph_isomorphic',\n",
       "   'actually',\n",
       "   'find',\n",
       "   'isomorphism'],\n",
       "  ['practice', 'frequently', 'easy', 'decide', 'graph_isomorphic'],\n",
       "  ['however',\n",
       "   'yet',\n",
       "   'find',\n",
       "   'general',\n",
       "   'procedure',\n",
       "   'determine',\n",
       "   'graph_isomorphic',\n",
       "   'guarantee',\n",
       "   'run',\n",
       "   'polynomial',\n",
       "   'time',\n",
       "   'jv'],\n",
       "  ['procedure', 'would', 'useful'],\n",
       "  ['example',\n",
       "   'would',\n",
       "   'make',\n",
       "   'easy',\n",
       "   'search',\n",
       "   'particular',\n",
       "   'molecule',\n",
       "   'database',\n",
       "   'give',\n",
       "   'molecular',\n",
       "   'bond'],\n",
       "  ['amount',\n",
       "   'time',\n",
       "   'upper',\n",
       "   'bound',\n",
       "   'jv',\n",
       "   'chapter_graph',\n",
       "   'theory',\n",
       "   'hand',\n",
       "   'know',\n",
       "   'efficient',\n",
       "   'procedure',\n",
       "   'would',\n",
       "   'also',\n",
       "   'valu',\n",
       "   'able',\n",
       "   'secure',\n",
       "   'protocol',\n",
       "   'encryption',\n",
       "   'remote',\n",
       "   'authentication',\n",
       "   'build',\n",
       "   'hypothesis',\n",
       "   'graph',\n",
       "   'isomorphism',\n",
       "   'computationally',\n",
       "   'exhausting']],\n",
       " [['subgraphs', 'definition'],\n",
       "  ['graph',\n",
       "   'example',\n",
       "   'empty',\n",
       "   'graph',\n",
       "   'node',\n",
       "   'subgraph',\n",
       "   'fg',\n",
       "   'ig',\n",
       "   'fh',\n",
       "   'ig',\n",
       "   'subgraph',\n",
       "   'graph_figure',\n",
       "   'graph_figure',\n",
       "   'contain',\n",
       "   'edge'],\n",
       "  ['note',\n",
       "   'subgraph',\n",
       "   'graph',\n",
       "   'endpoint',\n",
       "   'edge',\n",
       "   'sub',\n",
       "   'graph',\n",
       "   'must_also',\n",
       "   'subgraph'],\n",
       "  ['word']],\n",
       " [['weighted',\n",
       "   'graph',\n",
       "   'sometimes',\n",
       "   'use',\n",
       "   'edge',\n",
       "   'denote',\n",
       "   'connection',\n",
       "   'pair_node',\n",
       "   'connection',\n",
       "   'capacity',\n",
       "   'weight'],\n",
       "  ['example',\n",
       "   'may',\n",
       "   'interested',\n",
       "   'capacity',\n",
       "   'internet',\n",
       "   'fiber',\n",
       "   'pair',\n",
       "   'computer',\n",
       "   'resistance',\n",
       "   'wire',\n",
       "   'pair',\n",
       "   'terminal',\n",
       "   'tension',\n",
       "   'spring',\n",
       "   'connect_pair',\n",
       "   'device',\n",
       "   'dynamical',\n",
       "   'system',\n",
       "   'tension',\n",
       "   'bond',\n",
       "   'pair',\n",
       "   'atom',\n",
       "   'molecule',\n",
       "   'distance',\n",
       "   'highway',\n",
       "   'pair',\n",
       "   'city'],\n",
       "  ['case',\n",
       "   'useful',\n",
       "   'represent',\n",
       "   'system',\n",
       "   'edge_weight',\n",
       "   'graph',\n",
       "   'aka',\n",
       "   'weight_graph'],\n",
       "  ['weighted',\n",
       "   'graph',\n",
       "   'simple',\n",
       "   'graph',\n",
       "   'associate',\n",
       "   'real_number',\n",
       "   'weight_edge',\n",
       "   'graph'],\n",
       "  ['mathematically', 'speak', 'weight_graph', 'consist', 'graph'],\n",
       "  ['weight', 'function'],\n",
       "  ['example', 'figure_show', 'weight_graph', 'weight_edge', 'bg']],\n",
       " [['adjacency', 'matrice', 'many_way', 'represent', 'graph'],\n",
       "  ['already', 'see', 'way', 'draw', 'figure', 'example', 'represent', 'set'],\n",
       "  ['common', 'representation', 'adjacency_matrix'],\n",
       "  ['figure'],\n",
       "  ['node', 'weight_graph', 'edge_bg', 'weight'],\n",
       "  ['figure'],\n",
       "  ['example', 'adjacency', 'matrices'],\n",
       "  ['show', 'adjacency_matrix', 'graph_figure', 'definition'],\n",
       "  ['give', 'node_graph'],\n",
       "  ['fv',\n",
       "   'adjacency_matrix',\n",
       "   'matrix',\n",
       "   'ij',\n",
       "   'weight_graph',\n",
       "   'edge_weight',\n",
       "   'give',\n",
       "   'adja',\n",
       "   'cency',\n",
       "   'matrix',\n",
       "   'ij',\n",
       "   'example',\n",
       "   'figure',\n",
       "   'display',\n",
       "   'adjacency',\n",
       "   'matrices',\n",
       "   'graph_show',\n",
       "   'figure',\n",
       "   'chapter_graph',\n",
       "   'theory']],\n",
       " [['match',\n",
       "   'problem',\n",
       "   'begin',\n",
       "   'study',\n",
       "   'graph_theory',\n",
       "   'consider',\n",
       "   'scenario',\n",
       "   'node_graph',\n",
       "   'represent',\n",
       "   'people',\n",
       "   'edge',\n",
       "   'represent',\n",
       "   'relationship',\n",
       "   'pair_people',\n",
       "   'like',\n",
       "   'marrie'],\n",
       "  ['may', 'wonder', 'marriage', 'computer_science', 'good', 'reason'],\n",
       "  ['turn',\n",
       "   'technique',\n",
       "   'develop',\n",
       "   'apply',\n",
       "   'much',\n",
       "   'general',\n",
       "   'scenario',\n",
       "   'instead',\n",
       "   'match',\n",
       "   'man_woman',\n",
       "   'need',\n",
       "   'match',\n",
       "   'packet',\n",
       "   'path',\n",
       "   'network',\n",
       "   'applicant',\n",
       "   'job',\n",
       "   'internet',\n",
       "   'traffic',\n",
       "   'web',\n",
       "   'server'],\n",
       "  ['describe', 'later', 'technique', 'widely', 'use', 'practice'],\n",
       "  ['first',\n",
       "   'example',\n",
       "   'show',\n",
       "   'graph_theory',\n",
       "   'use',\n",
       "   'debunk',\n",
       "   'urban',\n",
       "   'legend',\n",
       "   'sexual',\n",
       "   'practices',\n",
       "   'america'],\n",
       "  ['read', 'correctly'],\n",
       "  ['fasten',\n",
       "   'seat',\n",
       "   'belt',\n",
       "   'know',\n",
       "   'math',\n",
       "   'may',\n",
       "   'actually',\n",
       "   'interesting']],\n",
       " [['sex',\n",
       "   'america',\n",
       "   'average',\n",
       "   'opposite_gender_partner',\n",
       "   'man_woman',\n",
       "   'sexual',\n",
       "   'demographic',\n",
       "   'subject',\n",
       "   'many',\n",
       "   'study'],\n",
       "  ['large',\n",
       "   'researcher',\n",
       "   'university',\n",
       "   'chicago',\n",
       "   'interview',\n",
       "   'random',\n",
       "   'sample',\n",
       "   'americans',\n",
       "   'several',\n",
       "   'year',\n",
       "   'try',\n",
       "   'answer_question'],\n",
       "  ['study',\n",
       "   'publish',\n",
       "   'entitle',\n",
       "   'social',\n",
       "   'organization',\n",
       "   'sexuality',\n",
       "   'find',\n",
       "   'average',\n",
       "   'man',\n",
       "   'gender_partner',\n",
       "   'woman'],\n",
       "  ['study', 'find', 'disparity', 'even', 'large'],\n",
       "  ['particular',\n",
       "   'abc',\n",
       "   'news',\n",
       "   'claim',\n",
       "   'average',\n",
       "   'man',\n",
       "   'partner',\n",
       "   'lifetime',\n",
       "   'aver',\n",
       "   'age',\n",
       "   'woman',\n",
       "   'percentage',\n",
       "   'disparity'],\n",
       "  ['abc',\n",
       "   'news',\n",
       "   'study',\n",
       "   'air',\n",
       "   'primetime',\n",
       "   'live',\n",
       "   'purport',\n",
       "   'scientific',\n",
       "   'ever',\n",
       "   'do'],\n",
       "  ['margin', 'error'],\n",
       "  ['call', 'american', 'sex', 'survey', 'peek', 'sheet'],\n",
       "  ['promotion',\n",
       "   'study',\n",
       "   'even',\n",
       "   'better',\n",
       "   'ground',\n",
       "   'break',\n",
       "   'abc',\n",
       "   'news',\n",
       "   'primetime',\n",
       "   'live',\n",
       "   'survey',\n",
       "   'find',\n",
       "   'range',\n",
       "   'eye',\n",
       "   'pop',\n",
       "   'sexual',\n",
       "   'activity',\n",
       "   'fantasy',\n",
       "   'attitude',\n",
       "   'country',\n",
       "   'confirm',\n",
       "   'conventional',\n",
       "   'wisdom',\n",
       "   'explode',\n",
       "   'myth',\n",
       "   'venture',\n",
       "   'scientific',\n",
       "   'survey',\n",
       "   'go'],\n",
       "  ['probably',\n",
       "   'last',\n",
       "   'part',\n",
       "   'go',\n",
       "   'scientific',\n",
       "   'survey',\n",
       "   'go',\n",
       "   'pretty',\n",
       "   'accurate',\n",
       "   'yet',\n",
       "   'august'],\n",
       "  ['times', 'report', 'study', 'national', 'center', 'health', 'statistic'],\n",
       "  ['government', 'show', 'man', 'partner', 'woman'],\n",
       "  ['number',\n",
       "   'think',\n",
       "   'accurate',\n",
       "   'university',\n",
       "   'chicago',\n",
       "   'abc',\n",
       "   'news',\n",
       "   'national',\n",
       "   'center',\n",
       "   'health',\n",
       "   'statistic',\n",
       "   'answer',\n",
       "   'setup',\n",
       "   'question',\n",
       "   'stop',\n",
       "   'beat',\n",
       "   'wife',\n",
       "   'use',\n",
       "   'little',\n",
       "   'graph_theory',\n",
       "   'explain',\n",
       "   'none',\n",
       "   'finding',\n",
       "   'anywhere',\n",
       "   'truth'],\n",
       "  ['let',\n",
       "   'model',\n",
       "   'question',\n",
       "   'heterosexual',\n",
       "   'partner',\n",
       "   'graph',\n",
       "   'theoretic',\n",
       "   'term'],\n",
       "  ['let', 'graph_vertex', 'people', 'america'],\n",
       "  ['split', 'separate', 'subset', 'contain', 'male', 'contain', 'female'],\n",
       "  ['put', 'edge', 'male', 'female', 'iff', 'sexual', 'partner'],\n",
       "  ['possible',\n",
       "   'subgraph',\n",
       "   'graph',\n",
       "   'illustrate_figure',\n",
       "   'male',\n",
       "   'leave',\n",
       "   'female',\n",
       "   'right'],\n",
       "  ['figure'],\n",
       "  ['possible', 'subgraph', 'sex', 'partner', 'graph'],\n",
       "  ['actually', 'pretty', 'hard', 'graph_figure', 'let', 'alone', 'draw'],\n",
       "  ['graph', 'enormous', 'us', 'population', 'jv'],\n",
       "  ['united', 'states', 'approximately'],\n",
       "  ['populatin', 'female'],\n",
       "  ['male', 'jm', 'jf'],\n",
       "  ['even',\n",
       "   'trustworthy',\n",
       "   'estimate',\n",
       "   'many',\n",
       "   'edge',\n",
       "   'let',\n",
       "   'alone',\n",
       "   'exactly',\n",
       "   'couple',\n",
       "   'adja',\n",
       "   'cent'],\n",
       "  ['turn',\n",
       "   'need',\n",
       "   'know',\n",
       "   'debunk',\n",
       "   'sex',\n",
       "   'survey',\n",
       "   'need',\n",
       "   'figure',\n",
       "   'relationship',\n",
       "   'average',\n",
       "   'number',\n",
       "   'partner',\n",
       "   'male',\n",
       "   'partner',\n",
       "   'female'],\n",
       "  ['note',\n",
       "   'edge_incident',\n",
       "   'exactly',\n",
       "   'vertex',\n",
       "   'vertex',\n",
       "   'remember',\n",
       "   'sidere',\n",
       "   'male',\n",
       "   'female',\n",
       "   'relationship',\n",
       "   'sum',\n",
       "   'degree_vertex',\n",
       "   'equal_number',\n",
       "   'edge',\n",
       "   'sum',\n",
       "   'degree_vertex',\n",
       "   'equal',\n",
       "   'simplicity',\n",
       "   'ignore',\n",
       "   'possibility',\n",
       "   'man_woman'],\n",
       "  ['chapter_graph', 'theory', 'number_edge'],\n",
       "  ['sum', 'equal', 'deg'],\n",
       "  ['deg'],\n",
       "  ['divide',\n",
       "   'side_equation',\n",
       "   'product',\n",
       "   'size',\n",
       "   'set',\n",
       "   'jm',\n",
       "   'jf',\n",
       "   'obtain',\n",
       "   'notice',\n",
       "   'jm',\n",
       "   'simply',\n",
       "   'average',\n",
       "   'degree_node'],\n",
       "  ['average', 'number', 'opposite_gender_partner', 'male', 'america'],\n",
       "  ['similarly',\n",
       "   'jf',\n",
       "   'average',\n",
       "   'degree_node',\n",
       "   'average',\n",
       "   'number',\n",
       "   'opposite_gender_partner',\n",
       "   'female',\n",
       "   'america'],\n",
       "  ['hence',\n",
       "   'equation',\n",
       "   'imply',\n",
       "   'average',\n",
       "   'american',\n",
       "   'male',\n",
       "   'jf',\n",
       "   'jm',\n",
       "   'times',\n",
       "   'many',\n",
       "   'opposite_gender_partner',\n",
       "   'average',\n",
       "   'american',\n",
       "   'female'],\n",
       "  ['census',\n",
       "   'bureau',\n",
       "   'report',\n",
       "   'know',\n",
       "   'slightly',\n",
       "   'female',\n",
       "   'males',\n",
       "   'america',\n",
       "   'particular',\n",
       "   'jf',\n",
       "   'jm'],\n",
       "  ['know', 'average', 'male'],\n",
       "  ['opposite_gender_partner', 'female'],\n",
       "  ['course',\n",
       "   'statistic',\n",
       "   'really',\n",
       "   'say',\n",
       "   'sex',\n",
       "   'promiscuity',\n",
       "   'selectivity'],\n",
       "  ['remark', 'ably', 'promiscuity', 'completely', 'irrelevant', 'analysis'],\n",
       "  ['ratio',\n",
       "   'average',\n",
       "   'number',\n",
       "   'partner',\n",
       "   'completely',\n",
       "   'determine',\n",
       "   'relative',\n",
       "   'number',\n",
       "   'male',\n",
       "   'female'],\n",
       "  ['collectively',\n",
       "   'male',\n",
       "   'female',\n",
       "   'number',\n",
       "   'opposite_gender_partner',\n",
       "   'take',\n",
       "   'set',\n",
       "   'partnership',\n",
       "   'few',\n",
       "   'male',\n",
       "   'high',\n",
       "   'ratio'],\n",
       "  ['means',\n",
       "   'university',\n",
       "   'chicago',\n",
       "   'abc',\n",
       "   'federal',\n",
       "   'government',\n",
       "   'study',\n",
       "   'way'],\n",
       "  ['huge', 'effort', 'give', 'totally', 'wrong', 'answer'],\n",
       "  ['definite', 'explanation', 'survey', 'consistently', 'wrong'],\n",
       "  ['hypothesis',\n",
       "   'male',\n",
       "   'exaggerate',\n",
       "   'number',\n",
       "   'partner',\n",
       "   'maybe',\n",
       "   'male',\n",
       "   'downplay',\n",
       "   'explanation',\n",
       "   'speculative'],\n",
       "  ['interestingly',\n",
       "   'principal',\n",
       "   'author',\n",
       "   'national',\n",
       "   'center',\n",
       "   'health',\n",
       "   'statistics',\n",
       "   'study',\n",
       "   'report',\n",
       "   'know',\n",
       "   'result',\n",
       "   'wrong',\n",
       "   'datum',\n",
       "   'collect',\n",
       "   'job',\n",
       "   'report'],\n",
       "  ['underlie', 'issue', 'lead', 'serious', 'survey', 'datum'],\n",
       "  ['example',\n",
       "   'year_ago',\n",
       "   'boston',\n",
       "   'globe',\n",
       "   'run',\n",
       "   'story',\n",
       "   'survey',\n",
       "   'study',\n",
       "   'habit',\n",
       "   'students',\n",
       "   'boston',\n",
       "   'area',\n",
       "   'campus'],\n",
       "  ['survey',\n",
       "   'show',\n",
       "   'average',\n",
       "   'minority',\n",
       "   'student',\n",
       "   'tend',\n",
       "   'study',\n",
       "   'non',\n",
       "   'minority',\n",
       "   'student',\n",
       "   'way',\n",
       "   'around'],\n",
       "  ['go',\n",
       "   'great',\n",
       "   'length',\n",
       "   'explain',\n",
       "   'remarkable',\n",
       "   'phenomenon',\n",
       "   'may',\n",
       "   'true'],\n",
       "  ['remarkable',\n",
       "   'use',\n",
       "   'graph_theory',\n",
       "   'formulation',\n",
       "   'see',\n",
       "   'say',\n",
       "   'few',\n",
       "   'minority',\n",
       "   'student',\n",
       "   'non',\n",
       "   'minority',\n",
       "   'student',\n",
       "   'course',\n",
       "   'minority',\n",
       "   'mean'],\n",
       "  ['handshaking',\n",
       "   'lemma',\n",
       "   'previous',\n",
       "   'argument',\n",
       "   'hinge',\n",
       "   'connection',\n",
       "   'sum',\n",
       "   'degree',\n",
       "   'number_edge'],\n",
       "  ['simple', 'connection', 'quantity', 'graph', 'lemma'],\n",
       "  ['handshaking', 'lemma'],\n",
       "  ['sum', 'degree_vertex', 'graph', 'equal', 'twice', 'number_edge'],\n",
       "  ['proof'],\n",
       "  ['edge', 'contribute', 'sum', 'degree', 'endpoint'],\n",
       "  ['lemma',\n",
       "   'call',\n",
       "   'handshake',\n",
       "   'lemma',\n",
       "   'total_number',\n",
       "   'people',\n",
       "   'person',\n",
       "   'party',\n",
       "   'shake',\n",
       "   'hand',\n",
       "   'total',\n",
       "   'twice',\n",
       "   'number',\n",
       "   'handshake',\n",
       "   'occur']],\n",
       " [['bipartite',\n",
       "   'matching',\n",
       "   'kind',\n",
       "   'vertex',\n",
       "   'sex',\n",
       "   'america',\n",
       "   'graph',\n",
       "   'males',\n",
       "   'edge',\n",
       "   'go',\n",
       "   'kind'],\n",
       "  ['graph',\n",
       "   'come',\n",
       "   'frequently',\n",
       "   'earn',\n",
       "   'special',\n",
       "   'name',\n",
       "   'call',\n",
       "   'bipartite',\n",
       "   'graphs'],\n",
       "  ['definition'],\n",
       "  ['bipartite_graph',\n",
       "   'graph',\n",
       "   'together',\n",
       "   'partition',\n",
       "   'vertex',\n",
       "   'set',\n",
       "   'edge_incident',\n",
       "   'vertex',\n",
       "   'vertex'],\n",
       "  ['bipartite',\n",
       "   'match',\n",
       "   'problem',\n",
       "   'relate',\n",
       "   'sex',\n",
       "   'america',\n",
       "   'problem',\n",
       "   'study',\n",
       "   'goal',\n",
       "   'get',\n",
       "   'happily',\n",
       "   'married'],\n",
       "  ['may',\n",
       "   'imagine',\n",
       "   'possible',\n",
       "   'variety',\n",
       "   'reason',\n",
       "   'least',\n",
       "   'fact',\n",
       "   'woman',\n",
       "   'america',\n",
       "   'man'],\n",
       "  ['simply', 'possible', 'marry', 'woman', 'man', 'man', 'marry'],\n",
       "  ['get',\n",
       "   'mate',\n",
       "   'man_woman',\n",
       "   'marry',\n",
       "   'possible',\n",
       "   'man',\n",
       "   'pair',\n",
       "   'woman_like',\n",
       "   'answer',\n",
       "   'course',\n",
       "   'depend',\n",
       "   'bipartite_graph',\n",
       "   'represent',\n",
       "   'chapter_graph',\n",
       "   'theory',\n",
       "   'alice',\n",
       "   'chuck',\n",
       "   'tom',\n",
       "   'martha',\n",
       "   'sara',\n",
       "   'michael',\n",
       "   'jane',\n",
       "   'john',\n",
       "   'mergatroid',\n",
       "   'figure'],\n",
       "  ['graph', 'edge', 'man_woman', 'denote', 'man_like', 'woman'],\n",
       "  ['like',\n",
       "   'good_news',\n",
       "   'possible',\n",
       "   'find',\n",
       "   'natural',\n",
       "   'property',\n",
       "   'like',\n",
       "   'graph',\n",
       "   'completely',\n",
       "   'determine',\n",
       "   'answer_question'],\n",
       "  ['general',\n",
       "   'suppose',\n",
       "   'set',\n",
       "   'man',\n",
       "   'equal',\n",
       "   'sized',\n",
       "   'large',\n",
       "   'set',\n",
       "   'woman',\n",
       "   'graph',\n",
       "   'edge',\n",
       "   'man_woman',\n",
       "   'man_like',\n",
       "   'woman'],\n",
       "  ['note',\n",
       "   'scenario',\n",
       "   'like',\n",
       "   'relationship',\n",
       "   'need',\n",
       "   'symmetric',\n",
       "   'time',\n",
       "   'worry',\n",
       "   'finding',\n",
       "   'mate',\n",
       "   'man_like'],\n",
       "  ['problem',\n",
       "   'match',\n",
       "   'mean',\n",
       "   'way',\n",
       "   'assign',\n",
       "   'man_woman',\n",
       "   'different',\n",
       "   'man',\n",
       "   'assign',\n",
       "   'different',\n",
       "   'woman',\n",
       "   'man',\n",
       "   'always',\n",
       "   'assign',\n",
       "   'woman_like'],\n",
       "  ['example',\n",
       "   'possible',\n",
       "   'match',\n",
       "   'man',\n",
       "   'show_figure',\n",
       "   'matching',\n",
       "   'condition',\n",
       "   'famous',\n",
       "   'result',\n",
       "   'know',\n",
       "   'hall',\n",
       "   'matching',\n",
       "   'theorem',\n",
       "   'give',\n",
       "   'necessary',\n",
       "   'sufficient',\n",
       "   'condition',\n",
       "   'existence',\n",
       "   'match',\n",
       "   'bipartite_graph'],\n",
       "  ['turn', 'remarkably', 'useful', 'mathematical', 'tool'],\n",
       "  ['state',\n",
       "   'prove',\n",
       "   'hall',\n",
       "   'theorem',\n",
       "   'use',\n",
       "   'man_like',\n",
       "   'woman',\n",
       "   'terminology'],\n",
       "  ['de',\n",
       "   'fine',\n",
       "   'set',\n",
       "   'woman_like',\n",
       "   'give',\n",
       "   'set',\n",
       "   'man',\n",
       "   'consist',\n",
       "   'woman_like',\n",
       "   'least',\n",
       "   'man'],\n",
       "  ['example',\n",
       "   'set',\n",
       "   'woman_like',\n",
       "   'tom',\n",
       "   'john',\n",
       "   'way',\n",
       "   'mean',\n",
       "   'imply',\n",
       "   'marriage',\n",
       "   'heterosexual',\n",
       "   'nature'],\n",
       "  ['mean', 'imply', 'man_get', 'choice', 'instead', 'woman'],\n",
       "  ['bipartite',\n",
       "   'graphs',\n",
       "   'edge_connect',\n",
       "   'male',\n",
       "   'node',\n",
       "   'female',\n",
       "   'node',\n",
       "   'few',\n",
       "   'man',\n",
       "   'america'],\n",
       "  ['take', 'offense'],\n",
       "  ['alice',\n",
       "   'chuck',\n",
       "   'martha',\n",
       "   'tom',\n",
       "   'sara',\n",
       "   'michael',\n",
       "   'jane',\n",
       "   'john',\n",
       "   'mergatroid',\n",
       "   'figure'],\n",
       "  ['possible', 'match', 'man', 'show', 'bold', 'edge'],\n",
       "  ['example', 'john', 'match', 'jane'],\n",
       "  ['figure', 'consist', 'martha', 'sarah', 'mergatroid'],\n",
       "  ['chance',\n",
       "   'match',\n",
       "   'man',\n",
       "   'follow',\n",
       "   'match_condition',\n",
       "   'must',\n",
       "   'hold',\n",
       "   'subset',\n",
       "   'man_like',\n",
       "   'least',\n",
       "   'large',\n",
       "   'set',\n",
       "   'woman'],\n",
       "  ['example', 'find', 'match', 'set', 'man_woman'],\n",
       "  ['hall',\n",
       "   'theorem',\n",
       "   'say',\n",
       "   'necessary',\n",
       "   'condition',\n",
       "   'actually',\n",
       "   'sufficient',\n",
       "   'match',\n",
       "   'ing',\n",
       "   'condition_hold',\n",
       "   'matching',\n",
       "   'exist'],\n",
       "  ['theorem'],\n",
       "  ['match', 'set', 'man', 'set', 'woman', 'find', 'match_condition', 'hold'],\n",
       "  ['proof'],\n",
       "  ['first',\n",
       "   'let',\n",
       "   'suppose',\n",
       "   'matching',\n",
       "   'exist',\n",
       "   'show',\n",
       "   'matching',\n",
       "   'condi',\n",
       "   'tion',\n",
       "   'hold'],\n",
       "  ['consider', 'arbitrary', 'subset', 'man'],\n",
       "  ['man_like', 'least', 'woman', 'match'],\n",
       "  ['therefore', 'subset', 'man_like', 'least', 'large', 'set', 'woman'],\n",
       "  ['thus', 'match_condition', 'hold'],\n",
       "  ['next',\n",
       "   'let',\n",
       "   'suppose',\n",
       "   'match_condition',\n",
       "   'hold',\n",
       "   'show',\n",
       "   'matching',\n",
       "   'exist'],\n",
       "  ['use_strong_induction', 'jm', 'number', 'man', 'predicate'],\n",
       "  ['wwd', 'set', 'man', 'match_condition', 'hold', 'match'],\n",
       "  ['base_case',\n",
       "   'jm',\n",
       "   'jm',\n",
       "   'match_condition',\n",
       "   'imply',\n",
       "   'lone',\n",
       "   'man_like',\n",
       "   'least',\n",
       "   'woman',\n",
       "   'match',\n",
       "   'exist'],\n",
       "  ['inductive_step', 'need', 'show'],\n",
       "  ['imply',\n",
       "   'chapter_graph',\n",
       "   'theory',\n",
       "   'case',\n",
       "   'proper',\n",
       "   'subset',\n",
       "   'man_like',\n",
       "   'strictly',\n",
       "   'large',\n",
       "   'set',\n",
       "   'woman'],\n",
       "  ['case',\n",
       "   'latitude',\n",
       "   'pair',\n",
       "   'arbitrary',\n",
       "   'man_woman',\n",
       "   'like',\n",
       "   'send',\n",
       "   'away'],\n",
       "  ['match_condition',\n",
       "   'still',\n",
       "   'hold',\n",
       "   'remain',\n",
       "   'man_woman',\n",
       "   'remove',\n",
       "   'woman',\n",
       "   'match',\n",
       "   'rest',\n",
       "   'man',\n",
       "   'induction'],\n",
       "  ['case', 'proper', 'subset', 'man_like', 'equal', 'size', 'set', 'woman'],\n",
       "  ['match', 'man_woman', 'induction', 'send', 'away'],\n",
       "  ['also',\n",
       "   'match',\n",
       "   'rest',\n",
       "   'man',\n",
       "   'induction',\n",
       "   'show',\n",
       "   'match_condition',\n",
       "   'hold',\n",
       "   'remain',\n",
       "   'man_woman'],\n",
       "  ['check',\n",
       "   'match_condition',\n",
       "   'remain',\n",
       "   'people',\n",
       "   'consider',\n",
       "   'arbitrary',\n",
       "   'subset',\n",
       "   'remain',\n",
       "   'man',\n",
       "   'jy'],\n",
       "  ['originally',\n",
       "   'combine',\n",
       "   'set',\n",
       "   'man',\n",
       "   'jx',\n",
       "   'jy',\n",
       "   'send',\n",
       "   'jx',\n",
       "   'man',\n",
       "   'set',\n",
       "   'leave',\n",
       "   'leave',\n",
       "   'jy',\n",
       "   'claim'],\n",
       "  ['case', 'match', 'man', 'complete', 'proof', 'inductive_step'],\n",
       "  ['theorem', 'follow', 'induction'],\n",
       "  ['proof_theorem',\n",
       "   'give',\n",
       "   'algorithm',\n",
       "   'find',\n",
       "   'match',\n",
       "   'bipar',\n",
       "   'tite',\n",
       "   'graph',\n",
       "   'efficient'],\n",
       "  ['however',\n",
       "   'efficient',\n",
       "   'algorithm',\n",
       "   'find',\n",
       "   'match',\n",
       "   'bipartite_graph',\n",
       "   'exist'],\n",
       "  ['thus',\n",
       "   'problem',\n",
       "   'reduce',\n",
       "   'finding',\n",
       "   'matching',\n",
       "   'problem',\n",
       "   'solve',\n",
       "   'computational',\n",
       "   'perspective'],\n",
       "  ['formal',\n",
       "   'statement',\n",
       "   'let',\n",
       "   'restate',\n",
       "   'theorem',\n",
       "   'abstract',\n",
       "   'term',\n",
       "   'always',\n",
       "   'con',\n",
       "   'demned',\n",
       "   'say',\n",
       "   'group',\n",
       "   'man_like',\n",
       "   'least',\n",
       "   'many',\n",
       "   'woman'],\n",
       "  ['definition'],\n",
       "  ['match', 'graph', 'set', 'edge', 'edge', 'set', 'share', 'vertex'],\n",
       "  ['matching',\n",
       "   'say',\n",
       "   'cover',\n",
       "   'set',\n",
       "   'vertex',\n",
       "   'iff',\n",
       "   'vertex_edge',\n",
       "   'match',\n",
       "   'incident'],\n",
       "  ['matching', 'say', 'perfect', 'node_graph', 'incident_edge', 'match'],\n",
       "  ['graph', 'set'],\n",
       "  ['neighbor', 'set', 'vertex', 'set', 'vertex_adjacent', 'vertex'],\n",
       "  ['wwd', 'fs', 'rg', 'edge', 'recall', 'subset', 'proper'],\n",
       "  ['call', 'bottleneck', 'jsj', 'jn'],\n",
       "  ['theorem'],\n",
       "  ['hall', 'theorem'],\n",
       "  ['let', 'bipartite_graph', 'vertex', 'partition'],\n",
       "  ['match', 'cover', 'iff', 'subset', 'bottleneck'],\n",
       "  ['easy',\n",
       "   'matching',\n",
       "   'condition',\n",
       "   'bipartite',\n",
       "   'match_condition',\n",
       "   'require',\n",
       "   'subset',\n",
       "   'man',\n",
       "   'certain',\n",
       "   'property'],\n",
       "  ['general',\n",
       "   'verify',\n",
       "   'subset',\n",
       "   'property',\n",
       "   'even',\n",
       "   'easy',\n",
       "   'check',\n",
       "   'particular',\n",
       "   'subset',\n",
       "   'property',\n",
       "   'quickly',\n",
       "   'become',\n",
       "   'overwhelming',\n",
       "   'number',\n",
       "   'subset',\n",
       "   'even',\n",
       "   'relatively',\n",
       "   'small',\n",
       "   'set',\n",
       "   'enormous',\n",
       "   'subset',\n",
       "   'set',\n",
       "   'size'],\n",
       "  ['however',\n",
       "   'simple',\n",
       "   'property',\n",
       "   'vertex_degree',\n",
       "   'bipartite_graph',\n",
       "   'guarantee',\n",
       "   'existence',\n",
       "   'match'],\n",
       "  ['namely',\n",
       "   'call',\n",
       "   'bipartite_graph',\n",
       "   'degree_constrain',\n",
       "   'vertex_degree',\n",
       "   'leave',\n",
       "   'least',\n",
       "   'large',\n",
       "   'right'],\n",
       "  ['precisely', 'definition'],\n",
       "  ['bipartite_graph',\n",
       "   'vertex',\n",
       "   'partition',\n",
       "   'jlj',\n",
       "   'jrj',\n",
       "   'degree_constrain',\n",
       "   'deg'],\n",
       "  ['deg'],\n",
       "  ['example',\n",
       "   'graph_figure',\n",
       "   'degree_constrain',\n",
       "   'node_leave',\n",
       "   'adjacent',\n",
       "   'least',\n",
       "   'node',\n",
       "   'right',\n",
       "   'right',\n",
       "   'incident',\n",
       "   'node_leave'],\n",
       "  ['theorem'],\n",
       "  ['let', 'bipartite_graph', 'vertex', 'partition', 'jlj', 'jrj'],\n",
       "  ['degree_constrain', 'matching', 'cover'],\n",
       "  ['proof'],\n",
       "  ['proof_contradiction'],\n",
       "  ['suppose', 'degree_constrain', 'matching', 'cover'],\n",
       "  ['theorem', 'let', 'value', 'deg'],\n",
       "  ['deg'],\n",
       "  ['edge_incident', 'node', 'incident', 'node'],\n",
       "  ['know', 'jn'],\n",
       "  ['jx', 'jsjx', 'thus', 'jn'],\n",
       "  ['jsj', 'mean', 'bottleneck', 'contradiction'],\n",
       "  ['hence', 'match', 'cover'],\n",
       "  ['regular',\n",
       "   'graph',\n",
       "   'provide',\n",
       "   'large',\n",
       "   'class',\n",
       "   'graph',\n",
       "   'often',\n",
       "   'arise_practice',\n",
       "   'degree_constrain'],\n",
       "  ['hence',\n",
       "   'use',\n",
       "   'theorem_prove',\n",
       "   'regular',\n",
       "   'bipartite_graph',\n",
       "   'perfect',\n",
       "   'matching'],\n",
       "  ['turn',\n",
       "   'surprisingly',\n",
       "   'useful',\n",
       "   'result',\n",
       "   'computer_science',\n",
       "   'chapter_graph',\n",
       "   'theory',\n",
       "   'definition'],\n",
       "  ['graph', 'say', 'regular', 'node', 'degree'],\n",
       "  ['theorem'],\n",
       "  ['regular', 'bipartite_graph', 'perfect', 'matching'],\n",
       "  ['proof'],\n",
       "  ['let', 'regular', 'bipartite_graph', 'vertex', 'partition', 'jlj', 'jrj'],\n",
       "  ['regular',\n",
       "   'graphs',\n",
       "   'degree_constrain',\n",
       "   'know',\n",
       "   'theorem',\n",
       "   'must',\n",
       "   'matching',\n",
       "   'cover'],\n",
       "  ['regular',\n",
       "   'also',\n",
       "   'know',\n",
       "   'jlj',\n",
       "   'jrj',\n",
       "   'thus',\n",
       "   'match',\n",
       "   'must_also',\n",
       "   'cover'],\n",
       "  ['mean', 'node', 'incident_edge', 'match', 'thus', 'perfect', 'matching']],\n",
       " [['stable',\n",
       "   'marriage',\n",
       "   'problem',\n",
       "   'next',\n",
       "   'consider',\n",
       "   'version',\n",
       "   'bipartite',\n",
       "   'match',\n",
       "   'problem',\n",
       "   'equal_number',\n",
       "   'man_woman',\n",
       "   'person',\n",
       "   'preference',\n",
       "   'would',\n",
       "   'like',\n",
       "   'marry'],\n",
       "  ['fact',\n",
       "   'assume',\n",
       "   'man',\n",
       "   'complete',\n",
       "   'list',\n",
       "   'woman',\n",
       "   'rank',\n",
       "   'accord',\n",
       "   'preference',\n",
       "   'tie'],\n",
       "  ['likewise', 'woman', 'rank', 'list', 'man'],\n",
       "  ['preference', 'symmetric'],\n",
       "  ['jennifer',\n",
       "   'may',\n",
       "   'like',\n",
       "   'brad',\n",
       "   'best',\n",
       "   'brad',\n",
       "   'necessarily',\n",
       "   'jennifer',\n",
       "   'best'],\n",
       "  ['goal',\n",
       "   'marry',\n",
       "   'man',\n",
       "   'must',\n",
       "   'marry',\n",
       "   'exactly',\n",
       "   'woman',\n",
       "   'vice',\n",
       "   'versa',\n",
       "   'polygamy'],\n",
       "  ['would',\n",
       "   'find',\n",
       "   'matching',\n",
       "   'man_woman',\n",
       "   'stable',\n",
       "   'sense',\n",
       "   'pair_people',\n",
       "   'prefer',\n",
       "   'spouse'],\n",
       "  ['example_suppose',\n",
       "   'man_like',\n",
       "   'angelina',\n",
       "   'best',\n",
       "   'woman_like',\n",
       "   'brad',\n",
       "   'best',\n",
       "   'brad',\n",
       "   'angelina',\n",
       "   'married',\n",
       "   'people',\n",
       "   'say',\n",
       "   'jennifer',\n",
       "   'billy',\n",
       "   'bob'],\n",
       "  ['brad',\n",
       "   'angelina',\n",
       "   'prefer',\n",
       "   'spouse',\n",
       "   'put',\n",
       "   'marriage',\n",
       "   'risk',\n",
       "   'pretty',\n",
       "   'soon',\n",
       "   'likely',\n",
       "   'start',\n",
       "   'spend',\n",
       "   'late',\n",
       "   'night',\n",
       "   'together',\n",
       "   'work',\n",
       "   'problem',\n",
       "   'set',\n",
       "   'unfortunate',\n",
       "   'situation',\n",
       "   'illustrate_figure',\n",
       "   'generally',\n",
       "   'match',\n",
       "   'man_woman',\n",
       "   'marry',\n",
       "   'well',\n",
       "   'spouse',\n",
       "   'call',\n",
       "   'rogue_couple'],\n",
       "  ['situation',\n",
       "   'show_figure',\n",
       "   'rogue_couple',\n",
       "   'good',\n",
       "   'thing',\n",
       "   'threaten',\n",
       "   'stability',\n",
       "   'marriage'],\n",
       "  ['hand',\n",
       "   'rogue_couple',\n",
       "   'man_woman',\n",
       "   'marry',\n",
       "   'least',\n",
       "   'one',\n",
       "   'like',\n",
       "   'spouse',\n",
       "   'better',\n",
       "   'tempt',\n",
       "   'start',\n",
       "   'affair'],\n",
       "  ['definition'],\n",
       "  ['stable_matching', 'match', 'rogue_couple'],\n",
       "  ['question',\n",
       "   'give',\n",
       "   'preference',\n",
       "   'find',\n",
       "   'stable',\n",
       "   'set',\n",
       "   'marriage',\n",
       "   'example',\n",
       "   'consist',\n",
       "   'solely',\n",
       "   'people',\n",
       "   'figure'],\n",
       "  ['match', 'problem', 'brad', 'billy', 'bob', 'figure'],\n",
       "  ['preference', 'people'],\n",
       "  ['man', 'angelina', 'good', 'woman', 'brad', 'best'],\n",
       "  ['could', 'let', 'brad', 'angelina', 'first', 'choice', 'marry'],\n",
       "  ['brad', 'angelina', 'prefer', 'else', 'spouse', 'rogue_couple'],\n",
       "  ['leave',\n",
       "   'jen',\n",
       "   'happily',\n",
       "   'marry',\n",
       "   'billy',\n",
       "   'bob',\n",
       "   'jen',\n",
       "   'billy',\n",
       "   'bob',\n",
       "   'entice',\n",
       "   'else',\n",
       "   'marry',\n",
       "   'stable_matching'],\n",
       "  ['surprisingly', 'always', 'stable', 'match', 'group', 'man_woman'],\n",
       "  ['surprise',\n",
       "   'springs',\n",
       "   'part',\n",
       "   'consider',\n",
       "   'apparently',\n",
       "   'similar',\n",
       "   'buddy',\n",
       "   'match',\n",
       "   'ing',\n",
       "   'problem'],\n",
       "  ['people',\n",
       "   'pair',\n",
       "   'buddy',\n",
       "   'regardless',\n",
       "   'gender',\n",
       "   'stable_matching',\n",
       "   'may',\n",
       "   'possible'],\n",
       "  ['example',\n",
       "   'figure_show',\n",
       "   'situ',\n",
       "   'ation',\n",
       "   'love',\n",
       "   'triangle',\n",
       "   'fourth',\n",
       "   'person',\n",
       "   'last',\n",
       "   'choice'],\n",
       "  ['figure', 'mergatroid', 'preference', 'show', 'even', 'matter'],\n",
       "  ['let_see', 'stable_matching'],\n",
       "  ['mergatroid', 'figure'],\n",
       "  ['preference', 'stable', 'buddy', 'matching'],\n",
       "  ['lemma'],\n",
       "  ['stable',\n",
       "   'buddy',\n",
       "   'match',\n",
       "   'people',\n",
       "   'fig_ure',\n",
       "   'get',\n",
       "   'stable',\n",
       "   'buddy',\n",
       "   'matching',\n",
       "   'may',\n",
       "   'hard',\n",
       "   'may',\n",
       "   'impossible'],\n",
       "  ['men',\n",
       "   'allow',\n",
       "   'marry',\n",
       "   'woman',\n",
       "   'vice',\n",
       "   'versa',\n",
       "   'turn',\n",
       "   'stable_matching',\n",
       "   'always',\n",
       "   'find'],\n",
       "  ['mate_ritual',\n",
       "   'procedure',\n",
       "   'find',\n",
       "   'stable_matching',\n",
       "   'involve',\n",
       "   'mate_ritual',\n",
       "   'take',\n",
       "   'place',\n",
       "   'several',\n",
       "   'day'],\n",
       "  ['follow', 'event', 'happen', 'day', 'morning', 'woman', 'stand', 'balcony'],\n",
       "  ['man', 'stand', 'bal', 'cony', 'favorite', 'woman_list', 'serenade'],\n",
       "  ['man_woman', 'leave', 'list', 'stay', 'home', 'math', 'homework'],\n",
       "  ['afternoon',\n",
       "   'woman',\n",
       "   'one',\n",
       "   'suitor',\n",
       "   'serenading',\n",
       "   'say',\n",
       "   'favorite',\n",
       "   'may',\n",
       "   'engage'],\n",
       "  ['come', 'back', 'tomorrow'],\n",
       "  ['suitor', 'say'],\n",
       "  ['never',\n",
       "   'marry',\n",
       "   'take',\n",
       "   'hike',\n",
       "   'evening',\n",
       "   'man',\n",
       "   'tell',\n",
       "   'woman',\n",
       "   'take',\n",
       "   'hike',\n",
       "   'crosse',\n",
       "   'woman_list'],\n",
       "  ['termination',\n",
       "   'condition',\n",
       "   'day',\n",
       "   'arrive',\n",
       "   'woman',\n",
       "   'suitor',\n",
       "   'ritual',\n",
       "   'end',\n",
       "   'woman',\n",
       "   'marry',\n",
       "   'suitor'],\n",
       "  ['number',\n",
       "   'fact',\n",
       "   'mate_ritual',\n",
       "   'would',\n",
       "   'prove',\n",
       "   'ritual',\n",
       "   'eventually',\n",
       "   'reach',\n",
       "   'termination',\n",
       "   'condition'],\n",
       "  ['end', 'married'],\n",
       "  ['result', 'marriage', 'stable'],\n",
       "  ['marriage',\n",
       "   'day',\n",
       "   'easy',\n",
       "   'see',\n",
       "   'mate_ritual',\n",
       "   'terminal',\n",
       "   'day',\n",
       "   'people',\n",
       "   'finally',\n",
       "   'get',\n",
       "   'married'],\n",
       "  ['day', 'ritual', 'terminate', 'least', 'man', 'cross', 'woman_list'],\n",
       "  ['ritual',\n",
       "   'terminate',\n",
       "   'must',\n",
       "   'woman',\n",
       "   'serenade',\n",
       "   'least',\n",
       "   'man',\n",
       "   'least',\n",
       "   'cross',\n",
       "   'disclaim',\n",
       "   'political',\n",
       "   'statement',\n",
       "   'way',\n",
       "   'math',\n",
       "   'work'],\n",
       "  ['list'],\n",
       "  ['start',\n",
       "   'man_woman',\n",
       "   'man',\n",
       "   'list',\n",
       "   'initially',\n",
       "   'woman',\n",
       "   'total',\n",
       "   'live',\n",
       "   'happily'],\n",
       "  ['still', 'prove', 'mate_ritual', 'leave', 'stable', 'marriage'],\n",
       "  ['note',\n",
       "   'useful',\n",
       "   'fact',\n",
       "   'ritual',\n",
       "   'woman',\n",
       "   'favorite',\n",
       "   'suitor',\n",
       "   'morning',\n",
       "   'ritual',\n",
       "   'favorite',\n",
       "   'suitor',\n",
       "   'still',\n",
       "   'serenad',\n",
       "   'e',\n",
       "   'next',\n",
       "   'morning',\n",
       "   'list',\n",
       "   'change'],\n",
       "  ['sure', 'today', 'favorite', 'man', 'suitor', 'tomorrow'],\n",
       "  ['mean',\n",
       "   'able',\n",
       "   'choose',\n",
       "   'favorite',\n",
       "   'suitor',\n",
       "   'tomorrow',\n",
       "   'least',\n",
       "   'desirable',\n",
       "   'today',\n",
       "   'favorite'],\n",
       "  ['day', 'day', 'favorite', 'suitor', 'stay', 'get', 'well', 'never', 'bad'],\n",
       "  ['sound', 'invariant'],\n",
       "  ['definition'],\n",
       "  ['let', 'predicate', 'woman', 'man', 'cross', 'list', 'suitor', 'prefer'],\n",
       "  ['lemma'],\n",
       "  ['invariant', 'mating', 'ritual'],\n",
       "  ['proof'],\n",
       "  ['induction', 'number', 'day'],\n",
       "  ['base_case',\n",
       "   'begin_end',\n",
       "   'day',\n",
       "   'woman_list',\n",
       "   'cross',\n",
       "   'vacuously',\n",
       "   'true'],\n",
       "  ['inductive_step_assume',\n",
       "   'true',\n",
       "   'end_day',\n",
       "   'let',\n",
       "   'woman',\n",
       "   'crossed',\n",
       "   'man',\n",
       "   'list',\n",
       "   'end_day'],\n",
       "  ['case', 'cross', 'list', 'day'],\n",
       "  ['must', 'suitor', 'prefer', 'day'],\n",
       "  ['case', 'cross', 'list', 'prior', 'day'],\n",
       "  ['true', 'end_day', 'mean', 'suitor', 'prefer', 'day'],\n",
       "  ['therefore', 'suitor', 'prefer', 'well', 'end_day'],\n",
       "  ['case', 'true', 'end_day', 'must', 'invariant'],\n",
       "  ['lemma', 'hand', 'prove_theorem'],\n",
       "  ['marry', 'mate_ritual'],\n",
       "  ['proof'],\n",
       "  ['contradiction'],\n",
       "  ['assume', 'last', 'day', 'mate_ritual', 'marry'],\n",
       "  ['equal_number',\n",
       "   'man_woman',\n",
       "   'chapter_graph',\n",
       "   'theory',\n",
       "   'bigamy',\n",
       "   'allow',\n",
       "   'mean',\n",
       "   'least',\n",
       "   'man',\n",
       "   'call',\n",
       "   'bob',\n",
       "   'least',\n",
       "   'woman',\n",
       "   'marry'],\n",
       "  ['bob', 'marry', 'serenade', 'list', 'must', 'empty'],\n",
       "  ['mean',\n",
       "   'bob',\n",
       "   'cross',\n",
       "   'woman_list',\n",
       "   'invariant',\n",
       "   'woman',\n",
       "   'suitor',\n",
       "   'prefer',\n",
       "   'bob'],\n",
       "  ['last',\n",
       "   'day',\n",
       "   'woman',\n",
       "   'still',\n",
       "   'suitor',\n",
       "   'mean',\n",
       "   'woman',\n",
       "   'get',\n",
       "   'married'],\n",
       "  ['contradiction', 'already', 'argue', 'least', 'woman', 'married'],\n",
       "  ['hence', 'assumption', 'must', 'false', 'must', 'married'],\n",
       "  ['theorem'],\n",
       "  ['mate_ritual', 'produce', 'stable_matching'],\n",
       "  ['proof'],\n",
       "  ['let',\n",
       "   'brad',\n",
       "   'jen',\n",
       "   'man_woman',\n",
       "   'respectively',\n",
       "   'marry',\n",
       "   'last',\n",
       "   'day',\n",
       "   'mate_ritual'],\n",
       "  ['prove',\n",
       "   'brad',\n",
       "   'jen',\n",
       "   'rogue_couple',\n",
       "   'thus',\n",
       "   'marriage',\n",
       "   'last',\n",
       "   'day',\n",
       "   'stable'],\n",
       "  ['case', 'consider'],\n",
       "  ['case', 'jen', 'brad', 'list', 'end'],\n",
       "  ['invariant', 'know', 'jen', 'suitor', 'hence', 'husband', 'prefer', 'brad'],\n",
       "  ['go', 'run', 'brad', 'brad', 'jen', 'can', 'rogue_couple'],\n",
       "  ['case', 'jen', 'brad', 'list'],\n",
       "  ['brad',\n",
       "   'marry',\n",
       "   'jen',\n",
       "   'must',\n",
       "   'choose',\n",
       "   'serenade',\n",
       "   'wife',\n",
       "   'instead',\n",
       "   'jen',\n",
       "   'must',\n",
       "   'prefer',\n",
       "   'wife'],\n",
       "  ['go', 'run', 'jen', 'brad', 'jenn', 'rogue_couple'],\n",
       "  ['favor',\n",
       "   'mate_ritual',\n",
       "   'man_woman',\n",
       "   'woman',\n",
       "   'seem',\n",
       "   'power',\n",
       "   'stand',\n",
       "   'balcony',\n",
       "   'choose',\n",
       "   'finest',\n",
       "   'suitor',\n",
       "   'spurn',\n",
       "   'rest'],\n",
       "  ['know', 'suitor', 'change', 'well', 'ritual', 'progress'],\n",
       "  ['similarly',\n",
       "   'man',\n",
       "   'keep',\n",
       "   'serenade',\n",
       "   'woman',\n",
       "   'prefer',\n",
       "   'list',\n",
       "   'must',\n",
       "   'cross',\n",
       "   'point',\n",
       "   'serenade',\n",
       "   'preferred',\n",
       "   'woman_list'],\n",
       "  ['man', 'perspective', 'woman', 'serenade', 'change', 'bad'],\n",
       "  ['sound', 'good', 'deal', 'woman'],\n",
       "  ['fact',\n",
       "   'begin',\n",
       "   'man',\n",
       "   'serenade',\n",
       "   'first',\n",
       "   'choice',\n",
       "   'woman',\n",
       "   'desirability',\n",
       "   'woman',\n",
       "   'serenade',\n",
       "   'decrease',\n",
       "   'enough',\n",
       "   'ensure',\n",
       "   'overall',\n",
       "   'stability'],\n",
       "  ['mate_ritual',\n",
       "   'actually',\n",
       "   'well',\n",
       "   'possible',\n",
       "   'man',\n",
       "   'bad',\n",
       "   'possible',\n",
       "   'job',\n",
       "   'woman'],\n",
       "  ['explain', 'need', 'definition'],\n",
       "  ['let',\n",
       "   'begin',\n",
       "   'observe',\n",
       "   'mate_ritual',\n",
       "   'produce',\n",
       "   'stable_matching',\n",
       "   'may',\n",
       "   'stable',\n",
       "   'match',\n",
       "   'ing',\n",
       "   'set',\n",
       "   'man_woman'],\n",
       "  ['example',\n",
       "   'reverse',\n",
       "   'role',\n",
       "   'man_woman',\n",
       "   'often',\n",
       "   'yield',\n",
       "   'different',\n",
       "   'stable_matching'],\n",
       "  ['spouse', 'may', 'question', 'possible', 'stable_matching'],\n",
       "  ['example', 'give', 'preference', 'show_figure', 'definition'],\n",
       "  ['give',\n",
       "   'set',\n",
       "   'preference',\n",
       "   'list',\n",
       "   'man_woman',\n",
       "   'son',\n",
       "   'person',\n",
       "   'realm',\n",
       "   'possible',\n",
       "   'spouse',\n",
       "   'stable',\n",
       "   'match',\n",
       "   'people',\n",
       "   'married'],\n",
       "  ['person',\n",
       "   'optimal_spouse',\n",
       "   'pre',\n",
       "   'ferre',\n",
       "   'person',\n",
       "   'realm',\n",
       "   'possibility'],\n",
       "  ['person',\n",
       "   'pessimal',\n",
       "   'spouse',\n",
       "   'least',\n",
       "   'preferred',\n",
       "   'person',\n",
       "   'realm',\n",
       "   'possibility'],\n",
       "  ['optimal',\n",
       "   'pessimal',\n",
       "   'spouse',\n",
       "   'know',\n",
       "   'least',\n",
       "   'stable_matching',\n",
       "   'namely',\n",
       "   'produce',\n",
       "   'mating',\n",
       "   'ritual'],\n",
       "  ['shocking', 'truth', 'mate_ritual', 'theorem'],\n",
       "  ['mate_ritual', 'marrie', 'man', 'optimal_spouse'],\n",
       "  ['proof'],\n",
       "  ['contradiction'],\n",
       "  ['assume', 'purpose', 'contradiction', 'man', 'optimal_spouse'],\n",
       "  ['must',\n",
       "   'day',\n",
       "   'cross',\n",
       "   'optimal_spouse',\n",
       "   'otherwise',\n",
       "   'would',\n",
       "   'still',\n",
       "   'serenade',\n",
       "   'would',\n",
       "   'ulti',\n",
       "   'mately',\n",
       "   'marry',\n",
       "   'even',\n",
       "   'desirable',\n",
       "   'woman'],\n",
       "  ['order_principle',\n",
       "   'must',\n",
       "   'first',\n",
       "   'day',\n",
       "   'man',\n",
       "   'call',\n",
       "   'keith',\n",
       "   'cross',\n",
       "   'optimal_spouse',\n",
       "   'call',\n",
       "   'nicole'],\n",
       "  ['accord',\n",
       "   'rule',\n",
       "   'ritual',\n",
       "   'keith',\n",
       "   'cross',\n",
       "   'nicole',\n",
       "   'preferred',\n",
       "   'suitor',\n",
       "   'call',\n",
       "   'tom',\n",
       "   'nicole',\n",
       "   'prefer',\n",
       "   'tom',\n",
       "   'keith'],\n",
       "  ['first',\n",
       "   'day',\n",
       "   'optimal',\n",
       "   'woman',\n",
       "   'get',\n",
       "   'cross',\n",
       "   'know',\n",
       "   'tom',\n",
       "   'previously',\n",
       "   'cross',\n",
       "   'optimal_spouse',\n",
       "   'tom',\n",
       "   'rank',\n",
       "   'nicole',\n",
       "   'least',\n",
       "   'high',\n",
       "   'optimal_spouse'],\n",
       "  ['definition',\n",
       "   'optimal_spouse',\n",
       "   'must',\n",
       "   'stable',\n",
       "   'set',\n",
       "   'marriages',\n",
       "   'keith',\n",
       "   'get',\n",
       "   'optimal_spouse',\n",
       "   'nicole'],\n",
       "  ['preference',\n",
       "   'give',\n",
       "   'imply',\n",
       "   'tom',\n",
       "   'rogue_couple',\n",
       "   'supposedly',\n",
       "   'stable',\n",
       "   'set',\n",
       "   'marriage',\n",
       "   'think'],\n",
       "  ['contradiction'],\n",
       "  ['theorem'],\n",
       "  ['mate_ritual', 'marrie', 'woman', 'pessimal', 'spouse'],\n",
       "  ['proof'],\n",
       "  ['contradiction'],\n",
       "  ['assume', 'theorem', 'true'],\n",
       "  ['hence',\n",
       "   'must',\n",
       "   'stable',\n",
       "   'set',\n",
       "   'marriage',\n",
       "   'woman',\n",
       "   'call',\n",
       "   'nicole',\n",
       "   'married',\n",
       "   'man',\n",
       "   'call',\n",
       "   'tom',\n",
       "   'like',\n",
       "   'less',\n",
       "   'spouse',\n",
       "   'mate_ritual',\n",
       "   'call',\n",
       "   'keith'],\n",
       "  ['means', 'nicole', 'prefer', 'keith', 'tom'],\n",
       "  ['chapter_graph',\n",
       "   'theory',\n",
       "   'theorem',\n",
       "   'fact',\n",
       "   'keith',\n",
       "   'marry',\n",
       "   'mate_ritual',\n",
       "   'know',\n",
       "   'keith',\n",
       "   'prefer',\n",
       "   'nicole',\n",
       "   'spouse'],\n",
       "  ['mean',\n",
       "   'keith',\n",
       "   'nicole',\n",
       "   'form',\n",
       "   'rogue_couple',\n",
       "   'contradict',\n",
       "   'stability'],\n",
       "  ['application', 'mate_ritual', 'first', 'announce', 'paper'],\n",
       "  ['gale'],\n",
       "  ['shapley',\n",
       "   'year',\n",
       "   'gale',\n",
       "   'shapley',\n",
       "   'paper',\n",
       "   'publish',\n",
       "   'unknown',\n",
       "   'similar',\n",
       "   'algorithm',\n",
       "   'use',\n",
       "   'assign',\n",
       "   'resident',\n",
       "   'hospital',\n",
       "   'national',\n",
       "   'resident',\n",
       "   'matching',\n",
       "   'program',\n",
       "   'nrmp',\n",
       "   'internet',\n",
       "   'infrastructure',\n",
       "   'company',\n",
       "   'akamai',\n",
       "   'also',\n",
       "   'use',\n",
       "   'variation',\n",
       "   'mate_ritual',\n",
       "   'assign',\n",
       "   'web',\n",
       "   'traffic',\n",
       "   'server'],\n",
       "  ['early',\n",
       "   'day',\n",
       "   'akamai',\n",
       "   'use',\n",
       "   'com',\n",
       "   'binatorial',\n",
       "   'optimization',\n",
       "   'algorithm',\n",
       "   'get',\n",
       "   'slow',\n",
       "   'number',\n",
       "   'server',\n",
       "   'request',\n",
       "   'day',\n",
       "   'increase'],\n",
       "  ['akamai',\n",
       "   'switch',\n",
       "   'ritual',\n",
       "   'approach',\n",
       "   'fast',\n",
       "   'run',\n",
       "   'distribute',\n",
       "   'manner'],\n",
       "  ['case',\n",
       "   'web',\n",
       "   'request',\n",
       "   'correspond',\n",
       "   'woman',\n",
       "   'web',\n",
       "   'server',\n",
       "   'corre',\n",
       "   'spond',\n",
       "   'man'],\n",
       "  ['web',\n",
       "   'request',\n",
       "   'preference',\n",
       "   'base',\n",
       "   'latency',\n",
       "   'packet',\n",
       "   'loss',\n",
       "   'web',\n",
       "   'server',\n",
       "   'preference',\n",
       "   'base',\n",
       "   'cost',\n",
       "   'bandwidth',\n",
       "   'collocation'],\n",
       "  ['surprisingly',\n",
       "   'mate_ritual',\n",
       "   'also',\n",
       "   'use',\n",
       "   'least',\n",
       "   'large',\n",
       "   'online',\n",
       "   'dating',\n",
       "   'agency'],\n",
       "  ['even', 'serenade', 'go', 'handle', 'computer'],\n",
       "  ['course',\n",
       "   'serenade',\n",
       "   'go',\n",
       "   'hospital',\n",
       "   'preference',\n",
       "   'submit',\n",
       "   'program',\n",
       "   'whole',\n",
       "   'process',\n",
       "   'carry',\n",
       "   'computer'],\n",
       "  ['much',\n",
       "   'stable',\n",
       "   'marriage',\n",
       "   'problem',\n",
       "   'find',\n",
       "   'readable',\n",
       "   'mathematical',\n",
       "   'monograph',\n",
       "   'dan',\n",
       "   'gusfield',\n",
       "   'robert'],\n",
       "  ['irving', 'mit', 'press', 'cambridge', 'massachusetts', 'pp'],\n",
       "  ['figure'],\n",
       "  ['schedule', 'graph', 'exam'],\n",
       "  ['exam', 'connect', 'edge', 'can', 'give', 'time']],\n",
       " [['color', 'section']],\n",
       " [['exam',\n",
       "   'scheduling',\n",
       "   'problem',\n",
       "   'term',\n",
       "   'mit',\n",
       "   'schedules',\n",
       "   'office',\n",
       "   'must',\n",
       "   'assign',\n",
       "   'time',\n",
       "   'slot',\n",
       "   'final',\n",
       "   'exam'],\n",
       "  ['easy',\n",
       "   'student',\n",
       "   'take',\n",
       "   'several',\n",
       "   'class',\n",
       "   'final',\n",
       "   'even',\n",
       "   'mit_student',\n",
       "   'take',\n",
       "   'test',\n",
       "   'particular',\n",
       "   'time',\n",
       "   'slot'],\n",
       "  ['schedule', 'office', 'want', 'avoid', 'conflict'],\n",
       "  ['course',\n",
       "   'make',\n",
       "   'schedule',\n",
       "   'exam',\n",
       "   'different',\n",
       "   'slot',\n",
       "   'would',\n",
       "   'need',\n",
       "   'hun',\n",
       "   'dreds',\n",
       "   'slot',\n",
       "   'hundred',\n",
       "   'course',\n",
       "   'exam',\n",
       "   'period',\n",
       "   'would',\n",
       "   'run',\n",
       "   'year',\n",
       "   'schedule',\n",
       "   'office',\n",
       "   'would',\n",
       "   'also',\n",
       "   'like',\n",
       "   'keep',\n",
       "   'exam',\n",
       "   'period',\n",
       "   'short'],\n",
       "  ['schedule', 'office', 'problem', 'easy', 'describe', 'graph'],\n",
       "  ['vertex',\n",
       "   'course',\n",
       "   'final',\n",
       "   'exam',\n",
       "   'vertex_adjacent',\n",
       "   'exactly',\n",
       "   'student',\n",
       "   'take',\n",
       "   'course'],\n",
       "  ['example_suppose', 'need', 'sche', 'ule', 'exam'],\n",
       "  ['schedule', 'graph', 'may', 'appear', 'figure'],\n",
       "  ['can', 'exam', 'time', 'student', 'course', 'edge', 'node'],\n",
       "  ['hand'],\n",
       "  ['exam',\n",
       "   'time',\n",
       "   'teach',\n",
       "   'time',\n",
       "   'sometimes',\n",
       "   'student',\n",
       "   'enrol',\n",
       "   'student',\n",
       "   'enrol',\n",
       "   'timing',\n",
       "   'conflict'],\n",
       "  ['chapter_graph', 'theory', 'blue', 'red', 'green', 'green', 'figure'],\n",
       "  ['color',\n",
       "   'exam',\n",
       "   'graph_figure',\n",
       "   'next',\n",
       "   'identify',\n",
       "   'time',\n",
       "   'slot',\n",
       "   'color'],\n",
       "  ['example',\n",
       "   'monday',\n",
       "   'morning',\n",
       "   'red',\n",
       "   'monday',\n",
       "   'afternoon',\n",
       "   'blue',\n",
       "   'tuesday',\n",
       "   'morning',\n",
       "   'green'],\n",
       "  ['assign',\n",
       "   'exam',\n",
       "   'time',\n",
       "   'slot',\n",
       "   'equivalent',\n",
       "   'color',\n",
       "   'correspond',\n",
       "   'vertex'],\n",
       "  ['main',\n",
       "   'constraint',\n",
       "   'adjacent_vertex',\n",
       "   'must',\n",
       "   'different_color',\n",
       "   'otherwise',\n",
       "   'student',\n",
       "   'exam',\n",
       "   'time'],\n",
       "  ['furthermore',\n",
       "   'order',\n",
       "   'keep',\n",
       "   'exam',\n",
       "   'period',\n",
       "   'short',\n",
       "   'try',\n",
       "   'color',\n",
       "   'vertex',\n",
       "   'use',\n",
       "   'different_color',\n",
       "   'possible'],\n",
       "  ['show_figure',\n",
       "   'coloring',\n",
       "   'figure',\n",
       "   'correspond',\n",
       "   'give',\n",
       "   'final',\n",
       "   'monday',\n",
       "   'morning',\n",
       "   'red',\n",
       "   'monday',\n",
       "   'afternoon',\n",
       "   'blue',\n",
       "   'tuesday',\n",
       "   'morning',\n",
       "   'green'],\n",
       "  ['use',\n",
       "   'few',\n",
       "   'color',\n",
       "   'use',\n",
       "   'color',\n",
       "   'triangle',\n",
       "   'graph_vertex',\n",
       "   'triangle',\n",
       "   'must',\n",
       "   'different_color'],\n",
       "  ['example',\n",
       "   'graph',\n",
       "   'color',\n",
       "   'problem',\n",
       "   'give',\n",
       "   'graph',\n",
       "   'assign',\n",
       "   'color_node',\n",
       "   'adjacent',\n",
       "   'node',\n",
       "   'different_color'],\n",
       "  ['color',\n",
       "   'assignment',\n",
       "   'property',\n",
       "   'call',\n",
       "   'valid',\n",
       "   'color',\n",
       "   'graph',\n",
       "   'color',\n",
       "   'short'],\n",
       "  ['graph_colorable', 'coloring', 'use', 'color'],\n",
       "  ['definition'],\n",
       "  ['minimum',\n",
       "   'value',\n",
       "   'graph',\n",
       "   'valid',\n",
       "   'color',\n",
       "   'call',\n",
       "   'chromatic',\n",
       "   'number'],\n",
       "  ['general',\n",
       "   'trying',\n",
       "   'figure',\n",
       "   'color',\n",
       "   'graph',\n",
       "   'fix',\n",
       "   'number',\n",
       "   'color',\n",
       "   'take',\n",
       "   'long',\n",
       "   'time'],\n",
       "  ['classic', 'example', 'problem', 'fast', 'algorithm', 'know'],\n",
       "  ['easy', 'check', 'coloring', 'work', 'seem', 'really', 'hard', 'find'],\n",
       "  ['figure', 'clay', 'prize']],\n",
       " [['degree',\n",
       "   'bound',\n",
       "   'color',\n",
       "   'simple',\n",
       "   'graph',\n",
       "   'property',\n",
       "   'give',\n",
       "   'useful',\n",
       "   'upper',\n",
       "   'bound',\n",
       "   'chro',\n",
       "   'matic',\n",
       "   'number'],\n",
       "  ['example',\n",
       "   'graph',\n",
       "   'bipartite',\n",
       "   'color',\n",
       "   'color',\n",
       "   'color_node',\n",
       "   'leave',\n",
       "   'set',\n",
       "   'second',\n",
       "   'color_node',\n",
       "   'set'],\n",
       "  ['fact', 'graph', 'edge', 'bipartite', 'equivalent', 'colorable'],\n",
       "  ['alternatively',\n",
       "   'graph',\n",
       "   'planar',\n",
       "   'famous',\n",
       "   'color',\n",
       "   'theorem',\n",
       "   'say',\n",
       "   'graph_colorable'],\n",
       "  ['hard',\n",
       "   'result',\n",
       "   'prove',\n",
       "   'come',\n",
       "   'close',\n",
       "   'section',\n",
       "   'define',\n",
       "   'planar_graph',\n",
       "   'prove',\n",
       "   'colorable'],\n",
       "  ['chromatic',\n",
       "   'number',\n",
       "   'graph',\n",
       "   'also',\n",
       "   'show',\n",
       "   'small',\n",
       "   'vertex_degree',\n",
       "   'graph',\n",
       "   'small'],\n",
       "  ['particular',\n",
       "   'upper_bind',\n",
       "   'degree_vertex',\n",
       "   'graph',\n",
       "   'easily',\n",
       "   'find',\n",
       "   'color',\n",
       "   'color',\n",
       "   'degree',\n",
       "   'bind'],\n",
       "  ['theorem'],\n",
       "  ['graph', 'maximum', 'degree'],\n",
       "  ['colorable'],\n",
       "  ['natural_way', 'try_prove', 'theorem', 'use_induction'],\n",
       "  ['unfor', 'tunately', 'approach', 'lead', 'disaster'],\n",
       "  ['impossible',\n",
       "   'extremely',\n",
       "   'painful',\n",
       "   'would',\n",
       "   'ruin',\n",
       "   'week',\n",
       "   'try',\n",
       "   'exam'],\n",
       "  ['encounter',\n",
       "   'disaster',\n",
       "   'use_induction',\n",
       "   'graph',\n",
       "   'usually',\n",
       "   'good',\n",
       "   'change',\n",
       "   'induct'],\n",
       "  ['graph',\n",
       "   'typical',\n",
       "   'good',\n",
       "   'choice',\n",
       "   'induction',\n",
       "   'parameter',\n",
       "   'number',\n",
       "   'node',\n",
       "   'number_edge'],\n",
       "  ['proof_theorem',\n",
       "   'base_case',\n",
       "   'vertex_graph',\n",
       "   'maximum',\n",
       "   'degree',\n",
       "   'colorable'],\n",
       "  ['true'],\n",
       "  ['inductive_step_assume'],\n",
       "  ['true', 'let'],\n",
       "  ['nc', 'vertex_graph', 'maximum', 'degree'],\n",
       "  ['remove', 'vertex_edge', 'incident', 'leave', 'vertex', 'subgraph'],\n",
       "  ['maximum', 'degree'],\n",
       "  ['colorable', 'assumption'],\n",
       "  ['add', 'back', 'vertex'],\n",
       "  ['assign',\n",
       "   'color',\n",
       "   'set',\n",
       "   'color',\n",
       "   'different',\n",
       "   'adjacent_vertex',\n",
       "   'vertex_adjacent',\n",
       "   'least',\n",
       "   'color',\n",
       "   'still',\n",
       "   'available'],\n",
       "  ['therefore'],\n",
       "  ['colorable'],\n",
       "  ['complete', 'inductive_step', 'theorem', 'follow', 'induction'],\n",
       "  ['sometimes', 'color', 'best'],\n",
       "  ['example', 'complete', 'graph', 'give', 'best', 'possible', 'bind'],\n",
       "  ['similar',\n",
       "   'argument',\n",
       "   'show',\n",
       "   'theorem',\n",
       "   'give',\n",
       "   'good',\n",
       "   'possible',\n",
       "   'bind',\n",
       "   'graph',\n",
       "   'degree',\n",
       "   'bound',\n",
       "   'kc',\n",
       "   'chapter_graph',\n",
       "   'theory_figure'],\n",
       "  ['node', 'star', 'graph'],\n",
       "  ['sometimes', 'color', 'far', 'best'],\n",
       "  ['example',\n",
       "   'node',\n",
       "   'star',\n",
       "   'graph_show',\n",
       "   'figure',\n",
       "   'maximum',\n",
       "   'degree',\n",
       "   'color',\n",
       "   'use',\n",
       "   'color']],\n",
       " [['color',\n",
       "   'reason',\n",
       "   'color',\n",
       "   'problem',\n",
       "   'frequently',\n",
       "   'arise_practice',\n",
       "   'scheduling',\n",
       "   'conflict',\n",
       "   'common'],\n",
       "  ['example',\n",
       "   'akamai',\n",
       "   'new',\n",
       "   'version',\n",
       "   'software',\n",
       "   'deploy',\n",
       "   'server',\n",
       "   'day'],\n",
       "  ['update',\n",
       "   'can',\n",
       "   'do',\n",
       "   'time',\n",
       "   'server',\n",
       "   'need',\n",
       "   'take',\n",
       "   'order',\n",
       "   'deploy',\n",
       "   'software'],\n",
       "  ['also',\n",
       "   'server',\n",
       "   'can',\n",
       "   'handle',\n",
       "   'time',\n",
       "   'would',\n",
       "   'take',\n",
       "   'forever',\n",
       "   'update',\n",
       "   'take',\n",
       "   'hour'],\n",
       "  ['moreover',\n",
       "   'certain',\n",
       "   'pair',\n",
       "   'server',\n",
       "   'can',\n",
       "   'take',\n",
       "   'time',\n",
       "   'common',\n",
       "   'critical',\n",
       "   'function'],\n",
       "  ['problem',\n",
       "   'eventually',\n",
       "   'solve',\n",
       "   'make',\n",
       "   'node',\n",
       "   'conflict',\n",
       "   'graph',\n",
       "   'coloring',\n",
       "   'color',\n",
       "   'wave',\n",
       "   'install',\n",
       "   'need',\n",
       "   'example',\n",
       "   'come',\n",
       "   'need',\n",
       "   'assign',\n",
       "   'frequency',\n",
       "   'radio',\n",
       "   'station'],\n",
       "  ['station', 'overlap', 'broadcast', 'area', 'give', 'frequency'],\n",
       "  ['frequencies',\n",
       "   'precious',\n",
       "   'expensive',\n",
       "   'want',\n",
       "   'minimize',\n",
       "   'number',\n",
       "   'hand'],\n",
       "  ['amount',\n",
       "   'find',\n",
       "   'minimum',\n",
       "   'color',\n",
       "   'graph_vertex',\n",
       "   'station',\n",
       "   'edge_connect',\n",
       "   'station',\n",
       "   'overlap',\n",
       "   'area'],\n",
       "  ['color', 'also', 'come', 'allocate', 'register', 'program', 'variable'],\n",
       "  ['variable', 'use', 'value', 'need', 'save', 'register'],\n",
       "  ['register',\n",
       "   'reuse',\n",
       "   'different',\n",
       "   'variable',\n",
       "   'variable',\n",
       "   'need',\n",
       "   'different',\n",
       "   'register',\n",
       "   'refer',\n",
       "   'ence',\n",
       "   'overlap',\n",
       "   'interval',\n",
       "   'program',\n",
       "   'execution'],\n",
       "  ['register',\n",
       "   'allocation',\n",
       "   'color',\n",
       "   'problem',\n",
       "   'graph_vertex',\n",
       "   'variable',\n",
       "   'vertex',\n",
       "   'ad',\n",
       "   'jacent',\n",
       "   'interval',\n",
       "   'overlap',\n",
       "   'color',\n",
       "   'register'],\n",
       "  ['goal', 'minimize', 'number', 'color', 'need', 'color', 'graph'],\n",
       "  ['finally',\n",
       "   'famous',\n",
       "   'map',\n",
       "   'color',\n",
       "   'problem',\n",
       "   'state',\n",
       "   'proposition',\n",
       "   'ritorie',\n",
       "   'get',\n",
       "   'different_color',\n",
       "   'number',\n",
       "   'color',\n",
       "   'need',\n",
       "   'color',\n",
       "   'graph',\n",
       "   'draw',\n",
       "   'plane',\n",
       "   'edge',\n",
       "   'crossing'],\n",
       "  ['proof',\n",
       "   'color',\n",
       "   'enough',\n",
       "   'planar_graph',\n",
       "   'acclaim',\n",
       "   'discover',\n",
       "   'year_ago'],\n",
       "  ['implicit',\n",
       "   'proof',\n",
       "   'color',\n",
       "   'procedure',\n",
       "   'take',\n",
       "   'time',\n",
       "   'proportional',\n",
       "   'number',\n",
       "   'vertice',\n",
       "   'graph',\n",
       "   'country',\n",
       "   'map'],\n",
       "  ['surprisingly',\n",
       "   'dollar',\n",
       "   'prize',\n",
       "   'question',\n",
       "   'find',\n",
       "   'efficient',\n",
       "   'procedure',\n",
       "   'tell',\n",
       "   'planar_graph',\n",
       "   'really',\n",
       "   'need',\n",
       "   'color',\n",
       "   'actually',\n",
       "   'job'],\n",
       "  ['always', 'easy', 'tell', 'arbitrary', 'graph_colorable'],\n",
       "  ['sec', 'tion']],\n",
       " [['get', 'graph']],\n",
       " [['path', 'walk', 'definition'],\n",
       "  ['walk',\n",
       "   'graph',\n",
       "   'sequence',\n",
       "   'vertice',\n",
       "   'edge',\n",
       "   'fv_fv',\n",
       "   'fv_fv',\n",
       "   'ic',\n",
       "   'edge'],\n",
       "  ['walk', 'say', 'start', 'ic', 'fu'],\n",
       "  ['path', 'walk', 'example', 'graph_figure', 'length', 'path'],\n",
       "  ['long', 'path', 'graph'],\n",
       "  ['course', 'graph', 'walk', 'arbitrarily', 'large', 'length', 'example'],\n",
       "  ['length',\n",
       "   'walk_path',\n",
       "   'total_number',\n",
       "   'time',\n",
       "   'traverse',\n",
       "   'edge',\n",
       "   'less',\n",
       "   'length',\n",
       "   'sequence',\n",
       "   'vertex'],\n",
       "  ['example', 'length', 'path', 'contain', 'sequence', 'vertex'],\n",
       "  ['text',\n",
       "   'use',\n",
       "   'word',\n",
       "   'path',\n",
       "   'definition',\n",
       "   'walk',\n",
       "   'term',\n",
       "   'simple',\n",
       "   'path',\n",
       "   'definition',\n",
       "   'path'],\n",
       "  ['work',\n",
       "   'fine',\n",
       "   'simple',\n",
       "   'graph',\n",
       "   'edge',\n",
       "   'walk',\n",
       "   'completely',\n",
       "   'determine',\n",
       "   'sequence',\n",
       "   'vertex',\n",
       "   'ambiguity'],\n",
       "  ['graphs',\n",
       "   'multiple',\n",
       "   'edge',\n",
       "   'would',\n",
       "   'need',\n",
       "   'specify',\n",
       "   'edge',\n",
       "   'well',\n",
       "   'node'],\n",
       "  ['chapter_graph', 'theory_figure'],\n",
       "  ['graph_contain', 'path', 'length']],\n",
       " [['find', 'path', 'walk_path'],\n",
       "  ['sort',\n",
       "   'obvious',\n",
       "   'easy',\n",
       "   'enough',\n",
       "   'prove',\n",
       "   'rigorously',\n",
       "   'use_well',\n",
       "   'order_principle'],\n",
       "  ['lemma'],\n",
       "  ['walk', 'vertex', 'vertex_graph', 'path'],\n",
       "  ['proof'],\n",
       "  ['walk', 'must', 'well_order', 'principle', 'minimum', 'length', 'walk'],\n",
       "  ['minimum', 'length', 'minimum', 'length', 'walk_path'],\n",
       "  ['otherwise',\n",
       "   'minimum',\n",
       "   'length',\n",
       "   'walk',\n",
       "   'yield',\n",
       "   'strictly',\n",
       "   'short',\n",
       "   'walk',\n",
       "   'contradict',\n",
       "   'minimality',\n",
       "   'give',\n",
       "   'walk'],\n",
       "  ['actually', 'prove', 'strong', 'corollary'],\n",
       "  ['walk_length', 'graph', 'path', 'length', 'endpoint'],\n",
       "  ['moreover', 'short', 'walk', 'pair_vertex', 'fact', 'path'],\n",
       "  ['figure'],\n",
       "  ['graph', 'walks', 'length']],\n",
       " [['number',\n",
       "   'walk',\n",
       "   'give',\n",
       "   'pair_node',\n",
       "   'connect',\n",
       "   'walk_length',\n",
       "   'graph',\n",
       "   'often',\n",
       "   'many',\n",
       "   'walk',\n",
       "   'use',\n",
       "   'node'],\n",
       "  ['example',\n",
       "   'walk_length',\n",
       "   'start',\n",
       "   'surprising',\n",
       "   'relationship',\n",
       "   'number',\n",
       "   'walk_length',\n",
       "   'tween',\n",
       "   'pair_node',\n",
       "   'graph',\n",
       "   'kth',\n",
       "   'power',\n",
       "   'adjacency_matrix',\n",
       "   'theorem'],\n",
       "  ['let'],\n",
       "  ['node_graph',\n",
       "   'fv',\n",
       "   'let',\n",
       "   'ij',\n",
       "   'word',\n",
       "   'determine',\n",
       "   'number',\n",
       "   'walk_length',\n",
       "   'pair_node',\n",
       "   'simply',\n",
       "   'compute',\n",
       "   'kth',\n",
       "   'power',\n",
       "   'adjacency_matrix',\n",
       "   'pretty',\n",
       "   'amazing'],\n",
       "  ['example',\n",
       "   'first',\n",
       "   'power',\n",
       "   'adjacency_matrix',\n",
       "   'graph',\n",
       "   'fig',\n",
       "   'sure_enough'],\n",
       "  ['coordinate', 'chapter_graph', 'theory', 'proof_theorem'],\n",
       "  ['ij'],\n",
       "  ['base_case', 'case', 'ij', 'ij', 'ij', 'ij', 'ij', 'case'],\n",
       "  ['case', 'ij', 'can', 'walk_length', 'ij', 'case', 'well'],\n",
       "  ['hence'],\n",
       "  ['inductive_step_assume'],\n",
       "  ['group',\n",
       "   'thus',\n",
       "   'count',\n",
       "   'number',\n",
       "   'walk_length',\n",
       "   'follow',\n",
       "   'tj',\n",
       "   'inductive',\n",
       "   'hypothesis',\n",
       "   'tj',\n",
       "   'tj']],\n",
       " [['short_path',\n",
       "   'connection',\n",
       "   'power',\n",
       "   'adjacency_matrix',\n",
       "   'num_ber',\n",
       "   'walk',\n",
       "   'cool',\n",
       "   'least',\n",
       "   'mathematician',\n",
       "   'problem',\n",
       "   'count',\n",
       "   'walk',\n",
       "   'come',\n",
       "   'often',\n",
       "   'practice'],\n",
       "  ['much', 'important', 'problem', 'find_short_path', 'pair_node', 'graph'],\n",
       "  ['good_news', 'bad_news', 'report', 'front'],\n",
       "  ['good_news', 'hard', 'find_short_path'],\n",
       "  ['bad_news', 'win', 'dollar', 'prize'],\n",
       "  ['fact',\n",
       "   'several',\n",
       "   'good',\n",
       "   'algorithm',\n",
       "   'know',\n",
       "   'find_short_path',\n",
       "   'tween',\n",
       "   'pair_node'],\n",
       "  ['simplest',\n",
       "   'explain',\n",
       "   'fastest',\n",
       "   'compute',\n",
       "   'power',\n",
       "   'adjacency_matrix',\n",
       "   'value',\n",
       "   'ij',\n",
       "   'theorem',\n",
       "   'corollary',\n",
       "   'imply',\n",
       "   'length',\n",
       "   'short_path',\n",
       "   'ij',\n",
       "   'path',\n",
       "   'weight',\n",
       "   'graphs',\n",
       "   'problem',\n",
       "   'compute',\n",
       "   'short_path',\n",
       "   'weight_graph',\n",
       "   'frequently',\n",
       "   'arise_practice'],\n",
       "  ['example',\n",
       "   'drive',\n",
       "   'home',\n",
       "   'vacation',\n",
       "   'usually',\n",
       "   'would',\n",
       "   'take',\n",
       "   'short',\n",
       "   'route'],\n",
       "  ['definition'],\n",
       "  ['give',\n",
       "   'weight_graph',\n",
       "   'length',\n",
       "   'path',\n",
       "   'graph',\n",
       "   'sum',\n",
       "   'weight_edge',\n",
       "   'path'],\n",
       "  ['find_short_path',\n",
       "   'weight',\n",
       "   'graphs',\n",
       "   'lot',\n",
       "   'hard',\n",
       "   'find_short_path',\n",
       "   'unweighted',\n",
       "   'graph'],\n",
       "  ['show',\n",
       "   'study',\n",
       "   'algorithm',\n",
       "   'find_short_path',\n",
       "   'take',\n",
       "   'algorithm',\n",
       "   'course'],\n",
       "  ['surprisingly', 'proof', 'correctness', 'use_induction']],\n",
       " [['connectivity', 'definition'],\n",
       "  ['vertex_graph', 'say', 'connected', 'path', 'begin_end'],\n",
       "  ['convention', 'vertex', 'consider', 'connected', 'path', 'length'],\n",
       "  ['definition'],\n",
       "  ['graph', 'say', 'connect_pair', 'vertex', 'connect']],\n",
       " [['connected_component', 'connect', 'usually', 'good', 'property', 'graph'],\n",
       "  ['example',\n",
       "   'could',\n",
       "   'mean',\n",
       "   'possible',\n",
       "   'node',\n",
       "   'node',\n",
       "   'chapter_graph',\n",
       "   'theory',\n",
       "   'possible',\n",
       "   'communicate',\n",
       "   'pair_node',\n",
       "   'depend',\n",
       "   'application'],\n",
       "  ['graphs', 'connect'],\n",
       "  ['example',\n",
       "   'graph',\n",
       "   'node',\n",
       "   'represent',\n",
       "   'city',\n",
       "   'edge',\n",
       "   'represent',\n",
       "   'highway',\n",
       "   'may',\n",
       "   'connect',\n",
       "   'north',\n",
       "   'american',\n",
       "   'city',\n",
       "   'would',\n",
       "   'surely',\n",
       "   'connect',\n",
       "   'also',\n",
       "   'include',\n",
       "   'city',\n",
       "   'australia'],\n",
       "  ['true',\n",
       "   'communication_network',\n",
       "   'internet',\n",
       "   'order',\n",
       "   'protect',\n",
       "   'virus',\n",
       "   'spread',\n",
       "   'internet',\n",
       "   'government',\n",
       "   'network',\n",
       "   'completely',\n",
       "   'isolate',\n",
       "   'internet'],\n",
       "  ['figure'],\n",
       "  ['graph', 'connect_component'],\n",
       "  ['example',\n",
       "   'diagram',\n",
       "   'figure',\n",
       "   'look',\n",
       "   'picture',\n",
       "   'graph',\n",
       "   'intend',\n",
       "   'picture',\n",
       "   'graph'],\n",
       "  ['graph', 'consist', 'piece', 'subgraph'],\n",
       "  ['piece', 'connected', 'path', 'tice', 'different', 'piece'],\n",
       "  ['connected', 'piece', 'graph', 'call', 'connected_component'],\n",
       "  ['definition'],\n",
       "  ['connected_component',\n",
       "   'subgraph',\n",
       "   'graph',\n",
       "   'consist',\n",
       "   'vertex',\n",
       "   'node',\n",
       "   'edge_connect',\n",
       "   'vertex'],\n",
       "  ['graph', 'connect', 'iff', 'exactly', 'connected_component'],\n",
       "  ['extreme', 'empty', 'graph_vertex', 'connect_component']],\n",
       " [['connected',\n",
       "   'graph',\n",
       "   'think',\n",
       "   'graph',\n",
       "   'modeling',\n",
       "   'cable',\n",
       "   'telephone',\n",
       "   'network',\n",
       "   'oil',\n",
       "   'pipeline',\n",
       "   'electrical',\n",
       "   'power',\n",
       "   'line',\n",
       "   'want',\n",
       "   'connectivity',\n",
       "   'want',\n",
       "   'connectivity',\n",
       "   'survive',\n",
       "   'component',\n",
       "   'failure'],\n",
       "  ['graph',\n",
       "   'call',\n",
       "   'edge_connect',\n",
       "   'take',\n",
       "   'least',\n",
       "   'edge',\n",
       "   'failure',\n",
       "   'disconnect'],\n",
       "  ['precisely', 'definition'],\n",
       "  ['vertex_graph',\n",
       "   'edge_connect',\n",
       "   'remain',\n",
       "   'con',\n",
       "   'necte',\n",
       "   'subgraph',\n",
       "   'obtain',\n",
       "   'deleting',\n",
       "   'edge'],\n",
       "  ['graph', 'least', 'vertex_edge', 'connect', 'vertex_edge', 'connect'],\n",
       "  ['correspond',\n",
       "   'definition',\n",
       "   'connectedness',\n",
       "   'base',\n",
       "   'deleting',\n",
       "   'vertex',\n",
       "   'rather',\n",
       "   'edge',\n",
       "   'common',\n",
       "   'graph_theory',\n",
       "   'text',\n",
       "   'usually',\n",
       "   'simply',\n",
       "   'call',\n",
       "   'connect',\n",
       "   'rather',\n",
       "   'vertex',\n",
       "   'connect'],\n",
       "  ['edge_connect', 'connected', 'vertex_graph'],\n",
       "  ['way',\n",
       "   'say',\n",
       "   'graph',\n",
       "   'edge_connect',\n",
       "   'subgraph',\n",
       "   'obtain',\n",
       "   'deleting',\n",
       "   'edge_connect'],\n",
       "  ['example',\n",
       "   'graph_figure',\n",
       "   'vertex',\n",
       "   'connected',\n",
       "   'edge',\n",
       "   'disjoint',\n",
       "   'path',\n",
       "   'path',\n",
       "   'traverse',\n",
       "   'edge',\n",
       "   'obviously',\n",
       "   'edge_connect'],\n",
       "  ['fundamental',\n",
       "   'fact',\n",
       "   'ingenious',\n",
       "   'proof',\n",
       "   'omit',\n",
       "   'menger',\n",
       "   'theorem',\n",
       "   'confirm',\n",
       "   'converse',\n",
       "   'also',\n",
       "   'true',\n",
       "   'vertex_edge',\n",
       "   'connected',\n",
       "   'edge',\n",
       "   'disjoint',\n",
       "   'path',\n",
       "   'connect'],\n",
       "  ['even', 'take', 'ingenuity', 'prove', 'case']],\n",
       " [['minimum',\n",
       "   'number_edge',\n",
       "   'connect_graph',\n",
       "   'following',\n",
       "   'theorem',\n",
       "   'say',\n",
       "   'graph',\n",
       "   'edge',\n",
       "   'must',\n",
       "   'many',\n",
       "   'connected_component'],\n",
       "  ['theorem'],\n",
       "  ['graph_vertex', 'edge', 'least', 'necte', 'component'],\n",
       "  ['course', 'theorem', 'use', 'must', 'few', 'edge', 'vertex'],\n",
       "  ['proof'],\n",
       "  ['use_induction', 'number_edge'],\n",
       "  ['let'],\n",
       "  ['proposition', 'graph_vertex', 'edge', 'least', 'connect_component'],\n",
       "  ['base_case'],\n",
       "  ['graph',\n",
       "   'edge',\n",
       "   'vertex',\n",
       "   'vertex',\n",
       "   'connect_component',\n",
       "   'exactly',\n",
       "   'connect_component'],\n",
       "  ['holds'],\n",
       "  ['inductive_step_assume',\n",
       "   'induction_hypothesis',\n",
       "   'hold',\n",
       "   'edge',\n",
       "   'graph',\n",
       "   'order',\n",
       "   'prove',\n",
       "   'hold'],\n",
       "  ['ec', 'edge', 'graph'],\n",
       "  ['consider', 'graph', 'edge', 'vertex'],\n",
       "  ['want', 'prove', 'least'],\n",
       "  ['connected', 'components'],\n",
       "  ['remove',\n",
       "   'arbitrary',\n",
       "   'edge_bg',\n",
       "   'call',\n",
       "   'result',\n",
       "   'graph',\n",
       "   'connect_component'],\n",
       "  ['add', 'back', 'edge_bg', 'obtain', 'original', 'graph'],\n",
       "  ['connected_component', 'connect_component'],\n",
       "  ['ec', 'components'],\n",
       "  ['chapter_graph', 'theory_figure'],\n",
       "  ['counterexample', 'graph', 'false', 'claim'],\n",
       "  ['otherwise', 'different', 'connected_component', 'corollary'],\n",
       "  ['connect_graph', 'vertex', 'least', 'edge'],\n",
       "  ['couple', 'point', 'proof_theorem', 'worth', 'noticing'],\n",
       "  ['first', 'used', 'induction', 'number_edge', 'graph'],\n",
       "  ['common', 'proofs', 'involve', 'graphs', 'induction', 'number', 'vertex'],\n",
       "  ['present', 'graph', 'problem', 'approach', 'first', 'consider'],\n",
       "  ['second', 'point', 'subtle'],\n",
       "  ['notice', 'inductive_step', 'take', 'arbitrary'],\n",
       "  ['nc',\n",
       "   'edge',\n",
       "   'graph',\n",
       "   'throw',\n",
       "   'edge',\n",
       "   'could',\n",
       "   'apply',\n",
       "   'induction',\n",
       "   'assumption',\n",
       "   'put',\n",
       "   'edge',\n",
       "   'back'],\n",
       "  ['see',\n",
       "   'shrink',\n",
       "   'grow',\n",
       "   'back',\n",
       "   'process',\n",
       "   'often',\n",
       "   'inductive_step',\n",
       "   'proof',\n",
       "   'relate',\n",
       "   'graph'],\n",
       "  ['may_seem', 'needless', 'effort', 'start', 'edge', 'graph', 'add', 'get'],\n",
       "  ['edge',\n",
       "   'graph',\n",
       "   'would',\n",
       "   'work',\n",
       "   'fine',\n",
       "   'case',\n",
       "   'open_door',\n",
       "   'nasty',\n",
       "   'logical',\n",
       "   'error',\n",
       "   'call',\n",
       "   'buildup',\n",
       "   'error']],\n",
       " [['build', 'error', 'false', 'claim'],\n",
       "  ['vertex_graph', 'degree_least', 'graph', 'connect'],\n",
       "  ['many', 'counterexample', 'example', 'see_figure', 'false', 'proof'],\n",
       "  ['use_induction'],\n",
       "  ['let'],\n",
       "  ['proposition',\n",
       "   'vertex',\n",
       "   'vertex_graph',\n",
       "   'degree_least',\n",
       "   'graph',\n",
       "   'connect'],\n",
       "  ['base_case', 'graph', 'single', 'vertex_degree'],\n",
       "  ['fore'],\n",
       "  ['vacuously', 'true', 'part', 'false'],\n",
       "  ['graph_figure'],\n",
       "  ['add', 'vertex_degree', 'least', 'connect', 'node_graph'],\n",
       "  ['inductive_step', 'must', 'show'],\n",
       "  ['imply'],\n",
       "  ['consider', 'vertex_graph', 'vertex_degree', 'least'],\n",
       "  ['assump', 'tion'],\n",
       "  ['graph', 'connect', 'path_pair', 'vertex'],\n",
       "  ['add', 'vertex', 'obtain'],\n",
       "  ['vertex_graph', 'show_figure', 'remain', 'check', 'path', 'vertex'],\n",
       "  ['degree_least', 'edge', 'vertex', 'call'],\n",
       "  ['thus', 'obtain', 'path', 'adjoin', 'edge', 'fx', 'yg', 'path'],\n",
       "  ['prove'],\n",
       "  ['principle', 'induction'],\n",
       "  ['true', 'prove_theorem'],\n",
       "  ['proof',\n",
       "   'look',\n",
       "   'fine',\n",
       "   'bug',\n",
       "   'turn',\n",
       "   'faulty',\n",
       "   'sumption',\n",
       "   'underlying',\n",
       "   'argument'],\n",
       "  ['nc',\n",
       "   'vertex_graph',\n",
       "   'minimum',\n",
       "   'degree',\n",
       "   'obtain',\n",
       "   'vertex_graph',\n",
       "   'minimum',\n",
       "   'degree',\n",
       "   'add',\n",
       "   'vertex'],\n",
       "  ['instead', 'start', 'consider', 'arbitrary'],\n",
       "  ['node_graph', 'proof', 'consider'],\n",
       "  ['node_graph', 'make', 'start', 'node_graph', 'minimum', 'degree'],\n",
       "  ['counterexample',\n",
       "   'figure_show',\n",
       "   'assumption',\n",
       "   'false',\n",
       "   'way',\n",
       "   'build',\n",
       "   'vertex_graph',\n",
       "   'figure',\n",
       "   'vertex_graph',\n",
       "   'minimum',\n",
       "   'degree'],\n",
       "  ['thus', 'first', 'error', 'proof', 'statement', 'prove'],\n",
       "  ['kind', 'flaw', 'know', 'build', 'error'],\n",
       "  ['usually',\n",
       "   'build',\n",
       "   'error',\n",
       "   'arise',\n",
       "   'faulty',\n",
       "   'assumption',\n",
       "   'size',\n",
       "   'graph',\n",
       "   'property',\n",
       "   'build',\n",
       "   'size',\n",
       "   'graph',\n",
       "   'property'],\n",
       "  ['assumption', 'cor', 'rect', 'property', 'incorrect', 'other', 'argument'],\n",
       "  ['chapter_graph',\n",
       "   'theory',\n",
       "   'way',\n",
       "   'avoid',\n",
       "   'accidental',\n",
       "   'build',\n",
       "   'error',\n",
       "   'use',\n",
       "   'shrink',\n",
       "   'grow',\n",
       "   'process',\n",
       "   'inductive_step',\n",
       "   'start',\n",
       "   'size',\n",
       "   'graph',\n",
       "   'remove',\n",
       "   'vertex_edge',\n",
       "   'apply',\n",
       "   'inductive',\n",
       "   'hypothesis'],\n",
       "  ['small', 'graph', 'add', 'back', 'vertex_edge', 'argue'],\n",
       "  ['holds'],\n",
       "  ['let_see',\n",
       "   'would',\n",
       "   'happen',\n",
       "   'try_prove',\n",
       "   'claim',\n",
       "   'method',\n",
       "   'revise',\n",
       "   'inductive_step',\n",
       "   'must',\n",
       "   'show'],\n",
       "  ['imply'],\n",
       "  ['consider'],\n",
       "  ['vertex_graph', 'vertex_degree', 'least'],\n",
       "  ['remove',\n",
       "   'arbitrary',\n",
       "   'vertex',\n",
       "   'leave',\n",
       "   'vertex_graph',\n",
       "   'reduce',\n",
       "   'graph',\n",
       "   'always',\n",
       "   'use',\n",
       "   'shrink',\n",
       "   'grow',\n",
       "   'back',\n",
       "   'argument',\n",
       "   'never',\n",
       "   'fall',\n",
       "   'trap']],\n",
       " [['around', 'go']],\n",
       " [['cycle', 'close', 'walks', 'definition'],\n",
       "  ['close_walk',\n",
       "   'graph',\n",
       "   'sequence',\n",
       "   'vertice',\n",
       "   'edge',\n",
       "   'fv_fv',\n",
       "   'fv',\n",
       "   'ic',\n",
       "   'edge'],\n",
       "  ['length', 'close_walk'],\n",
       "  ['closed_walk',\n",
       "   'say',\n",
       "   'cycle',\n",
       "   'example',\n",
       "   'close_walk',\n",
       "   'length',\n",
       "   'graph_show',\n",
       "   'figure',\n",
       "   'many_way',\n",
       "   'represent',\n",
       "   'closed_walk',\n",
       "   'cycle'],\n",
       "  ['example', 'start', 'node', 'instead', 'node', 'reverse', 'direction'],\n",
       "  ['text',\n",
       "   'use',\n",
       "   'word',\n",
       "   'cycle',\n",
       "   'definition',\n",
       "   'close_walk',\n",
       "   'simple',\n",
       "   'cycle',\n",
       "   'definition',\n",
       "   'cycle'],\n",
       "  ['cycle',\n",
       "   'similar',\n",
       "   'path',\n",
       "   'last',\n",
       "   'node',\n",
       "   'first',\n",
       "   'node',\n",
       "   'notion',\n",
       "   'first',\n",
       "   'last',\n",
       "   'matter'],\n",
       "  ['indeed',\n",
       "   'many',\n",
       "   'possible',\n",
       "   'vertex',\n",
       "   'order',\n",
       "   'use',\n",
       "   'describe',\n",
       "   'cycle',\n",
       "   'close_walk',\n",
       "   'walk_path',\n",
       "   'prescribe',\n",
       "   'begin_end',\n",
       "   'ordering']],\n",
       " [['odd',\n",
       "   'cycle',\n",
       "   'colorability',\n",
       "   'already',\n",
       "   'see',\n",
       "   'determine',\n",
       "   'chromatic',\n",
       "   'number',\n",
       "   'graph',\n",
       "   'chal',\n",
       "   'lenging',\n",
       "   'problem'],\n",
       "  ['special_case',\n",
       "   'problem',\n",
       "   'easy',\n",
       "   'namely',\n",
       "   'case',\n",
       "   'cycle',\n",
       "   'graph',\n",
       "   'even',\n",
       "   'length'],\n",
       "  ['case', 'graph_colorable', 'course', 'optimal', 'graph', 'edge'],\n",
       "  ['generally', 'prove_theorem'],\n",
       "  ['follow',\n",
       "   'properties',\n",
       "   'graph',\n",
       "   'equivalent',\n",
       "   'graph',\n",
       "   'property',\n",
       "   'propertie',\n",
       "   'graph',\n",
       "   'bipartite'],\n",
       "  ['graph_colorable'],\n",
       "  ['graph_contain', 'cycle', 'odd_length'],\n",
       "  ['graph_contain', 'closed', 'walks', 'odd_length'],\n",
       "  ['proof'],\n",
       "  ['show',\n",
       "   'property',\n",
       "   'imply_imply',\n",
       "   'imply_imply',\n",
       "   'section',\n",
       "   'imply',\n",
       "   'assume',\n",
       "   'bipartite_graph'],\n",
       "  ['parti', 'tione', 'set', 'edge_connect', 'pair_node', 'pair_node'],\n",
       "  ['hence', 'use', 'color_node', 'second', 'color_node'],\n",
       "  ['hence'],\n",
       "  ['imply', 'let', 'colorable', 'graph', 'wwd', 'cycle'],\n",
       "  ['consider', 'color_node'],\n",
       "  ['fv', 'ic', 'ic', 'even', 'length'],\n",
       "  ['chapter_graph', 'theory', 'imply', 'proof_contradiction'],\n",
       "  ['assume',\n",
       "   'purposes',\n",
       "   'contradic',\n",
       "   'tion',\n",
       "   'graph_contain',\n",
       "   'cycle',\n",
       "   'odd_length',\n",
       "   'satisfie',\n",
       "   'property',\n",
       "   'let',\n",
       "   'wwd',\n",
       "   'shortest',\n",
       "   'closed_walk',\n",
       "   'odd_length'],\n",
       "  ['odd_length', 'cycle', 'can', 'cycle'],\n",
       "  ['hence',\n",
       "   'ic',\n",
       "   'odd_length',\n",
       "   'closed_walk',\n",
       "   'must_also',\n",
       "   'odd_length',\n",
       "   'short'],\n",
       "  ['contradicts', 'minimality'],\n",
       "  ['hence', 'imply_imply', 'proof_contradiction'],\n",
       "  ['assume',\n",
       "   'purpose',\n",
       "   'contradictin',\n",
       "   'graph',\n",
       "   'closed',\n",
       "   'walks',\n",
       "   'odd_length',\n",
       "   'satisfie',\n",
       "   'property',\n",
       "   'bipartite',\n",
       "   'must',\n",
       "   'contain',\n",
       "   'connected_component',\n",
       "   'dist'],\n",
       "  ['wwd', 'length', 'short_path', 'distance'],\n",
       "  ['partition', 'dist'],\n",
       "  ['even', 'dist'],\n",
       "  ['odd', 'let', 'hence', 'imply', 'figure'],\n",
       "  ['possible', 'floor', 'plan', 'museum'],\n",
       "  ['find',\n",
       "   'walk',\n",
       "   'tra',\n",
       "   'verse',\n",
       "   'edge',\n",
       "   'exactly',\n",
       "   'theorem',\n",
       "   'turn',\n",
       "   'useful',\n",
       "   'bipartite_graph',\n",
       "   'come',\n",
       "   'fairly',\n",
       "   'often',\n",
       "   'practice'],\n",
       "  ['see', 'examples', 'talk', 'planar', 'graphs', 'section']],\n",
       " [['euler_tour',\n",
       "   'walk',\n",
       "   'hallway',\n",
       "   'museum',\n",
       "   'fine',\n",
       "   'art',\n",
       "   'exactly',\n",
       "   'represent',\n",
       "   'hallway',\n",
       "   'intersection',\n",
       "   'edge',\n",
       "   'vertex',\n",
       "   'reduce',\n",
       "   'question',\n",
       "   'graph'],\n",
       "  ['example',\n",
       "   'could',\n",
       "   'visit',\n",
       "   'hallway',\n",
       "   'exactly',\n",
       "   'museum',\n",
       "   'floor',\n",
       "   'plan',\n",
       "   'figure',\n",
       "   'entire',\n",
       "   'field',\n",
       "   'graph_theory',\n",
       "   'begin',\n",
       "   'euler',\n",
       "   'ask',\n",
       "   'bridge',\n",
       "   'konigsberg',\n",
       "   'could',\n",
       "   'traverse',\n",
       "   'exactly',\n",
       "   'essentially',\n",
       "   'question',\n",
       "   'ask',\n",
       "   'museum',\n",
       "   'fine',\n",
       "   'art'],\n",
       "  ['honor',\n",
       "   'euler',\n",
       "   'walk',\n",
       "   'define',\n",
       "   'walk',\n",
       "   'traverse',\n",
       "   'edge',\n",
       "   'graph',\n",
       "   'exactly'],\n",
       "  ['similarly', 'eul', 'tour', 'euler', 'walk', 'start', 'finish', 'vertex'],\n",
       "  ['graphs', 'eul', 'tour', 'euler', 'walk', 'simple'],\n",
       "  ['theorem'],\n",
       "  ['connected', 'graph', 'euler_tour', 'vertex', 'even', 'degree'],\n",
       "  ['proof'],\n",
       "  ['first', 'show', 'graph', 'euler_tour', 'vertex', 'even', 'degree'],\n",
       "  ['assume', 'graph'],\n",
       "  ['euler_tour', 'ic', 'edges', 'incident'],\n",
       "  ['chapter_graph', 'theory', 'fv', 'edges', 'incident'],\n",
       "  ['hence', 'degree_node', 'even'],\n",
       "  ['next', 'show', 'degree_node', 'even', 'graph'],\n",
       "  ['euler_tour'],\n",
       "  ['let',\n",
       "   'wwd',\n",
       "   'long',\n",
       "   'walk',\n",
       "   'traverse',\n",
       "   'edge',\n",
       "   'conclude',\n",
       "   'argument',\n",
       "   'proof_contradiction'],\n",
       "  ['suppose', 'euler_tour'],\n",
       "  ['connected', 'graph', 'find', 'edge_incident', 'vertex'],\n",
       "  ['call',\n",
       "   'edge',\n",
       "   'fu',\n",
       "   'ic',\n",
       "   'contradict',\n",
       "   'definition',\n",
       "   'must',\n",
       "   'euler_tour'],\n",
       "  ['difficult',\n",
       "   'extend',\n",
       "   'theorem_prove',\n",
       "   'connect_graph',\n",
       "   'euler',\n",
       "   'walk',\n",
       "   'precisely',\n",
       "   'node',\n",
       "   'odd',\n",
       "   'degree'],\n",
       "  ['hence',\n",
       "   'conclude',\n",
       "   'graph_show',\n",
       "   'figure',\n",
       "   'euler',\n",
       "   'walk',\n",
       "   'eul',\n",
       "   'tour',\n",
       "   'graph',\n",
       "   'precisely',\n",
       "   'node',\n",
       "   'odd',\n",
       "   'degree'],\n",
       "  ['proof_theorem',\n",
       "   'explicitly',\n",
       "   'define',\n",
       "   'method',\n",
       "   'find',\n",
       "   'euler_tour',\n",
       "   'one',\n",
       "   'exist',\n",
       "   'hard',\n",
       "   'modify',\n",
       "   'proof',\n",
       "   'produce',\n",
       "   'method'],\n",
       "  ['idea',\n",
       "   'grow',\n",
       "   'tour',\n",
       "   'continually',\n",
       "   'splice',\n",
       "   'closed',\n",
       "   'walks',\n",
       "   'edge',\n",
       "   'consume']],\n",
       " [['hamiltonian_cycle', 'hamiltonian_cycle', 'unruly', 'cousin', 'euler_tour'],\n",
       "  ['definition'],\n",
       "  ['hamiltonian_cycle', 'graph', 'cycle', 'visit_node', 'exactly'],\n",
       "  ['similarly', 'hamiltonian_path', 'path', 'visit_node', 'exactly'],\n",
       "  ['notice',\n",
       "   'use',\n",
       "   'variation',\n",
       "   'well_order',\n",
       "   'principle',\n",
       "   'be',\n",
       "   'plicitly',\n",
       "   'assume',\n",
       "   'long',\n",
       "   'walk',\n",
       "   'exist',\n",
       "   'ok',\n",
       "   'length',\n",
       "   'walk',\n",
       "   'edge',\n",
       "   'use',\n",
       "   'jej'],\n",
       "  ['figure'],\n",
       "  ['weighted', 'graph'],\n",
       "  ['find',\n",
       "   'cycle',\n",
       "   'weight',\n",
       "   'visit_node',\n",
       "   'exactly',\n",
       "   'hamiltonian_cycle',\n",
       "   'sound',\n",
       "   'similar',\n",
       "   'eul',\n",
       "   'tour',\n",
       "   'one',\n",
       "   'visit_node',\n",
       "   'visit',\n",
       "   'edge',\n",
       "   'find',\n",
       "   'hamiltonian_cycle',\n",
       "   'lot',\n",
       "   'hard',\n",
       "   'find',\n",
       "   'euler_tour'],\n",
       "  ['true', 'hamiltonian_path'],\n",
       "  ['discover', 'simple', 'graphs', 'hamiltonian_cycle'],\n",
       "  ['fact',\n",
       "   'determine',\n",
       "   'graph',\n",
       "   'hamiltonian_cycle',\n",
       "   'category',\n",
       "   'problem',\n",
       "   'sit',\n",
       "   'problem_section',\n",
       "   'color',\n",
       "   'problem_section']],\n",
       " [['traveling',\n",
       "   'salesperson',\n",
       "   'problem',\n",
       "   'problem',\n",
       "   'find',\n",
       "   'hamiltonian_cycle',\n",
       "   'hard',\n",
       "   'enough',\n",
       "   'graph',\n",
       "   'weight',\n",
       "   'often',\n",
       "   'want',\n",
       "   'find',\n",
       "   'hamiltonian_cycle',\n",
       "   'least',\n",
       "   'pos',\n",
       "   'sible',\n",
       "   'weight'],\n",
       "  ['famous',\n",
       "   'optimization',\n",
       "   'problem',\n",
       "   'know',\n",
       "   'travel',\n",
       "   'salesperson',\n",
       "   'problem'],\n",
       "  ['definition'],\n",
       "  ['give',\n",
       "   'weight_graph',\n",
       "   'weight',\n",
       "   'cycle',\n",
       "   'define',\n",
       "   'sum',\n",
       "   'weight_edge',\n",
       "   'cycle'],\n",
       "  ['example_consider',\n",
       "   'graph_show',\n",
       "   'figure',\n",
       "   'suppose',\n",
       "   'would',\n",
       "   'visit_node',\n",
       "   'finish',\n",
       "   'node',\n",
       "   'start'],\n",
       "  ['find',\n",
       "   'way',\n",
       "   'traverse',\n",
       "   'cycle',\n",
       "   'weight',\n",
       "   'needless',\n",
       "   'say',\n",
       "   'figure',\n",
       "   'fast',\n",
       "   'procedure',\n",
       "   'find',\n",
       "   'optimal',\n",
       "   'cycle',\n",
       "   'travel',\n",
       "   'salesperson',\n",
       "   'let',\n",
       "   'know',\n",
       "   'win',\n",
       "   'dollar'],\n",
       "  ['chapter_graph', 'theory_figure'],\n",
       "  ['node', 'tree'],\n",
       "  ['figure'],\n",
       "  ['node', 'forest', 'consist', 'component', 'tree'],\n",
       "  ['note', 'node_graph', 'tree', 'connect']],\n",
       " [['tree',\n",
       "   'see',\n",
       "   'find',\n",
       "   'good',\n",
       "   'cycle',\n",
       "   'graph',\n",
       "   'trickier',\n",
       "   'may',\n",
       "   'first',\n",
       "   'think'],\n",
       "  ['graph', 'cycle', 'sound', 'pretty', 'dull'],\n",
       "  ['graph',\n",
       "   'cycle',\n",
       "   'call',\n",
       "   'acyclic',\n",
       "   'graphs',\n",
       "   'probably',\n",
       "   'important',\n",
       "   'graph',\n",
       "   'come',\n",
       "   'computer_science']],\n",
       " [['definition', 'definition'],\n",
       "  ['connected', 'acyclic_graph', 'call', 'tree'],\n",
       "  ['example', 'figure_show', 'example', 'node', 'tree'],\n",
       "  ['graph_show', 'figure', 'tree', 'connect', 'forest'],\n",
       "  ['course', 'consist', 'collection', 'tree'],\n",
       "  ['definition'],\n",
       "  ['connected_component', 'graph', 'tree', 'forest'],\n",
       "  ['first', 'thing', 'notice', 'tree', 'tend', 'lot', 'node', 'degree'],\n",
       "  ['node', 'call', 'leave'],\n",
       "  ['definition'],\n",
       "  ['leaf', 'node', 'degree', 'tree', 'forest'],\n",
       "  ['example', 'tree', 'figure', 'leave', 'forest', 'figure', 'figure'],\n",
       "  ['tree', 'figure', 'redrawn', 'level', 'fashion', 'node', 'root'],\n",
       "  ['tree', 'fundamental', 'datum', 'structure', 'computer_science'],\n",
       "  ['example',\n",
       "   'formation',\n",
       "   'often',\n",
       "   'store',\n",
       "   'tree',\n",
       "   'data',\n",
       "   'structure',\n",
       "   'execution',\n",
       "   'many',\n",
       "   'recursive',\n",
       "   'program',\n",
       "   'model',\n",
       "   'traversal',\n",
       "   'tree'],\n",
       "  ['case',\n",
       "   'often',\n",
       "   'useful',\n",
       "   'draw',\n",
       "   'tree',\n",
       "   'level',\n",
       "   'fashion',\n",
       "   'node',\n",
       "   'top',\n",
       "   'level',\n",
       "   'identify',\n",
       "   'root',\n",
       "   'edge',\n",
       "   'join',\n",
       "   'parent',\n",
       "   'child'],\n",
       "  ['example',\n",
       "   'redrawn',\n",
       "   'tree',\n",
       "   'figure',\n",
       "   'fashion',\n",
       "   'figure',\n",
       "   'special_case',\n",
       "   'order',\n",
       "   'binary_tree',\n",
       "   'node',\n",
       "   'parent',\n",
       "   'child',\n",
       "   'child',\n",
       "   'label',\n",
       "   'left',\n",
       "   'child',\n",
       "   'right',\n",
       "   'child']],\n",
       " [['property', 'tree', 'many', 'unique', 'property'],\n",
       "  ['list', 'follow', 'theorem'],\n",
       "  ['theorem'],\n",
       "  ['tree', 'follow', 'property', 'connect', 'subgraph', 'tree'],\n",
       "  ['unique', 'simple', 'path_pair', 'vertex'],\n",
       "  ['add_edge', 'nonadjacent', 'node', 'tree', 'create', 'graph', 'cycle'],\n",
       "  ['remove', 'edge', 'graph'],\n",
       "  ['tree', 'least', 'vertex', 'least', 'leave'],\n",
       "  ['number', 'vertex', 'tree', 'large_number', 'edge'],\n",
       "  ['chapter_graph', 'theory_figure'],\n",
       "  ['path', 'graph', 'must', 'contain', 'cycle'],\n",
       "  ['proof'],\n",
       "  ['cycle',\n",
       "   'subgraph',\n",
       "   'also',\n",
       "   'cycle',\n",
       "   'whole',\n",
       "   'graph',\n",
       "   'sub',\n",
       "   'graph',\n",
       "   'acyclic_graph',\n",
       "   'must_also',\n",
       "   'acyclic'],\n",
       "  ['subgraph', 'also', 'con', 'necte', 'definition', 'tree'],\n",
       "  ['tree', 'connect', 'least', 'path_pair', 'ver', 'tice'],\n",
       "  ['suppose', 'purpose', 'contradiction', 'different', 'path_pair', 'vertex'],\n",
       "  ['begin',\n",
       "   'let',\n",
       "   'first',\n",
       "   'vertex',\n",
       "   'path',\n",
       "   'diverge',\n",
       "   'let',\n",
       "   'next',\n",
       "   'vertex',\n",
       "   'share'],\n",
       "  ['example',\n",
       "   'see_figure',\n",
       "   'additional',\n",
       "   'edge',\n",
       "   'fu',\n",
       "   'vg',\n",
       "   'together',\n",
       "   'unique',\n",
       "   'path',\n",
       "   'form',\n",
       "   'cycle'],\n",
       "  ['suppose', 'remove', 'edge', 'fu'],\n",
       "  ['tree', 'contain', 'unique', 'path', 'path', 'must', 'fu', 'vg'],\n",
       "  ['therefore', 'edge', 'remove', 'path', 'remain', 'graph', 'connect'],\n",
       "  ['let', 'path', 'otherwise', 'could', 'make', 'path', 'longer'],\n",
       "  ['therefore', 'edge_incident', 'mean'],\n",
       "  ['use_induction', 'proposition'],\n",
       "  ['wwd', 'edge', 'vertex', 'tree'],\n",
       "  ['base_case'],\n",
       "  ['true', 'tree', 'node', 'edge'],\n",
       "  ['figure'],\n",
       "  ['graph', 'edge', 'span_tree', 'thicken'],\n",
       "  ['inductive_step', 'suppose'],\n",
       "  ['true', 'consider'],\n",
       "  ['vertex', 'tree'],\n",
       "  ['let', 'leaf', 'tree'],\n",
       "  ['verify',\n",
       "   'delete',\n",
       "   'vertex_degree',\n",
       "   'incident_edge',\n",
       "   'connect_graph',\n",
       "   'leave',\n",
       "   'connect',\n",
       "   'subgraph'],\n",
       "  ['part', 'theorem'],\n",
       "  ['edge'],\n",
       "  ['hence'],\n",
       "  ['true', 'induction_proof', 'complete'],\n",
       "  ['various',\n",
       "   'subset',\n",
       "   'property',\n",
       "   'theorem',\n",
       "   'provide',\n",
       "   'alternative',\n",
       "   'characteriza',\n",
       "   'tion',\n",
       "   'tree',\n",
       "   'prove'],\n",
       "  ['example',\n",
       "   'connect_graph',\n",
       "   'number',\n",
       "   'vertice',\n",
       "   'large_number',\n",
       "   'edge',\n",
       "   'necessarily',\n",
       "   'tree'],\n",
       "  ['also', 'graph', 'unique', 'path_pair', 'vertex', 'necessarily', 'tree']],\n",
       " [['span_tree', 'tree', 'everywhere'],\n",
       "  ['fact', 'connect_graph', 'contain', 'subgraph', 'tree', 'vertice', 'graph'],\n",
       "  ['call', 'span_tree', 'graph'],\n",
       "  ['example', 'figure', 'connect_graph', 'span_tree', 'highlight'],\n",
       "  ['theorem'],\n",
       "  ['connect_graph', 'contain', 'span_tree'],\n",
       "  ['proof'],\n",
       "  ['contradiction'],\n",
       "  ['assume',\n",
       "   'connect_graph',\n",
       "   'spanning',\n",
       "   'tree',\n",
       "   'let',\n",
       "   'connected',\n",
       "   'subgraph',\n",
       "   'vertex',\n",
       "   'small',\n",
       "   'number_edge',\n",
       "   'possible',\n",
       "   'subgraph'],\n",
       "  ['assumption',\n",
       "   'span_tree',\n",
       "   'contain',\n",
       "   'cycle',\n",
       "   'fv_fv',\n",
       "   'suppose',\n",
       "   'remove',\n",
       "   'last',\n",
       "   'edge'],\n",
       "  ['pair_vertex', 'join', 'path', 'contain', 'fv', 'remain', 'joined', 'path'],\n",
       "  ['hand', 'join', 'path', 'contain', 'fv', 'chapter_graph', 'theory_figure'],\n",
       "  ['span_tree', 'weight_graph'],\n",
       "  ['remain', 'joined', 'walk', 'contain', 'remainder', 'cycle'],\n",
       "  ['lemma', 'must', 'true']],\n",
       " [['minimum_weight',\n",
       "   'span_tree',\n",
       "   'span_tree',\n",
       "   'interesting',\n",
       "   'connect',\n",
       "   'node_graph',\n",
       "   'use',\n",
       "   'small',\n",
       "   'possible',\n",
       "   'number_edge'],\n",
       "  ['example', 'span_tree', 'node_graph', 'show_figure', 'edge'],\n",
       "  ['span_tree',\n",
       "   'useful',\n",
       "   'practice',\n",
       "   'real',\n",
       "   'world',\n",
       "   'span',\n",
       "   'ning',\n",
       "   'tree',\n",
       "   'equally',\n",
       "   'desirable'],\n",
       "  ['practice', 'often', 'cost', 'associated', 'edges', 'graph'],\n",
       "  ['example_suppose',\n",
       "   'node_graph',\n",
       "   'represent',\n",
       "   'building',\n",
       "   'town',\n",
       "   'edge',\n",
       "   'represent',\n",
       "   'connection',\n",
       "   'building',\n",
       "   'town'],\n",
       "  ['cost',\n",
       "   'actually',\n",
       "   'make',\n",
       "   'connection',\n",
       "   'may',\n",
       "   'vary',\n",
       "   'lot',\n",
       "   'pair',\n",
       "   'building',\n",
       "   'town'],\n",
       "  ['cost', 'may', 'depend', 'distance', 'topography'],\n",
       "  ['example',\n",
       "   'cost',\n",
       "   'connect',\n",
       "   'ny',\n",
       "   'may',\n",
       "   'much',\n",
       "   'high',\n",
       "   'connect',\n",
       "   'ny',\n",
       "   'boston'],\n",
       "  ['cost', 'pipe', 'manhattan', 'may', 'cost', 'pipe', 'cornfield'],\n",
       "  ['case',\n",
       "   'typically',\n",
       "   'represent',\n",
       "   'cost',\n",
       "   'connect_pair',\n",
       "   'node',\n",
       "   'weight_edge',\n",
       "   'weight_edge',\n",
       "   'cost'],\n",
       "  ['weight', 'span_tree', 'sum', 'weight_edge', 'tree'],\n",
       "  ['example', 'weight', 'span_tree', 'show_figure'],\n",
       "  ['goal',\n",
       "   'course',\n",
       "   'find',\n",
       "   'span_tree',\n",
       "   'minimum_weight',\n",
       "   'call',\n",
       "   'min',\n",
       "   'weight',\n",
       "   'span_tree',\n",
       "   'mst',\n",
       "   'short'],\n",
       "  ['figure'],\n",
       "  ['mst', 'weight_graph', 'figure', 'definition'],\n",
       "  ['min',\n",
       "   'weight',\n",
       "   'span_tree',\n",
       "   'mst',\n",
       "   'edge_weight',\n",
       "   'graph',\n",
       "   'span_tree',\n",
       "   'small',\n",
       "   'possible',\n",
       "   'sum',\n",
       "   'edge_weight'],\n",
       "  ['span_tree',\n",
       "   'show_figure',\n",
       "   'also',\n",
       "   'span_tree',\n",
       "   'graph_show',\n",
       "   'figure',\n",
       "   'tree',\n",
       "   'show_figure',\n",
       "   'possible',\n",
       "   'algorithm',\n",
       "   'algorithm'],\n",
       "  ['grow',\n",
       "   'tree',\n",
       "   'edge',\n",
       "   'time',\n",
       "   'add',\n",
       "   'minimum_weight',\n",
       "   'edge',\n",
       "   'possible',\n",
       "   'tree',\n",
       "   'make',\n",
       "   'sure',\n",
       "   'tree',\n",
       "   'step'],\n",
       "  ['algorithm'],\n",
       "  ['grow',\n",
       "   'subgraph',\n",
       "   'edge',\n",
       "   'time',\n",
       "   'add',\n",
       "   'minimum_weight',\n",
       "   'edge',\n",
       "   'possible',\n",
       "   'subgraph',\n",
       "   'make',\n",
       "   'sure',\n",
       "   'acyclic',\n",
       "   'subgraph',\n",
       "   'step'],\n",
       "  ['example',\n",
       "   'weight_graph',\n",
       "   'considering',\n",
       "   'may',\n",
       "   'run',\n",
       "   'algorithm',\n",
       "   'follow'],\n",
       "  ['would', 'start', 'choose_weight', 'edge', 'small', 'weight_graph'],\n",
       "  ['suppose',\n",
       "   'choose_weight',\n",
       "   'edge',\n",
       "   'bottom',\n",
       "   'triangle',\n",
       "   'weight_edge',\n",
       "   'graph'],\n",
       "  ['edge_incident',\n",
       "   'weight_edge',\n",
       "   'weight_edge',\n",
       "   'weight_edge',\n",
       "   'weight_edge'],\n",
       "  ['would', 'choose', 'incident_edge', 'minimum_weight'],\n",
       "  ['case', 'weight_edge'],\n",
       "  ['point',\n",
       "   'can',\n",
       "   'choose',\n",
       "   'third',\n",
       "   'weight_edge',\n",
       "   'since',\n",
       "   'would',\n",
       "   'form',\n",
       "   'cycle',\n",
       "   'continue',\n",
       "   'choose_weight',\n",
       "   'edge'],\n",
       "  ['may', 'end', 'span_tree', 'show_figure', 'chapter_graph', 'theory_figure'],\n",
       "  ['span_tree',\n",
       "   'find',\n",
       "   'algorithm',\n",
       "   'suppose',\n",
       "   'instead',\n",
       "   'run',\n",
       "   'algorithm',\n",
       "   'graph'],\n",
       "  ['may',\n",
       "   'choose_weight',\n",
       "   'edge',\n",
       "   'bottom',\n",
       "   'triangle',\n",
       "   'weight_edge',\n",
       "   'graph'],\n",
       "  ['instead',\n",
       "   'choose_weight',\n",
       "   'edge',\n",
       "   'touch',\n",
       "   'may',\n",
       "   'choose_weight',\n",
       "   'edge',\n",
       "   'top',\n",
       "   'graph'],\n",
       "  ['note',\n",
       "   'edge',\n",
       "   'still',\n",
       "   'minimum_weight',\n",
       "   'form',\n",
       "   'cycle',\n",
       "   'algorithm',\n",
       "   'choose'],\n",
       "  ['would', 'choose', 'remain', 'weight_edge'],\n",
       "  ['note', 'cause', 'form', 'cycle'],\n",
       "  ['continue',\n",
       "   'algorithm',\n",
       "   'may',\n",
       "   'end',\n",
       "   'span_tree',\n",
       "   'figure',\n",
       "   'turn',\n",
       "   'algorithm',\n",
       "   'work',\n",
       "   'may',\n",
       "   'end',\n",
       "   'different',\n",
       "   'mst'],\n",
       "  ['mst',\n",
       "   'necessarily',\n",
       "   'unique',\n",
       "   'indeed',\n",
       "   'edge',\n",
       "   'node_graph',\n",
       "   'weight',\n",
       "   'span_tree',\n",
       "   'weight'],\n",
       "  ['examples', 'greedy', 'approach', 'optimization'],\n",
       "  ['sometimes', 'work', 'sometimes'],\n",
       "  ['good_news', 'work', 'find', 'mst'],\n",
       "  ['fact', 'variation', 'work'],\n",
       "  ['little', 'easy', 'prove', 'algorithm', 'theorem'],\n",
       "  ['connect', 'weight_graph', 'algorithm', 'produce', 'mst'],\n",
       "  ['proof'],\n",
       "  ['proof', 'bit', 'tricky'],\n",
       "  ['need',\n",
       "   'show',\n",
       "   'algorithm',\n",
       "   'terminate',\n",
       "   'select',\n",
       "   'few',\n",
       "   'edge',\n",
       "   'always',\n",
       "   'find',\n",
       "   'edge',\n",
       "   'add',\n",
       "   'create',\n",
       "   'cycle'],\n",
       "  ['also', 'need', 'show', 'algorithm', 'create', 'tree', 'minimum_weight'],\n",
       "  ['key',\n",
       "   'show',\n",
       "   'algorithm',\n",
       "   'never',\n",
       "   'get',\n",
       "   'stuck',\n",
       "   'go',\n",
       "   'bad',\n",
       "   'direction',\n",
       "   'add_edge',\n",
       "   'keep',\n",
       "   'ultimately',\n",
       "   'produce',\n",
       "   'mst'],\n",
       "  ['natural_way',\n",
       "   'prove',\n",
       "   'show',\n",
       "   'set',\n",
       "   'edge',\n",
       "   'select',\n",
       "   'point',\n",
       "   'contain',\n",
       "   'mst',\n",
       "   'always',\n",
       "   'need'],\n",
       "  ['state', 'lemma'],\n",
       "  ['lemma'],\n",
       "  ['let',\n",
       "   'consist',\n",
       "   'first',\n",
       "   'edge',\n",
       "   'select',\n",
       "   'algo',\n",
       "   'rithm',\n",
       "   'prove',\n",
       "   'momentarily',\n",
       "   'first',\n",
       "   'let_see',\n",
       "   'help',\n",
       "   'prove_theorem'],\n",
       "  ['assume', 'lemma', 'true'],\n",
       "  ['know',\n",
       "   'algorithm',\n",
       "   'always',\n",
       "   'find',\n",
       "   'edge',\n",
       "   'add',\n",
       "   'create',\n",
       "   'cycle',\n",
       "   'long',\n",
       "   'few',\n",
       "   'edge',\n",
       "   'pick',\n",
       "   'exist',\n",
       "   'edge',\n",
       "   'edge',\n",
       "   'add',\n",
       "   'form',\n",
       "   'cycle'],\n",
       "  ['next', 'know', 'get', 'mst', 'end', 'know', 'mst'],\n",
       "  ['theorem', 'easy', 'corollary', 'lemma'],\n",
       "  ['prove',\n",
       "   'lemma',\n",
       "   'use_induction',\n",
       "   'number_edge',\n",
       "   'choose',\n",
       "   'algorithm',\n",
       "   'far'],\n",
       "  ['typical',\n",
       "   'prove',\n",
       "   'algorithm',\n",
       "   'preserve',\n",
       "   'kind',\n",
       "   'invariant',\n",
       "   'condition',\n",
       "   'induct',\n",
       "   'number',\n",
       "   'step',\n",
       "   'take',\n",
       "   'number_edge',\n",
       "   'add'],\n",
       "  ['inductive', 'hypothesis'],\n",
       "  ['follow',\n",
       "   'set',\n",
       "   'edge',\n",
       "   'initially',\n",
       "   'select',\n",
       "   'algorithm',\n",
       "   'base_case',\n",
       "   'need',\n",
       "   'show'],\n",
       "  ['case', 'trivially', 'hold', 'mst'],\n",
       "  ['inductive_step_assume'],\n",
       "  ['holds', 'show', 'imply'],\n",
       "  ['let', 'denote'],\n",
       "  ['mc', 'st', 'edge', 'select', 'algorithm', 'case', 'case', 'feg', 'thus'],\n",
       "  ['holds'],\n",
       "  ['case', 'illustrate_figure', 'happen', 'add', 'tree', 'get', 'cycle'],\n",
       "  ['use',\n",
       "   'part',\n",
       "   'theorem',\n",
       "   'note',\n",
       "   'weight',\n",
       "   'pick',\n",
       "   'minimum_weight',\n",
       "   'edge',\n",
       "   'make',\n",
       "   'cycle'],\n",
       "  ['would', 'select', 'ahead', 'almost', 'do'],\n",
       "  ['make', 'mst', 'contain', 'feg'],\n",
       "  ['let'],\n",
       "  ['fe', 'feg', 'swap', 'claim'],\n",
       "  ['mst'],\n",
       "  ['chapter_graph', 'theory_figure'],\n",
       "  ['graph', 'form', 'add'],\n",
       "  ['edge', 'denote', 'solid', 'line', 'edge', 'denote', 'dash', 'line'],\n",
       "  ['proof', 'claim'],\n",
       "  ['first', 'show', 'span_tree'],\n",
       "  ['acyclic', 'produce', 'remove', 'edge', 'cycle', 'feg'],\n",
       "  ['connect', 'edge', 'delete', 'feg', 'cycle'],\n",
       "  ['contain', 'node', 'must', 'span_tree'],\n",
       "  ['let_look', 'weight'],\n",
       "  ['weight', 'feg', 'must', 'eventually', 'produce', 'mst'],\n",
       "  ['happens', 'add', 'edges', 'subgraph', 'build'],\n",
       "  ['know',\n",
       "   'sure',\n",
       "   'mst',\n",
       "   'example',\n",
       "   'graph',\n",
       "   'weight',\n",
       "   'produce',\n",
       "   'algorithm']],\n",
       " [['planar', 'graphs']],\n",
       " [['draw',\n",
       "   'graphs',\n",
       "   'plane',\n",
       "   'suppose',\n",
       "   'dog',\n",
       "   'house',\n",
       "   'human',\n",
       "   'house',\n",
       "   'show',\n",
       "   'fig_ure',\n",
       "   'quadrapus',\n",
       "   'little',\n",
       "   'know',\n",
       "   'animal',\n",
       "   'similar',\n",
       "   'octopus',\n",
       "   'arm'],\n",
       "  ['suppose', 'quadrapi', 'rest', 'sea', 'floor', 'show_figure', 'figure'],\n",
       "  ['dog', 'house', 'human', 'house'],\n",
       "  ['route',\n",
       "   'dog',\n",
       "   'house',\n",
       "   'human',\n",
       "   'house',\n",
       "   'pair',\n",
       "   'route',\n",
       "   'cross',\n",
       "   'chapter_graph',\n",
       "   'theory_figure'],\n",
       "  ['quadrapi', 'armed', 'creature'],\n",
       "  ['quadrapus',\n",
       "   'simultaneously',\n",
       "   'shake',\n",
       "   'hand',\n",
       "   'way',\n",
       "   'arm',\n",
       "   'cross',\n",
       "   'definition'],\n",
       "  ['draw',\n",
       "   'graph',\n",
       "   'plane',\n",
       "   'consist',\n",
       "   'assignment',\n",
       "   'vertex',\n",
       "   'distinct',\n",
       "   'point',\n",
       "   'plane',\n",
       "   'assignment',\n",
       "   'edge',\n",
       "   'smooth',\n",
       "   'non',\n",
       "   'self',\n",
       "   'intersect',\n",
       "   'curve',\n",
       "   'plane',\n",
       "   'endpoint',\n",
       "   'nodes',\n",
       "   'incident_edge'],\n",
       "  ['draw',\n",
       "   'planar',\n",
       "   'planar_draw',\n",
       "   'none',\n",
       "   'curve',\n",
       "   'cross',\n",
       "   'point',\n",
       "   'appear',\n",
       "   'curve',\n",
       "   'vertex',\n",
       "   'point'],\n",
       "  ['planar_graph', 'graph', 'planar_draw'],\n",
       "  ['thus',\n",
       "   'puzzle',\n",
       "   'ask',\n",
       "   'graphs',\n",
       "   'figure',\n",
       "   'planar',\n",
       "   'redrawn',\n",
       "   'edge',\n",
       "   'cross'],\n",
       "  ['first',\n",
       "   'graph',\n",
       "   'call',\n",
       "   'complete',\n",
       "   'bipartite_graph',\n",
       "   'case',\n",
       "   'answer',\n",
       "   'almost',\n",
       "   'fact',\n",
       "   'remove',\n",
       "   'edge',\n",
       "   'result',\n",
       "   'graphs',\n",
       "   'redrawn',\n",
       "   'plane',\n",
       "   'edge',\n",
       "   'cross'],\n",
       "  ['example',\n",
       "   'illustrate',\n",
       "   'planar',\n",
       "   'drawing',\n",
       "   'result',\n",
       "   'graph_figure',\n",
       "   'figure'],\n",
       "  ['figure'],\n",
       "  ['planar',\n",
       "   'drawings',\n",
       "   'chapter_graph',\n",
       "   'theory',\n",
       "   'planar',\n",
       "   'drawing',\n",
       "   'applications',\n",
       "   'circuit',\n",
       "   'layout',\n",
       "   'helpful',\n",
       "   'display',\n",
       "   'graphical',\n",
       "   'datum',\n",
       "   'program',\n",
       "   'flow',\n",
       "   'chart',\n",
       "   'organizational',\n",
       "   'chart',\n",
       "   'scheduling',\n",
       "   'conflict'],\n",
       "  ['application',\n",
       "   'goal',\n",
       "   'draw',\n",
       "   'graph',\n",
       "   'plane',\n",
       "   'edge',\n",
       "   'crossing',\n",
       "   'possible'],\n",
       "  ['see', 'box', 'follow', 'page', 'example']],\n",
       " [['recursive_definition',\n",
       "   'planar_graph',\n",
       "   'definition',\n",
       "   'perfectly',\n",
       "   'precise',\n",
       "   'challenge',\n",
       "   'require',\n",
       "   'work',\n",
       "   'concept',\n",
       "   'smooth',\n",
       "   'curve',\n",
       "   'try_prove',\n",
       "   'result',\n",
       "   'planar_graph'],\n",
       "  ['trouble',\n",
       "   'really',\n",
       "   'lay',\n",
       "   'groundwork',\n",
       "   'geometry',\n",
       "   'topology',\n",
       "   'able',\n",
       "   'reason',\n",
       "   'carefully',\n",
       "   'concept'],\n",
       "  ['example',\n",
       "   'really',\n",
       "   'define',\n",
       "   'mean',\n",
       "   'curve',\n",
       "   'smooth',\n",
       "   'draw',\n",
       "   'simple',\n",
       "   'picture',\n",
       "   'example',\n",
       "   'figure',\n",
       "   'rely',\n",
       "   'picture',\n",
       "   'convey',\n",
       "   'new',\n",
       "   'concept',\n",
       "   'generally',\n",
       "   'good_idea',\n",
       "   'sometimes',\n",
       "   'lead',\n",
       "   'disaster',\n",
       "   'least',\n",
       "   'false',\n",
       "   'proof'],\n",
       "  ['indeed',\n",
       "   'issue',\n",
       "   'many',\n",
       "   'false',\n",
       "   'proof',\n",
       "   'relate',\n",
       "   'planar',\n",
       "   'graphs',\n",
       "   'time'],\n",
       "  ['proofs',\n",
       "   'usually',\n",
       "   'rely',\n",
       "   'way',\n",
       "   'heavily',\n",
       "   'picture',\n",
       "   'way',\n",
       "   'many',\n",
       "   'statement',\n",
       "   'figure',\n",
       "   'abc',\n",
       "   'must',\n",
       "   'property',\n",
       "   'xyz',\n",
       "   'hold',\n",
       "   'planar',\n",
       "   'graphs'],\n",
       "  ['good_news',\n",
       "   'way',\n",
       "   'define',\n",
       "   'planar_graph',\n",
       "   'use',\n",
       "   'discrete',\n",
       "   'mathematic'],\n",
       "  ['particular', 'define', 'class', 'planar_graph', 'recursive', 'datum_type'],\n",
       "  ['order',\n",
       "   'understand',\n",
       "   'work',\n",
       "   'first',\n",
       "   'need',\n",
       "   'understand',\n",
       "   'concept',\n",
       "   'face',\n",
       "   'planar_draw'],\n",
       "  ['face', 'planar_draw', 'graph'],\n",
       "  ['curve', 'correspond', 'edge', 'divide', 'plane', 'connect', 'region'],\n",
       "  ['region', 'call', 'continuous_face', 'continuous_face'],\n",
       "  ['face', 'iv', 'extend', 'infinity', 'direction', 'call', 'face'],\n",
       "  ['notice',\n",
       "   'vertex',\n",
       "   'boundary',\n",
       "   'face',\n",
       "   'figure',\n",
       "   'abca',\n",
       "   'abda',\n",
       "   'bcdb',\n",
       "   'acda',\n",
       "   'false',\n",
       "   'proof',\n",
       "   'color',\n",
       "   'theorem',\n",
       "   'planar_graph',\n",
       "   'example'],\n",
       "  ['text', 'drop', 'word', 'continuous', 'definition', 'face'],\n",
       "  ['need',\n",
       "   'differentiate',\n",
       "   'connected',\n",
       "   'region',\n",
       "   'plane',\n",
       "   'close_walk',\n",
       "   'graph',\n",
       "   'bound',\n",
       "   'region',\n",
       "   'call',\n",
       "   'discrete_face'],\n",
       "  ['wire',\n",
       "   'arrange',\n",
       "   'surface',\n",
       "   'circuit',\n",
       "   'board',\n",
       "   'microchip',\n",
       "   'crossing',\n",
       "   'require',\n",
       "   'troublesome',\n",
       "   'dimensional',\n",
       "   'structure'],\n",
       "  ['steve',\n",
       "   'wozniak',\n",
       "   'design',\n",
       "   'disk',\n",
       "   'drive',\n",
       "   'early',\n",
       "   'apple',\n",
       "   'ii',\n",
       "   'computer',\n",
       "   'struggle',\n",
       "   'mightily',\n",
       "   'achieve',\n",
       "   'nearly',\n",
       "   'planar',\n",
       "   'design',\n",
       "   'week',\n",
       "   'work',\n",
       "   'late',\n",
       "   'night',\n",
       "   'make',\n",
       "   'satisfactory',\n",
       "   'sign'],\n",
       "  ['finished',\n",
       "   'find',\n",
       "   'moved',\n",
       "   'connector',\n",
       "   'could',\n",
       "   'cut',\n",
       "   'feedthrough',\n",
       "   'make',\n",
       "   'board',\n",
       "   'reliable'],\n",
       "  ['make', 'move', 'however', 'start', 'design'],\n",
       "  ['time', 'take', 'hour'],\n",
       "  ['see', 'feedthrough', 'could', 'eliminate', 'start', 'design'],\n",
       "  ['final',\n",
       "   'design',\n",
       "   'generally',\n",
       "   'recognize',\n",
       "   'computer',\n",
       "   'engineer',\n",
       "   'bril',\n",
       "   'liant',\n",
       "   'engineering',\n",
       "   'aesthetic',\n",
       "   'beautiful'],\n",
       "  ['woz', 'later', 'say', 'engineer', 'pc', 'board', 'layout', 'person'],\n",
       "  ['artistic', 'layout'],\n",
       "  ['board', 'virtually', 'feedthrough'],\n",
       "  ['iii', 'ii', 'iv', 'figure'],\n",
       "  ['planar_draw', 'face'],\n",
       "  ['chapter_graph', 'theory', 'iii', 'iv', 'figure'],\n",
       "  ['draw', 'label', 'vertex'],\n",
       "  ['figure'],\n",
       "  ['planar_draw', 'bridge', 'namely', 'edge', 'fc', 'eg'],\n",
       "  ['cycle', 'correspond', 'nicely', 'continuous_face', 'figure', 'cycle'],\n",
       "  ['example', 'cycle', 'abca', 'identifies', 'face', 'iii'],\n",
       "  ['hence',\n",
       "   'say',\n",
       "   'cycle',\n",
       "   'equation',\n",
       "   'discrete_face',\n",
       "   'graph_figure',\n",
       "   'unfortunately',\n",
       "   'continuous_face',\n",
       "   'planar',\n",
       "   'drawing',\n",
       "   'always',\n",
       "   'bound',\n",
       "   'cycle',\n",
       "   'graph',\n",
       "   'thing',\n",
       "   'get',\n",
       "   'little',\n",
       "   'complicated'],\n",
       "  ['example',\n",
       "   'con',\n",
       "   'sider',\n",
       "   'planar_draw',\n",
       "   'figure',\n",
       "   'abcefgecda',\n",
       "   'cycle',\n",
       "   'traverse',\n",
       "   'bridge',\n",
       "   'fc',\n",
       "   'eg',\n",
       "   'twice',\n",
       "   'closed_walk'],\n",
       "  ['example_consider', 'planar_draw', 'figure', 'figure'],\n",
       "  ['planar_draw', 'dongle', 'namely', 'subgraph', 'node'],\n",
       "  ['inner',\n",
       "   'face',\n",
       "   'rstvxyxvwvtur',\n",
       "   'cycle',\n",
       "   'traverse',\n",
       "   'edge',\n",
       "   'dongle',\n",
       "   'twice',\n",
       "   'come',\n",
       "   'go',\n",
       "   'closed_walk'],\n",
       "  ['turn', 'bridge', 'dongle', 'complication', 'least', 'necte', 'graphs'],\n",
       "  ['particular',\n",
       "   'continuous_face',\n",
       "   'planar_draw',\n",
       "   'correspond',\n",
       "   'close_walk',\n",
       "   'graph'],\n",
       "  ['refer', 'closed', 'walks', 'discrete_face', 'draw'],\n",
       "  ['recursive_definition',\n",
       "   'planar',\n",
       "   'embedding',\n",
       "   'association',\n",
       "   'continuous_face',\n",
       "   'planar_draw',\n",
       "   'closed_walk',\n",
       "   'allow',\n",
       "   'characterize',\n",
       "   'planar',\n",
       "   'drawing',\n",
       "   'term',\n",
       "   'close_walk',\n",
       "   'bind',\n",
       "   'continuous_face'],\n",
       "  ['particular',\n",
       "   'lead',\n",
       "   'discrete',\n",
       "   'datum_type',\n",
       "   'pla',\n",
       "   'nar',\n",
       "   'embedding',\n",
       "   'use',\n",
       "   'place',\n",
       "   'continuous',\n",
       "   'planar',\n",
       "   'drawing'],\n",
       "  ['namely',\n",
       "   'define',\n",
       "   'planar_embed',\n",
       "   'recursively',\n",
       "   'set',\n",
       "   'boundary',\n",
       "   'tracing',\n",
       "   'closed_walk',\n",
       "   'could',\n",
       "   'draw',\n",
       "   'edge'],\n",
       "  ['definition'],\n",
       "  ['planar_embed',\n",
       "   'connect_graph',\n",
       "   'consist',\n",
       "   'nonempty_set',\n",
       "   'closed',\n",
       "   'walks',\n",
       "   'graph',\n",
       "   'call',\n",
       "   'discrete_face',\n",
       "   'embed'],\n",
       "  ['planar',\n",
       "   'embedding',\n",
       "   'define_recursively',\n",
       "   'follow',\n",
       "   'base_case',\n",
       "   'graph',\n",
       "   'consist',\n",
       "   'single',\n",
       "   'vertex',\n",
       "   'planar_embed',\n",
       "   'discrete_face',\n",
       "   'namely',\n",
       "   'length',\n",
       "   'closed_walk'],\n",
       "  ['chapter_graph', 'theory_figure'],\n",
       "  ['split', 'face', 'case'],\n",
       "  ['constructor_case',\n",
       "   'split',\n",
       "   'face',\n",
       "   'suppose',\n",
       "   'connect_graph',\n",
       "   'planar_embed',\n",
       "   'suppose',\n",
       "   'distinct',\n",
       "   'nonadjacent',\n",
       "   'vertex',\n",
       "   'appear',\n",
       "   'discrete_face',\n",
       "   'planar_embed'],\n",
       "  ['closed_walk',\n",
       "   'form',\n",
       "   'graph',\n",
       "   'obtain',\n",
       "   'add_edge',\n",
       "   'bg',\n",
       "   'edge',\n",
       "   'planar_embed',\n",
       "   'discrete_face',\n",
       "   'face',\n",
       "   'replace',\n",
       "   'discrete_face',\n",
       "   'ba',\n",
       "   'ab',\n",
       "   'illustrated',\n",
       "   'figure',\n",
       "   'constructor_case',\n",
       "   'add',\n",
       "   'bridge',\n",
       "   'suppose',\n",
       "   'connect',\n",
       "   'graphs',\n",
       "   'planar',\n",
       "   'embedding',\n",
       "   'disjoint',\n",
       "   'set',\n",
       "   'vertex'],\n",
       "  ['let',\n",
       "   'vertex',\n",
       "   'discrete_face',\n",
       "   'similarly',\n",
       "   'let',\n",
       "   'vertex',\n",
       "   'discrete_face',\n",
       "   'embed'],\n",
       "  ['form',\n",
       "   'graph',\n",
       "   'obtain',\n",
       "   'connect',\n",
       "   'new',\n",
       "   'edge_bg',\n",
       "   'planar_embed',\n",
       "   'discrete_face',\n",
       "   'union',\n",
       "   'discrete_face',\n",
       "   'special_case',\n",
       "   'rule'],\n",
       "  ['line', 'graph', 'begin_end', 'cycle', 'split', 'actually'],\n",
       "  ['add_edge', 'bg', 'create', 'simple', 'cycle', 'graph_figure'],\n",
       "  ['add', 'bridge', 'case'],\n",
       "  ['face',\n",
       "   'replace',\n",
       "   'new',\n",
       "   'face',\n",
       "   'ab',\n",
       "   'ba',\n",
       "   'illustrated',\n",
       "   'figure',\n",
       "   'faxyza',\n",
       "   'axya',\n",
       "   'ayzag',\n",
       "   'fbtuvwb',\n",
       "   'btvwb',\n",
       "   'tuvtg',\n",
       "   'add',\n",
       "   'bridge',\n",
       "   'bg',\n",
       "   'single',\n",
       "   'connected',\n",
       "   'graph',\n",
       "   'face',\n",
       "   'faxyz',\n",
       "   'ab',\n",
       "   'tuvw',\n",
       "   'ba',\n",
       "   'work',\n",
       "   'general',\n",
       "   'graph',\n",
       "   'planar',\n",
       "   'connect',\n",
       "   'components',\n",
       "   'planar_embed',\n",
       "   'define',\n",
       "   'definition',\n",
       "   'bad_news',\n",
       "   'definition',\n",
       "   'look',\n",
       "   'lot',\n",
       "   'complicate',\n",
       "   'intuitively',\n",
       "   'simple',\n",
       "   'notion',\n",
       "   'draw',\n",
       "   'edge',\n",
       "   'cross'],\n",
       "  ['seem',\n",
       "   'would',\n",
       "   'easier',\n",
       "   'stick',\n",
       "   'simple',\n",
       "   'notion',\n",
       "   'give',\n",
       "   'proofs',\n",
       "   'use',\n",
       "   'picture'],\n",
       "  ['perhaps',\n",
       "   'proof',\n",
       "   'likely',\n",
       "   'complete',\n",
       "   'correct',\n",
       "   'work',\n",
       "   'discrete',\n",
       "   'definition',\n",
       "   'instead',\n",
       "   'continuous',\n",
       "   'definition',\n",
       "   'outer',\n",
       "   'face',\n",
       "   'go',\n",
       "   'planar_draw',\n",
       "   'immediately',\n",
       "   'recognizable',\n",
       "   'outer',\n",
       "   'face',\n",
       "   'one',\n",
       "   'go',\n",
       "   'infinity',\n",
       "   'direction'],\n",
       "  ['outer', 'face', 'planar_embed', 'chapter_graph', 'theory_figure'],\n",
       "  ['illustration', 'embed'],\n",
       "  ['really', 'need', 'distinguish'],\n",
       "  ['fact', 'planar_embed', 'could', 'draw', 'give', 'face', 'outside'],\n",
       "  ['intuitive',\n",
       "   'explanation',\n",
       "   'think',\n",
       "   'draw',\n",
       "   'embedding',\n",
       "   'sphere',\n",
       "   'instead',\n",
       "   'plane'],\n",
       "  ['face',\n",
       "   'make',\n",
       "   'outside',\n",
       "   'face',\n",
       "   'puncture',\n",
       "   'face',\n",
       "   'sphere',\n",
       "   'stretch',\n",
       "   'puncture',\n",
       "   'hole',\n",
       "   'circle',\n",
       "   'rest',\n",
       "   'face',\n",
       "   'flatten',\n",
       "   'circular',\n",
       "   'drawing',\n",
       "   'plane'],\n",
       "  ['picture',\n",
       "   'show',\n",
       "   'different',\n",
       "   'boundary',\n",
       "   'may',\n",
       "   'actually',\n",
       "   'illustra',\n",
       "   'tion',\n",
       "   'planar_embed'],\n",
       "  ['example', 'embedding', 'show_figure', 'really'],\n",
       "  ['justifie', 'add', 'bridge', 'case', 'definition']],\n",
       " [['euler_formula',\n",
       "   'value',\n",
       "   'recursive_definition',\n",
       "   'provide',\n",
       "   'powerful',\n",
       "   'technique',\n",
       "   'prove',\n",
       "   'property',\n",
       "   'planar_graph',\n",
       "   'namely',\n",
       "   'structural_induction'],\n",
       "  ['example',\n",
       "   'use',\n",
       "   'definition',\n",
       "   'structural_induction',\n",
       "   'establish',\n",
       "   'basic',\n",
       "   'property',\n",
       "   'connect',\n",
       "   'planar_graph',\n",
       "   'namely',\n",
       "   'number',\n",
       "   'vertex_edge',\n",
       "   'completely',\n",
       "   'determine',\n",
       "   'number',\n",
       "   'face',\n",
       "   'possible',\n",
       "   'planar',\n",
       "   'embe',\n",
       "   'ding',\n",
       "   'graph'],\n",
       "  ['theorem'],\n",
       "  ['euler_formula'],\n",
       "  ['connected',\n",
       "   'graph',\n",
       "   'planar_embed',\n",
       "   'number',\n",
       "   'vertex',\n",
       "   'number_edge',\n",
       "   'number',\n",
       "   'face'],\n",
       "  ['example', 'figure', 'euler_formula', 'claim'],\n",
       "  ['proof'],\n",
       "  ['proof', 'structural_induction', 'definition', 'planar', 'embedding'],\n",
       "  ['let'],\n",
       "  ['proposition', 'embedding'],\n",
       "  ['base_case', 'vertex', 'planar_embed'],\n",
       "  ['definition'],\n",
       "  ['indeed', 'hold'],\n",
       "  ['constructor_case',\n",
       "   'split',\n",
       "   'face',\n",
       "   'suppose',\n",
       "   'connect_graph',\n",
       "   'planar_embed',\n",
       "   'suppose',\n",
       "   'distinct',\n",
       "   'nonadjacent',\n",
       "   'vertex',\n",
       "   'appear',\n",
       "   'discrete_face',\n",
       "   'planar_embed'],\n",
       "  ['graph',\n",
       "   'obtain',\n",
       "   'add_edge',\n",
       "   'bg',\n",
       "   'edge',\n",
       "   'planar_embed',\n",
       "   'face',\n",
       "   'edge'],\n",
       "  ['quantity',\n",
       "   'ecf',\n",
       "   'remain',\n",
       "   'graph',\n",
       "   'structural_induction',\n",
       "   'quantity',\n",
       "   'embedding',\n",
       "   'also',\n",
       "   'embed',\n",
       "   'add_edge'],\n",
       "  ['holds', 'construct', 'embed'],\n",
       "  ['constructor_case',\n",
       "   'add',\n",
       "   'bridge',\n",
       "   'suppose',\n",
       "   'connect',\n",
       "   'graphs',\n",
       "   'pla',\n",
       "   'nar',\n",
       "   'embedding',\n",
       "   'disjoint',\n",
       "   'set',\n",
       "   'vertex'],\n",
       "  ['connect',\n",
       "   'graphs',\n",
       "   'bridge',\n",
       "   'merge',\n",
       "   'bridge',\n",
       "   'face',\n",
       "   'single',\n",
       "   'face',\n",
       "   'leave',\n",
       "   'face',\n",
       "   'unchanged'],\n",
       "  ['bridge', 'operation', 'yield', 'planar_embed', 'connect_graph'],\n",
       "  ['remain', 'equal', 'construct', 'embedding'],\n",
       "  ['also', 'hold', 'case'],\n",
       "  ['complete',\n",
       "   'proof',\n",
       "   'constructor_case',\n",
       "   'theorem',\n",
       "   'follow',\n",
       "   'structural_induction']],\n",
       " [['bound',\n",
       "   'number_edge',\n",
       "   'planar_graph',\n",
       "   'eul',\n",
       "   'formula',\n",
       "   'follow',\n",
       "   'lemmas',\n",
       "   'follow',\n",
       "   'structural_induction',\n",
       "   'definition',\n",
       "   'lemma'],\n",
       "  ['planar_embed',\n",
       "   'connect_graph',\n",
       "   'edge',\n",
       "   'traverse',\n",
       "   'different',\n",
       "   'face',\n",
       "   'traverse',\n",
       "   'exactly',\n",
       "   'twice',\n",
       "   'face'],\n",
       "  ['lemma'],\n",
       "  ['planar_embed',\n",
       "   'connect_graph',\n",
       "   'least',\n",
       "   'vertex',\n",
       "   'face',\n",
       "   'length',\n",
       "   'least'],\n",
       "  ['combine',\n",
       "   'lemmas',\n",
       "   'euler_formula',\n",
       "   'prove',\n",
       "   'planar_graph',\n",
       "   'limited',\n",
       "   'number_edge',\n",
       "   'chapter_graph',\n",
       "   'theory',\n",
       "   'theorem'],\n",
       "  ['suppose', 'connect', 'planar_graph', 'vertex_edge'],\n",
       "  ['proof'],\n",
       "  ['definition', 'connect_graph', 'planar', 'iff', 'planar_embed'],\n",
       "  ['suppose', 'connect_graph', 'vertex_edge', 'planar_embed', 'face'],\n",
       "  ['lemma', 'euler_formula', 'substituting']],\n",
       " [['return',\n",
       "   'theorem',\n",
       "   'let',\n",
       "   'prove',\n",
       "   'quadrapi',\n",
       "   'shake',\n",
       "   'hand',\n",
       "   'cross',\n",
       "   'ing'],\n",
       "  ['represent',\n",
       "   'quadrapi',\n",
       "   'vertice',\n",
       "   'necessary',\n",
       "   'handshake',\n",
       "   'edge',\n",
       "   'get',\n",
       "   'complete',\n",
       "   'graph',\n",
       "   'require',\n",
       "   'corollary'],\n",
       "  ['also',\n",
       "   'use',\n",
       "   'eul',\n",
       "   'formula',\n",
       "   'show',\n",
       "   'use',\n",
       "   'additional',\n",
       "   'fact',\n",
       "   'theorem'],\n",
       "  ['proof'],\n",
       "  ['contradiction'],\n",
       "  ['assume']],\n",
       " [['planar_graph', 'choose', 'pick', 'theorem'],\n",
       "  ['kuratowski'],\n",
       "  ['graph', 'planar', 'contain', 'definition'],\n",
       "  ['minor',\n",
       "   'graph',\n",
       "   'graph',\n",
       "   'obtain',\n",
       "   'peatedly',\n",
       "   'delete',\n",
       "   'vertex',\n",
       "   'delete',\n",
       "   'edge',\n",
       "   'merge',\n",
       "   'adjacent_vertex'],\n",
       "  ['merge',\n",
       "   'adjacent_vertex',\n",
       "   'example',\n",
       "   'figure',\n",
       "   'illustrate',\n",
       "   'prove_theorem',\n",
       "   'prove',\n",
       "   'follow',\n",
       "   'handy',\n",
       "   'fact',\n",
       "   'obvious',\n",
       "   'give',\n",
       "   'continuous',\n",
       "   'definition',\n",
       "   'lemma'],\n",
       "  ['delete', 'edge', 'planar_graph', 'leave', 'planar_graph'],\n",
       "  ['corollary'],\n",
       "  ['delete',\n",
       "   'vertex',\n",
       "   'planar_graph',\n",
       "   'incident_edge',\n",
       "   'leave',\n",
       "   'planar_graph'],\n",
       "  ['theorem'],\n",
       "  ['subgraph', 'planar_graph', 'planar'],\n",
       "  ['theorem'],\n",
       "  ['merge', 'adjacent_vertex', 'planar_graph', 'leave', 'planar_graph'],\n",
       "  ['operation', 'perform', 'order', 'quantity'],\n",
       "  ['chapter_graph', 'theory_figure'],\n",
       "  ['merge', 'adjacent_vertex']],\n",
       " [['color',\n",
       "   'planar_graph',\n",
       "   'cover',\n",
       "   'lot',\n",
       "   'ground',\n",
       "   'planar_graph',\n",
       "   'nearly',\n",
       "   'enough',\n",
       "   'prove',\n",
       "   'famous',\n",
       "   'color',\n",
       "   'theorem'],\n",
       "  ['awfully', 'close'],\n",
       "  ['indeed',\n",
       "   'do',\n",
       "   'almost',\n",
       "   'enough',\n",
       "   'work',\n",
       "   'prove',\n",
       "   'planar_graph',\n",
       "   'color',\n",
       "   'use',\n",
       "   'color'],\n",
       "  ['need', 'lemma_lemma'],\n",
       "  ['planar_graph', 'vertex_degree'],\n",
       "  ['proof'],\n",
       "  ['contradiction'],\n",
       "  ['vertex_degree',\n",
       "   'least',\n",
       "   'sum',\n",
       "   'vertex_degree',\n",
       "   'least',\n",
       "   'sum',\n",
       "   'vertex_degree',\n",
       "   'equal',\n",
       "   'handshake',\n",
       "   'lemma_lemma',\n",
       "   'theorem',\n",
       "   'theorem'],\n",
       "  ['planar_graph', 'colorable'],\n",
       "  ['proof'],\n",
       "  ['proof',\n",
       "   'strong_induction',\n",
       "   'number',\n",
       "   'vertice',\n",
       "   'induction_hypothesis',\n",
       "   'planar_graph',\n",
       "   'vertex',\n",
       "   'colorable'],\n",
       "  ['base_case', 'immediate'],\n",
       "  ['inductive', 'case', 'suppose', 'planar_graph', 'vertex'],\n",
       "  ['describe', 'coloring'],\n",
       "  ['figure'],\n",
       "  ['method',\n",
       "   'graph',\n",
       "   'reduce',\n",
       "   'geometric',\n",
       "   'construct',\n",
       "   'rediscover',\n",
       "   'polyhedron',\n",
       "   'convex',\n",
       "   'dimensional',\n",
       "   'region',\n",
       "   'bound',\n",
       "   'finite',\n",
       "   'number',\n",
       "   'polygonal',\n",
       "   'face'],\n",
       "  ['face',\n",
       "   'identical',\n",
       "   'regular',\n",
       "   'polygon',\n",
       "   'equal_number',\n",
       "   'polygon',\n",
       "   'meet',\n",
       "   'corner',\n",
       "   'polyhedron',\n",
       "   'regular'],\n",
       "  ['example',\n",
       "   'regular',\n",
       "   'polyhedra',\n",
       "   'show_figure',\n",
       "   'determine',\n",
       "   'many',\n",
       "   'regular',\n",
       "   'polyhedra',\n",
       "   'think',\n",
       "   'planarity'],\n",
       "  ['suppose', 'take', 'polyhedron', 'place', 'sphere', 'inside'],\n",
       "  ['could',\n",
       "   'project',\n",
       "   'polyhedron',\n",
       "   'face',\n",
       "   'boundary',\n",
       "   'sphere',\n",
       "   'would',\n",
       "   'give',\n",
       "   'image',\n",
       "   'planar_graph',\n",
       "   'embed',\n",
       "   'sphere',\n",
       "   'image',\n",
       "   'figure'],\n",
       "  ['tetrahedron', 'cube', 'octahedron'],\n",
       "  ['figure'],\n",
       "  ['planar', 'embeddings', 'tetrahedron', 'cube', 'octahe', 'dron'],\n",
       "  ['corners', 'polyhedron', 'correspond', 'vertex_graph'],\n",
       "  ['already',\n",
       "   'observe',\n",
       "   'embedding',\n",
       "   'sphere',\n",
       "   'embedding',\n",
       "   'plane',\n",
       "   'euler_formula',\n",
       "   'planar_graph',\n",
       "   'help',\n",
       "   'guide',\n",
       "   'search',\n",
       "   'regular',\n",
       "   'polyhedra'],\n",
       "  ['example',\n",
       "   'planar',\n",
       "   'embedding',\n",
       "   'polyhedra',\n",
       "   'figure_show',\n",
       "   'figure',\n",
       "   'let',\n",
       "   'number',\n",
       "   'face',\n",
       "   'meet',\n",
       "   'corner',\n",
       "   'polyhedron',\n",
       "   'let',\n",
       "   'number_edge',\n",
       "   'face'],\n",
       "  ['correspond', 'planar_graph', 'edge_incident', 'vertex'],\n",
       "  ['handshake', 'lemma', 'mv', 'also', 'face', 'bound', 'edge'],\n",
       "  ['edge',\n",
       "   'boundary',\n",
       "   'face',\n",
       "   'solve',\n",
       "   'equation',\n",
       "   'substitute',\n",
       "   'eul',\n",
       "   'formula',\n",
       "   'chapter_graph',\n",
       "   'theory_figure'],\n",
       "  ['possible', 'regular', 'polyhedra'],\n",
       "  ['equation', 'place', 'strong', 'restriction', 'structure', 'polyhedron'],\n",
       "  ['nondegenerate', 'polygon', 'least', 'side'],\n",
       "  ['least', 'polygon', 'must', 'meet', 'form', 'corner'],\n",
       "  ['hand', 'leave_side', 'equation', 'could', 'less', 'right_side'],\n",
       "  ['check',\n",
       "   'finitely',\n",
       "   'many',\n",
       "   'case',\n",
       "   'remain',\n",
       "   'turn',\n",
       "   'solution',\n",
       "   'show_figure',\n",
       "   'polyhedra',\n",
       "   'figure',\n",
       "   'possible',\n",
       "   'regular',\n",
       "   'polyhedra'],\n",
       "  ['want',\n",
       "   'put',\n",
       "   'geocentric',\n",
       "   'satellite',\n",
       "   'orbit',\n",
       "   'uniformly',\n",
       "   'blanket',\n",
       "   'globe',\n",
       "   'tough',\n",
       "   'luck']],\n",
       " [['direct_graph']],\n",
       " [['definition', 'far', 'work', 'graphs', 'undirected', 'edge'],\n",
       "  ['directed_edge', 'edge', 'endpoint', 'distinguish', 'head', 'tail'],\n",
       "  ['particular', 'directed_edge', 'specify', 'order_pair', 'vertex', 'denote'],\n",
       "  ['case', 'tail', 'edge', 'head'],\n",
       "  ['example',\n",
       "   'see_figure',\n",
       "   'graph',\n",
       "   'direct_edge',\n",
       "   'call',\n",
       "   'direct_graph',\n",
       "   'digraph'],\n",
       "  ['definition'],\n",
       "  ['direct_graph'],\n",
       "  ['consist', 'nonempty_set', 'node', 'set', 'direct_edge'],\n",
       "  ['edge', 'specify', 'order_pair', 'vertex'],\n",
       "  ['directed', 'graph', 'simple', 'loop', 'edge', 'form', 'multiple', 'edge'],\n",
       "  ['focus',\n",
       "   'case',\n",
       "   'simple',\n",
       "   'direct_graphs',\n",
       "   'chapter',\n",
       "   'generally',\n",
       "   'omit',\n",
       "   'word',\n",
       "   'simple',\n",
       "   'refer'],\n",
       "  ['note',\n",
       "   'graph_contain',\n",
       "   'edge',\n",
       "   'edge',\n",
       "   'different',\n",
       "   'edge',\n",
       "   'example',\n",
       "   'different',\n",
       "   'tail'],\n",
       "  ['direct_graph',\n",
       "   'arise',\n",
       "   'application',\n",
       "   'relationship',\n",
       "   'represent',\n",
       "   'edge',\n",
       "   'way',\n",
       "   'asymmetric'],\n",
       "  ['example',\n",
       "   'include',\n",
       "   'way',\n",
       "   'street',\n",
       "   'person',\n",
       "   'like',\n",
       "   'feeling',\n",
       "   'necessarily',\n",
       "   'reciprocate',\n",
       "   'communication',\n",
       "   'channel',\n",
       "   'cable',\n",
       "   'modem',\n",
       "   'capacity',\n",
       "   'download',\n",
       "   'upload',\n",
       "   'entity',\n",
       "   'large',\n",
       "   'job',\n",
       "   'need',\n",
       "   'complete',\n",
       "   'job',\n",
       "   'begin'],\n",
       "  ['see',\n",
       "   'several',\n",
       "   'example',\n",
       "   'chapter',\n",
       "   'also',\n",
       "   'chapter',\n",
       "   'definition',\n",
       "   'undirecte',\n",
       "   'graphs',\n",
       "   'chapter',\n",
       "   'carry',\n",
       "   'natural_way',\n",
       "   'direct_graph'],\n",
       "  ['example', 'direct_graph', 'iff'],\n",
       "  ['tail', 'head', 'figure'],\n",
       "  ['directed_edge'],\n",
       "  ['tail', 'head'],\n",
       "  ['chapter_direct_graphs', 'figure'],\n",
       "  ['node', 'direct_graph', 'edge'],\n",
       "  ['direct_graphs', 'adjacency_matrix', 'undirected_graph'],\n",
       "  ['case', 'direct_graph'],\n",
       "  ['adjacency_matrix', 'ij', 'ij', 'otherwise'],\n",
       "  ['difference',\n",
       "   'adjacency_matrix',\n",
       "   'direct_graph',\n",
       "   'nece',\n",
       "   'sarily',\n",
       "   'symmetric',\n",
       "   'may']],\n",
       " [['degree',\n",
       "   'direct_graphs',\n",
       "   'notion',\n",
       "   'degree',\n",
       "   'split',\n",
       "   'indegree',\n",
       "   'outdegree'],\n",
       "  ['example', 'indegree'],\n",
       "  ['outdegree'],\n",
       "  ['graph_figure', 'source', 'node', 'sink']],\n",
       " [['direct',\n",
       "   'walks',\n",
       "   'path',\n",
       "   'cycle',\n",
       "   'definition',\n",
       "   'direct',\n",
       "   'walk_path',\n",
       "   'cycle',\n",
       "   'direct_graph',\n",
       "   'similar',\n",
       "   'undirected_graph',\n",
       "   'direction',\n",
       "   'edge',\n",
       "   'need',\n",
       "   'consistent',\n",
       "   'order',\n",
       "   'walk',\n",
       "   'traverse'],\n",
       "  ['definition'],\n",
       "  ['direct',\n",
       "   'walk',\n",
       "   'simply',\n",
       "   'walk',\n",
       "   'direct_graph',\n",
       "   'sequence',\n",
       "   'vertex',\n",
       "   'undirected_graph',\n",
       "   'typically',\n",
       "   'refer',\n",
       "   'walk',\n",
       "   'direct_graph',\n",
       "   'sequence',\n",
       "   'vertex'],\n",
       "  ['example', 'graph_figure', 'walk_path', 'close_walk', 'cycle'],\n",
       "  ['note',\n",
       "   'also',\n",
       "   'cycle',\n",
       "   'graph_figure',\n",
       "   'also',\n",
       "   'note',\n",
       "   'walk',\n",
       "   'graph_show',\n",
       "   'figure',\n",
       "   'path',\n",
       "   'cycle',\n",
       "   'direct_graph',\n",
       "   'say',\n",
       "   'hamiltonian',\n",
       "   'visit_node',\n",
       "   'graph'],\n",
       "  ['example', 'hamiltonian_path', 'graph_figure', 'hamiltonian_cycle'],\n",
       "  ['walk', 'direct_graph', 'say', 'eulerian', 'contain', 'edge'],\n",
       "  ['graph_show', 'figure', 'eulerian', 'walk'],\n",
       "  ['see', 'hint', 'look', 'node']],\n",
       " [['strong',\n",
       "   'connectivity',\n",
       "   'notion',\n",
       "   'connect',\n",
       "   'little',\n",
       "   'complicated',\n",
       "   'direct_graph',\n",
       "   'undirecte',\n",
       "   'graph'],\n",
       "  ['example_consider',\n",
       "   'graph_figure',\n",
       "   'connect',\n",
       "   'path',\n",
       "   'node',\n",
       "   'node',\n",
       "   'basis',\n",
       "   'may',\n",
       "   'answer'],\n",
       "  ['path', 'node', 'node', 'basis', 'may', 'answer'],\n",
       "  ['reason',\n",
       "   'graph',\n",
       "   'theorist',\n",
       "   'come',\n",
       "   'notion',\n",
       "   'strong',\n",
       "   'connectivity',\n",
       "   'direct_graph'],\n",
       "  ['definition'],\n",
       "  ['direct_graph'],\n",
       "  ['say',\n",
       "   'strongly',\n",
       "   'connect_pair',\n",
       "   'node',\n",
       "   'direct',\n",
       "   'path',\n",
       "   'vice',\n",
       "   'versa'],\n",
       "  ['example',\n",
       "   'graph_figure',\n",
       "   'strongly',\n",
       "   'connect',\n",
       "   'direct',\n",
       "   'path',\n",
       "   'node',\n",
       "   'node'],\n",
       "  ['node', 'remove', 'result', 'graph', 'would', 'strongly', 'connect'],\n",
       "  ['chapter_direct_graphs', 'figure'],\n",
       "  ['node', 'direct', 'acyclic_graph', 'dag'],\n",
       "  ['direct_graph',\n",
       "   'say',\n",
       "   'weakly',\n",
       "   'connect',\n",
       "   'simply',\n",
       "   'connect',\n",
       "   'correspond',\n",
       "   'undirected_graph',\n",
       "   'direct_edge',\n",
       "   'replace',\n",
       "   'single',\n",
       "   'undirected',\n",
       "   'edge',\n",
       "   'fu',\n",
       "   'connect'],\n",
       "  ['example', 'graph_figure', 'weakly', 'connect']],\n",
       " [['dag', 'undirected_graph', 'cycle', 'tree', 'forest'],\n",
       "  ['directed',\n",
       "   'graph',\n",
       "   'look',\n",
       "   'cycle',\n",
       "   'example_consider',\n",
       "   'graph_figure',\n",
       "   'definition'],\n",
       "  ['direct_graph',\n",
       "   'call',\n",
       "   'direct',\n",
       "   'acyclic_graph',\n",
       "   'dag',\n",
       "   'contain',\n",
       "   'direct',\n",
       "   'cycle'],\n",
       "  ['first', 'glance', 'dag', 'appear', 'particularly', 'interesting'],\n",
       "  ['first', 'be', 'pression', 'always', 'accurate'],\n",
       "  ['fact',\n",
       "   'dag',\n",
       "   'arise',\n",
       "   'many',\n",
       "   'scheduling',\n",
       "   'optimization',\n",
       "   'problem',\n",
       "   'several',\n",
       "   'interesting',\n",
       "   'property'],\n",
       "  ['study', 'extensively', 'chapter']],\n",
       " [['tournament',\n",
       "   'graphs',\n",
       "   'suppose',\n",
       "   'player',\n",
       "   'compete',\n",
       "   'round',\n",
       "   'robin',\n",
       "   'tournament',\n",
       "   'pair',\n",
       "   'player',\n",
       "   'beat',\n",
       "   'beat'],\n",
       "  ['interpret',\n",
       "   'result',\n",
       "   'round',\n",
       "   'robin',\n",
       "   'tournament',\n",
       "   'problematic',\n",
       "   'may',\n",
       "   'sort',\n",
       "   'cycle',\n",
       "   'beat',\n",
       "   'beat',\n",
       "   'yet',\n",
       "   'beat'],\n",
       "  ['good',\n",
       "   'player',\n",
       "   'graph_theory',\n",
       "   'solve_problem',\n",
       "   'provide',\n",
       "   'interesting',\n",
       "   'perspective'],\n",
       "  ['figure'],\n",
       "  ['node', 'tournament_graph'],\n",
       "  ['result', 'round', 'robin', 'tournament', 'represent', 'tournament_graph'],\n",
       "  ['direct_graph',\n",
       "   'vertex',\n",
       "   'represent',\n",
       "   'player',\n",
       "   'edge',\n",
       "   'indicate',\n",
       "   'outcome',\n",
       "   'game'],\n",
       "  ['particular', 'edge', 'indicate', 'player', 'defeat', 'player'],\n",
       "  ['round', 'robin', 'tournament', 'pair', 'player', 'match'],\n",
       "  ['thus', 'tournament_graph', 'edge', 'edge', 'pair', 'distinct', 'vertex'],\n",
       "  ['example', 'tournament_graph', 'show_figure']],\n",
       " [['find',\n",
       "   'hamiltonian_path',\n",
       "   'tournament_graph',\n",
       "   'go',\n",
       "   'prove',\n",
       "   'round',\n",
       "   'robin',\n",
       "   'tournament',\n",
       "   'exist',\n",
       "   'rank',\n",
       "   'player',\n",
       "   'player',\n",
       "   'lose',\n",
       "   'player',\n",
       "   'position',\n",
       "   'higher'],\n",
       "  ['example',\n",
       "   'tournament',\n",
       "   'correspond',\n",
       "   'figure',\n",
       "   'satisfie',\n",
       "   'criterion',\n",
       "   'lose',\n",
       "   'lose',\n",
       "   'lose',\n",
       "   'lose'],\n",
       "  ['graph',\n",
       "   'term',\n",
       "   'prove',\n",
       "   'existence',\n",
       "   'rank',\n",
       "   'amount',\n",
       "   'prove',\n",
       "   'tournament_graph',\n",
       "   'hamiltonian_path'],\n",
       "  ['theorem'],\n",
       "  ['tournament_graph', 'contain', 'direct', 'hamiltonian_path'],\n",
       "  ['proof'],\n",
       "  ['use_strong_induction'],\n",
       "  ['let'],\n",
       "  ['proposition',\n",
       "   'tournament_graph',\n",
       "   'vertex',\n",
       "   'contain',\n",
       "   'direct',\n",
       "   'hamiltonian_path'],\n",
       "  ['base_case'],\n",
       "  ['trivially',\n",
       "   'true',\n",
       "   'graph',\n",
       "   'single',\n",
       "   'vertex',\n",
       "   'hamiltonian_path',\n",
       "   'consist',\n",
       "   'vertex'],\n",
       "  ['chapter_direct_graphs', 'figure'],\n",
       "  ['set', 'tournament_graph'],\n",
       "  ['inductive_step_assume'],\n",
       "  ['true', 'prove'],\n",
       "  ['consider', 'tournament_graph'],\n",
       "  ['player'],\n",
       "  ['select', 'vertex', 'arbitrarily'],\n",
       "  ['vertex', 'tournament', 'edge', 'vertex_edge', 'vertex'],\n",
       "  ['thus',\n",
       "   'partition',\n",
       "   'remain',\n",
       "   'vertex',\n",
       "   'correspond',\n",
       "   'set',\n",
       "   'contain',\n",
       "   'vertex'],\n",
       "  ['example',\n",
       "   'see_figure',\n",
       "   'vertex',\n",
       "   'together',\n",
       "   'edge',\n",
       "   'join',\n",
       "   'form',\n",
       "   'small',\n",
       "   'tourna',\n",
       "   'ment'],\n",
       "  ['thus', 'strong_induction', 'hamiltonian_path'],\n",
       "  ['similarly', 'hamiltonian_path', 'tournament', 'vertex'],\n",
       "  ['join',\n",
       "   'path',\n",
       "   'vertex',\n",
       "   'follow',\n",
       "   'path',\n",
       "   'give',\n",
       "   'hamiltonian_path',\n",
       "   'whole',\n",
       "   'tournament'],\n",
       "  ['special_case', 'empty', 'correspond', 'portion', 'path'],\n",
       "  ['rank', 'define', 'hamiltonian_path', 'entirely', 'satisfactory'],\n",
       "  ['ex',\n",
       "   'ample',\n",
       "   'tournament',\n",
       "   'associate',\n",
       "   'figure',\n",
       "   'practice',\n",
       "   'player',\n",
       "   'typically',\n",
       "   'rank',\n",
       "   'accord',\n",
       "   'many',\n",
       "   'victory',\n",
       "   'achieve'],\n",
       "  ['make_sense', 'several', 'reason'],\n",
       "  ['obvious',\n",
       "   'reason',\n",
       "   'player',\n",
       "   'victory',\n",
       "   'beat',\n",
       "   'player',\n",
       "   'guaran',\n",
       "   'teed',\n",
       "   'least',\n",
       "   'beat',\n",
       "   'third',\n",
       "   'player',\n",
       "   'beat'],\n",
       "  ['prove', 'fact', 'shortly'],\n",
       "  ['first', 'let', 'talk', 'chicken'],\n",
       "  ['tournament', 'graphs', 'king', 'king', 'king', 'figure'],\n",
       "  ['chicken', 'tournament', 'chicken', 'king']],\n",
       " [['king', 'chicken', 'theorem', 'suppose', 'chicken', 'farmyard'],\n",
       "  ['chicken',\n",
       "   'rather',\n",
       "   'aggressive',\n",
       "   'bird',\n",
       "   'tend',\n",
       "   'establish',\n",
       "   'dominance',\n",
       "   'relationship',\n",
       "   'peck'],\n",
       "  ['hence', 'term', 'peck', 'order'],\n",
       "  ['particular',\n",
       "   'pair',\n",
       "   'distinct',\n",
       "   'chicken',\n",
       "   'first',\n",
       "   'peck',\n",
       "   'second',\n",
       "   'second',\n",
       "   'peck',\n",
       "   'first'],\n",
       "  ['say',\n",
       "   'chicken',\n",
       "   'virtually',\n",
       "   'peck_chicken',\n",
       "   'chicken',\n",
       "   'directly',\n",
       "   'peck_chicken',\n",
       "   'chicken',\n",
       "   'pecks',\n",
       "   'chicken',\n",
       "   'turn',\n",
       "   'peck_chicken'],\n",
       "  ['chicken', 'virtually', 'peck_chicken', 'call', 'king', 'chicken'],\n",
       "  ['model', 'situation', 'tournament', 'digraph'],\n",
       "  ['vertex', 'chick', 'ens', 'edge', 'indicate', 'chicken', 'peck_chicken'],\n",
       "  ['tournament', 'show_figure', 'theorem'],\n",
       "  ['king', 'chicken', 'theorem'],\n",
       "  ['chicken', 'large', 'outdegree', 'chicken', 'tournament', 'king'],\n",
       "  ['proof'],\n",
       "  ['contradiction'],\n",
       "  ['let', 'node', 'tournament_graph'],\n",
       "  ['maximum', 'outdegree', 'suppose', 'king'],\n",
       "  ['let', 'set', 'chicken', 'chicken', 'peck'],\n",
       "  ['outdegree'],\n",
       "  ['jy'],\n",
       "  ['king', 'chicken', 'peck_chicken', 'peck_chicken'],\n",
       "  ['pair', 'chicken', 'pecks', 'mean', 'peck', 'well', 'chicken'],\n",
       "  ['mean', 'outdegree'],\n",
       "  ['jy', 'outdegree'],\n",
       "  ['chapter_direct_graphs', 'figure'],\n",
       "  ['chicken', 'tournament', 'chicken', 'king'],\n",
       "  ['assumed', 'node', 'large', 'degree', 'tournament', 'contradiction'],\n",
       "  ['hence', 'must', 'king'],\n",
       "  ['theorem',\n",
       "   'mean',\n",
       "   'player',\n",
       "   'victory',\n",
       "   'defeat',\n",
       "   'player',\n",
       "   'defeat',\n",
       "   'third',\n",
       "   'player',\n",
       "   'defeat'],\n",
       "  ['sense', 'player', 'victory', 'sort', 'bragging', 'right', 'player'],\n",
       "  ['unfortunately',\n",
       "   'figure',\n",
       "   'illustrate',\n",
       "   'many',\n",
       "   'player',\n",
       "   'brag',\n",
       "   'right',\n",
       "   'even',\n",
       "   'few',\n",
       "   'victory'],\n",
       "  ['indeed', 'tournament', 'possible', 'player', 'king'],\n",
       "  ['example_consider', 'tournament', 'illustrate_figure']],\n",
       " [['communication_network',\n",
       "   'reason',\n",
       "   'chicken',\n",
       "   'peck',\n",
       "   'may',\n",
       "   'amuse',\n",
       "   'mathe',\n",
       "   'matician',\n",
       "   'least',\n",
       "   'use',\n",
       "   'direct_graphs',\n",
       "   'model',\n",
       "   'communication_network',\n",
       "   'serious',\n",
       "   'business'],\n",
       "  ['context',\n",
       "   'communication',\n",
       "   'problem',\n",
       "   'vertex',\n",
       "   'send',\n",
       "   'computer',\n",
       "   'processor',\n",
       "   'switch',\n",
       "   'edge',\n",
       "   'represent',\n",
       "   'wire',\n",
       "   'fiber',\n",
       "   'transmission',\n",
       "   'line',\n",
       "   'datum',\n",
       "   'flow'],\n",
       "  ['communication_network',\n",
       "   'internet',\n",
       "   'correspond',\n",
       "   'graph',\n",
       "   'enormous',\n",
       "   'largely',\n",
       "   'chaotic'],\n",
       "  ['highly',\n",
       "   'structured',\n",
       "   'network',\n",
       "   'array',\n",
       "   'butterfly',\n",
       "   'contrast',\n",
       "   'find',\n",
       "   'application',\n",
       "   'telephone',\n",
       "   'switching',\n",
       "   'system',\n",
       "   'communication',\n",
       "   'hardware',\n",
       "   'parallel',\n",
       "   'com',\n",
       "   'puter']],\n",
       " [['packet',\n",
       "   'route',\n",
       "   'architecture',\n",
       "   'choose',\n",
       "   'goal',\n",
       "   'communication_network',\n",
       "   'get',\n",
       "   'data',\n",
       "   'input_output'],\n",
       "  ['text', 'focus', 'model', 'datum', 'communicate', 'form', 'packet'],\n",
       "  ['practice',\n",
       "   'packet',\n",
       "   'would',\n",
       "   'consist',\n",
       "   'fix',\n",
       "   'amount',\n",
       "   'datum',\n",
       "   'message',\n",
       "   'web',\n",
       "   'page',\n",
       "   'movie',\n",
       "   'would',\n",
       "   'consist',\n",
       "   'many',\n",
       "   'packet'],\n",
       "  ['simplicity',\n",
       "   'restrict',\n",
       "   'attention',\n",
       "   'scenario',\n",
       "   'packet',\n",
       "   'input',\n",
       "   'packet',\n",
       "   'destine',\n",
       "   'output'],\n",
       "  ['denote', 'number', 'input_output', 'often', 'assume', 'power'],\n",
       "  ['specify', 'desire', 'destination', 'packet', 'permutation'],\n",
       "  ['permutation',\n",
       "   'define',\n",
       "   'route_problem',\n",
       "   'get',\n",
       "   'packet',\n",
       "   'start',\n",
       "   'input_output'],\n",
       "  ['route',\n",
       "   'solve',\n",
       "   'route_problem',\n",
       "   'set',\n",
       "   'path',\n",
       "   'input',\n",
       "   'specify',\n",
       "   'output'],\n",
       "  ['set',\n",
       "   'path',\n",
       "   'course',\n",
       "   'goal',\n",
       "   'get',\n",
       "   'packet',\n",
       "   'destination',\n",
       "   'quickly',\n",
       "   'possible',\n",
       "   'use',\n",
       "   'little',\n",
       "   'hardware',\n",
       "   'possible'],\n",
       "  ['time',\n",
       "   'need',\n",
       "   'get',\n",
       "   'package',\n",
       "   'destination',\n",
       "   'depend',\n",
       "   'several',\n",
       "   'factor',\n",
       "   'many',\n",
       "   'switch',\n",
       "   'need',\n",
       "   'go',\n",
       "   'many',\n",
       "   'packet',\n",
       "   'need',\n",
       "   'cross',\n",
       "   'wire'],\n",
       "  ['assume', 'packet', 'cross', 'wire', 'time'],\n",
       "  ['complexity',\n",
       "   'hardware',\n",
       "   'depend',\n",
       "   'factor',\n",
       "   'number',\n",
       "   'switch',\n",
       "   'need',\n",
       "   'size',\n",
       "   'switch'],\n",
       "  ['let_see', 'work', 'example', 'route_packet', 'complete_binary_tree']],\n",
       " [['complete_binary_tree',\n",
       "   'simple',\n",
       "   'structured',\n",
       "   'communication_network',\n",
       "   'complete_binary_tree'],\n",
       "  ['complete_binary_tree',\n",
       "   'input_output',\n",
       "   'show_figure',\n",
       "   'diagram',\n",
       "   'many',\n",
       "   'follow',\n",
       "   'square',\n",
       "   'represent',\n",
       "   'terminal',\n",
       "   'input_output',\n",
       "   'circle',\n",
       "   'represent',\n",
       "   'switch',\n",
       "   'direct',\n",
       "   'packet',\n",
       "   'network'],\n",
       "  ['switch',\n",
       "   'receive',\n",
       "   'packet',\n",
       "   'incoming',\n",
       "   'edge',\n",
       "   'relays',\n",
       "   'forward',\n",
       "   'outgoing',\n",
       "   'edge'],\n",
       "  ['thus',\n",
       "   'imagine',\n",
       "   'datum',\n",
       "   'packet',\n",
       "   'hopping',\n",
       "   'network',\n",
       "   'input',\n",
       "   'terminal',\n",
       "   'sequence',\n",
       "   'switch',\n",
       "   'join',\n",
       "   'directed_edge',\n",
       "   'output',\n",
       "   'terminal'],\n",
       "  ['recall', 'unique', 'simple', 'path_pair', 'vertex', 'tree'],\n",
       "  ['natural_way',\n",
       "   'route_packet',\n",
       "   'datum',\n",
       "   'input',\n",
       "   'terminal',\n",
       "   'output',\n",
       "   'terminal',\n",
       "   'complete_binary_tree',\n",
       "   'correspond',\n",
       "   'direct',\n",
       "   'path'],\n",
       "  ['permutation', 'sequence', 'reordering', 'sequence'],\n",
       "  ['chapter_direct_graphs', 'figure'],\n",
       "  ['input_output', 'complete_binary_tree'],\n",
       "  ['square',\n",
       "   'represent',\n",
       "   'termi',\n",
       "   'nal',\n",
       "   'input_output',\n",
       "   'register',\n",
       "   'circle',\n",
       "   'represent',\n",
       "   'switch'],\n",
       "  ['directed_edge',\n",
       "   'represent',\n",
       "   'communication',\n",
       "   'channel',\n",
       "   'network',\n",
       "   'datum',\n",
       "   'packet',\n",
       "   'move'],\n",
       "  ['unique', 'path', 'input_output', 'show', 'bold'],\n",
       "  ['example',\n",
       "   'route_packet',\n",
       "   'travel',\n",
       "   'input_output',\n",
       "   'show',\n",
       "   'bold',\n",
       "   'figure']],\n",
       " [['network',\n",
       "   'diameter',\n",
       "   'delay',\n",
       "   'time',\n",
       "   'packet',\n",
       "   'arrive',\n",
       "   'input',\n",
       "   'time',\n",
       "   'reach',\n",
       "   'designate',\n",
       "   'output',\n",
       "   'refer',\n",
       "   'latency',\n",
       "   'critical',\n",
       "   'issue',\n",
       "   'communication_network'],\n",
       "  ['congestion',\n",
       "   'factor',\n",
       "   'delay',\n",
       "   'generally',\n",
       "   'proportional',\n",
       "   'length',\n",
       "   'path',\n",
       "   'packet',\n",
       "   'follow'],\n",
       "  ['assume',\n",
       "   'take',\n",
       "   'time',\n",
       "   'unit',\n",
       "   'travel',\n",
       "   'wire',\n",
       "   'additional',\n",
       "   'delay',\n",
       "   'switch',\n",
       "   'delay',\n",
       "   'packet',\n",
       "   'number',\n",
       "   'wire',\n",
       "   'crosse',\n",
       "   'go',\n",
       "   'input_output'],\n",
       "  ['generally',\n",
       "   'packet',\n",
       "   'route',\n",
       "   'input_output',\n",
       "   'use',\n",
       "   'short_path',\n",
       "   'possible'],\n",
       "  ['length', 'short_path', 'distance', 'input_output'],\n",
       "  ['short_path',\n",
       "   'route',\n",
       "   'worst',\n",
       "   'possible',\n",
       "   'delay',\n",
       "   'distance',\n",
       "   'input_output',\n",
       "   'farthest',\n",
       "   'apart'],\n",
       "  ['call', 'diameter', 'network'],\n",
       "  ['word',\n",
       "   'diameter',\n",
       "   'network',\n",
       "   'maximum',\n",
       "   'length',\n",
       "   'short',\n",
       "   'latency',\n",
       "   'also',\n",
       "   'measure',\n",
       "   'number',\n",
       "   'switch',\n",
       "   'packet',\n",
       "   'must',\n",
       "   'pass',\n",
       "   'travel',\n",
       "   'distant',\n",
       "   'input_output',\n",
       "   'switch',\n",
       "   'usually',\n",
       "   'big',\n",
       "   'impact',\n",
       "   'network',\n",
       "   'speed'],\n",
       "  ['example',\n",
       "   'complete_binary_tree',\n",
       "   'example',\n",
       "   'packet',\n",
       "   'travel',\n",
       "   'input_output',\n",
       "   'crosse',\n",
       "   'switch',\n",
       "   'less',\n",
       "   'number_edge',\n",
       "   'traverse'],\n",
       "  ['usual',\n",
       "   'definition',\n",
       "   'diameter',\n",
       "   'general',\n",
       "   'graph',\n",
       "   'simple',\n",
       "   'direct',\n",
       "   'large',\n",
       "   'distance',\n",
       "   'vertex',\n",
       "   'context',\n",
       "   'communication_network',\n",
       "   'interested',\n",
       "   'distance',\n",
       "   'input_output',\n",
       "   'arbitrary',\n",
       "   'pair_vertex'],\n",
       "  ['path', 'input_output'],\n",
       "  ['example',\n",
       "   'complete_binary_tree',\n",
       "   'show_figure',\n",
       "   'generally',\n",
       "   'diameter',\n",
       "   'complete_binary_tree',\n",
       "   'input_output',\n",
       "   'log'],\n",
       "  ['logarithms', 'lecture', 'computer_science', 'base'],\n",
       "  ['quite', 'good', 'logarithm', 'function', 'grow', 'slowly'],\n",
       "  ['could', 'connect']],\n",
       " [['switch',\n",
       "   'size_way',\n",
       "   'reduce',\n",
       "   'diameter',\n",
       "   'network',\n",
       "   'hence',\n",
       "   'latency',\n",
       "   'need',\n",
       "   'route_packet',\n",
       "   'use',\n",
       "   'large',\n",
       "   'switch'],\n",
       "  ['example',\n",
       "   'complete_binary_tree',\n",
       "   'switch',\n",
       "   'incoming',\n",
       "   'edge',\n",
       "   'outgoing',\n",
       "   'edge',\n",
       "   'make',\n",
       "   'switch'],\n",
       "  ['switch',\n",
       "   'could',\n",
       "   'construct',\n",
       "   'complete',\n",
       "   'ternary',\n",
       "   'tree',\n",
       "   'even',\n",
       "   'small',\n",
       "   'diameter'],\n",
       "  ['principle',\n",
       "   'could',\n",
       "   'even',\n",
       "   'connect',\n",
       "   'inputs',\n",
       "   'output',\n",
       "   'single',\n",
       "   'monster',\n",
       "   'switch',\n",
       "   'show_figure',\n",
       "   'productive',\n",
       "   'however',\n",
       "   'conceal',\n",
       "   'original',\n",
       "   'net',\n",
       "   'work',\n",
       "   'design',\n",
       "   'problem',\n",
       "   'abstract',\n",
       "   'monster',\n",
       "   'switch'],\n",
       "  ['eventually',\n",
       "   'design',\n",
       "   'internal',\n",
       "   'monster',\n",
       "   'switch',\n",
       "   'use',\n",
       "   'simple',\n",
       "   'component',\n",
       "   'right',\n",
       "   'back',\n",
       "   'start'],\n",
       "  ['challenge',\n",
       "   'designing',\n",
       "   'communication_network',\n",
       "   'figure',\n",
       "   'get',\n",
       "   'functionality',\n",
       "   'switch',\n",
       "   'use',\n",
       "   'fix',\n",
       "   'size',\n",
       "   'elementary',\n",
       "   'device',\n",
       "   'switch']],\n",
       " [['switch',\n",
       "   'count',\n",
       "   'goal',\n",
       "   'design',\n",
       "   'communication_network',\n",
       "   'use',\n",
       "   'switch',\n",
       "   'possible'],\n",
       "  ['number',\n",
       "   'switch',\n",
       "   'complete_binary_tree',\n",
       "   'switch',\n",
       "   'top',\n",
       "   'root',\n",
       "   'switch',\n",
       "   'forth'],\n",
       "  ['nearly',\n",
       "   'good',\n",
       "   'possible',\n",
       "   'switch',\n",
       "   'chapter',\n",
       "   'direct_graph',\n",
       "   'since',\n",
       "   'least',\n",
       "   'switch',\n",
       "   'need',\n",
       "   'pair',\n",
       "   'inputs',\n",
       "   'output']],\n",
       " [['congestion',\n",
       "   'complete_binary_tree',\n",
       "   'fatal',\n",
       "   'drawback',\n",
       "   'root',\n",
       "   'switch',\n",
       "   'bottleneck'],\n",
       "  ['good',\n",
       "   'switch',\n",
       "   'must',\n",
       "   'handle',\n",
       "   'enormous',\n",
       "   'amount',\n",
       "   'traffic',\n",
       "   'packet',\n",
       "   'travel',\n",
       "   'leave_side',\n",
       "   'network',\n",
       "   'right',\n",
       "   'vice',\n",
       "   'versa'],\n",
       "  ['pass', 'packet', 'single', 'switch', 'could', 'take', 'long', 'time'],\n",
       "  ['bad', 'switch', 'fail', 'network', 'break', 'equal', 'sized', 'piece'],\n",
       "  ['traffic', 'root', 'depend', 'route_problem'],\n",
       "  ['example', 'route_problem', 'give', 'identity', 'permutation'],\n",
       "  ['wwd',\n",
       "   'easy',\n",
       "   'routing',\n",
       "   'solve_problem',\n",
       "   'let',\n",
       "   'distinguish',\n",
       "   'good',\n",
       "   'set',\n",
       "   'path',\n",
       "   'bad',\n",
       "   'set',\n",
       "   'base',\n",
       "   'congestion'],\n",
       "  ['congestion',\n",
       "   'route',\n",
       "   'equal',\n",
       "   'large_number',\n",
       "   'path',\n",
       "   'pass',\n",
       "   'single',\n",
       "   'switch'],\n",
       "  ['generally',\n",
       "   'low',\n",
       "   'congestion',\n",
       "   'well',\n",
       "   'packet',\n",
       "   'delay',\n",
       "   'overloaded',\n",
       "   'switch'],\n",
       "  ['extend',\n",
       "   'notion',\n",
       "   'congestion',\n",
       "   'network',\n",
       "   'also',\n",
       "   'distinguish',\n",
       "   'tween',\n",
       "   'good',\n",
       "   'bad',\n",
       "   'network',\n",
       "   'respect',\n",
       "   'bottleneck',\n",
       "   'problem'],\n",
       "  ['route_problem',\n",
       "   'network',\n",
       "   'assume',\n",
       "   'route',\n",
       "   'chosen',\n",
       "   'optimize',\n",
       "   'congestion',\n",
       "   'minimum',\n",
       "   'congestion',\n",
       "   'routing',\n",
       "   'solve',\n",
       "   'may',\n",
       "   'find',\n",
       "   'helpful',\n",
       "   'think',\n",
       "   'max',\n",
       "   'congestion',\n",
       "   'term',\n",
       "   'value',\n",
       "   'game'],\n",
       "  ['design', 'spiffy', 'new', 'communication_network', 'define', 'game'],\n",
       "  ['opponent',\n",
       "   'make',\n",
       "   'first',\n",
       "   'move',\n",
       "   'game',\n",
       "   'inspect',\n",
       "   'network',\n",
       "   'specify',\n",
       "   'permutation',\n",
       "   'route_problem',\n",
       "   'strain',\n",
       "   'network'],\n",
       "  ['move',\n",
       "   'second',\n",
       "   'give',\n",
       "   'specification',\n",
       "   'choose',\n",
       "   'precise',\n",
       "   'path',\n",
       "   'packet',\n",
       "   'take',\n",
       "   'network',\n",
       "   'try',\n",
       "   'avoid',\n",
       "   'overload',\n",
       "   'switch'],\n",
       "  ['next',\n",
       "   'move',\n",
       "   'pick',\n",
       "   'switch',\n",
       "   'large',\n",
       "   'possible',\n",
       "   'number',\n",
       "   'packet',\n",
       "   'pass',\n",
       "   'number',\n",
       "   'score',\n",
       "   'competition'],\n",
       "  ['max',\n",
       "   'congestion',\n",
       "   'network',\n",
       "   'large',\n",
       "   'score',\n",
       "   'ensure',\n",
       "   'word',\n",
       "   'precisely',\n",
       "   'max',\n",
       "   'value',\n",
       "   'game'],\n",
       "  ['example',\n",
       "   'enemy',\n",
       "   'try',\n",
       "   'defeat',\n",
       "   'complete_binary_tree',\n",
       "   'would',\n",
       "   'choose',\n",
       "   'permutation'],\n",
       "  ['packet', 'would', 'force', 'select', 'path'],\n",
       "  ['table'],\n",
       "  ['summary', 'attribute', 'complete_binary_tree'],\n",
       "  ['figure'],\n",
       "  ['dimensional', 'array'],\n",
       "  ['enemy', 'would', 'choose', 'root', 'switch', 'achieve', 'score'],\n",
       "  ['word',\n",
       "   'max',\n",
       "   'congestion',\n",
       "   'complete_binary_tree',\n",
       "   'horrible',\n",
       "   'summarized',\n",
       "   'result',\n",
       "   'analysis',\n",
       "   'complete_binary_tree',\n",
       "   'table']],\n",
       " [['array',\n",
       "   'illustration',\n",
       "   'array',\n",
       "   'also',\n",
       "   'know',\n",
       "   'grid',\n",
       "   'crossbar',\n",
       "   'show_figure',\n",
       "   'case'],\n",
       "  ['diameter', 'array', 'number_edge', 'input_output'],\n",
       "  ['generally',\n",
       "   'diameter',\n",
       "   'array',\n",
       "   'input_output',\n",
       "   'much',\n",
       "   'bad',\n",
       "   'diameter',\n",
       "   'complete_binary_tree',\n",
       "   'log'],\n",
       "  ['hand',\n",
       "   'replace',\n",
       "   'complete_binary_tree',\n",
       "   'array',\n",
       "   'almost',\n",
       "   'eliminate',\n",
       "   'congestion'],\n",
       "  ['theorem'],\n",
       "  ['congestion', 'input', 'array'],\n",
       "  ['proof'],\n",
       "  ['first', 'show', 'congestion'],\n",
       "  ['let', 'permutation'],\n",
       "  ['define', 'solution', 'set', 'path', 'table'],\n",
       "  ['compare', 'input', 'array', 'input', 'complete_binary_tree'],\n",
       "  ['input', 'column'],\n",
       "  ['go', 'output'],\n",
       "  ['solution',\n",
       "   'switch',\n",
       "   'row',\n",
       "   'column',\n",
       "   'encounter',\n",
       "   'packet',\n",
       "   'packet',\n",
       "   'originate',\n",
       "   'input',\n",
       "   'packet',\n",
       "   'destine',\n",
       "   'output'],\n",
       "  ['next', 'show', 'congestion', 'least'],\n",
       "  ['follow',\n",
       "   'route_problem',\n",
       "   'packet',\n",
       "   'must',\n",
       "   'pass',\n",
       "   'low',\n",
       "   'left',\n",
       "   'switch'],\n",
       "  ['characteristics', 'array', 'record', 'table']],\n",
       " [['butterfly',\n",
       "   'holy',\n",
       "   'grail',\n",
       "   'switching',\n",
       "   'network',\n",
       "   'would',\n",
       "   'combine',\n",
       "   'good',\n",
       "   'property',\n",
       "   'complete_binary_tree',\n",
       "   'low',\n",
       "   'diameter',\n",
       "   'switch',\n",
       "   'array',\n",
       "   'low',\n",
       "   'congestion'],\n",
       "  ['butterfly', 'widely', 'use', 'compromise'],\n",
       "  ['butterfly',\n",
       "   'network',\n",
       "   'input',\n",
       "   'show_figure',\n",
       "   'structure',\n",
       "   'butterfly',\n",
       "   'certainly',\n",
       "   'complicate',\n",
       "   'com',\n",
       "   'plete',\n",
       "   'binary',\n",
       "   'array'],\n",
       "  ['let_see', 'construct'],\n",
       "  ['terminal', 'switch', 'network', 'row'],\n",
       "  ['particular',\n",
       "   'input',\n",
       "   'leave',\n",
       "   'end',\n",
       "   'row',\n",
       "   'output',\n",
       "   'right',\n",
       "   'end',\n",
       "   'row'],\n",
       "  ['let',\n",
       "   'label',\n",
       "   'row',\n",
       "   'binary',\n",
       "   'label',\n",
       "   'row',\n",
       "   'binary',\n",
       "   'number',\n",
       "   'log',\n",
       "   'inputs',\n",
       "   'output',\n",
       "   'log'],\n",
       "  ['level', 'switch', 'num', 'bered', 'log'],\n",
       "  ['level', 'consist', 'column', 'switch', 'row'],\n",
       "  ['thus', 'switch', 'network', 'uniquely', 'identify', 'sequence'],\n",
       "  ['log_log', 'remain', 'describe', 'switch', 'connect'],\n",
       "  ['basic', 'level', 'figure'],\n",
       "  ['input_output', 'butterfly'],\n",
       "  ['chapter_direct_graphs',\n",
       "   'connection',\n",
       "   'pattern',\n",
       "   'express',\n",
       "   'compact',\n",
       "   'notation',\n",
       "   'say',\n",
       "   'direct_edge',\n",
       "   'switch'],\n",
       "  ['log',\n",
       "   'lc',\n",
       "   'butterfly',\n",
       "   'network',\n",
       "   'recursive',\n",
       "   'structure',\n",
       "   'specifically',\n",
       "   'butterfly',\n",
       "   'size',\n",
       "   'consist',\n",
       "   'butterfly',\n",
       "   'size',\n",
       "   'additional',\n",
       "   'level',\n",
       "   'switch'],\n",
       "  ['switch',\n",
       "   'additional',\n",
       "   'level',\n",
       "   'direct_edge',\n",
       "   'correspond',\n",
       "   'switch',\n",
       "   'small',\n",
       "   'butterfly'],\n",
       "  ['example',\n",
       "   'see_figure',\n",
       "   'relatively',\n",
       "   'complicated',\n",
       "   'structure',\n",
       "   'butterfly',\n",
       "   'simple',\n",
       "   'way',\n",
       "   'route_packet',\n",
       "   'switch'],\n",
       "  ['particular',\n",
       "   'suppose_want',\n",
       "   'send',\n",
       "   'packet',\n",
       "   'input',\n",
       "   'log_log',\n",
       "   'log_log',\n",
       "   'log_log',\n",
       "   'log',\n",
       "   'fact',\n",
       "   'path',\n",
       "   'input_output',\n",
       "   'congestion',\n",
       "   'butterfly',\n",
       "   'network'],\n",
       "  ['precisely', 'con', 'gestion', 'even', 'power', 'odd', 'power'],\n",
       "  ['task', 'prove', 'fact', 'leave', 'problem_section'],\n",
       "  ['comparison',\n",
       "   'butterfly',\n",
       "   'complete_binary_tree',\n",
       "   'array',\n",
       "   'provide',\n",
       "   'table',\n",
       "   'routing',\n",
       "   'problem',\n",
       "   'result',\n",
       "   'congestion',\n",
       "   'arise_practice',\n",
       "   'routing',\n",
       "   'problem',\n",
       "   'congestion',\n",
       "   'much',\n",
       "   'low',\n",
       "   'log',\n",
       "   'reason',\n",
       "   'butterfly',\n",
       "   'useful',\n",
       "   'practice'],\n",
       "  ['level', 'figure'],\n",
       "  ['input',\n",
       "   'butterfly',\n",
       "   'contain',\n",
       "   'input',\n",
       "   'butterfly',\n",
       "   'show',\n",
       "   'dash',\n",
       "   'box'],\n",
       "  ['switch',\n",
       "   'first',\n",
       "   'level',\n",
       "   'adjacent',\n",
       "   'corresponding',\n",
       "   'switch',\n",
       "   'sub',\n",
       "   'butterfly'],\n",
       "  ['example', 'use', 'dash', 'line', 'show', 'edge', 'node'],\n",
       "  ['table'],\n",
       "  ['comparison', 'figure'],\n",
       "  ['input', 'benes_network'],\n",
       "  ['array'],\n",
       "  ['however',\n",
       "   'butterfly',\n",
       "   'capture',\n",
       "   'good',\n",
       "   'quality',\n",
       "   'network',\n",
       "   'rather',\n",
       "   'compromise',\n",
       "   'somewhere'],\n",
       "  ['quest', 'holy', 'grail', 'route', 'network', 'go']],\n",
       " [['benes_network',\n",
       "   'researcher',\n",
       "   'bell',\n",
       "   'labs',\n",
       "   'name',\n",
       "   'vaclav',\n",
       "   'benes',\n",
       "   'remarkable',\n",
       "   'idea'],\n",
       "  ['obtain',\n",
       "   'marvelous',\n",
       "   'communication_network',\n",
       "   'congestion',\n",
       "   'place',\n",
       "   'butterfly',\n",
       "   'back',\n",
       "   'back'],\n",
       "  ['example',\n",
       "   'input',\n",
       "   'benes_network',\n",
       "   'show_figure',\n",
       "   'put',\n",
       "   'butterfly',\n",
       "   'back',\n",
       "   'roughly',\n",
       "   'double',\n",
       "   'number',\n",
       "   'switch',\n",
       "   'diameter',\n",
       "   'single',\n",
       "   'butterfly',\n",
       "   'completely',\n",
       "   'eliminate',\n",
       "   'congestion',\n",
       "   'problem',\n",
       "   'proof',\n",
       "   'fact',\n",
       "   'rely',\n",
       "   'clever',\n",
       "   'induction',\n",
       "   'argument',\n",
       "   'come',\n",
       "   'table'],\n",
       "  ['comparison', 'figure'],\n",
       "  ['input', 'benes_network'],\n",
       "  ['moment'],\n",
       "  ['let', 'first', 'see', 'benes_network', 'stack', 'network', 'study'],\n",
       "  ['see', 'table', 'theorem'],\n",
       "  ['congestion', 'power'],\n",
       "  ['proof'],\n",
       "  ['use_induction'],\n",
       "  ['let'],\n",
       "  ['base_case',\n",
       "   'possible',\n",
       "   'permutation',\n",
       "   'route_problem',\n",
       "   'input',\n",
       "   'network'],\n",
       "  ['inductive_step',\n",
       "   'imply',\n",
       "   'assume',\n",
       "   'congestion',\n",
       "   'digression',\n",
       "   'time',\n",
       "   'let',\n",
       "   'work',\n",
       "   'example',\n",
       "   'develop',\n",
       "   'intuition',\n",
       "   'com',\n",
       "   'plete',\n",
       "   'proof'],\n",
       "  ['notice', 'benes_network', 'size', 'chapter_direct_graphs', 'figure'],\n",
       "  ['show',\n",
       "   'size',\n",
       "   'inductive',\n",
       "   'assumption',\n",
       "   'subnetwork',\n",
       "   'route',\n",
       "   'arbitrary',\n",
       "   'mutation',\n",
       "   'congestion'],\n",
       "  ['guide',\n",
       "   'packet',\n",
       "   'safely',\n",
       "   'first',\n",
       "   'last',\n",
       "   'level',\n",
       "   'rely',\n",
       "   'induction',\n",
       "   'rest',\n",
       "   'let_see',\n",
       "   'work',\n",
       "   'example'],\n",
       "  ['consider_follow',\n",
       "   'permutation',\n",
       "   'routing',\n",
       "   'problem',\n",
       "   'route_packet',\n",
       "   'destination',\n",
       "   'upper',\n",
       "   'subnetwork',\n",
       "   'low',\n",
       "   'subnetwork'],\n",
       "  ['however', 'choice', 'packet', 'may', 'constrain', 'choice'],\n",
       "  ['example',\n",
       "   'route_packet',\n",
       "   'inputs',\n",
       "   'network',\n",
       "   'would',\n",
       "   'cause',\n",
       "   'packet',\n",
       "   'collide',\n",
       "   'single',\n",
       "   'switch',\n",
       "   'result',\n",
       "   'congestion'],\n",
       "  ['packet', 'must', 'go', 'upper', 'network', 'low', 'network'],\n",
       "  ['similarly', 'packet', 'inputs', 'figure'],\n",
       "  ['beginning', 'constraint_graph', 'packet', 'routing', 'problem'],\n",
       "  ['adjacent', 'packet', 'can', 'route', 'use', 'sub', 'benes_network'],\n",
       "  ['figure'],\n",
       "  ['update', 'constraint_graph'],\n",
       "  ['must', 'route', 'different', 'network'],\n",
       "  ['let', 'record', 'constraint_graph'],\n",
       "  ['vertex', 'packet', 'label', 'accord', 'input', 'position'],\n",
       "  ['packet', 'must', 'pass', 'different', 'network', 'edge'],\n",
       "  ['result',\n",
       "   'constraint_graph',\n",
       "   'illustrate_figure',\n",
       "   'output',\n",
       "   'side',\n",
       "   'network',\n",
       "   'impose',\n",
       "   'constraint'],\n",
       "  ['example',\n",
       "   'packet',\n",
       "   'destine',\n",
       "   'output',\n",
       "   'packet',\n",
       "   'packet',\n",
       "   'destine',\n",
       "   'output',\n",
       "   'packet',\n",
       "   'pass',\n",
       "   'network',\n",
       "   'would',\n",
       "   'require',\n",
       "   'packet',\n",
       "   'arrive',\n",
       "   'switch'],\n",
       "  ['similarly',\n",
       "   'packet',\n",
       "   'destine',\n",
       "   'output',\n",
       "   'must_also',\n",
       "   'pass',\n",
       "   'different',\n",
       "   'switch'],\n",
       "  ['record',\n",
       "   'additional',\n",
       "   'constraint',\n",
       "   'constraint_graph',\n",
       "   'gray',\n",
       "   'edge',\n",
       "   'illustrate_figure',\n",
       "   'notice',\n",
       "   'new',\n",
       "   'edge_incident',\n",
       "   'vertex'],\n",
       "  ['line',\n",
       "   'draw',\n",
       "   'vertex',\n",
       "   'reflect',\n",
       "   'different',\n",
       "   'reason',\n",
       "   'packet',\n",
       "   'must',\n",
       "   'route',\n",
       "   'different',\n",
       "   'network'],\n",
       "  ['however',\n",
       "   'intend',\n",
       "   'simple',\n",
       "   'graph',\n",
       "   'chapter_direct_graphs',\n",
       "   'line',\n",
       "   'still',\n",
       "   'signify',\n",
       "   'single',\n",
       "   'edge'],\n",
       "  ['key',\n",
       "   'insight',\n",
       "   'color',\n",
       "   'graph',\n",
       "   'correspond',\n",
       "   'solution',\n",
       "   'route_problem',\n",
       "   'red',\n",
       "   'blue',\n",
       "   'adjacent_vertex',\n",
       "   'color',\n",
       "   'differently'],\n",
       "  ['constraint',\n",
       "   'satisfy',\n",
       "   'send',\n",
       "   'red',\n",
       "   'packet',\n",
       "   'upper',\n",
       "   'network',\n",
       "   'blue',\n",
       "   'packet',\n",
       "   'low',\n",
       "   'network'],\n",
       "  ['remain', 'question', 'constraint_graph', 'colorable'],\n",
       "  ['tunately', 'easy', 'verify', 'lemma'],\n",
       "  ['edges',\n",
       "   'undirected_graph',\n",
       "   'group',\n",
       "   'set',\n",
       "   'vertex',\n",
       "   'incident_edge',\n",
       "   'set',\n",
       "   'graph_colorable'],\n",
       "  ['proof'],\n",
       "  ['set',\n",
       "   'edge',\n",
       "   'may',\n",
       "   'overlap',\n",
       "   'let',\n",
       "   'call',\n",
       "   'edge',\n",
       "   'set',\n",
       "   'double',\n",
       "   'edge',\n",
       "   'theorem',\n",
       "   'even',\n",
       "   'length'],\n",
       "  ['example',\n",
       "   'color',\n",
       "   'constraint_graph',\n",
       "   'figure_show',\n",
       "   'figure',\n",
       "   'proof_theorem',\n",
       "   'continue',\n",
       "   'let',\n",
       "   'arbitrary',\n",
       "   'permutation'],\n",
       "  ['graph_vertex',\n",
       "   'packet',\n",
       "   'number_edge',\n",
       "   'come',\n",
       "   'union_set',\n",
       "   'wwdf',\n",
       "   'fu',\n",
       "   'vg',\n",
       "   'ju',\n",
       "   'vj',\n",
       "   'wwdf',\n",
       "   'fu'],\n",
       "  ['vertex', 'fu', 'fu', 'blue', 'blue', 'blue', 'red', 'figure'],\n",
       "  ['color', 'constraint_graph', 'figure', 'vertex'],\n",
       "  ['route_packet',\n",
       "   'color',\n",
       "   'upper',\n",
       "   'subnetwork',\n",
       "   'packet',\n",
       "   'color',\n",
       "   'low',\n",
       "   'subnetwork'],\n",
       "  ['edge', 'subnetwork', 'induction_hypothesis']],\n",
       " [['relation_partial_order',\n",
       "   'relation',\n",
       "   'mathematical',\n",
       "   'tool',\n",
       "   'describe',\n",
       "   'association',\n",
       "   'element_set'],\n",
       "  ['relation',\n",
       "   'widely',\n",
       "   'use',\n",
       "   'computer_science',\n",
       "   'especially',\n",
       "   'database',\n",
       "   'schedule',\n",
       "   'application'],\n",
       "  ['relation',\n",
       "   'define',\n",
       "   'many',\n",
       "   'item',\n",
       "   'many',\n",
       "   'set',\n",
       "   'text',\n",
       "   'focus',\n",
       "   'binary_relation',\n",
       "   'represent',\n",
       "   'association',\n",
       "   'item_set']],\n",
       " [['binary_relation']],\n",
       " [['definition', 'example', 'definition'],\n",
       "  ['give', 'set', 'binary_relation', 'subset'],\n",
       "  ['set', 'call', 'domain', 'codomain', 'respectively'],\n",
       "  ['commonly_use', 'notation', 'arb', 'relation', 'similar', 'function'],\n",
       "  ['fact', 'function', 'rela', 'tion'],\n",
       "  ['general',\n",
       "   'difference',\n",
       "   'function',\n",
       "   'relation',\n",
       "   'relation',\n",
       "   'may',\n",
       "   'associate',\n",
       "   'multiple',\n",
       "   'element',\n",
       "   'ofb',\n",
       "   'single',\n",
       "   'element',\n",
       "   'ofa',\n",
       "   'func_tion',\n",
       "   'associate',\n",
       "   'element',\n",
       "   'namely'],\n",
       "  ['element'],\n",
       "  ['already', 'encounter', 'example', 'relation', 'early', 'chapter'],\n",
       "  ['ex',\n",
       "   'ample',\n",
       "   'section',\n",
       "   'rc',\n",
       "   'rs',\n",
       "   'example',\n",
       "   'define',\n",
       "   'charge',\n",
       "   'relation',\n",
       "   'set',\n",
       "   'mit',\n",
       "   'faculty',\n",
       "   'set',\n",
       "   'subject',\n",
       "   'mit',\n",
       "   'course',\n",
       "   'catalog'],\n",
       "  ['relation', 'contain', 'pair', 'form', 'also', 'say', 'relationship'],\n",
       "  ['chapter_relation', 'partial_order'],\n",
       "  ['uat'],\n",
       "  ['figure'],\n",
       "  ['item', 'charge', 'relation', 'faculty', 'sub', 'ject', 'number'],\n",
       "  ['faculty',\n",
       "   'member',\n",
       "   'name',\n",
       "   'hinstructor',\n",
       "   'namei',\n",
       "   'charge_subject',\n",
       "   'number',\n",
       "   'hsubject',\n",
       "   'numi'],\n",
       "  ['contain',\n",
       "   'pair',\n",
       "   'show_figure',\n",
       "   'surprisingly',\n",
       "   'complicate',\n",
       "   'relation',\n",
       "   'meyer',\n",
       "   'charge_subject',\n",
       "   'number'],\n",
       "  ['leighton',\n",
       "   'also',\n",
       "   'charge_subject',\n",
       "   'number',\n",
       "   'subject',\n",
       "   'mathematic',\n",
       "   'computer_science',\n",
       "   'number'],\n",
       "  ['meyer', 'leighton', 'jointly', 'charge_subject'],\n",
       "  ['freeman',\n",
       "   'charge',\n",
       "   'even',\n",
       "   'subject',\n",
       "   'number',\n",
       "   'around',\n",
       "   'department',\n",
       "   'education',\n",
       "   'officer',\n",
       "   'charge',\n",
       "   'whole',\n",
       "   'block',\n",
       "   'special',\n",
       "   'sub',\n",
       "   'ject',\n",
       "   'number'],\n",
       "  ['subject'],\n",
       "  ['person', 'charge'],\n",
       "  ['faculty',\n",
       "   'guttag',\n",
       "   'charge_subject',\n",
       "   'number',\n",
       "   'else',\n",
       "   'jointly',\n",
       "   'charge_subject'],\n",
       "  ['subject',\n",
       "   'codomain',\n",
       "   'appear',\n",
       "   'list_element',\n",
       "   'pair',\n",
       "   'graph',\n",
       "   'fall',\n",
       "   'term',\n",
       "   'subject'],\n",
       "  ['similarly',\n",
       "   'faculty',\n",
       "   'domain',\n",
       "   'appear',\n",
       "   'list',\n",
       "   'charge_subject',\n",
       "   'fall',\n",
       "   'term']],\n",
       " [['representation',\n",
       "   'bipartite_graph',\n",
       "   'relation',\n",
       "   'easily',\n",
       "   'represent',\n",
       "   'bipartite_graph'],\n",
       "  ['create', 'leave', 'node', 'element', 'right', 'node', 'element'],\n",
       "  ['create', 'edge', 'leave', 'node', 'right', 'node', 'whenever', 'arb'],\n",
       "  ['similarly',\n",
       "   'bipartite_graph',\n",
       "   'partition',\n",
       "   'node_leave',\n",
       "   'right',\n",
       "   'set',\n",
       "   'edge_connect',\n",
       "   'pair',\n",
       "   'leave',\n",
       "   'node',\n",
       "   'pair',\n",
       "   'right',\n",
       "   'node',\n",
       "   'determine',\n",
       "   'relation',\n",
       "   'node_leave',\n",
       "   'node',\n",
       "   'right'],\n",
       "  ['meyer', 'leighton', 'freeman', 'eng', 'guttag', 'uat', 'figure'],\n",
       "  ['part',\n",
       "   'bipartite_graph',\n",
       "   'charge',\n",
       "   'relation',\n",
       "   'fig_ure',\n",
       "   'example',\n",
       "   'show',\n",
       "   'part',\n",
       "   'bipartite_graph',\n",
       "   'charge',\n",
       "   'relation',\n",
       "   'figure',\n",
       "   'figure',\n",
       "   'hinstructor',\n",
       "   'namei',\n",
       "   'hsubject',\n",
       "   'numberi',\n",
       "   'hinstructor',\n",
       "   'namei',\n",
       "   'charge',\n",
       "   'hsubject',\n",
       "   'numberi'],\n",
       "  ['relation',\n",
       "   'finite_set',\n",
       "   'also',\n",
       "   'represent',\n",
       "   'matrix',\n",
       "   'ij',\n",
       "   'jaj',\n",
       "   'jbj'],\n",
       "  ['example', 'matrix', 'relation', 'figure']],\n",
       " [['relational',\n",
       "   'image',\n",
       "   'idea',\n",
       "   'image_set',\n",
       "   'function',\n",
       "   'extend',\n",
       "   'directly',\n",
       "   'relation'],\n",
       "  ['chapter_relation', 'partial_order', 'figure'],\n",
       "  ['matrix',\n",
       "   'charge',\n",
       "   'relation',\n",
       "   'restrict',\n",
       "   'faculty',\n",
       "   'subject',\n",
       "   'number',\n",
       "   'show_figure',\n",
       "   'definition'],\n",
       "  ['image_set', 'relation', 'write'],\n",
       "  ['set', 'element', 'relate', 'element', 'namely'],\n",
       "  ['wwd', 'yrb', 'image', 'domain'],\n",
       "  ['call', 'range'],\n",
       "  ['example',\n",
       "   'find',\n",
       "   'subject',\n",
       "   'number',\n",
       "   'meyer',\n",
       "   'charge',\n",
       "   'look',\n",
       "   'pair',\n",
       "   'form',\n",
       "   'graph',\n",
       "   'teaching',\n",
       "   'relation',\n",
       "   'list',\n",
       "   'right',\n",
       "   'hand_side',\n",
       "   'pair'],\n",
       "  ['right', 'hand_side', 'exactly', 'image'],\n",
       "  ['meyer', 'happen'],\n",
       "  ['similarly', 'domain', 'set', 'charge', 'faculty'],\n",
       "  ['range', 'exactly', 'set', 'subject', 'teach']],\n",
       " [['inverse', 'relation', 'image', 'definition'],\n",
       "  ['inverse', 'image_set', 'relation', 'call', 'inverse', 'image_set'],\n",
       "  ['inverse',\n",
       "   'image_set',\n",
       "   'relation',\n",
       "   'continue',\n",
       "   'charge',\n",
       "   'example',\n",
       "   'find',\n",
       "   'faculty',\n",
       "   'charge'],\n",
       "  ['uat',\n",
       "   'take',\n",
       "   'pair',\n",
       "   'form',\n",
       "   'teach',\n",
       "   'relation',\n",
       "   'list',\n",
       "   'left',\n",
       "   'hand_side',\n",
       "   'pair',\n",
       "   'turn',\n",
       "   'eng',\n",
       "   'freeman'],\n",
       "  ['left', 'hand_side', 'exactly', 'inverse', 'image'],\n",
       "  ['uatg']],\n",
       " [['combine',\n",
       "   'relation',\n",
       "   'least',\n",
       "   'natural_way',\n",
       "   'combine',\n",
       "   'relation',\n",
       "   'form',\n",
       "   'new',\n",
       "   'relation'],\n",
       "  ['example', 'give', 'relation', 'composition', 'relation'],\n",
       "  ['define', 'rule'],\n",
       "  ['iff'],\n",
       "  ['special_case', 'composition', 'function', 'function', 'define'],\n",
       "  ['example'],\n",
       "  ['also', 'define', 'product', 'relation', 'swa', 'iff']],\n",
       " [['relation', 'cardinality']],\n",
       " [['surjective',\n",
       "   'injective',\n",
       "   'relation',\n",
       "   'propertie',\n",
       "   'relation',\n",
       "   'useful',\n",
       "   'take',\n",
       "   'topic',\n",
       "   'count',\n",
       "   'part',\n",
       "   'imply',\n",
       "   'certain',\n",
       "   'relation',\n",
       "   'size',\n",
       "   'domain',\n",
       "   'codomain'],\n",
       "  ['particular',\n",
       "   'say',\n",
       "   'binary_relation',\n",
       "   'surjective',\n",
       "   'element',\n",
       "   'assign',\n",
       "   'least',\n",
       "   'element'],\n",
       "  ['concisely', 'surjective', 'iff'],\n",
       "  ['range',\n",
       "   'codomain',\n",
       "   'chapter_relation',\n",
       "   'partial_order',\n",
       "   'total',\n",
       "   'element',\n",
       "   'assign',\n",
       "   'element'],\n",
       "  ['concisely',\n",
       "   'total',\n",
       "   'iff',\n",
       "   'injective',\n",
       "   'element',\n",
       "   'map',\n",
       "   'bijective',\n",
       "   'total',\n",
       "   'surjective',\n",
       "   'injective',\n",
       "   'function',\n",
       "   'illustrate',\n",
       "   'property',\n",
       "   'relation',\n",
       "   'term',\n",
       "   'cor',\n",
       "   'respond',\n",
       "   'bipartite_graph',\n",
       "   'relation',\n",
       "   'node_leave',\n",
       "   'side',\n",
       "   'correspond',\n",
       "   'element',\n",
       "   'node',\n",
       "   'right_side',\n",
       "   'correspond',\n",
       "   'ele',\n",
       "   'ment'],\n",
       "  ['example',\n",
       "   'example_consider',\n",
       "   'relation',\n",
       "   'notice',\n",
       "   'need',\n",
       "   'know',\n",
       "   'domain',\n",
       "   'determine',\n",
       "   'relation',\n",
       "   'total',\n",
       "   'nee',\n",
       "   'know',\n",
       "   'codomain',\n",
       "   'determine',\n",
       "   'surjective'],\n",
       "  ['example',\n",
       "   'function',\n",
       "   'define',\n",
       "   'formula',\n",
       "   'word',\n",
       "   'surjective',\n",
       "   'injective',\n",
       "   'bijective',\n",
       "   'memorable'],\n",
       "  ['author',\n",
       "   'use',\n",
       "   'possibly',\n",
       "   'memorable',\n",
       "   'phrase',\n",
       "   'surjective',\n",
       "   'injective',\n",
       "   'exact',\n",
       "   'correspon',\n",
       "   'dence',\n",
       "   'bijective'],\n",
       "  ['show']],\n",
       " [['cardinality',\n",
       "   'relational',\n",
       "   'properties',\n",
       "   'section',\n",
       "   'useful',\n",
       "   'figuring',\n",
       "   'relative',\n",
       "   'size',\n",
       "   'domain',\n",
       "   'codomain'],\n",
       "  ['finite_set', 'use', 'jaj', 'denote', 'number', 'element'],\n",
       "  ['call', 'cardinality'],\n",
       "  ['general',\n",
       "   'finite_set',\n",
       "   'may',\n",
       "   'element',\n",
       "   'empty',\n",
       "   'set',\n",
       "   'element',\n",
       "   'element'],\n",
       "  ['nonnegative_integer', 'number', 'element', 'finite_set', 'jaj'],\n",
       "  ['suppose', 'function'],\n",
       "  ['edge', 'bipartite_graph'],\n",
       "  ['incident', 'exactly', 'element', 'num_ber', 'edge', 'number', 'element'],\n",
       "  ['function',\n",
       "   'jej',\n",
       "   'similarly',\n",
       "   'surjective',\n",
       "   'element',\n",
       "   'incident_edge',\n",
       "   'must',\n",
       "   'least',\n",
       "   'many',\n",
       "   'edge',\n",
       "   'graph',\n",
       "   'size'],\n",
       "  ['jej',\n",
       "   'jbj',\n",
       "   'combine',\n",
       "   'inequality',\n",
       "   'imply',\n",
       "   'surjective',\n",
       "   'function',\n",
       "   'jb'],\n",
       "  ['fact',\n",
       "   'similar',\n",
       "   'rule',\n",
       "   'relate',\n",
       "   'domain',\n",
       "   'codomain',\n",
       "   'size',\n",
       "   'relational',\n",
       "   'property',\n",
       "   'capture',\n",
       "   'follow',\n",
       "   'theorem'],\n",
       "  ['chapter_relation', 'partial_order', 'theorem'],\n",
       "  ['mapping_rule'],\n",
       "  ['let', 'finite_set'],\n",
       "  ['surjection', 'jaj', 'jbj'],\n",
       "  ['injection', 'jaj', 'jbj', 'bijection', 'jbj'],\n",
       "  ['mapping_rule',\n",
       "   'explain',\n",
       "   'kind',\n",
       "   'reasoning',\n",
       "   'use',\n",
       "   'rule',\n",
       "   'immediate',\n",
       "   'consequence',\n",
       "   'first',\n",
       "   'mapping_rule'],\n",
       "  ['see',\n",
       "   'many',\n",
       "   'example',\n",
       "   'theorem',\n",
       "   'use',\n",
       "   'determine',\n",
       "   'car',\n",
       "   'dinality',\n",
       "   'finite_set'],\n",
       "  ['later', 'chapter']],\n",
       " [['relation',\n",
       "   'set',\n",
       "   'rest',\n",
       "   'chapter',\n",
       "   'go',\n",
       "   'focus',\n",
       "   'relationship',\n",
       "   'element',\n",
       "   'single',\n",
       "   'set',\n",
       "   'relation',\n",
       "   'set',\n",
       "   'set'],\n",
       "  ['thus', 'relation', 'set', 'subset'],\n",
       "  ['example',\n",
       "   'let',\n",
       "   'set',\n",
       "   'people',\n",
       "   'relation',\n",
       "   'describe',\n",
       "   'like',\n",
       "   'let',\n",
       "   'set',\n",
       "   'city'],\n",
       "  ['define', 'relation', 'xry', 'nonstop', 'flight', 'city', 'city'],\n",
       "  ['let', 'let', 'xry', 'hold'],\n",
       "  ['mod'],\n",
       "  ['let', 'let', 'xry'],\n",
       "  ['let', 'let', 'xry'],\n",
       "  ['last', 'example', 'clarify', 'reason', 'use', 'xry']],\n",
       " [['representation',\n",
       "   'digraph',\n",
       "   'relation',\n",
       "   'single',\n",
       "   'set',\n",
       "   'model',\n",
       "   'directed',\n",
       "   'graph',\n",
       "   'may',\n",
       "   'contain',\n",
       "   'loop'],\n",
       "  ['example',\n",
       "   'graph_figure',\n",
       "   'describe',\n",
       "   'like',\n",
       "   'relation',\n",
       "   'particular',\n",
       "   'set',\n",
       "   'people'],\n",
       "  ['case', 'see', 'julie', 'bob', 'figure'],\n",
       "  ['direct_graph', 'like', 'relation', 'set', 'fbill', 'bob', 'julieg'],\n",
       "  ['figure'],\n",
       "  ['digraph', 'divisibility'],\n",
       "  ['julie', 'likes', 'bill', 'bob'],\n",
       "  ['bill', 'like'],\n",
       "  ['bob', 'like', 'julie', 'bill'],\n",
       "  ['relationship', 'convey', 'direct_graph'],\n",
       "  ['coincidence',\n",
       "   'set',\n",
       "   'together',\n",
       "   'relation',\n",
       "   'precisely',\n",
       "   'thing',\n",
       "   'direct_graph'],\n",
       "  ['vertex', 'set', 'edge', 'set', 'may', 'loop'],\n",
       "  ['example',\n",
       "   'illustrate',\n",
       "   'direct_graph',\n",
       "   'divisibility',\n",
       "   'relationship',\n",
       "   'set',\n",
       "   'figure',\n",
       "   'relation',\n",
       "   'single',\n",
       "   'set',\n",
       "   'also',\n",
       "   'represent',\n",
       "   'matrix'],\n",
       "  ['case', 'matrix', 'identical', 'adjacency_matrix', 'correspond', 'digraph'],\n",
       "  ['chapter_relation',\n",
       "   'partial_order',\n",
       "   'example',\n",
       "   'matrix',\n",
       "   'relation',\n",
       "   'show_figure',\n",
       "   'simply']],\n",
       " [['symmetry',\n",
       "   'transitivity',\n",
       "   'special',\n",
       "   'property',\n",
       "   'many',\n",
       "   'relation',\n",
       "   'single',\n",
       "   'set',\n",
       "   'arise_practice',\n",
       "   'possess',\n",
       "   'noteworthy',\n",
       "   'property'],\n",
       "  ['property', 'summarize', 'box', 'follow', 'page'],\n",
       "  ['case',\n",
       "   'provide',\n",
       "   'formal',\n",
       "   'definition',\n",
       "   'property',\n",
       "   'explain',\n",
       "   'property',\n",
       "   'look',\n",
       "   'digraph',\n",
       "   'relation',\n",
       "   'give',\n",
       "   'example',\n",
       "   'property',\n",
       "   'mean',\n",
       "   'like',\n",
       "   'relation'],\n",
       "  ['example',\n",
       "   'congruence',\n",
       "   'relation',\n",
       "   'modulo',\n",
       "   'reflexive',\n",
       "   'symmetric',\n",
       "   'transitive',\n",
       "   'irreflexive',\n",
       "   'antisymmetric',\n",
       "   'asymmetric'],\n",
       "  ['true', 'connected', 'relation', 'undirected_graph'],\n",
       "  ['urv', 'connect_component', 'graph'],\n",
       "  ['fact',\n",
       "   'relation',\n",
       "   'property',\n",
       "   'common',\n",
       "   'give',\n",
       "   'special',\n",
       "   'name',\n",
       "   'equivalence_relation'],\n",
       "  ['discuss', 'great', 'detail', 'moment'],\n",
       "  ['example',\n",
       "   'divide',\n",
       "   'relation',\n",
       "   'final',\n",
       "   'example_consider',\n",
       "   'like',\n",
       "   'relation',\n",
       "   'set',\n",
       "   'fjulie',\n",
       "   'bill',\n",
       "   'bobg',\n",
       "   'il',\n",
       "   'lustrated',\n",
       "   'figure']],\n",
       " [['equivalence_relation',\n",
       "   'relation',\n",
       "   'equivalence_relation',\n",
       "   'reflexive',\n",
       "   'symmetric',\n",
       "   'transitive'],\n",
       "  ['congruence',\n",
       "   'modulo',\n",
       "   'excellent',\n",
       "   'example',\n",
       "   'equivalence_relation',\n",
       "   'reflexive'],\n",
       "  ['mod'],\n",
       "  ['symmetric'],\n",
       "  ['mod_imply'],\n",
       "  ['mod'],\n",
       "  ['transitive'],\n",
       "  ['mod'],\n",
       "  ['mod_imply',\n",
       "   'propertie',\n",
       "   'relation',\n",
       "   'reflexivity',\n",
       "   'reflexive',\n",
       "   'xrx',\n",
       "   'node',\n",
       "   'loop'],\n",
       "  ['irreflexivity', 'irreflexive', 'loop'],\n",
       "  ['symmetry', 'symmetric', 'xry', 'imply', 'edge', 'edge', 'well'],\n",
       "  ['antisymmetry', 'antisymmetric'],\n",
       "  ['xry', 'imply', 'directed_edge', 'pair', 'distinct', 'node'],\n",
       "  ['asymmetry', 'asymmetric', 'loop', 'directed_edge', 'pair_node'],\n",
       "  ['transitivity', 'transitive'],\n",
       "  ['xry',\n",
       "   'imply',\n",
       "   'walk',\n",
       "   'chapter_relation',\n",
       "   'partial_order',\n",
       "   'even_well',\n",
       "   'know',\n",
       "   'example',\n",
       "   'equivalence_relation',\n",
       "   'equality'],\n",
       "  ['thus', 'equivalence_relation', 'relation', 'share', 'key', 'property']],\n",
       " [['partition',\n",
       "   'way',\n",
       "   'think',\n",
       "   'equivalence_relation',\n",
       "   'need',\n",
       "   'couple',\n",
       "   'definition',\n",
       "   'understand',\n",
       "   'alternative',\n",
       "   'perspective'],\n",
       "  ['definition'],\n",
       "  ['give', 'equivalence_relation', 'example_suppose', 'xry'],\n",
       "  ['mod', 'notice'],\n",
       "  ['equivalence', 'class', 'definition'],\n",
       "  ['partition',\n",
       "   'finite_set',\n",
       "   'example',\n",
       "   'possible',\n",
       "   'partition',\n",
       "   'connection',\n",
       "   'stuff',\n",
       "   'exact',\n",
       "   'correspondence',\n",
       "   'equivalence_relation',\n",
       "   'theorem'],\n",
       "  ['equivalence',\n",
       "   'class',\n",
       "   'equivalence_relation',\n",
       "   'set',\n",
       "   'prove_theorem',\n",
       "   'dull',\n",
       "   'even',\n",
       "   'let_look',\n",
       "   'example'],\n",
       "  ['think', 'call', 'part', 'partition'],\n",
       "  ['think',\n",
       "   'make',\n",
       "   'lot',\n",
       "   'sense',\n",
       "   'congruent',\n",
       "   'mod',\n",
       "   'relation',\n",
       "   'partition',\n",
       "   'integer',\n",
       "   'equivalence',\n",
       "   'class',\n",
       "   'term'],\n",
       "  ['mod', 'equivalent', 'assertion', 'block', 'partition'],\n",
       "  ['example'],\n",
       "  ['mod', 'second', 'block'],\n",
       "  ['mod', 'third', 'block', 'last', 'block'],\n",
       "  ['social',\n",
       "   'term',\n",
       "   'like',\n",
       "   'equivalence_relation',\n",
       "   'would',\n",
       "   'partition',\n",
       "   'clique',\n",
       "   'friend',\n",
       "   'else']],\n",
       " [['partial_order']],\n",
       " [['strong', 'weak_partial_order', 'definition'],\n",
       "  ['relation',\n",
       "   'set',\n",
       "   'weak_partial_order',\n",
       "   'transitive',\n",
       "   'antisymmetric',\n",
       "   'reflexive'],\n",
       "  ['relation',\n",
       "   'say',\n",
       "   'strong',\n",
       "   'partial_order',\n",
       "   'transitive',\n",
       "   'antisymmetric',\n",
       "   'irreflexive'],\n",
       "  ['author',\n",
       "   'define',\n",
       "   'partial_order',\n",
       "   'call',\n",
       "   'weak_partial_order',\n",
       "   'use',\n",
       "   'phrase',\n",
       "   'partial_order',\n",
       "   'mean',\n",
       "   'weak',\n",
       "   'strong',\n",
       "   'partial_order'],\n",
       "  ['difference',\n",
       "   'weak_partial_order',\n",
       "   'strong',\n",
       "   'reflexivity',\n",
       "   'property',\n",
       "   'weak_partial_order',\n",
       "   'element',\n",
       "   'relate',\n",
       "   'strong',\n",
       "   'partial_order',\n",
       "   'element',\n",
       "   'relate'],\n",
       "  ['otherwise', 'transitive', 'antisymmetric'],\n",
       "  ['example',\n",
       "   'weak_partial_order',\n",
       "   'include',\n",
       "   'set',\n",
       "   'subset',\n",
       "   'say',\n",
       "   'divide',\n",
       "   'relation',\n",
       "   'equivalently',\n",
       "   'relation',\n",
       "   'transitive',\n",
       "   'asymmetric',\n",
       "   'state',\n",
       "   'way',\n",
       "   'may',\n",
       "   'obscure',\n",
       "   'irreflexivity',\n",
       "   'property'],\n",
       "  ['feel',\n",
       "   'comfortable',\n",
       "   'definition',\n",
       "   'throw',\n",
       "   'probably',\n",
       "   'good_idea',\n",
       "   'verify',\n",
       "   'relation',\n",
       "   'indeed',\n",
       "   'partial_order',\n",
       "   'check',\n",
       "   'transitivity',\n",
       "   'antisymmetry',\n",
       "   'property'],\n",
       "  ['chapter_relation',\n",
       "   'partial_order',\n",
       "   'often',\n",
       "   'denote',\n",
       "   'weak_partial_order',\n",
       "   'symbol',\n",
       "   'instead',\n",
       "   'letter'],\n",
       "  ['make_sense',\n",
       "   'perspective',\n",
       "   'symbol',\n",
       "   'call',\n",
       "   'mind',\n",
       "   'define',\n",
       "   'common',\n",
       "   'partial_order'],\n",
       "  ['hand',\n",
       "   'partial_order',\n",
       "   'really',\n",
       "   'set',\n",
       "   'related',\n",
       "   'pair',\n",
       "   'item',\n",
       "   'letter',\n",
       "   'would',\n",
       "   'normal'],\n",
       "  ['likewise', 'often', 'use', 'symbol', 'denote', 'strong', 'partial_order']],\n",
       " [['total_order', 'partial_order', 'partial', 'element', 'relation'],\n",
       "  ['example', 'divide', 'partial_order', 'relation', 'divide'],\n",
       "  ['general', 'say', 'element', 'incomparable'],\n",
       "  ['otherwise', 'say', 'comparable'],\n",
       "  ['definition'],\n",
       "  ['total_order',\n",
       "   'partial_order',\n",
       "   'pair',\n",
       "   'distinct',\n",
       "   'element',\n",
       "   'comparable'],\n",
       "  ['example', 'partial_order', 'total_order', 'pair', 'real_number', 'either'],\n",
       "  ['divide', 'partial_order', 'total_order']],\n",
       " [['poset', 'dag']],\n",
       " [['partially', 'order', 'set', 'definition'],\n",
       "  ['give', 'partial_order', 'set', 'pair'],\n",
       "  ['call', 'partially', 'order', 'set', 'poset'],\n",
       "  ['terms', 'graph_theory', 'poset', 'simply', 'direct_graph'],\n",
       "  ['vertex', 'set', 'edge', 'set'],\n",
       "  ['example', 'figure_show', 'graph', 'form', 'poset', 'divide', 'relation'],\n",
       "  ['show', 'graph', 'form', 'poset', 'relation', 'figure']],\n",
       " [['posets', 'acyclic', 'notice', 'common', 'figure', 'figure'],\n",
       "  ['represent', 'poset', 'relation', 'digraph'],\n",
       "  ['poset', 'acyclic_graph', 'dag', 'least', 'count', 'loop', 'cycle'],\n",
       "  ['prove', 'fact', 'follow', 'theorem'],\n",
       "  ['theorem'],\n",
       "  ['poset', 'direct', 'cycle', 'self', 'loop'],\n",
       "  ['proof'],\n",
       "  ['use', 'proof_contradiction'],\n",
       "  ['let'],\n",
       "  ['poset'],\n",
       "  ['suppose', 'exist', 'distinct', 'element', 'direct', 'cycle'],\n",
       "  ['thus',\n",
       "   'delete',\n",
       "   'self',\n",
       "   'loop',\n",
       "   'poset',\n",
       "   'leave',\n",
       "   'direct_graph',\n",
       "   'cycle',\n",
       "   'make',\n",
       "   'direct',\n",
       "   'acyclic_graph',\n",
       "   'dag']],\n",
       " [['transitive_closure', 'theorem', 'tell', 'poset', 'correspond', 'dag'],\n",
       "  ['reverse',\n",
       "   'true',\n",
       "   'dag',\n",
       "   'correspond',\n",
       "   'poset',\n",
       "   'answer',\n",
       "   'need',\n",
       "   'modify',\n",
       "   'dag',\n",
       "   'make',\n",
       "   'sure',\n",
       "   'satisfie',\n",
       "   'transitivity',\n",
       "   'property'],\n",
       "  ['example_consider',\n",
       "   'dag',\n",
       "   'show_figure',\n",
       "   'satisfy',\n",
       "   'transitivity',\n",
       "   'property',\n",
       "   'digraph',\n",
       "   'would',\n",
       "   'cycle',\n",
       "   'length',\n",
       "   'could',\n",
       "   'dag'],\n",
       "  ['chapter_relation', 'partial_order', 'figure'],\n",
       "  ['node', 'digraph', 'satisfy', 'transitivity', 'property'],\n",
       "  ['figure'],\n",
       "  ['transitive_closure', 'digraph', 'figure', 'definition'],\n",
       "  ['give', 'digraph'],\n",
       "  ['transitive_closure',\n",
       "   'digraph',\n",
       "   'similarly',\n",
       "   'relation',\n",
       "   'correspond',\n",
       "   'transitive_closure',\n",
       "   'note',\n",
       "   'example',\n",
       "   'transitive_closure',\n",
       "   'graph_figure',\n",
       "   'show',\n",
       "   'fig_ure',\n",
       "   'dag',\n",
       "   'transitive_closure',\n",
       "   'strong',\n",
       "   'partial_order'],\n",
       "  ['proof', 'fact', 'leave', 'exercise', 'problem_section']],\n",
       " [['hasse_diagram',\n",
       "   'problem',\n",
       "   'view',\n",
       "   'poset',\n",
       "   'digraph',\n",
       "   'tend',\n",
       "   'lot',\n",
       "   'edge',\n",
       "   'due',\n",
       "   'transitivity',\n",
       "   'property'],\n",
       "  ['fortunately', 'necessarily', 'draw', 'figure'],\n",
       "  ['hasse_diagram',\n",
       "   'poset',\n",
       "   'figure',\n",
       "   'edge',\n",
       "   'know',\n",
       "   'digraph',\n",
       "   'correspond',\n",
       "   'poset'],\n",
       "  ['example',\n",
       "   'could',\n",
       "   'choose',\n",
       "   'draw',\n",
       "   'edge',\n",
       "   'would',\n",
       "   'imply',\n",
       "   'transitivity',\n",
       "   'property',\n",
       "   'know',\n",
       "   'really',\n",
       "   'implication'],\n",
       "  ['general', 'hasse_diagram', 'poset'],\n",
       "  ['digraph',\n",
       "   'vertex',\n",
       "   'set',\n",
       "   'edge',\n",
       "   'set',\n",
       "   'minus',\n",
       "   'self',\n",
       "   'loop',\n",
       "   'edge',\n",
       "   'imply',\n",
       "   'transitivity'],\n",
       "  ['example', 'hasse_diagram', 'poset', 'show_figure', 'show_figure']],\n",
       " [['topological_sort',\n",
       "   'total_order',\n",
       "   'consistent',\n",
       "   'partial_order',\n",
       "   'call',\n",
       "   'topological_sort'],\n",
       "  ['precisely', 'definition'],\n",
       "  ['topological_sort', 'poset'],\n",
       "  ['total_order'],\n",
       "  ['imply',\n",
       "   'example_consider',\n",
       "   'poset',\n",
       "   'describe',\n",
       "   'guy',\n",
       "   'may',\n",
       "   'dress',\n",
       "   'formal',\n",
       "   'occasion'],\n",
       "  ['hasse_diagram',\n",
       "   'poset',\n",
       "   'show_figure',\n",
       "   'chapter_relation',\n",
       "   'partial_order',\n",
       "   'leave',\n",
       "   'sock',\n",
       "   'right',\n",
       "   'sock',\n",
       "   'underwear',\n",
       "   'shirt',\n",
       "   'leave',\n",
       "   'shoe',\n",
       "   'right',\n",
       "   'shoe',\n",
       "   'belt',\n",
       "   'jacket',\n",
       "   'figure'],\n",
       "  ['hasse_diagram',\n",
       "   'poset',\n",
       "   'describe',\n",
       "   'item',\n",
       "   'much',\n",
       "   'pre',\n",
       "   'cede',\n",
       "   'other',\n",
       "   'get',\n",
       "   'dress'],\n",
       "  ['poset',\n",
       "   'set',\n",
       "   'garment',\n",
       "   'partial_order',\n",
       "   'specify',\n",
       "   'item',\n",
       "   'much',\n",
       "   'precede',\n",
       "   'other',\n",
       "   'get',\n",
       "   'dress'],\n",
       "  ['several',\n",
       "   'total_order',\n",
       "   'consistent',\n",
       "   'partial_order',\n",
       "   'show_figure',\n",
       "   'theorem'],\n",
       "  ['finite', 'poset', 'topological_sort'],\n",
       "  ['prove_theorem', 'constructively'],\n",
       "  ['basic',\n",
       "   'idea',\n",
       "   'pull',\n",
       "   'small',\n",
       "   'element',\n",
       "   'poset',\n",
       "   'find',\n",
       "   'topological_sort',\n",
       "   'remainder',\n",
       "   'recursively',\n",
       "   'add',\n",
       "   'back',\n",
       "   'topological_sort',\n",
       "   'element',\n",
       "   'small',\n",
       "   'other'],\n",
       "  ['first',\n",
       "   'hurdle',\n",
       "   'small',\n",
       "   'simple',\n",
       "   'concept',\n",
       "   'set',\n",
       "   'partially',\n",
       "   'order'],\n",
       "  ['poset'],\n",
       "  ['element', 'minimal_element'],\n",
       "  ['example',\n",
       "   'minimal_element',\n",
       "   'get',\n",
       "   'dress',\n",
       "   'poset',\n",
       "   'leave',\n",
       "   'sock',\n",
       "   'right',\n",
       "   'sock',\n",
       "   'underwear',\n",
       "   'shirt'],\n",
       "  ['may_seem', 'figure'],\n",
       "  ['possible',\n",
       "   'topological_sort',\n",
       "   'poset',\n",
       "   'show_figure',\n",
       "   'odd',\n",
       "   'minimal_element',\n",
       "   'top',\n",
       "   'hasse_diagram',\n",
       "   'rather',\n",
       "   'bottom'],\n",
       "  ['people', 'adopt', 'opposite', 'convention'],\n",
       "  ['sure', 'minimal_element', 'top', 'bottom', 'particular', 'context', 'ask'],\n",
       "  ['similarly', 'element', 'maximal', 'element'],\n",
       "  ['prove', 'poset', 'minimal_element', 'extremely', 'difficult', 'true'],\n",
       "  ['example', 'poset'],\n",
       "  ['minimal_element'],\n",
       "  ['however', 'least', 'minimal_element', 'finite', 'poset'],\n",
       "  ['lemma'],\n",
       "  ['finite', 'poset', 'minimal_element'],\n",
       "  ['proof'],\n",
       "  ['let'],\n",
       "  ['arbitrary', 'poset'],\n",
       "  ['let',\n",
       "   'existence',\n",
       "   'maximum',\n",
       "   'length',\n",
       "   'sequence',\n",
       "   'follow',\n",
       "   'well_order',\n",
       "   'principle',\n",
       "   'fact',\n",
       "   'finite'],\n",
       "  ['cycle',\n",
       "   'exist',\n",
       "   'poset',\n",
       "   'theorem',\n",
       "   'ready',\n",
       "   'prove_theorem',\n",
       "   'chapter_relation',\n",
       "   'partial_order',\n",
       "   'proof_theorem',\n",
       "   'base_case',\n",
       "   'element',\n",
       "   'poset',\n",
       "   'already',\n",
       "   'total_order',\n",
       "   'thus',\n",
       "   'topo',\n",
       "   'logical',\n",
       "   'sort'],\n",
       "  ['true'],\n",
       "  ['inductive_step_assume'],\n",
       "  ['order', 'prove'],\n",
       "  ['let'],\n",
       "  ['element', 'poset'],\n",
       "  ['lemma',\n",
       "   'remain',\n",
       "   'check',\n",
       "   'total_order',\n",
       "   'consistent',\n",
       "   'original',\n",
       "   'partial_order'],\n",
       "  ['must',\n",
       "   'show',\n",
       "   'imply',\n",
       "   'assume',\n",
       "   'leave_side',\n",
       "   'true',\n",
       "   'show',\n",
       "   'right_side',\n",
       "   'follow'],\n",
       "  ['case'],\n",
       "  ['case', 'hold'],\n",
       "  ['case', 'equal', 'minimal_element', 'partial_order'],\n",
       "  ['thus', 'thus'],\n",
       "  ['induction', 'prove_theorem']],\n",
       " [['parallel',\n",
       "   'task',\n",
       "   'scheduling',\n",
       "   'item',\n",
       "   'poset',\n",
       "   'task',\n",
       "   'need',\n",
       "   'do',\n",
       "   'partial_order',\n",
       "   'precedence',\n",
       "   'constraint',\n",
       "   'topological',\n",
       "   'sorting',\n",
       "   'provide',\n",
       "   'way',\n",
       "   'execute',\n",
       "   'task',\n",
       "   'sequentially',\n",
       "   'violate',\n",
       "   'precedence',\n",
       "   'constraint'],\n",
       "  ['ability',\n",
       "   'execute',\n",
       "   'task',\n",
       "   'time',\n",
       "   'example_suppose',\n",
       "   'task',\n",
       "   'program',\n",
       "   'partial_order',\n",
       "   'indicate',\n",
       "   'datum'],\n",
       "  ['parallel',\n",
       "   'task',\n",
       "   'scheduling',\n",
       "   'leave',\n",
       "   'sock',\n",
       "   'right',\n",
       "   'sock',\n",
       "   'underwear',\n",
       "   'shirt',\n",
       "   'leave',\n",
       "   'shoe',\n",
       "   'right',\n",
       "   'shoe',\n",
       "   'belt',\n",
       "   'jacket',\n",
       "   'figure'],\n",
       "  ['parallel',\n",
       "   'schedule',\n",
       "   'task',\n",
       "   'get',\n",
       "   'dress',\n",
       "   'poset',\n",
       "   'fig_ure',\n",
       "   'dependence',\n",
       "   'parallel',\n",
       "   'machine',\n",
       "   'lot',\n",
       "   'processor',\n",
       "   'instead',\n",
       "   'sequential',\n",
       "   'machine',\n",
       "   'processor'],\n",
       "  ['schedule',\n",
       "   'task',\n",
       "   'minimize',\n",
       "   'total',\n",
       "   'time',\n",
       "   'use',\n",
       "   'simplicity',\n",
       "   'assume',\n",
       "   'task',\n",
       "   'take',\n",
       "   'unit',\n",
       "   'time',\n",
       "   'unlimited',\n",
       "   'number',\n",
       "   'identical',\n",
       "   'processor'],\n",
       "  ['example',\n",
       "   'clothe',\n",
       "   'example',\n",
       "   'figure',\n",
       "   'first',\n",
       "   'unit',\n",
       "   'time',\n",
       "   'minimal',\n",
       "   'item',\n",
       "   'would',\n",
       "   'put',\n",
       "   'left',\n",
       "   'sock',\n",
       "   'right',\n",
       "   'sock',\n",
       "   'underwear',\n",
       "   'shirt'],\n",
       "  ['second', 'unit', 'time', 'put', 'pant', 'tie'],\n",
       "  ['note', 'can', 'put', 'leave_right', 'shoe', 'yet', 'yet', 'put', 'pant'],\n",
       "  ['third', 'unit', 'time', 'put', 'left', 'shoe', 'right', 'shoe', 'belt'],\n",
       "  ['finally', 'last', 'unit', 'time', 'put', 'jacket'],\n",
       "  ['schedule', 'illustrate_figure', 'total', 'time', 'task', 'unit'],\n",
       "  ['can',\n",
       "   'well',\n",
       "   'unit',\n",
       "   'know',\n",
       "   'actually',\n",
       "   'put',\n",
       "   'sock',\n",
       "   'imagine',\n",
       "   'dress',\n",
       "   'bunch',\n",
       "   'robot',\n",
       "   'processor',\n",
       "   'big',\n",
       "   'hurry'],\n",
       "  ['still',\n",
       "   'work',\n",
       "   'forget',\n",
       "   'clothe',\n",
       "   'imagine',\n",
       "   'program',\n",
       "   'precedence',\n",
       "   'constraint',\n",
       "   'show_figure',\n",
       "   'chapter_relation',\n",
       "   'partial_order',\n",
       "   'time',\n",
       "   'sequence',\n",
       "   'task',\n",
       "   'need',\n",
       "   'do',\n",
       "   'next',\n",
       "   'length'],\n",
       "  ['example',\n",
       "   'must',\n",
       "   'put',\n",
       "   'shirt',\n",
       "   'pant',\n",
       "   'pant',\n",
       "   'belt',\n",
       "   'belt',\n",
       "   'jacket'],\n",
       "  ['sequence', 'item', 'know', 'chain', 'definition'],\n",
       "  ['chain',\n",
       "   'sequence',\n",
       "   'thus',\n",
       "   'time',\n",
       "   'take',\n",
       "   'schedule',\n",
       "   'task',\n",
       "   'even',\n",
       "   'unlimited',\n",
       "   'number',\n",
       "   'pro',\n",
       "   'cessor',\n",
       "   'least',\n",
       "   'length',\n",
       "   'long_chain'],\n",
       "  ['indeed',\n",
       "   'use',\n",
       "   'less',\n",
       "   'time',\n",
       "   'item',\n",
       "   'long_chain',\n",
       "   'would',\n",
       "   'do',\n",
       "   'time',\n",
       "   'tradict',\n",
       "   'precedence',\n",
       "   'constraint'],\n",
       "  ['reason', 'long_chain', 'also', 'know', 'critical', 'path'],\n",
       "  ['example', 'figure_show', 'critical', 'path', 'get', 'dress', 'poset'],\n",
       "  ['example',\n",
       "   'fact',\n",
       "   'able',\n",
       "   'schedule',\n",
       "   'task',\n",
       "   'step',\n",
       "   'length',\n",
       "   'long_chain'],\n",
       "  ['really',\n",
       "   'nice',\n",
       "   'thing',\n",
       "   'poset',\n",
       "   'always',\n",
       "   'possible',\n",
       "   'word',\n",
       "   'poset',\n",
       "   'legal',\n",
       "   'parallel',\n",
       "   'schedule',\n",
       "   'run',\n",
       "   'step',\n",
       "   'length',\n",
       "   'long_chain'],\n",
       "  ['lot', 'way', 'prove', 'fact'],\n",
       "  ['proof',\n",
       "   'also',\n",
       "   'give',\n",
       "   'corre',\n",
       "   'sponde',\n",
       "   'schedule',\n",
       "   'time',\n",
       "   'step',\n",
       "   'allow',\n",
       "   'obtain',\n",
       "   'nice',\n",
       "   'corollary'],\n",
       "  ['theorem'],\n",
       "  ['give', 'finite', 'poset'],\n",
       "  ['long_chain',\n",
       "   'length',\n",
       "   'possible',\n",
       "   'partition',\n",
       "   'subset',\n",
       "   'prove_theorem',\n",
       "   'first',\n",
       "   'note',\n",
       "   'item',\n",
       "   'corollary'],\n",
       "  ['total',\n",
       "   'amount',\n",
       "   'parallel',\n",
       "   'time',\n",
       "   'need',\n",
       "   'complete',\n",
       "   'task',\n",
       "   'length',\n",
       "   'long_chain'],\n",
       "  ['proof_theorem', 'prove', 'contradiction'],\n",
       "  ['assume',\n",
       "   'unlimited',\n",
       "   'number',\n",
       "   'processor',\n",
       "   'time',\n",
       "   'complete',\n",
       "   'task',\n",
       "   'equal',\n",
       "   'length',\n",
       "   'long_chain',\n",
       "   'dependent',\n",
       "   'task'],\n",
       "  ['case',\n",
       "   'limited',\n",
       "   'number',\n",
       "   'processor',\n",
       "   'useful',\n",
       "   'practice',\n",
       "   'cover',\n",
       "   'problem_section']],\n",
       " [['dilworth', 'lemma', 'definition'],\n",
       "  ['antichain', 'poset', 'set', 'element', 'element_set', 'incomparable'],\n",
       "  ['example',\n",
       "   'figure',\n",
       "   'antichain',\n",
       "   'element',\n",
       "   'dependency',\n",
       "   'could',\n",
       "   'execute',\n",
       "   'time'],\n",
       "  ['conclusion', 'scheduling', 'also', 'tell', 'antichain'],\n",
       "  ['corollary'],\n",
       "  ['large', 'chain', 'partial_order', 'set', 'size', 'partition', 'antichain'],\n",
       "  ['proof'],\n",
       "  ['let',\n",
       "   'antichains',\n",
       "   'set',\n",
       "   'corollary',\n",
       "   'imply',\n",
       "   'famous',\n",
       "   'result',\n",
       "   'partially',\n",
       "   'order',\n",
       "   'set',\n",
       "   'lemma'],\n",
       "  ['dilworth'],\n",
       "  ['partially',\n",
       "   'order',\n",
       "   'set',\n",
       "   'element',\n",
       "   'must',\n",
       "   'chain',\n",
       "   'size',\n",
       "   'great',\n",
       "   'antichain',\n",
       "   'size',\n",
       "   'least'],\n",
       "  ['proof'],\n",
       "  ['contradiction'],\n",
       "  ['assume', 'long_chain', 'length', 'long', 'antichain', 'size', 'less'],\n",
       "  ['corollary', 'antichain', 'least', 'element'],\n",
       "  ['application',\n",
       "   'consider',\n",
       "   'permutation',\n",
       "   'number',\n",
       "   'arrange',\n",
       "   'sequence',\n",
       "   'leave_right',\n",
       "   'line'],\n",
       "  ['corollary',\n",
       "   'use',\n",
       "   'show',\n",
       "   'must',\n",
       "   'length',\n",
       "   'subsequence',\n",
       "   'number',\n",
       "   'completely',\n",
       "   'lemma',\n",
       "   'also',\n",
       "   'follow',\n",
       "   'general',\n",
       "   'result',\n",
       "   'know',\n",
       "   'dilworth',\n",
       "   'theorem',\n",
       "   'discuss'],\n",
       "  ['chapter_relation',\n",
       "   'partial_order',\n",
       "   'increase',\n",
       "   'completely',\n",
       "   'decrease',\n",
       "   'move',\n",
       "   'leave_right'],\n",
       "  ['example',\n",
       "   'sequence',\n",
       "   'increase',\n",
       "   'subsequence',\n",
       "   'length',\n",
       "   'example',\n",
       "   'decrease',\n",
       "   'subsequence',\n",
       "   'length',\n",
       "   'example'],\n",
       "  ['proof',\n",
       "   'result',\n",
       "   'leave',\n",
       "   'exercise',\n",
       "   'test',\n",
       "   'ability',\n",
       "   'find',\n",
       "   'right',\n",
       "   'partial_order',\n",
       "   'number',\n",
       "   'sequence']],\n",
       " [['state', 'machine', 'chapter', 'need', 'rework'],\n",
       "  ['iii', 'count', 'introduction', 'counting', 'seem', 'easy', 'enough'],\n",
       "  ['direct',\n",
       "   'approach',\n",
       "   'work',\n",
       "   'well',\n",
       "   'count',\n",
       "   'simple',\n",
       "   'thing',\n",
       "   'toe',\n",
       "   'may',\n",
       "   'approach',\n",
       "   'ex',\n",
       "   'tremely',\n",
       "   'complicated',\n",
       "   'thing',\n",
       "   'identifiable',\n",
       "   'structure'],\n",
       "  ['however',\n",
       "   'subtler',\n",
       "   'meth',\n",
       "   'ods',\n",
       "   'help',\n",
       "   'count',\n",
       "   'many',\n",
       "   'thing',\n",
       "   'vast',\n",
       "   'middle',\n",
       "   'ground',\n",
       "   'number',\n",
       "   'different_way',\n",
       "   'select',\n",
       "   'dozen',\n",
       "   'doughnut',\n",
       "   'variety',\n",
       "   'available'],\n",
       "  ['number', 'bit', 'number', 'exactly', 'one'],\n",
       "  ['perhaps',\n",
       "   'surprisingly',\n",
       "   'certainly',\n",
       "   'coincidentally',\n",
       "   'number',\n",
       "   'situation'],\n",
       "  ['count',\n",
       "   'useful',\n",
       "   'computer_science',\n",
       "   'several',\n",
       "   'reason',\n",
       "   'determine',\n",
       "   'time',\n",
       "   'storage',\n",
       "   'require',\n",
       "   'solve',\n",
       "   'computational',\n",
       "   'problem',\n",
       "   'central',\n",
       "   'objective',\n",
       "   'computer_science',\n",
       "   'often',\n",
       "   'come',\n",
       "   'solve',\n",
       "   'counting_problem'],\n",
       "  ['count',\n",
       "   'basis',\n",
       "   'probability',\n",
       "   'theory',\n",
       "   'play',\n",
       "   'central',\n",
       "   'role',\n",
       "   'science',\n",
       "   'include',\n",
       "   'computer_science'],\n",
       "  ['remarkable',\n",
       "   'proof',\n",
       "   'technique',\n",
       "   'pigeonhole_principle',\n",
       "   'combi',\n",
       "   'natorial',\n",
       "   'proof',\n",
       "   'rely',\n",
       "   'count'],\n",
       "  ['lead', 'variety', 'interesting', 'useful', 'insight'],\n",
       "  ['next', 'several', 'chapter', 'go', 'present', 'lot', 'rule', 'count'],\n",
       "  ['rule',\n",
       "   'actually',\n",
       "   'theorem_prove',\n",
       "   'focus',\n",
       "   'proof',\n",
       "   'se',\n",
       "   'objective',\n",
       "   'teach',\n",
       "   'simple',\n",
       "   'count',\n",
       "   'practical',\n",
       "   'skill',\n",
       "   'integration'],\n",
       "  ['part',\n",
       "   'iii',\n",
       "   'count',\n",
       "   'begin',\n",
       "   'study',\n",
       "   'count',\n",
       "   'chapter',\n",
       "   'collection',\n",
       "   'rule',\n",
       "   'meth',\n",
       "   'ods',\n",
       "   'find',\n",
       "   'closed_form',\n",
       "   'expression',\n",
       "   'commonly',\n",
       "   'occur',\n",
       "   'sum',\n",
       "   'prod',\n",
       "   'quantity',\n",
       "   'running',\n",
       "   'time',\n",
       "   'program',\n",
       "   'grow',\n",
       "   'size',\n",
       "   'input'],\n",
       "  ['chapter',\n",
       "   'chapter',\n",
       "   'conclude',\n",
       "   'chapter',\n",
       "   'brief',\n",
       "   'digression',\n",
       "   'final',\n",
       "   'frontier',\n",
       "   'count',\n",
       "   'infinity'],\n",
       "  ['define',\n",
       "   'mean',\n",
       "   'set',\n",
       "   'countable',\n",
       "   'show',\n",
       "   'example',\n",
       "   'set',\n",
       "   'really',\n",
       "   'big',\n",
       "   'big',\n",
       "   'even',\n",
       "   'set',\n",
       "   'real_number']],\n",
       " [['sum_asymptotic',\n",
       "   'sum_product',\n",
       "   'arise',\n",
       "   'regularly',\n",
       "   'analysis',\n",
       "   'algorithms',\n",
       "   'financial',\n",
       "   'applica',\n",
       "   'tions',\n",
       "   'physical',\n",
       "   'problem',\n",
       "   'probabilistic',\n",
       "   'system'],\n",
       "  ['example',\n",
       "   'already',\n",
       "   'encounter',\n",
       "   'sum',\n",
       "   'would',\n",
       "   'lot',\n",
       "   'easy',\n",
       "   'helpful',\n",
       "   'express',\n",
       "   'sum',\n",
       "   'close_form',\n",
       "   'value',\n",
       "   'close_form',\n",
       "   'mean',\n",
       "   'expression',\n",
       "   'make',\n",
       "   'use',\n",
       "   'summation',\n",
       "   'product',\n",
       "   'symbol',\n",
       "   'otherwise',\n",
       "   'need',\n",
       "   'handy',\n",
       "   'sometimes',\n",
       "   'troublesome',\n",
       "   'dot'],\n",
       "  ['expression',\n",
       "   'close_form',\n",
       "   'usually',\n",
       "   'easy',\n",
       "   'evaluate',\n",
       "   'get',\n",
       "   'much',\n",
       "   'simple',\n",
       "   'find_close_form',\n",
       "   'sum_product',\n",
       "   'well',\n",
       "   'part',\n",
       "   'math',\n",
       "   'part',\n",
       "   'art'],\n",
       "  ['subject', 'chapter'],\n",
       "  ['start', 'chapter', 'motivate', 'example', 'involve', 'annuity'],\n",
       "  ['figure', 'value_annuity', 'involve', 'large', 'nasty', 'look', 'sum'],\n",
       "  ['describe',\n",
       "   'several',\n",
       "   'method',\n",
       "   'find',\n",
       "   'closed_form',\n",
       "   'sort',\n",
       "   'sum',\n",
       "   'include',\n",
       "   'annuity',\n",
       "   'sum'],\n",
       "  ['case',\n",
       "   'close_form',\n",
       "   'sum',\n",
       "   'may',\n",
       "   'exist',\n",
       "   'provide',\n",
       "   'general',\n",
       "   'method',\n",
       "   'find',\n",
       "   'good',\n",
       "   'upper',\n",
       "   'low',\n",
       "   'bound',\n",
       "   'sum',\n",
       "   'close_form',\n",
       "   'course'],\n",
       "  ['method',\n",
       "   'develop',\n",
       "   'sum',\n",
       "   'also',\n",
       "   'work',\n",
       "   'product',\n",
       "   'convert',\n",
       "   'product',\n",
       "   'sum',\n",
       "   'take',\n",
       "   'logarithm',\n",
       "   'product'],\n",
       "  ['example',\n",
       "   'use',\n",
       "   'approach',\n",
       "   'find',\n",
       "   'good',\n",
       "   'close_form',\n",
       "   'approximation',\n",
       "   'wwd',\n",
       "   'conclude',\n",
       "   'chapter',\n",
       "   'discussion',\n",
       "   'asymptotic_notation'],\n",
       "  ['asymptotic_notation',\n",
       "   'often',\n",
       "   'use',\n",
       "   'bind',\n",
       "   'error',\n",
       "   'term',\n",
       "   'exact',\n",
       "   'close_form_expression',\n",
       "   'sum_product'],\n",
       "  ['also',\n",
       "   'provide',\n",
       "   'convenient',\n",
       "   'way',\n",
       "   'express',\n",
       "   'growth',\n",
       "   'rate',\n",
       "   'order',\n",
       "   'magnitude',\n",
       "   'sum_product'],\n",
       "  ['chapter_sum', 'asymptotic']],\n",
       " [['value_annuity',\n",
       "   'would',\n",
       "   'prefer',\n",
       "   'dollar',\n",
       "   'today',\n",
       "   'year',\n",
       "   'rest',\n",
       "   'life',\n",
       "   'hand',\n",
       "   'instant',\n",
       "   'gratification',\n",
       "   'nice'],\n",
       "  ['hand',\n",
       "   'total',\n",
       "   'dollar',\n",
       "   'receive',\n",
       "   'year',\n",
       "   'much',\n",
       "   'large',\n",
       "   'live',\n",
       "   'long',\n",
       "   'enough'],\n",
       "  ['formally', 'question', 'value_annuity'],\n",
       "  ['annuity',\n",
       "   'finan',\n",
       "   'cial',\n",
       "   'instrument',\n",
       "   'pay',\n",
       "   'fix',\n",
       "   'amount',\n",
       "   'money',\n",
       "   'begin',\n",
       "   'year',\n",
       "   'specify',\n",
       "   'number',\n",
       "   'year'],\n",
       "  ['particular',\n",
       "   'year',\n",
       "   'payment',\n",
       "   'annuity',\n",
       "   'pay',\n",
       "   'dollar',\n",
       "   'start',\n",
       "   'year',\n",
       "   'year'],\n",
       "  ['case', 'finite', 'always'],\n",
       "  ['example',\n",
       "   'include',\n",
       "   'lottery',\n",
       "   'payout',\n",
       "   'student',\n",
       "   'loan',\n",
       "   'home',\n",
       "   'mortgage'],\n",
       "  ['even', 'wall', 'street', 'people', 'specialize', 'trading', 'annuity'],\n",
       "  ['key',\n",
       "   'question',\n",
       "   'annuity',\n",
       "   'worth',\n",
       "   'example',\n",
       "   'lottery',\n",
       "   'often',\n",
       "   'pay',\n",
       "   'jackpot',\n",
       "   'many',\n",
       "   'year'],\n",
       "  ['intuitively', 'year', 'year', 'ought', 'worth', 'less', 'dollar', 'right'],\n",
       "  ['cash', 'right', 'away', 'could', 'invest', 'begin', 'collect', 'interest'],\n",
       "  ['choice', 'year', 'year', 'dollar', 'today', 'clear', 'option', 'better']],\n",
       " [['future',\n",
       "   'value',\n",
       "   'money',\n",
       "   'order',\n",
       "   'answer_question',\n",
       "   'need',\n",
       "   'know',\n",
       "   'dollar',\n",
       "   'pay',\n",
       "   'future',\n",
       "   'worth',\n",
       "   'today'],\n",
       "  ['model',\n",
       "   'let',\n",
       "   'assume',\n",
       "   'money',\n",
       "   'invest',\n",
       "   'fix',\n",
       "   'annual',\n",
       "   'interest',\n",
       "   'rate'],\n",
       "  ['assume', 'rate', 'rest', 'discussion'],\n",
       "  ['interest', 'rate', 'matter'],\n",
       "  ['dollar', 'invest', 'today', 'interest', 'rate', 'become'],\n",
       "  ['dollars', 'year'],\n",
       "  ['year',\n",
       "   'payment',\n",
       "   'annuity',\n",
       "   'first',\n",
       "   'payment',\n",
       "   'dollar',\n",
       "   'truly',\n",
       "   'worth',\n",
       "   'dollar'],\n",
       "  ['second', 'payment', 'year', 'later', 'worth'],\n",
       "  ['dollar'],\n",
       "  ['similarly', 'third', 'payment', 'worth'],\n",
       "  ['trading', 'ultimately', 'lead', 'subprime', 'mortgage', 'disaster'],\n",
       "  ['talk', 'section'],\n",
       "  ['interest',\n",
       "   'rate',\n",
       "   'drop',\n",
       "   'steadily',\n",
       "   'several',\n",
       "   'year',\n",
       "   'ordinary',\n",
       "   'bank',\n",
       "   'deposit',\n",
       "   'earn'],\n",
       "  ['year_ago', 'rate', 'rate', 'make', 'example', 'little', 'dramatic'],\n",
       "  ['rate', 'high', 'past', 'year'],\n",
       "  ['payment', 'value'],\n",
       "  ['give',\n",
       "   'goal',\n",
       "   'precede',\n",
       "   'substitution',\n",
       "   'get',\n",
       "   'summation',\n",
       "   'simple',\n",
       "   'special',\n",
       "   'form',\n",
       "   'solve',\n",
       "   'general',\n",
       "   'formula'],\n",
       "  ['particular',\n",
       "   'term',\n",
       "   'sum',\n",
       "   'form',\n",
       "   'geometric_series',\n",
       "   'mean',\n",
       "   'ratio',\n",
       "   'consecutive',\n",
       "   'term',\n",
       "   'always',\n",
       "   'positive',\n",
       "   'value',\n",
       "   'less'],\n",
       "  ['case', 'ratio', 'always', 'assume'],\n",
       "  ['turn',\n",
       "   'nice',\n",
       "   'close_form_expression',\n",
       "   'geometric_series',\n",
       "   'namely',\n",
       "   'equation',\n",
       "   'verify',\n",
       "   'induction',\n",
       "   'often',\n",
       "   'case',\n",
       "   'proof',\n",
       "   'induction',\n",
       "   'give',\n",
       "   'hint',\n",
       "   'formula',\n",
       "   'find',\n",
       "   'first',\n",
       "   'place'],\n",
       "  ['take', 'opportunity', 'describe', 'method', 'could', 'use', 'figure'],\n",
       "  ['call', 'perturbation', 'method']],\n",
       " [['perturbation',\n",
       "   'method',\n",
       "   'give',\n",
       "   'sum',\n",
       "   'nice',\n",
       "   'structure',\n",
       "   'often',\n",
       "   'useful',\n",
       "   'perturb',\n",
       "   'sum',\n",
       "   'somehow',\n",
       "   'combine',\n",
       "   'sum',\n",
       "   'perturbation',\n",
       "   'get',\n",
       "   'much',\n",
       "   'simple'],\n",
       "  ['example_suppose',\n",
       "   'example',\n",
       "   'perturbation',\n",
       "   'would',\n",
       "   'xs',\n",
       "   'chapter_sum',\n",
       "   'asymptotic',\n",
       "   'difference',\n",
       "   'xs',\n",
       "   'great',\n",
       "   'subtract',\n",
       "   'xs',\n",
       "   'would',\n",
       "   'massive',\n",
       "   'cancellation',\n",
       "   'xs',\n",
       "   'result',\n",
       "   'subtraction',\n",
       "   'xs',\n",
       "   'solving',\n",
       "   'give',\n",
       "   'desire',\n",
       "   'close_form_expression',\n",
       "   'equation',\n",
       "   'see',\n",
       "   'example',\n",
       "   'method',\n",
       "   'introduce',\n",
       "   'generate_function',\n",
       "   'chapter']],\n",
       " [['closed_form',\n",
       "   'annuity',\n",
       "   'value',\n",
       "   'use',\n",
       "   'equation',\n",
       "   'equation',\n",
       "   'much',\n",
       "   'easy',\n",
       "   'use',\n",
       "   'summation',\n",
       "   'dozen',\n",
       "   'term'],\n",
       "  ['example',\n",
       "   'real',\n",
       "   'value',\n",
       "   'win',\n",
       "   'lottery',\n",
       "   'ticket',\n",
       "   'pay',\n",
       "   'year',\n",
       "   'year',\n",
       "   'plug',\n",
       "   'give']],\n",
       " [['infinite',\n",
       "   'geometric_series',\n",
       "   'question',\n",
       "   'begin',\n",
       "   'would',\n",
       "   'prefer',\n",
       "   'dollar',\n",
       "   'today',\n",
       "   'year',\n",
       "   'rest',\n",
       "   'life'],\n",
       "  ['course',\n",
       "   'depend',\n",
       "   'long',\n",
       "   'live',\n",
       "   'optimistically',\n",
       "   'assume',\n",
       "   'second',\n",
       "   'option',\n",
       "   'receive',\n",
       "   'year',\n",
       "   'forever'],\n",
       "  ['sound',\n",
       "   'infinite',\n",
       "   'money',\n",
       "   'compute',\n",
       "   'value_annuity',\n",
       "   'infinite',\n",
       "   'number',\n",
       "   'payment',\n",
       "   'take',\n",
       "   'limit',\n",
       "   'geometric_sum',\n",
       "   'equation',\n",
       "   'tend',\n",
       "   'infinity'],\n",
       "  ['theorem'],\n",
       "  ['jxj', 'would', 'proof'],\n",
       "  ['final', 'line', 'follow', 'fact', 'lim', 'annuity', 'problem'],\n",
       "  ['theorem', 'apply', 'get', 'plug', 'see', 'value'],\n",
       "  ['amazingly',\n",
       "   'dollar',\n",
       "   'today',\n",
       "   'worth',\n",
       "   'much',\n",
       "   'pay',\n",
       "   'year',\n",
       "   'forever',\n",
       "   'dollar',\n",
       "   'today',\n",
       "   'bank',\n",
       "   'earn',\n",
       "   'interest',\n",
       "   'could',\n",
       "   'take',\n",
       "   'spend',\n",
       "   'year',\n",
       "   'forever'],\n",
       "  ['second', 'thought', 'answer', 'really', 'amazing']],\n",
       " [['example',\n",
       "   'equation',\n",
       "   'theorem',\n",
       "   'incredibly',\n",
       "   'useful',\n",
       "   'computer_science'],\n",
       "  ['fact',\n",
       "   'already',\n",
       "   'use',\n",
       "   'equation',\n",
       "   'implicitly',\n",
       "   'claim',\n",
       "   'chapter',\n",
       "   'input',\n",
       "   'complete_binary_tree',\n",
       "   'cn',\n",
       "   'chapter_sum',\n",
       "   'asymptotic',\n",
       "   'node'],\n",
       "  ['common',\n",
       "   'sum',\n",
       "   'put',\n",
       "   'closed_form',\n",
       "   'use',\n",
       "   'equation',\n",
       "   'theorem',\n",
       "   'term',\n",
       "   'geometric_sum',\n",
       "   'grow',\n",
       "   'small',\n",
       "   'equation',\n",
       "   'theorem']],\n",
       " [['variations', 'geometric_sum', 'know', 'geometric_sum', 'life', 'easy'],\n",
       "  ['practice',\n",
       "   'often',\n",
       "   'encounter',\n",
       "   'sum',\n",
       "   'can',\n",
       "   'transform',\n",
       "   'simple',\n",
       "   'variable',\n",
       "   'substitution',\n",
       "   'form',\n",
       "   'non',\n",
       "   'obvious',\n",
       "   'useful',\n",
       "   'way',\n",
       "   'obtain',\n",
       "   'new',\n",
       "   'summation',\n",
       "   'formula',\n",
       "   'old',\n",
       "   'differentiate',\n",
       "   'integrate',\n",
       "   'respect'],\n",
       "  ['example_consider', 'follow', 'sum'],\n",
       "  ['geometric_sum',\n",
       "   'ratio',\n",
       "   'successive',\n",
       "   'term',\n",
       "   'fix',\n",
       "   'formula',\n",
       "   'sum',\n",
       "   'geometric_sum',\n",
       "   'can',\n",
       "   'directly',\n",
       "   'apply'],\n",
       "  ['suppose',\n",
       "   'differentiate',\n",
       "   'equation',\n",
       "   'leave_hand',\n",
       "   'side_equation',\n",
       "   'simply',\n",
       "   'hence',\n",
       "   'equation',\n",
       "   'mean',\n",
       "   'often',\n",
       "   'differentiate',\n",
       "   'integrate',\n",
       "   'mess',\n",
       "   'exponent',\n",
       "   'term'],\n",
       "  ['case',\n",
       "   'formula',\n",
       "   'sum',\n",
       "   'form',\n",
       "   'desire',\n",
       "   'close_form_expression',\n",
       "   'sum',\n",
       "   'notice',\n",
       "   'jxj',\n",
       "   'series',\n",
       "   'converge',\n",
       "   'finite',\n",
       "   'value',\n",
       "   'even',\n",
       "   'infinitely_many',\n",
       "   'term'],\n",
       "  ['take',\n",
       "   'limit',\n",
       "   'equation',\n",
       "   'tend',\n",
       "   'infinity',\n",
       "   'give',\n",
       "   'follow',\n",
       "   'theorem',\n",
       "   'could',\n",
       "   'easily',\n",
       "   'made',\n",
       "   'mistake',\n",
       "   'calculation',\n",
       "   'always',\n",
       "   'good_idea',\n",
       "   'go_back',\n",
       "   'validate',\n",
       "   'formula',\n",
       "   'obtain',\n",
       "   'way',\n",
       "   'proof',\n",
       "   'induction'],\n",
       "  ['chapter_sum', 'asymptotic', 'theorem'],\n",
       "  ['jxj',\n",
       "   'consequence',\n",
       "   'suppose',\n",
       "   'annuity',\n",
       "   'pay',\n",
       "   'be',\n",
       "   'dollar',\n",
       "   'end',\n",
       "   'year',\n",
       "   'forever'],\n",
       "  ['example', 'payouts'],\n",
       "  ['hard',\n",
       "   'believe',\n",
       "   'value_annuity',\n",
       "   'finite',\n",
       "   'use',\n",
       "   'theorem',\n",
       "   'compute',\n",
       "   'value',\n",
       "   'be',\n",
       "   'second_line',\n",
       "   'follow',\n",
       "   'application',\n",
       "   'theorem',\n",
       "   'example',\n",
       "   'usual',\n",
       "   'value_annuity'],\n",
       "  ['even',\n",
       "   'payment',\n",
       "   'increase',\n",
       "   'year',\n",
       "   'crease',\n",
       "   'additive',\n",
       "   'time',\n",
       "   'contrast',\n",
       "   'dollar',\n",
       "   'pay',\n",
       "   'future',\n",
       "   'decrease',\n",
       "   'value',\n",
       "   'exponentially',\n",
       "   'time'],\n",
       "  ['geometric', 'decrease', 'swamp', 'additive', 'increase'],\n",
       "  ['payment',\n",
       "   'distant',\n",
       "   'future',\n",
       "   'almost',\n",
       "   'worthless',\n",
       "   'value_annuity',\n",
       "   'finite'],\n",
       "  ['important',\n",
       "   'thing',\n",
       "   'remember',\n",
       "   'trick',\n",
       "   'take',\n",
       "   'derivative',\n",
       "   'integral',\n",
       "   'summation',\n",
       "   'formula'],\n",
       "  ['course',\n",
       "   'technique',\n",
       "   'require',\n",
       "   'compute',\n",
       "   'nasty',\n",
       "   'derivative',\n",
       "   'correctly',\n",
       "   'least',\n",
       "   'theoretically',\n",
       "   'possible']],\n",
       " [['power', 'sums', 'chapter', 'source', 'formula', 'still', 'mystery'],\n",
       "  ['prove',\n",
       "   'true',\n",
       "   'use_well',\n",
       "   'order',\n",
       "   'induction',\n",
       "   'expression',\n",
       "   'right',\n",
       "   'come',\n",
       "   'first',\n",
       "   'place',\n",
       "   'even',\n",
       "   'inexplicable',\n",
       "   'close_form_expression',\n",
       "   'sum',\n",
       "   'consecutive',\n",
       "   'square'],\n",
       "  ['turn',\n",
       "   'way',\n",
       "   'derive',\n",
       "   'expression',\n",
       "   'explain',\n",
       "   'thought',\n",
       "   'would',\n",
       "   'fun',\n",
       "   'show',\n",
       "   'gauss',\n",
       "   'prove',\n",
       "   'equation',\n",
       "   'young',\n",
       "   'boy'],\n",
       "  ['gauss',\n",
       "   'idea',\n",
       "   'related',\n",
       "   'perturbation',\n",
       "   'method',\n",
       "   'use',\n",
       "   'section',\n",
       "   'would',\n",
       "   'write',\n",
       "   'sum',\n",
       "   'order'],\n",
       "  ['add', 'equation', 'give'],\n",
       "  ['hence', 'bad', 'young', 'child'],\n",
       "  ['look', 'gauss', 'potential'],\n",
       "  ['unfortunately', 'trick', 'work', 'sum', 'consecutive', 'square'],\n",
       "  ['however',\n",
       "   'observe',\n",
       "   'result',\n",
       "   'may',\n",
       "   'third',\n",
       "   'degree',\n",
       "   'polynomial',\n",
       "   'sum',\n",
       "   'contain',\n",
       "   'term',\n",
       "   'average',\n",
       "   'value',\n",
       "   'grow',\n",
       "   'quadratically'],\n",
       "  ['may',\n",
       "   'guess',\n",
       "   'guess',\n",
       "   'correct',\n",
       "   'determine',\n",
       "   'parameter',\n",
       "   'plug',\n",
       "   'value'],\n",
       "  ['value',\n",
       "   'give',\n",
       "   'linear_equation',\n",
       "   'remember',\n",
       "   'mathematician',\n",
       "   'definition',\n",
       "   'fun',\n",
       "   'may',\n",
       "   'different'],\n",
       "  ['suspect', 'gauss', 'probably', 'ordinary', 'boy'],\n",
       "  ['chapter_sum', 'asymptotic'],\n",
       "  ['plug', 'enough', 'value', 'may', 'linear', 'system', 'unique', 'solution'],\n",
       "  ['apply',\n",
       "   'method',\n",
       "   'example',\n",
       "   'give',\n",
       "   'solve',\n",
       "   'system',\n",
       "   'give',\n",
       "   'solution'],\n",
       "  ['therefore',\n",
       "   'initial',\n",
       "   'guess',\n",
       "   'form',\n",
       "   'solution',\n",
       "   'correct',\n",
       "   'summation',\n",
       "   'equal',\n",
       "   'point',\n",
       "   'desire',\n",
       "   'formula',\n",
       "   'turn',\n",
       "   'polynomial',\n",
       "   'get',\n",
       "   'estimate',\n",
       "   'degree',\n",
       "   'polynomial',\n",
       "   'coefficient',\n",
       "   'polynomial',\n",
       "   'find',\n",
       "   'automatically'],\n",
       "  ['careful',\n",
       "   'method',\n",
       "   'let',\n",
       "   'discover',\n",
       "   'formula',\n",
       "   'guarantee',\n",
       "   'right',\n",
       "   'obtain',\n",
       "   'formula',\n",
       "   'method',\n",
       "   'important',\n",
       "   'go_back',\n",
       "   'prove',\n",
       "   'use_induction',\n",
       "   'method',\n",
       "   'initial',\n",
       "   'guess',\n",
       "   'solution',\n",
       "   'right',\n",
       "   'form',\n",
       "   'result',\n",
       "   'formula',\n",
       "   'completely',\n",
       "   'wrong']],\n",
       " [['approximate',\n",
       "   'sum',\n",
       "   'unfortunately',\n",
       "   'always',\n",
       "   'possible',\n",
       "   'find_close_form',\n",
       "   'expression',\n",
       "   'sum'],\n",
       "  ['example_consider', 'sum', 'would', 'close_form_expression', 'know'],\n",
       "  ['case', 'need', 'resort', 'approximation', 'want', 'close_form'],\n",
       "  ['good_news',\n",
       "   'general',\n",
       "   'method',\n",
       "   'find_close_form',\n",
       "   'upper',\n",
       "   'low',\n",
       "   'bound',\n",
       "   'work',\n",
       "   'sum'],\n",
       "  ['even_well', 'method', 'simple', 'easy', 'remember'],\n",
       "  ['work',\n",
       "   'replace',\n",
       "   'sum',\n",
       "   'integral',\n",
       "   'add',\n",
       "   'first',\n",
       "   'last',\n",
       "   'term',\n",
       "   'sum'],\n",
       "  ['alternatively',\n",
       "   'use',\n",
       "   'method',\n",
       "   'base',\n",
       "   'generating_function',\n",
       "   'describe',\n",
       "   'chapter',\n",
       "   'theorem'],\n",
       "  ['let', 'continuous', 'function', 'let'],\n",
       "  ['dx'],\n",
       "  ['similarly', 'nonincrease'],\n",
       "  ['proof'],\n",
       "  ['let', 'consider', 'graph_show', 'figure'],\n",
       "  ['represent', 'shaded', 'area', 'figure'],\n",
       "  ['ith', 'rectangle', 'figure', 'counting', 'leave_right', 'width', 'height'],\n",
       "  ['value'],\n",
       "  ['dx', 'shaded', 'area', 'curve'],\n",
       "  ['show_figure', 'area', 'leftmost', 'rectangle'],\n",
       "  ['hence', 'lower', 'bind'],\n",
       "  ['next', 'derive', 'upper_bind'],\n",
       "  ['figure_show', 'curve'],\n",
       "  ['shifted', 'left'],\n",
       "  ['curve'],\n",
       "  ['area'],\n",
       "  ['compare', 'shaded', 'region', 'figure', 'area', 'rightmost', 'rectangle'],\n",
       "  ['hence', 'function', 'nondecrease'],\n",
       "  ['whenever'],\n",
       "  ['nonincrease'],\n",
       "  ['whenever'],\n",
       "  ['chapter_sum', 'asymptotic'],\n",
       "  ['figure'],\n",
       "  ['would'],\n",
       "  ['area', 'ith', 'rectangle'],\n",
       "  ['shaded', 'region', 'area'],\n",
       "  ['figure'],\n",
       "  ['shaded', 'area', 'curve'],\n",
       "  ['show', 'bold'],\n",
       "  ['figure'],\n",
       "  ['shaded', 'area', 'curve'],\n",
       "  ['area', 'curve'],\n",
       "  ['curve', 'curve', 'figure', 'shift', 'left'],\n",
       "  ['combine', 'equation'],\n",
       "  ['nondecrease',\n",
       "   'function',\n",
       "   'claim',\n",
       "   'argument',\n",
       "   'case',\n",
       "   'nonincrease',\n",
       "   'similar'],\n",
       "  ['analo', 'gous', 'graph_show', 'figure', 'provide', 'figure'],\n",
       "  ['similarly', 'compare', 'shaded', 'region', 'figure'],\n",
       "  ['hence', 'nonincrease'],\n",
       "  ['claim'],\n",
       "  ['theorem', 'provide', 'good', 'bound', 'sum'],\n",
       "  ['bad', 'bound', 'large', 'term', 'sum'],\n",
       "  ['example', 'use', 'theorem', 'bind', 'sum', 'follow'],\n",
       "  ['word', 'sum', 'close', 'use', 'theorem', 'extensively', 'go', 'forward'],\n",
       "  ['end',\n",
       "   'chapter',\n",
       "   'also',\n",
       "   'introduce',\n",
       "   'notation',\n",
       "   'express',\n",
       "   'phrase',\n",
       "   'sum',\n",
       "   'close',\n",
       "   'precise',\n",
       "   'mathematical',\n",
       "   'manner'],\n",
       "  ['first',\n",
       "   'see',\n",
       "   'theorem',\n",
       "   'use',\n",
       "   'resolve',\n",
       "   'classic',\n",
       "   'paradox',\n",
       "   'structural',\n",
       "   'engineering']],\n",
       " [['hang',\n",
       "   'edge',\n",
       "   'suppose',\n",
       "   'identical',\n",
       "   'block',\n",
       "   'stack',\n",
       "   'top',\n",
       "   'next',\n",
       "   'table',\n",
       "   'show_figure',\n",
       "   'people',\n",
       "   'first',\n",
       "   'response',\n",
       "   'question',\n",
       "   'sometimes',\n",
       "   'also',\n",
       "   'second',\n",
       "   'third',\n",
       "   'response'],\n",
       "  ['block', 'ever', 'get', 'completely', 'past', 'edge_table'],\n",
       "  ['fact',\n",
       "   'large',\n",
       "   'enough',\n",
       "   'top_block',\n",
       "   'stick',\n",
       "   'far',\n",
       "   'want',\n",
       "   'block',\n",
       "   'length',\n",
       "   'block',\n",
       "   'length',\n",
       "   'number',\n",
       "   'block',\n",
       "   'length',\n",
       "   'assume',\n",
       "   'block',\n",
       "   'rectangular',\n",
       "   'uniformly',\n",
       "   'weight',\n",
       "   'length'],\n",
       "  ['chapter_sum', 'asymptotic', 'table', 'figure'],\n",
       "  ['stack', 'identical', 'block', 'table'],\n",
       "  ['top_block',\n",
       "   'hang',\n",
       "   'edge_table',\n",
       "   'try',\n",
       "   'stack_block',\n",
       "   'way',\n",
       "   'stack',\n",
       "   'fall']],\n",
       " [['stability', 'stack_block', 'say', 'stable', 'fall', 'accord'],\n",
       "  ['example',\n",
       "   'stack',\n",
       "   'illustrate_figure',\n",
       "   'stable',\n",
       "   'top_block',\n",
       "   'sure',\n",
       "   'fall'],\n",
       "  ['center_mass_top_block', 'hang', 'air'],\n",
       "  ['general', 'stack_block', 'stable', 'center_mass_top_block', 'sit'],\n",
       "  ['st', 'block'],\n",
       "  ['table'],\n",
       "  ['define',\n",
       "   'overhang',\n",
       "   'stable',\n",
       "   'stack',\n",
       "   'distance',\n",
       "   'edge_table',\n",
       "   'rightmost',\n",
       "   'end',\n",
       "   'rightmost_block',\n",
       "   'stack'],\n",
       "  ['goal', 'thus', 'maximize', 'overhang', 'stable', 'stack'],\n",
       "  ['example', 'maximum_possible', 'overhang', 'single', 'block'],\n",
       "  ['center_mass',\n",
       "   'single',\n",
       "   'block',\n",
       "   'middle',\n",
       "   'block',\n",
       "   'distance',\n",
       "   'right',\n",
       "   'edge',\n",
       "   'block'],\n",
       "  ['place',\n",
       "   'block',\n",
       "   'right',\n",
       "   'edge',\n",
       "   'edge_table',\n",
       "   'center_mass',\n",
       "   'would',\n",
       "   'air',\n",
       "   'block',\n",
       "   'would',\n",
       "   'tip'],\n",
       "  ['place',\n",
       "   'block',\n",
       "   'center_mass',\n",
       "   'edge_table',\n",
       "   'thereby',\n",
       "   'achieve',\n",
       "   'overhang'],\n",
       "  ['position',\n",
       "   'illustrated',\n",
       "   'figure',\n",
       "   'center_mass',\n",
       "   'block',\n",
       "   'table',\n",
       "   'figure'],\n",
       "  ['block', 'overhang', 'half', 'block', 'length'],\n",
       "  ['general',\n",
       "   'overhang',\n",
       "   'stack_block',\n",
       "   'maximize',\n",
       "   'slide',\n",
       "   'entire',\n",
       "   'stack',\n",
       "   'rightward',\n",
       "   'center_mass',\n",
       "   'edge_table'],\n",
       "  ['overhang',\n",
       "   'equal',\n",
       "   'distance',\n",
       "   'center_mass',\n",
       "   'stack',\n",
       "   'rightmost',\n",
       "   'edge',\n",
       "   'rightmost_block'],\n",
       "  ['call', 'distance', 'spread', 'stack'],\n",
       "  ['note',\n",
       "   'spread',\n",
       "   'depend',\n",
       "   'location',\n",
       "   'stack',\n",
       "   'table',\n",
       "   'purely',\n",
       "   'property',\n",
       "   'block',\n",
       "   'stack'],\n",
       "  ['course',\n",
       "   'observe',\n",
       "   'maximum_possible',\n",
       "   'overhang',\n",
       "   'equal',\n",
       "   'maximum_possible',\n",
       "   'spread'],\n",
       "  ['relationship', 'illustrate_figure']],\n",
       " [['recursive',\n",
       "   'solution',\n",
       "   'goal',\n",
       "   'find',\n",
       "   'formula',\n",
       "   'maximum_possible',\n",
       "   'spread',\n",
       "   'already_know',\n",
       "   'suppose',\n",
       "   'stable',\n",
       "   'stack_block',\n",
       "   'maximum_possible',\n",
       "   'spread',\n",
       "   'chapter_sum',\n",
       "   'asymptotics',\n",
       "   'center_mass',\n",
       "   'whole',\n",
       "   'stack',\n",
       "   'overhang',\n",
       "   'figure'],\n",
       "  ['overhang',\n",
       "   'maximize',\n",
       "   'maximize',\n",
       "   'spread',\n",
       "   'plac',\n",
       "   'ing',\n",
       "   'stack',\n",
       "   'center_mass',\n",
       "   'edge_table'],\n",
       "  ['case', 'rightmost_block', 'bottom_block'],\n",
       "  ['center_mass_top_block',\n",
       "   'must',\n",
       "   'bottom_block',\n",
       "   'stability',\n",
       "   'spread',\n",
       "   'maximize',\n",
       "   'center_mass_top_block',\n",
       "   'directly',\n",
       "   'leave',\n",
       "   'edge',\n",
       "   'bottom_block'],\n",
       "  ['case',\n",
       "   'center_mass',\n",
       "   'example',\n",
       "   'see_figure',\n",
       "   'fact',\n",
       "   'scenario',\n",
       "   'describe',\n",
       "   'easily',\n",
       "   'achieve',\n",
       "   'arrange',\n",
       "   'block',\n",
       "   'show_figure',\n",
       "   'better',\n",
       "   'good',\n",
       "   'spread',\n",
       "   'case',\n",
       "   'always',\n",
       "   'less',\n",
       "   'mean',\n",
       "   'can',\n",
       "   'block',\n",
       "   'fully',\n",
       "   'edge_table',\n",
       "   'scenario'],\n",
       "  ['maybe', 'intuition', 'right', 'better'],\n",
       "  ['jump', 'false', 'conclusion', 'however', 'let_see', 'happen', 'case'],\n",
       "  ['case', 'rightmost_block', 'top_block'],\n",
       "  ['case',\n",
       "   'spread',\n",
       "   'maximize',\n",
       "   'place',\n",
       "   'top_block',\n",
       "   'center_mass',\n",
       "   'directly',\n",
       "   'right',\n",
       "   'end',\n",
       "   'bottom_block'],\n",
       "  ['means', 'center_mass', 'location', 'location', 'center_mass_top_block'],\n",
       "  ['word', 'center_mass', 'leave', 'center_mass_top_block'],\n",
       "  ['difference',\n",
       "   'due',\n",
       "   'effect',\n",
       "   'bottom_block',\n",
       "   'center_mass',\n",
       "   'unit',\n",
       "   'leave'],\n",
       "  ['mean',\n",
       "   'spread',\n",
       "   'great',\n",
       "   'spread',\n",
       "   'top',\n",
       "   'blocks',\n",
       "   'case',\n",
       "   'center_mass',\n",
       "   'stack_block',\n",
       "   'average',\n",
       "   'center_mass',\n",
       "   'individual',\n",
       "   'block'],\n",
       "  ['chapter', 'sums', 'asymptotics', 'center_mass', 'figure'],\n",
       "  ['scenario', 'bottom_block', 'rightmost_block'],\n",
       "  ['case',\n",
       "   'spread',\n",
       "   'maximized',\n",
       "   'center_mass_top_block',\n",
       "   'directly',\n",
       "   'leave',\n",
       "   'edge',\n",
       "   'bottom_block'],\n",
       "  ['blocks', 'table', 'figure'],\n",
       "  ['method',\n",
       "   'achieve',\n",
       "   'spread',\n",
       "   'hence',\n",
       "   'overhang',\n",
       "   'block',\n",
       "   'bottom_block',\n",
       "   'rightmost_block'],\n",
       "  ['look', 'complicated'],\n",
       "  ['maybe', 'almost', 'do', 'equation', 'example', 'recurrence'],\n",
       "  ['describe',\n",
       "   'numerous',\n",
       "   'tech',\n",
       "   'nique',\n",
       "   'solve_recurrence',\n",
       "   'chapter',\n",
       "   'simple',\n",
       "   'enough',\n",
       "   'solve',\n",
       "   'wait',\n",
       "   'hardware',\n",
       "   'chap',\n",
       "   'ter',\n",
       "   'first',\n",
       "   'thing',\n",
       "   'recurrence',\n",
       "   'get',\n",
       "   'feel',\n",
       "   'compute',\n",
       "   'first',\n",
       "   'term'],\n",
       "  ['often', 'give', 'clue', 'way', 'solve_recurrence', 'case'],\n",
       "  ['already_know', 'case', 'give', 'spread', 'different', 'approach'],\n",
       "  ['example', 'see_figure', 'easy', 'enough'],\n",
       "  ['max', 'see', 'method', 'provide', 'case', 'best'],\n",
       "  ['let', 'check'],\n",
       "  ['table', 'table', 'figure'],\n",
       "  ['way', 'achieve', 'spread', 'hence', 'overhang', 'block'],\n",
       "  ['first', 'way', 'case', 'second', 'case'],\n",
       "  ['chapter_sum', 'asymptotic', 'breakthrough', 'reason'],\n",
       "  ['first',\n",
       "   'equation',\n",
       "   'tell',\n",
       "   'use',\n",
       "   'block',\n",
       "   'make',\n",
       "   'stack_block',\n",
       "   'hang',\n",
       "   'completely',\n",
       "   'edge_table'],\n",
       "  ['way',\n",
       "   'show_figure',\n",
       "   'second',\n",
       "   'reason',\n",
       "   'equation',\n",
       "   'important',\n",
       "   'know',\n",
       "   'show',\n",
       "   'good',\n",
       "   'spread',\n",
       "   'always',\n",
       "   'achieve',\n",
       "   'use',\n",
       "   'case'],\n",
       "  ['recurrence_equation',\n",
       "   'much',\n",
       "   'easy',\n",
       "   'solve',\n",
       "   'start',\n",
       "   'equation',\n",
       "   'indeed',\n",
       "   'case'],\n",
       "  ['equation', 'verify', 'induction'],\n",
       "  ['base_case',\n",
       "   'true',\n",
       "   'know',\n",
       "   'know',\n",
       "   'maximum_possible',\n",
       "   'spread',\n",
       "   'hence',\n",
       "   'maximum_possible',\n",
       "   'overhang',\n",
       "   'stable',\n",
       "   'stack',\n",
       "   'book'],\n",
       "  ['do', 'quite'],\n",
       "  ['number']],\n",
       " [['harmonic_number', 'definition'],\n",
       "  ['nth', 'harmonic_number', 'wwd', 'would', 'table', 'table', 'figure'],\n",
       "  ['way', 'achieve', 'spread', 'overhang'],\n",
       "  ['method', 'use', 'case', 'top_block', 'case', 'other'],\n",
       "  ['method', 'use', 'case', 'block', 'add', 'stack'],\n",
       "  ['good_news', 'bad_news', 'harmonic_number'],\n",
       "  ['bad_news', 'close_form_expression', 'know', 'harmonic_number'],\n",
       "  ['good_news',\n",
       "   'use',\n",
       "   'theorem',\n",
       "   'get',\n",
       "   'close',\n",
       "   'upper',\n",
       "   'low',\n",
       "   'bound',\n",
       "   'word',\n",
       "   'nth',\n",
       "   'harmonic_number',\n",
       "   'close',\n",
       "   'ln'],\n",
       "  ['harmonic_number',\n",
       "   'frequently',\n",
       "   'arise_practice',\n",
       "   'mathematician',\n",
       "   'work',\n",
       "   'hard',\n",
       "   'get',\n",
       "   'even_well',\n",
       "   'approximation'],\n",
       "  ['fact', 'value', 'call', 'euler', 'constant'],\n",
       "  ['prove', 'formula'],\n",
       "  ['finally', 'do', 'analysis', 'block', 'stack', 'problem'],\n",
       "  ['plug', 'ging', 'value']],\n",
       " [['asymptotic',\n",
       "   'equality',\n",
       "   'case',\n",
       "   'equation',\n",
       "   'understand',\n",
       "   'growth',\n",
       "   'function',\n",
       "   'definition'],\n",
       "  ['function', 'say', 'asymptotically', 'equal', 'symbol'],\n",
       "  ['iff', 'lim'],\n",
       "  ['tempting', 'write', 'ln'],\n",
       "  ['reason', 'notation', 'useful', 'often', 'care', 'low', 'order', 'term'],\n",
       "  ['example', 'compute'],\n",
       "  ['great',\n",
       "   'precision',\n",
       "   'spend',\n",
       "   'lot',\n",
       "   'time',\n",
       "   'talk',\n",
       "   'asymptotic_notation',\n",
       "   'end',\n",
       "   'chapter'],\n",
       "  ['let', 'sum']],\n",
       " [['double',\n",
       "   'trouble',\n",
       "   'sometimes',\n",
       "   'evaluate',\n",
       "   'sum',\n",
       "   'sum',\n",
       "   'otherwise',\n",
       "   'know',\n",
       "   'double',\n",
       "   'summa',\n",
       "   'tion'],\n",
       "  ['sound', 'hairy', 'sometimes'],\n",
       "  ['usually',\n",
       "   'straightforward',\n",
       "   'evaluate',\n",
       "   'inner',\n",
       "   'sum',\n",
       "   'replace',\n",
       "   'close_form',\n",
       "   'evaluate',\n",
       "   'chapter_sum',\n",
       "   'asymptotic',\n",
       "   'outer',\n",
       "   'sum',\n",
       "   'long',\n",
       "   'summation',\n",
       "   'inside'],\n",
       "  ['example',\n",
       "   'obvious',\n",
       "   'closed_form',\n",
       "   'inner',\n",
       "   'sum',\n",
       "   'special',\n",
       "   'trick',\n",
       "   'often',\n",
       "   'useful',\n",
       "   'try',\n",
       "   'exchange',\n",
       "   'order',\n",
       "   'summation'],\n",
       "  ['example_suppose',\n",
       "   'want',\n",
       "   'compute',\n",
       "   'sum',\n",
       "   'first',\n",
       "   'harmonic_number',\n",
       "   'intuition',\n",
       "   'sum',\n",
       "   'apply',\n",
       "   'theorem',\n",
       "   'equation',\n",
       "   'con',\n",
       "   'clude',\n",
       "   'sum',\n",
       "   'close',\n",
       "   'let_look',\n",
       "   'exact',\n",
       "   'answer'],\n",
       "  ['think', 'pair'],\n",
       "  ['maybe', 'little', 'hairy', 'also', 'fairly', 'straightforward'],\n",
       "  ['wait',\n",
       "   'see',\n",
       "   'next',\n",
       "   'sum',\n",
       "   'form',\n",
       "   'triangle',\n",
       "   'summation',\n",
       "   'equation',\n",
       "   'sum',\n",
       "   'row',\n",
       "   'add',\n",
       "   'row',\n",
       "   'sum'],\n",
       "  ['instead', 'sum', 'column', 'add', 'column', 'sum'],\n",
       "  ['inspect',\n",
       "   'table',\n",
       "   'see',\n",
       "   'double',\n",
       "   'sum',\n",
       "   'write',\n",
       "   'chapter_sum',\n",
       "   'asymptotic']],\n",
       " [['product',\n",
       "   'cover',\n",
       "   'several',\n",
       "   'technique',\n",
       "   'find',\n",
       "   'closed_form',\n",
       "   'sum',\n",
       "   'method',\n",
       "   'deal',\n",
       "   'product'],\n",
       "  ['fortunately',\n",
       "   'need',\n",
       "   'develop',\n",
       "   'entirely',\n",
       "   'new',\n",
       "   'set',\n",
       "   'tool',\n",
       "   'encounter',\n",
       "   'product',\n",
       "   'would',\n",
       "   'convert',\n",
       "   'product',\n",
       "   'sum',\n",
       "   'take',\n",
       "   'logarithm'],\n",
       "  ['example',\n",
       "   'ln_ln',\n",
       "   'would',\n",
       "   'apply',\n",
       "   'summing',\n",
       "   'tool',\n",
       "   'find_close_form',\n",
       "   'approximate',\n",
       "   'close_form',\n",
       "   'ln',\n",
       "   'example',\n",
       "   'let_see',\n",
       "   'work',\n",
       "   'factorial',\n",
       "   'function',\n",
       "   'ln_ln',\n",
       "   'ln_ln',\n",
       "   'would',\n",
       "   'unfortunately',\n",
       "   'close_form',\n",
       "   'sum',\n",
       "   'know'],\n",
       "  ['however',\n",
       "   'apply',\n",
       "   'theorem',\n",
       "   'find',\n",
       "   'good',\n",
       "   'closed_form',\n",
       "   'bound',\n",
       "   'sum'],\n",
       "  ['first',\n",
       "   'compute',\n",
       "   'plugging',\n",
       "   'theorem',\n",
       "   'ln_ln',\n",
       "   'ln_ln',\n",
       "   'exponentiating',\n",
       "   'give',\n",
       "   'mean']],\n",
       " [['stirle',\n",
       "   'formula',\n",
       "   'probably',\n",
       "   'commonly_use',\n",
       "   'product',\n",
       "   'discrete',\n",
       "   'mathematic',\n",
       "   'mathematician',\n",
       "   'put',\n",
       "   'effort',\n",
       "   'find',\n",
       "   'much',\n",
       "   'better',\n",
       "   'close_form',\n",
       "   'bound',\n",
       "   'value'],\n",
       "  ['useful', 'bound', 'give', 'theorem', 'theorem'],\n",
       "  ['stirle', 'formula'],\n",
       "  ['theorem_prove',\n",
       "   'induction',\n",
       "   'several',\n",
       "   'important',\n",
       "   'thing',\n",
       "   'notice',\n",
       "   'stirle',\n",
       "   'formula'],\n",
       "  ['first', 'rather', 'surprising'],\n",
       "  ['would',\n",
       "   'expect',\n",
       "   'third',\n",
       "   'notation',\n",
       "   'define',\n",
       "   'section',\n",
       "   'chapter_sum',\n",
       "   'asymptotic',\n",
       "   'table'],\n",
       "  ['error',\n",
       "   'bound',\n",
       "   'common',\n",
       "   'approximations',\n",
       "   'approximation',\n",
       "   'correct',\n",
       "   'value'],\n",
       "  ['need',\n",
       "   'even',\n",
       "   'close',\n",
       "   'approximation',\n",
       "   'depend',\n",
       "   'want',\n",
       "   'upper_bind',\n",
       "   'lower',\n",
       "   'bind',\n",
       "   'respectively'],\n",
       "  ['theorem', 'correct', 'value'],\n",
       "  ['quick', 'future', 'reference', 'fact', 'summarize', 'corollary', 'table']],\n",
       " [['asymptotic_notation',\n",
       "   'asymptotic_notation',\n",
       "   'shorthand',\n",
       "   'use',\n",
       "   'give',\n",
       "   'quick',\n",
       "   'measure',\n",
       "   'behavior',\n",
       "   'function'],\n",
       "  ['grow', 'large'],\n",
       "  ['example',\n",
       "   'asymptotic_notation',\n",
       "   'defi',\n",
       "   'nition',\n",
       "   'binary_relation',\n",
       "   'indicate',\n",
       "   'function',\n",
       "   'grow',\n",
       "   'rate'],\n",
       "  ['also',\n",
       "   'binary_relation',\n",
       "   'indicate',\n",
       "   'function',\n",
       "   'grow',\n",
       "   'significantly',\n",
       "   'slow',\n",
       "   'rate']],\n",
       " [['little', 'definition'],\n",
       "  ['function', 'nonnegative', 'say', 'asymptotically', 'small', 'symbol'],\n",
       "  ['iff', 'lim'],\n",
       "  ['example', 'lemma'],\n",
       "  ['use', 'familiar', 'fact', 'log', 'prove', 'lemma'],\n",
       "  ['log'],\n",
       "  ['proof'],\n",
       "  ['choose', 'log'],\n",
       "  ['lemma', 'corollary'],\n",
       "  ['lemma',\n",
       "   'corollary',\n",
       "   'also',\n",
       "   'prove',\n",
       "   'use',\n",
       "   'hopital',\n",
       "   's',\n",
       "   'rule',\n",
       "   'mclaurin',\n",
       "   'series',\n",
       "   'log',\n",
       "   'chapter_sum',\n",
       "   'asymptotic']],\n",
       " [['big', 'big', 'frequently', 'use', 'asymptotic_notation'],\n",
       "  ['use', 'give', 'upper_bind', 'growth', 'function', 'run_time', 'algorithm'],\n",
       "  ['definition'],\n",
       "  ['give', 'nonnegative', 'function', 'say'],\n",
       "  ['iff', 'lim', 'sup'],\n",
       "  ['definition', 'make', 'clear', 'lemma'],\n",
       "  ['proof'],\n",
       "  ['lim', 'lim', 'imply', 'lim'],\n",
       "  ['easy', 'see', 'converse', 'lemma', 'true'],\n",
       "  ['example'],\n",
       "  ['usual',\n",
       "   'formulation',\n",
       "   'big',\n",
       "   'spell',\n",
       "   'definition',\n",
       "   'lim',\n",
       "   'sup',\n",
       "   'mention'],\n",
       "  ['namely', 'equivalent', 'definition', 'definition'],\n",
       "  ['give', 'function', 'say'],\n",
       "  ['iff',\n",
       "   'exist',\n",
       "   'constant',\n",
       "   'definition',\n",
       "   'rather',\n",
       "   'complicated',\n",
       "   'idea',\n",
       "   'simple'],\n",
       "  ['means'],\n",
       "  ['less', 'equal'],\n",
       "  ['willing',\n",
       "   'ignore',\n",
       "   'constant',\n",
       "   'factor',\n",
       "   'namely',\n",
       "   'allow',\n",
       "   'exception',\n",
       "   'small',\n",
       "   'namely',\n",
       "   'observe',\n",
       "   'lemma'],\n",
       "  ['true'],\n",
       "  ['simply', 'use', 'limit', 'definition'],\n",
       "  ['oscillate', 'say', 'grow'],\n",
       "  ['lim', 'precise', 'definition', 'lim', 'sup', 'lim', 'sup'],\n",
       "  ['wwd', 'lim', 'lub'],\n",
       "  ['lub', 'abbreviates', 'least', 'upper_bind'],\n",
       "  ['proposition'],\n",
       "  ['omit', 'routine', 'proof'],\n",
       "  ['big',\n",
       "   'notation',\n",
       "   'especially',\n",
       "   'useful',\n",
       "   'describe',\n",
       "   'running',\n",
       "   'time',\n",
       "   'algorithm'],\n",
       "  ['example',\n",
       "   'usual',\n",
       "   'algorithm',\n",
       "   'multiplying',\n",
       "   'matrix',\n",
       "   'use',\n",
       "   'number',\n",
       "   'operation',\n",
       "   'proportional']],\n",
       " [['omega',\n",
       "   'suppose_want',\n",
       "   'make',\n",
       "   'statement',\n",
       "   'form',\n",
       "   'run_time',\n",
       "   'algo',\n",
       "   'rithm',\n",
       "   'least'],\n",
       "  ['say', 'least'],\n",
       "  ['even', 'conceivable'],\n",
       "  ['example', 'run_time', 'algorithm', 'inputs', 'size'],\n",
       "  ['want', 'say', 'least', 'quadratic', 'say'],\n",
       "  ['little',\n",
       "   'omega',\n",
       "   'also',\n",
       "   'symbol',\n",
       "   'call',\n",
       "   'little',\n",
       "   'omega',\n",
       "   'analogous',\n",
       "   'little',\n",
       "   'denote',\n",
       "   'function',\n",
       "   'grow',\n",
       "   'strictly',\n",
       "   'faster',\n",
       "   'function'],\n",
       "  ['definition'],\n",
       "  ['function', 'nonnegative', 'say'],\n",
       "  ['iff'],\n",
       "  ['lim', 'word'],\n",
       "  ['iff'],\n",
       "  ['example'],\n",
       "  ['ln',\n",
       "   'little',\n",
       "   'omega',\n",
       "   'symbol',\n",
       "   'widely',\n",
       "   'use',\n",
       "   'asymptotic',\n",
       "   'symbol',\n",
       "   'discuss']],\n",
       " [['theta', 'sometimes', 'want', 'specify', 'run_time'],\n",
       "  ['precisely',\n",
       "   'quadratic',\n",
       "   'constant',\n",
       "   'factor',\n",
       "   'upper_bind',\n",
       "   'low',\n",
       "   'bind'],\n",
       "  ['could', 'say'],\n",
       "  ['definition'],\n",
       "  ['iff'],\n",
       "  ['statement'],\n",
       "  ['paraphrase', 'intuitively', 'equal', 'constant', 'factor'],\n",
       "  ['indeed', 'theorem'],\n",
       "  ['iff'],\n",
       "  ['theta',\n",
       "   'notation',\n",
       "   'allow',\n",
       "   'highlight',\n",
       "   'growth',\n",
       "   'rate',\n",
       "   'allow',\n",
       "   'suppression',\n",
       "   'distracting',\n",
       "   'factor',\n",
       "   'low',\n",
       "   'order',\n",
       "   'term'],\n",
       "  ['example', 'run_time', 'algorithm'],\n",
       "  ['simply', 'write'],\n",
       "  ['case', 'would', 'say', 'order', 'know', 'run_time', 'algorithm'],\n",
       "  ['time'],\n",
       "  ['could', 'regularly', 'exceed'],\n",
       "  ['factor', 'large'],\n",
       "  ['factor', 'sure', 'close', 'large'],\n",
       "  ['chapter_sum', 'asymptotic']],\n",
       " [['pitfalls',\n",
       "   'asymptotic_notation',\n",
       "   'long',\n",
       "   'list',\n",
       "   'way_make',\n",
       "   'mistake',\n",
       "   'asymptotic_notation'],\n",
       "  ['section', 'present', 'way', 'big', 'notation', 'lead', 'ruin', 'despair'],\n",
       "  ['minimal', 'effort', 'cause', 'much', 'chaos', 'symbol'],\n",
       "  ['exponential',\n",
       "   'fiasco',\n",
       "   'sometimes',\n",
       "   'relationship',\n",
       "   'involve',\n",
       "   'big',\n",
       "   'obvious'],\n",
       "  ['example', 'may', 'guess', 'constant', 'confusion', 'constant'],\n",
       "  ['example'],\n",
       "  ['true', 'let'],\n",
       "  ['exist'],\n",
       "  ['construct', 'false', 'theorem', 'exploit', 'fact'],\n",
       "  ['false', 'theorem'],\n",
       "  ['would', 'error', 'stem', 'confusion', 'mean', 'statement'],\n",
       "  ['constant', 'true'],\n",
       "  ['precisely', 'constant', 'function'],\n",
       "  ['false', 'theorem', 'constant', 'range', 'set', 'value'],\n",
       "  ['depend'],\n",
       "  ['add'],\n",
       "  ['number'],\n",
       "  ['never', 'even', 'define'],\n",
       "  ['mean', 'use', 'context'],\n",
       "  ['describe', 'relation', 'function'],\n",
       "  ['lower',\n",
       "   'bind',\n",
       "   'blunder',\n",
       "   'sometimes',\n",
       "   'people',\n",
       "   'incorrectly',\n",
       "   'use',\n",
       "   'big',\n",
       "   'context',\n",
       "   'lower',\n",
       "   'bind'],\n",
       "  ['example', 'may', 'say', 'running', 'time'],\n",
       "  ['least'],\n",
       "  ['also', 'correctly', 'express', 'equality', 'blunder', 'notation'],\n",
       "  ['know', 'mean']],\n",
       " [['recurrence', 'recurrence', 'describe_sequence', 'number'],\n",
       "  ['early',\n",
       "   'term',\n",
       "   'specify',\n",
       "   'explic',\n",
       "   'itly',\n",
       "   'later',\n",
       "   'term',\n",
       "   'express',\n",
       "   'function',\n",
       "   'predecessor'],\n",
       "  ['trivial', 'example', 'recurrence', 'describe_sequence'],\n",
       "  ['first', 'term', 'define', 'subsequent', 'term', 'predecessor'],\n",
       "  ['recurrence', 'turn', 'powerful', 'tool'],\n",
       "  ['chapter',\n",
       "   'emphasize',\n",
       "   'use',\n",
       "   'recurrence',\n",
       "   'analyze',\n",
       "   'performance',\n",
       "   'recursive',\n",
       "   'algorithm'],\n",
       "  ['however',\n",
       "   'recur',\n",
       "   'rence',\n",
       "   'application',\n",
       "   'computer_science',\n",
       "   'well',\n",
       "   'enumeration',\n",
       "   'structure',\n",
       "   'analysis',\n",
       "   'random',\n",
       "   'process'],\n",
       "  ['see',\n",
       "   'section',\n",
       "   'recurrence',\n",
       "   'isolation',\n",
       "   'useful',\n",
       "   'description',\n",
       "   'sequence'],\n",
       "  ['easily',\n",
       "   'answer',\n",
       "   'simple',\n",
       "   'question',\n",
       "   'hundredth',\n",
       "   'term',\n",
       "   'asymptotic',\n",
       "   'growth',\n",
       "   'rate',\n",
       "   'typically',\n",
       "   'want',\n",
       "   'solve_recurrence',\n",
       "   'find_close_form',\n",
       "   'expression',\n",
       "   'nth',\n",
       "   'term'],\n",
       "  ['first',\n",
       "   'introduce',\n",
       "   'general',\n",
       "   'solve',\n",
       "   'technique',\n",
       "   'guess_verify',\n",
       "   'plug_chug'],\n",
       "  ['method',\n",
       "   'applicable',\n",
       "   'recurrence',\n",
       "   'success',\n",
       "   'quire',\n",
       "   'flash',\n",
       "   'insight',\n",
       "   'sometimes',\n",
       "   'unrealistically',\n",
       "   'brilliant',\n",
       "   'flash'],\n",
       "  ['also',\n",
       "   'introduce',\n",
       "   'big',\n",
       "   'class',\n",
       "   'recurrence',\n",
       "   'linear',\n",
       "   'divide_conquer',\n",
       "   'often',\n",
       "   'come',\n",
       "   'computer_science'],\n",
       "  ['essentially',\n",
       "   'recurrence',\n",
       "   'class',\n",
       "   'solvable',\n",
       "   'use',\n",
       "   'cookbook',\n",
       "   'technique',\n",
       "   'follow',\n",
       "   'recipe',\n",
       "   'get',\n",
       "   'answer'],\n",
       "  ['drawback', 'calculation', 'replace', 'insight'],\n",
       "  ['moment',\n",
       "   'essential',\n",
       "   'guess_verify',\n",
       "   'plug_chug',\n",
       "   'method',\n",
       "   'replace',\n",
       "   'huh',\n",
       "   'end',\n",
       "   'cookbook',\n",
       "   'procedure'],\n",
       "  ['end',\n",
       "   'chapter',\n",
       "   'develop',\n",
       "   'rule_thumb',\n",
       "   'help',\n",
       "   'assess',\n",
       "   'many',\n",
       "   'recurrence',\n",
       "   'calculation'],\n",
       "  ['rule',\n",
       "   'help',\n",
       "   'distinguish',\n",
       "   'promis',\n",
       "   'ing',\n",
       "   'approach',\n",
       "   'bad',\n",
       "   'idea',\n",
       "   'early',\n",
       "   'process',\n",
       "   'design',\n",
       "   'algorithm'],\n",
       "  ['recurrence',\n",
       "   'aspect',\n",
       "   'broad',\n",
       "   'theme',\n",
       "   'computer_science',\n",
       "   'reduce',\n",
       "   'big',\n",
       "   'problem',\n",
       "   'progressively',\n",
       "   'small',\n",
       "   'problem',\n",
       "   'easy',\n",
       "   'base_case',\n",
       "   'reach'],\n",
       "  ['idea', 'underlie', 'induction_proof', 'recursive', 'algorithm'],\n",
       "  ['see', 'idea', 'snap', 'together', 'nicely'],\n",
       "  ['example',\n",
       "   'may',\n",
       "   'describe',\n",
       "   'running',\n",
       "   'time',\n",
       "   'recursive',\n",
       "   'algorithm',\n",
       "   'recurrence',\n",
       "   'use_induction',\n",
       "   'verify',\n",
       "   'solution'],\n",
       "  ['chapter', 'recurrences', 'figure'],\n",
       "  ['initial', 'configuration', 'disk', 'tower_hanoi', 'problem']],\n",
       " [['towers',\n",
       "   'hanoi',\n",
       "   'accord',\n",
       "   'legend',\n",
       "   'temple',\n",
       "   'hanoi',\n",
       "   'post',\n",
       "   'gold',\n",
       "   'disk',\n",
       "   'different',\n",
       "   'size'],\n",
       "  ['disk', 'hole', 'center', 'fit', 'post'],\n",
       "  ['misty',\n",
       "   'past',\n",
       "   'disk',\n",
       "   'first',\n",
       "   'post',\n",
       "   'large',\n",
       "   'bottom',\n",
       "   'small',\n",
       "   'top',\n",
       "   'show_figure',\n",
       "   'monk',\n",
       "   'temple',\n",
       "   'labor',\n",
       "   'year',\n",
       "   'move',\n",
       "   'disk',\n",
       "   'post',\n",
       "   'accord',\n",
       "   'follow',\n",
       "   'rule',\n",
       "   'permit',\n",
       "   'action',\n",
       "   'remove',\n",
       "   'top',\n",
       "   'disk',\n",
       "   'post',\n",
       "   'drop',\n",
       "   'pe',\n",
       "   'post'],\n",
       "  ['large', 'disk', 'never', 'lie', 'small', 'disk', 'post'],\n",
       "  ['example', 'pick', 'whole', 'stack', 'disk', 'drop', 'post', 'illegal'],\n",
       "  ['good',\n",
       "   'legend',\n",
       "   'say',\n",
       "   'monk',\n",
       "   'complete',\n",
       "   'puzzle',\n",
       "   'world',\n",
       "   'end',\n",
       "   'clarify',\n",
       "   'problem',\n",
       "   'suppose',\n",
       "   'gold',\n",
       "   'disk',\n",
       "   'instead'],\n",
       "  ['puzzle',\n",
       "   'could',\n",
       "   'solved',\n",
       "   'step',\n",
       "   'show_figure',\n",
       "   'question',\n",
       "   'must',\n",
       "   'answer',\n",
       "   'give',\n",
       "   'sufficient',\n",
       "   'time',\n",
       "   'monk',\n",
       "   'suc',\n",
       "   'ceed',\n",
       "   'long',\n",
       "   'world',\n",
       "   'end',\n",
       "   'importantly',\n",
       "   'happen',\n",
       "   'final',\n",
       "   'exam']],\n",
       " [['recursive', 'solution', 'tower_hanoi', 'problem', 'solve', 'recursively'],\n",
       "  ['describe', 'pro', 'cedure', 'also', 'analyze', 'running', 'time'],\n",
       "  ['end',\n",
       "   'let',\n",
       "   'recursive',\n",
       "   'solution',\n",
       "   'stage',\n",
       "   'describe',\n",
       "   'illustrate_figure',\n",
       "   'figure'],\n",
       "  ['step', 'solution', 'tower_hanoi', 'problem', 'disk'],\n",
       "  ['figure'],\n",
       "  ['recursive', 'solution', 'tower_hanoi', 'problem'],\n",
       "  ['stage'],\n",
       "  ['move',\n",
       "   'solution',\n",
       "   'disk',\n",
       "   'second',\n",
       "   'post',\n",
       "   'third',\n",
       "   'post',\n",
       "   'use',\n",
       "   'disk'],\n",
       "  ['also',\n",
       "   'do',\n",
       "   'algorithm',\n",
       "   'show',\n",
       "   'continue',\n",
       "   'way',\n",
       "   'could',\n",
       "   'eventually',\n",
       "   'compute',\n",
       "   'upper_bind']],\n",
       " [['find',\n",
       "   'recurrence',\n",
       "   'compute',\n",
       "   'exact',\n",
       "   'number',\n",
       "   'step',\n",
       "   'monk',\n",
       "   'nee',\n",
       "   'move',\n",
       "   'disk',\n",
       "   'upper_bind'],\n",
       "  ['perhaps',\n",
       "   'ponder',\n",
       "   'problem',\n",
       "   'begin',\n",
       "   'time',\n",
       "   'monk',\n",
       "   'devise',\n",
       "   'well',\n",
       "   'algorithm'],\n",
       "  ['fact', 'well', 'algorithm'],\n",
       "  ['step',\n",
       "   'monk',\n",
       "   'must',\n",
       "   'move',\n",
       "   'large',\n",
       "   'disk',\n",
       "   'first',\n",
       "   'post',\n",
       "   'different',\n",
       "   'post'],\n",
       "  ['happen', 'small', 'disk', 'must', 'stack', 'way', 'remain', 'post'],\n",
       "  ['arrange',\n",
       "   'small',\n",
       "   'disk',\n",
       "   'way',\n",
       "   'require',\n",
       "   'least',\n",
       "   'argument',\n",
       "   'show',\n",
       "   'number',\n",
       "   'step',\n",
       "   'require',\n",
       "   'least',\n",
       "   'typical',\n",
       "   'recurrence'],\n",
       "  ['line',\n",
       "   'define',\n",
       "   'sequence',\n",
       "   'value',\n",
       "   'use',\n",
       "   'recurrence',\n",
       "   'compute',\n",
       "   'number',\n",
       "   'term',\n",
       "   'sequence']],\n",
       " [['solve_recurrence',\n",
       "   'could',\n",
       "   'determine',\n",
       "   'number',\n",
       "   'step',\n",
       "   'move',\n",
       "   'disk',\n",
       "   'tower',\n",
       "   'compute',\n",
       "   'several',\n",
       "   'method',\n",
       "   'solve_recurrence',\n",
       "   'equation'],\n",
       "  ['simple',\n",
       "   'guess',\n",
       "   'solution',\n",
       "   'verify',\n",
       "   'guess',\n",
       "   'correct',\n",
       "   'induction_proof'],\n",
       "  ['basis',\n",
       "   'good',\n",
       "   'guess',\n",
       "   'let_look',\n",
       "   'pattern',\n",
       "   'value',\n",
       "   'verification',\n",
       "   'proof',\n",
       "   'especially',\n",
       "   'tidy',\n",
       "   'recurrence',\n",
       "   'equations',\n",
       "   'induction_proof',\n",
       "   'analogous',\n",
       "   'structure'],\n",
       "  ['particular',\n",
       "   'base_case',\n",
       "   'rely',\n",
       "   'first',\n",
       "   'line',\n",
       "   'recurrence',\n",
       "   'define',\n",
       "   'guess_verify'],\n",
       "  ['resolve', 'remain', 'question', 'disk', 'puzzle']],\n",
       " [['upper',\n",
       "   'bound',\n",
       "   'trap',\n",
       "   'solution_recurrence',\n",
       "   'complicate',\n",
       "   'may',\n",
       "   'try_prove',\n",
       "   'simple',\n",
       "   'expression',\n",
       "   'upper_bind',\n",
       "   'solution'],\n",
       "  ['example', 'exact', 'lution', 'tower_hanoi', 'recurrence', 'proof'],\n",
       "  ['fail', 'attempt'],\n",
       "  ['proof', 'induction'],\n",
       "  ['induction_hypothesis',\n",
       "   'first',\n",
       "   'equality',\n",
       "   'recurrence',\n",
       "   'relation',\n",
       "   'second',\n",
       "   'follow',\n",
       "   'induction_hypothesis',\n",
       "   'third',\n",
       "   'step',\n",
       "   'flame',\n",
       "   'train',\n",
       "   'wreck'],\n",
       "  ['proof',\n",
       "   'work',\n",
       "   'often',\n",
       "   'case',\n",
       "   'induction_proof',\n",
       "   'ar',\n",
       "   'gument',\n",
       "   'go',\n",
       "   'strong',\n",
       "   'hypothesis'],\n",
       "  ['say',\n",
       "   'upper',\n",
       "   'bound',\n",
       "   'solution_recurrence',\n",
       "   'hopeless',\n",
       "   'situation',\n",
       "   'duction',\n",
       "   'recurrence',\n",
       "   'mix',\n",
       "   'well']],\n",
       " [['plug_chug',\n",
       "   'guess_verify',\n",
       "   'simple',\n",
       "   'general',\n",
       "   'way',\n",
       "   'solve_recurrence',\n",
       "   'equation'],\n",
       "  ['big', 'drawback', 'guess', 'right'],\n",
       "  ['hard', 'tower_hanoi', 'example'],\n",
       "  ['sometimes',\n",
       "   'solution_recurrence',\n",
       "   'strange',\n",
       "   'form',\n",
       "   'quite',\n",
       "   'difficult',\n",
       "   'guess'],\n",
       "  ['practice', 'help', 'course', 'method'],\n",
       "  ['plug_chug', 'way', 'solve_recurrence'],\n",
       "  ['also', 'sometimes', 'call', 'expansion', 'iteration'],\n",
       "  ['guess_verify', 'key', 'step', 'identify', 'pattern'],\n",
       "  ['instead',\n",
       "   'look',\n",
       "   'sequence',\n",
       "   'number',\n",
       "   'spot',\n",
       "   'pattern',\n",
       "   'sequence',\n",
       "   'expression',\n",
       "   'sometimes',\n",
       "   'easy'],\n",
       "  ['method',\n",
       "   'consist',\n",
       "   'step',\n",
       "   'describe',\n",
       "   'illustrated',\n",
       "   'tower_hanoi',\n",
       "   'example'],\n",
       "  ['step',\n",
       "   'plug_chug',\n",
       "   'pattern',\n",
       "   'appear',\n",
       "   'first_step',\n",
       "   'expand',\n",
       "   'recurrence_equation',\n",
       "   'alternately',\n",
       "   'plug',\n",
       "   'apply',\n",
       "   'ing',\n",
       "   'recurrence',\n",
       "   'chug',\n",
       "   'simplifying',\n",
       "   'result',\n",
       "   'pattern',\n",
       "   'appear'],\n",
       "  ['careful', 'much', 'simplification', 'make', 'pattern', 'hard', 'spot'],\n",
       "  ['rule',\n",
       "   'remember',\n",
       "   'indeed',\n",
       "   'rule',\n",
       "   'applicable',\n",
       "   'whole',\n",
       "   'college',\n",
       "   'life',\n",
       "   'chug',\n",
       "   'moderation'],\n",
       "  ['start', 'recurrence_equation'],\n",
       "  ['replace',\n",
       "   'nk',\n",
       "   'nk',\n",
       "   'pattern',\n",
       "   'clear',\n",
       "   'simplify',\n",
       "   'safe',\n",
       "   'convenient'],\n",
       "  ['particular', 'collapse', 'geometric_sum', 'close_form', 'second_line'],\n",
       "  ['chapter_recurrence',\n",
       "   'step',\n",
       "   'verify',\n",
       "   'pattern',\n",
       "   'next',\n",
       "   'step',\n",
       "   'verify',\n",
       "   'general',\n",
       "   'formula',\n",
       "   'round',\n",
       "   'plug_chug'],\n",
       "  ['final', 'expression', 'right', 'expression', 'first', 'line', 'replace'],\n",
       "  ['surprisingly', 'effectively', 'prove', 'formula', 'correct'],\n",
       "  ['know', 'formula', 'hold', 'original', 'recurrence_equation'],\n",
       "  ['show', 'formula', 'hold', 'also', 'hold'],\n",
       "  ['formula', 'hold', 'induction'],\n",
       "  ['step',\n",
       "   'write',\n",
       "   'last',\n",
       "   'step',\n",
       "   'express',\n",
       "   'do',\n",
       "   'answer',\n",
       "   'get',\n",
       "   'guess_verify'],\n",
       "  ['let', 'compare', 'guess_verify', 'plug_chug'],\n",
       "  ['guess_verify',\n",
       "   'method',\n",
       "   'compute',\n",
       "   'several',\n",
       "   'term',\n",
       "   'begin',\n",
       "   'sequence']],\n",
       " [['merge_sort',\n",
       "   'algorithms',\n",
       "   'textbook',\n",
       "   'traditionally',\n",
       "   'claim',\n",
       "   'sort',\n",
       "   'important',\n",
       "   'fundamental',\n",
       "   'problem',\n",
       "   'computer_science'],\n",
       "  ['smack',\n",
       "   'sort',\n",
       "   'algorithm',\n",
       "   'life',\n",
       "   'disk',\n",
       "   'stack',\n",
       "   'monk',\n",
       "   'hanoi',\n",
       "   'sound',\n",
       "   'delightful'],\n",
       "  ['cover', 'well', 'know', 'sort', 'algorithm', 'merge_sort'],\n",
       "  ['analysis', 'introduce', 'kind', 'recurrence'],\n",
       "  ['merge_sort', 'work'],\n",
       "  ['input', 'list', 'number', 'output', 'number', 'nondecrease', 'order'],\n",
       "  ['case',\n",
       "   'input',\n",
       "   'single',\n",
       "   'number',\n",
       "   'algorithm',\n",
       "   'list',\n",
       "   'already',\n",
       "   'sort'],\n",
       "  ['otherwise', 'list', 'contain', 'number'],\n",
       "  ['first', 'second', 'half', 'list', 'sort', 'recursively'],\n",
       "  ['half', 'merge', 'form', 'sorted', 'list', 'number'],\n",
       "  ['let', 'work', 'example'],\n",
       "  ['suppose_want', 'sort', 'list'],\n",
       "  ['number', 'first', 'second', 'half', 'sorted', 'recursively'],\n",
       "  ['result'],\n",
       "  ['remain', 'merge', 'list'],\n",
       "  ['do', 'repeatedly', 'emit', 'small', 'lead', 'term'],\n",
       "  ['list', 'empty', 'whole', 'list', 'emit'],\n",
       "  ['example', 'work'],\n",
       "  ['table', 'underlined', 'number', 'emit'],\n",
       "  ['lead', 'term', 'initially'],\n",
       "  ['output'],\n",
       "  ['lead', 'term', 'output'],\n",
       "  ['eventually', 'second', 'list', 'become', 'empty'],\n",
       "  ['point', 'output', 'whole', 'first', 'list', 'consist'],\n",
       "  ['complete', 'output', 'consist', 'number', 'sort', 'order'],\n",
       "  ['chapter_recurrence']],\n",
       " [['find',\n",
       "   'recurrence',\n",
       "   'traditional',\n",
       "   'question',\n",
       "   'sort',\n",
       "   'algorithm',\n",
       "   'maximum',\n",
       "   'number',\n",
       "   'comparison',\n",
       "   'use',\n",
       "   'sort',\n",
       "   'item',\n",
       "   'take',\n",
       "   'estimate',\n",
       "   'run_time'],\n",
       "  ['case', 'merge_sort', 'express', 'quantity', 'recurrence'],\n",
       "  ['let', 'number', 'list', 'comparison', 'require'],\n",
       "  ['otherwise',\n",
       "   'least',\n",
       "   'number',\n",
       "   'emit',\n",
       "   'comparison',\n",
       "   'number',\n",
       "   'emit',\n",
       "   'end',\n",
       "   'list',\n",
       "   'become',\n",
       "   'empty'],\n",
       "  ['item', 'emit', 'comparison'],\n",
       "  ['therefore',\n",
       "   'maximum',\n",
       "   'number',\n",
       "   'comparison',\n",
       "   'need',\n",
       "   'merge_sort',\n",
       "   'item',\n",
       "   'give',\n",
       "   'recurrence',\n",
       "   'power',\n",
       "   'fully',\n",
       "   'describe',\n",
       "   'number',\n",
       "   'comparison',\n",
       "   'useful',\n",
       "   'way',\n",
       "   'closed_form',\n",
       "   'expression',\n",
       "   'would',\n",
       "   'much',\n",
       "   'helpful'],\n",
       "  ['solve_recurrence']],\n",
       " [['solve_recurrence',\n",
       "   'let',\n",
       "   'first',\n",
       "   'try',\n",
       "   'solve',\n",
       "   'merge_sort_recurrence',\n",
       "   'guess_verify',\n",
       "   'tech',\n",
       "   'nique'],\n",
       "  ['first',\n",
       "   'value',\n",
       "   'trouble',\n",
       "   'guess',\n",
       "   'solution_recurrence',\n",
       "   'hard',\n",
       "   'obvious',\n",
       "   'pattern'],\n",
       "  ['let_try', 'plug_chug', 'method', 'instead'],\n",
       "  ['step',\n",
       "   'plug_chug',\n",
       "   'pattern',\n",
       "   'appear',\n",
       "   'first',\n",
       "   'expand',\n",
       "   'recurrence_equation',\n",
       "   'alternately',\n",
       "   'plug_chug',\n",
       "   'pattern',\n",
       "   'appear'],\n",
       "  ['pattern', 'emerge'],\n",
       "  ['particular',\n",
       "   'formula',\n",
       "   'seem',\n",
       "   'hold',\n",
       "   'second_line',\n",
       "   'group',\n",
       "   'term',\n",
       "   'power'],\n",
       "  ['third', 'collapse', 'geometric_sum'],\n",
       "  ['step',\n",
       "   'verify',\n",
       "   'pattern',\n",
       "   'verify',\n",
       "   'pattern',\n",
       "   'additional',\n",
       "   'round',\n",
       "   'plug_chug'],\n",
       "  ['guess', 'wrong', 'pattern', 'discover', 'mistake'],\n",
       "  ['formula', 'unchanged', 'replace'],\n",
       "  ['amounts', 'induction', 'step', 'proof', 'formula', 'hold'],\n",
       "  ['chapter_recurrence',\n",
       "   'step',\n",
       "   'write',\n",
       "   'finally',\n",
       "   'express',\n",
       "   'do',\n",
       "   'close_form_expression',\n",
       "   'maximum',\n",
       "   'number',\n",
       "   'com',\n",
       "   'parison',\n",
       "   'use',\n",
       "   'merge_sort',\n",
       "   'list',\n",
       "   'number'],\n",
       "  ['retrospect',\n",
       "   'easy',\n",
       "   'see',\n",
       "   'guess_verify',\n",
       "   'fail',\n",
       "   'formula',\n",
       "   'fairly',\n",
       "   'complicate'],\n",
       "  ['check',\n",
       "   'confirm',\n",
       "   'formula',\n",
       "   'give',\n",
       "   'value',\n",
       "   'compute',\n",
       "   'earlier',\n",
       "   'double',\n",
       "   'check',\n",
       "   'could',\n",
       "   'write',\n",
       "   'explicit',\n",
       "   'induction_proof'],\n",
       "  ['would',\n",
       "   'straightforward',\n",
       "   'already',\n",
       "   'work',\n",
       "   'gut',\n",
       "   'proof',\n",
       "   'step',\n",
       "   'plug_chug',\n",
       "   'procedure']],\n",
       " [['linear_recurrence',\n",
       "   'far',\n",
       "   'solve_recurrence',\n",
       "   'technique',\n",
       "   'guess_verify',\n",
       "   'plug_chug'],\n",
       "  ['method', 'require', 'spot', 'pattern', 'sequence', 'number', 'expression'],\n",
       "  ['section', 'give', 'cookbook', 'solution', 'large', 'class', 'recurrence'],\n",
       "  ['method',\n",
       "   'require',\n",
       "   'flash',\n",
       "   'insight',\n",
       "   'follow',\n",
       "   'recipe',\n",
       "   'get',\n",
       "   'answer']],\n",
       " [['climb_stair',\n",
       "   'many_different',\n",
       "   'way_climb_stair',\n",
       "   'step',\n",
       "   'stair',\n",
       "   'hop',\n",
       "   'example',\n",
       "   'different_way',\n",
       "   'climb_stair'],\n",
       "  ['step_step',\n",
       "   'step_step',\n",
       "   'hop',\n",
       "   'hop',\n",
       "   'hop',\n",
       "   'step_step',\n",
       "   'step',\n",
       "   'hop',\n",
       "   'step_step',\n",
       "   'step',\n",
       "   'hop',\n",
       "   'working',\n",
       "   'problem',\n",
       "   'demonstrate',\n",
       "   'major',\n",
       "   'feature',\n",
       "   'first',\n",
       "   'cook',\n",
       "   'book',\n",
       "   'method',\n",
       "   'solve_recurrence'],\n",
       "  ['fill', 'detail', 'general_solution', 'afterward'],\n",
       "  ['find',\n",
       "   'recurrence',\n",
       "   'special_case',\n",
       "   'way_climb_stair',\n",
       "   'way_climb_stair',\n",
       "   'step'],\n",
       "  ['general',\n",
       "   'ascent',\n",
       "   'stairs',\n",
       "   'consist',\n",
       "   'step',\n",
       "   'follow',\n",
       "   'ascent',\n",
       "   'remain',\n",
       "   'stairs',\n",
       "   'hop',\n",
       "   'follow',\n",
       "   'ascent',\n",
       "   'stair'],\n",
       "  ['total_number', 'way_climb_stair', 'equal_number', 'way'],\n",
       "  ['denote', 'number', 'way_climb_stair'],\n",
       "  ['also',\n",
       "   'switch',\n",
       "   'subscript',\n",
       "   'notation',\n",
       "   'functional',\n",
       "   'notation',\n",
       "   'fibonacci_recurrence',\n",
       "   'famous',\n",
       "   'recurrence_equation'],\n",
       "  ['fibonacci_number', 'arise', 'sort', 'application', 'nature'],\n",
       "  ['fibonacci', 'intro', 'duce', 'number', 'study', 'rabbit', 'reproduction'],\n",
       "  ['fibonacci_number',\n",
       "   'also',\n",
       "   'appear',\n",
       "   'oddly',\n",
       "   'enough',\n",
       "   'spiral',\n",
       "   'pattern',\n",
       "   'face',\n",
       "   'sunflower'],\n",
       "  ['input',\n",
       "   'number',\n",
       "   'make',\n",
       "   'euclid',\n",
       "   'gcd',\n",
       "   'algorithm',\n",
       "   'require',\n",
       "   'great',\n",
       "   'number',\n",
       "   'step',\n",
       "   'consecutive',\n",
       "   'fibonacci_number'],\n",
       "  ['solve_recurrence',\n",
       "   'fibonacci_recurrence',\n",
       "   'belong',\n",
       "   'class',\n",
       "   'linear',\n",
       "   'recurrences',\n",
       "   'es',\n",
       "   'sentially',\n",
       "   'solvable',\n",
       "   'technique',\n",
       "   'learn',\n",
       "   'hour'],\n",
       "  ['amazing',\n",
       "   'fibonacci_recurrence',\n",
       "   'remain',\n",
       "   'unsolved',\n",
       "   'almost',\n",
       "   'century',\n",
       "   'general',\n",
       "   'homogeneous_linear',\n",
       "   'recurrence',\n",
       "   'form'],\n",
       "  ['chapter_recurrence',\n",
       "   'let_try',\n",
       "   'solve',\n",
       "   'fibonacci_recurrence',\n",
       "   'benefit',\n",
       "   'century',\n",
       "   'hindsight'],\n",
       "  ['general', 'linear', 'recurrences', 'tend', 'exponential', 'solution'],\n",
       "  ['let', 'guess'],\n",
       "  ['parameter', 'introduce', 'improve', 'odd', 'make', 'correct', 'guess'],\n",
       "  ['figure', 'good', 'value', 'later'],\n",
       "  ['improve', 'odd', 'let', 'neglect', 'boundary_condition'],\n",
       "  ['plug', 'guess', 'recurrence'],\n",
       "  ['give',\n",
       "   'divide',\n",
       "   'side',\n",
       "   'leave',\n",
       "   'quadratic',\n",
       "   'equation',\n",
       "   'solve',\n",
       "   'equation',\n",
       "   'give',\n",
       "   'plausible',\n",
       "   'value',\n",
       "   'parameter',\n",
       "   'suggest',\n",
       "   'least',\n",
       "   'different',\n",
       "   'solution_recurrence',\n",
       "   'ne',\n",
       "   'glecte',\n",
       "   'boundary_condition'],\n",
       "  ['charming',\n",
       "   'feature',\n",
       "   'homogeneous_linear',\n",
       "   'recurrence',\n",
       "   'linear',\n",
       "   'com',\n",
       "   'bination',\n",
       "   'solution',\n",
       "   'solution'],\n",
       "  ['theorem'],\n",
       "  ['solution', 'homogeneous_linear', 'recurrence'],\n",
       "  ['sf'],\n",
       "  ['tg'],\n",
       "  ['also', 'solution'],\n",
       "  ['proof'],\n",
       "  ['sf'],\n",
       "  ['tg'],\n",
       "  ['tg'],\n",
       "  ['first_step',\n",
       "   'use',\n",
       "   'definition',\n",
       "   'function',\n",
       "   'second',\n",
       "   'use',\n",
       "   'fact',\n",
       "   'solution_recurrence'],\n",
       "  ['last', 'step', 'rearrange', 'term', 'use', 'definition'],\n",
       "  ['first', 'expression', 'equal', 'last', 'also', 'solution_recurrence'],\n",
       "  ['phenomenon',\n",
       "   'describe',\n",
       "   'theorem',\n",
       "   'linear_combination',\n",
       "   'solution',\n",
       "   'solution',\n",
       "   'also',\n",
       "   'hold',\n",
       "   'many',\n",
       "   'differential',\n",
       "   'equation',\n",
       "   'physical',\n",
       "   'system'],\n",
       "  ['fact',\n",
       "   'linear_recurrence',\n",
       "   'similar',\n",
       "   'linear',\n",
       "   'differential',\n",
       "   'equation',\n",
       "   'safely',\n",
       "   'snooze',\n",
       "   'topic',\n",
       "   'future',\n",
       "   'math',\n",
       "   'class'],\n",
       "  ['return',\n",
       "   'fibonacci_recurrence',\n",
       "   'theorem',\n",
       "   'imply',\n",
       "   'solution',\n",
       "   'real_number'],\n",
       "  ['theorem',\n",
       "   'expand',\n",
       "   'solution',\n",
       "   'whole',\n",
       "   'spectrum',\n",
       "   'possibilitie',\n",
       "   'give',\n",
       "   'option',\n",
       "   'choose',\n",
       "   'find',\n",
       "   'solution',\n",
       "   'satisfie',\n",
       "   'boundary_condition'],\n",
       "  ['boundary_condition', 'put', 'constraint', 'parameter'],\n",
       "  ['particular',\n",
       "   'first',\n",
       "   'boundary_condition',\n",
       "   'imply',\n",
       "   'similarly',\n",
       "   'second',\n",
       "   'boundary_condition',\n",
       "   'imply',\n",
       "   'linear_equation',\n",
       "   'unknown'],\n",
       "  ['system',\n",
       "   'degenerate',\n",
       "   'unique',\n",
       "   'solution',\n",
       "   'value',\n",
       "   'identify',\n",
       "   'solution',\n",
       "   'fibonacci_recurrence',\n",
       "   'also',\n",
       "   'satisfy',\n",
       "   'boundary_condition']],\n",
       " [['solve',\n",
       "   'homogeneous_linear',\n",
       "   'recurrence',\n",
       "   'method',\n",
       "   'use',\n",
       "   'solve',\n",
       "   'fibonacci_recurrence',\n",
       "   'extend',\n",
       "   'solve',\n",
       "   'homogeneous_linear',\n",
       "   'recurrence',\n",
       "   'recurrence',\n",
       "   'form'],\n",
       "  ['nd',\n",
       "   'divide',\n",
       "   'nd',\n",
       "   'give',\n",
       "   'call',\n",
       "   'characteristic_equation',\n",
       "   'recurrence'],\n",
       "  ['characteristic',\n",
       "   'equa',\n",
       "   'tion',\n",
       "   'read',\n",
       "   'quickly',\n",
       "   'coefficient',\n",
       "   'equation',\n",
       "   'coefficient',\n",
       "   'recurrence'],\n",
       "  ['solution', 'linear_recurrence', 'define', 'root_characteristic_equation'],\n",
       "  ['neglect',\n",
       "   'boundary_condition',\n",
       "   'moment',\n",
       "   'nonrepeate',\n",
       "   'root_characteristic_equation',\n",
       "   'repeat',\n",
       "   'root',\n",
       "   'multiplicity',\n",
       "   'theorem',\n",
       "   'imply',\n",
       "   'linear_combination',\n",
       "   'solution',\n",
       "   'also',\n",
       "   'solution'],\n",
       "  ['example_suppose',\n",
       "   'characteristic_equation',\n",
       "   'recurrence',\n",
       "   'root',\n",
       "   'twice'],\n",
       "  ['root', 'imply', 'distinct', 'solution'],\n",
       "  ['nu', 'furthermore', 'linear_combination', 'also', 'solution'],\n",
       "  ['remain',\n",
       "   'select',\n",
       "   'solution',\n",
       "   'consistent',\n",
       "   'boundary_condition',\n",
       "   'choose',\n",
       "   'constant',\n",
       "   'appropriately'],\n",
       "  ['boundary_condition', 'imply', 'linear_equation', 'involve', 'constant'],\n",
       "  ['determine', 'constant', 'solve', 'system', 'linear_equation'],\n",
       "  ['example_suppose', 'boundary_condition'],\n",
       "  ['would',\n",
       "   'obtain',\n",
       "   'equation',\n",
       "   'unknown',\n",
       "   'look',\n",
       "   'nasty',\n",
       "   'remember',\n",
       "   'constant'],\n",
       "  ['solve',\n",
       "   'sys',\n",
       "   'tem',\n",
       "   'give',\n",
       "   'value',\n",
       "   'define',\n",
       "   'solution_recurrence',\n",
       "   'consistent',\n",
       "   'boundary_condition']],\n",
       " [['solve',\n",
       "   'general',\n",
       "   'linear_recurrence',\n",
       "   'solve',\n",
       "   'linear',\n",
       "   'homogeneous',\n",
       "   'recurrence',\n",
       "   'form'],\n",
       "  ['many', 'recurrence', 'arise_practice', 'quite', 'fit', 'mold'],\n",
       "  ['example', 'towers', 'hanoi', 'problem', 'lead', 'recurrence'],\n",
       "  ['chapter_recurrence',\n",
       "   'problem',\n",
       "   'extra',\n",
       "   'allow',\n",
       "   'homogeneous_linear',\n",
       "   'recur',\n",
       "   'rence'],\n",
       "  ['general', 'add', 'extra', 'function'],\n",
       "  ['right_side',\n",
       "   'linear',\n",
       "   'recur',\n",
       "   'rence',\n",
       "   'give',\n",
       "   'inhomogeneous',\n",
       "   'linear_recurrence'],\n",
       "  ['solve',\n",
       "   'inhomogeneous',\n",
       "   'linear_recurrence',\n",
       "   'different',\n",
       "   'dif',\n",
       "   'ficult'],\n",
       "  ['divide', 'whole', 'job', 'step', 'replace'],\n",
       "  ['leave', 'homogeneous', 'recurrence'],\n",
       "  ['find', 'root_characteristic_equation'],\n",
       "  ['write',\n",
       "   'solution',\n",
       "   'homogeneous',\n",
       "   'recurrence',\n",
       "   'yet',\n",
       "   'use',\n",
       "   'boundary_condition',\n",
       "   'determine',\n",
       "   'coefficient'],\n",
       "  ['call', 'homo', 'geneous', 'solution'],\n",
       "  ['restore'],\n",
       "  ['find',\n",
       "   'single',\n",
       "   'solution_recurrence',\n",
       "   'ignore',\n",
       "   'bind',\n",
       "   'ary',\n",
       "   'condition'],\n",
       "  ['call', 'particular_solution'],\n",
       "  ['explain', 'find', 'particular_solution', 'shortly'],\n",
       "  ['add',\n",
       "   'homogeneous',\n",
       "   'particular_solution',\n",
       "   'together',\n",
       "   'obtain',\n",
       "   'general_solution'],\n",
       "  ['use',\n",
       "   'boundary_condition',\n",
       "   'determine',\n",
       "   'constant',\n",
       "   'usual',\n",
       "   'method',\n",
       "   'generate',\n",
       "   'solve',\n",
       "   'system',\n",
       "   'linear_equation'],\n",
       "  ['example', 'let', 'consider', 'variation', 'tower_hanoi', 'problem'],\n",
       "  ['sup', 'pose', 'move', 'disk', 'take', 'time', 'proportional', 'size'],\n",
       "  ['specifically',\n",
       "   'move',\n",
       "   'small',\n",
       "   'disk',\n",
       "   'take',\n",
       "   'second',\n",
       "   'next',\n",
       "   'small',\n",
       "   'take',\n",
       "   'second',\n",
       "   'move',\n",
       "   'nth',\n",
       "   'disk',\n",
       "   'require',\n",
       "   'second',\n",
       "   'instead'],\n",
       "  ['variation',\n",
       "   'time',\n",
       "   'complete',\n",
       "   'job',\n",
       "   'give',\n",
       "   'recurrence',\n",
       "   'cn',\n",
       "   'term',\n",
       "   'instead'],\n",
       "  ['clearly',\n",
       "   'take',\n",
       "   'longer',\n",
       "   'much',\n",
       "   'longer',\n",
       "   'let',\n",
       "   'solve_recurrence',\n",
       "   'method',\n",
       "   'describe'],\n",
       "  ['step', 'drop', 'cn', 'leave', 'homogeneous', 'recurrence'],\n",
       "  ['characteristic_equation'],\n",
       "  ['homogeneous_solution'],\n",
       "  ['step', 'must', 'find', 'solution', 'full', 'recurrence'],\n",
       "  ['regard', 'boundary_condition'],\n",
       "  ['let', 'guess', 'solution', 'form'],\n",
       "  ['constant'],\n",
       "  ['substitute', 'guess', 'recurrence', 'give'],\n",
       "  ['second', 'equation', 'simplification', 'first'],\n",
       "  ['second', 'equation_hold', 'imply_imply'],\n",
       "  ['particular_solution'],\n",
       "  ['step',\n",
       "   'add',\n",
       "   'homogeneous',\n",
       "   'particular_solution',\n",
       "   'obtain',\n",
       "   'general_solution'],\n",
       "  ['finally', 'step', 'use', 'boundary_condition'],\n",
       "  ['determine', 'value', 'constant'],\n",
       "  ['therefore', 'function']],\n",
       " [['guess',\n",
       "   'particular_solution',\n",
       "   'find',\n",
       "   'particular_solution',\n",
       "   'hard',\n",
       "   'part',\n",
       "   'solve',\n",
       "   'inhomogeneous',\n",
       "   'recurrence'],\n",
       "  ['involve', 'guess', 'may', 'guess', 'wrong'],\n",
       "  ['however', 'rule_thumb', 'make', 'job', 'fairly', 'easy', 'time'],\n",
       "  ['generally',\n",
       "   'look',\n",
       "   'particular_solution',\n",
       "   'form',\n",
       "   'inhomo',\n",
       "   'geneous',\n",
       "   'term'],\n",
       "  ['constant', 'guess', 'particular_solution'],\n",
       "  ['work', 'try', 'polynomial', 'progressively', 'high', 'degree'],\n",
       "  ['generally'],\n",
       "  ['polynomial',\n",
       "   'try',\n",
       "   'polynomial',\n",
       "   'degree',\n",
       "   'polynomial',\n",
       "   'degree',\n",
       "   'high',\n",
       "   'high'],\n",
       "  ['example'],\n",
       "  ['try'],\n",
       "  ['chapter', 'chapter_recurrence'],\n",
       "  ['exponential', 'failing', 'try'],\n",
       "  ['bn', 'entire', 'process', 'summarize', 'follow', 'page']],\n",
       " [['divide_conquer_recurrence',\n",
       "   'recipe',\n",
       "   'solve',\n",
       "   'general',\n",
       "   'linear_recurrence'],\n",
       "  ['merge_sort_recurrence', 'encounter', 'earlier', 'linear'],\n",
       "  ['particular'],\n",
       "  ['linear_combination',\n",
       "   'fix',\n",
       "   'number',\n",
       "   'immediately',\n",
       "   'precede',\n",
       "   'term',\n",
       "   'rather'],\n",
       "  ['function'],\n",
       "  ['term', 'halfway', 'back', 'sequence'],\n",
       "  ['merge_sort',\n",
       "   'example',\n",
       "   'divide_conquer',\n",
       "   'algorithm',\n",
       "   'divide',\n",
       "   'put',\n",
       "   'conquer',\n",
       "   'piece',\n",
       "   'combine',\n",
       "   'result'],\n",
       "  ['analysis',\n",
       "   'algorithm',\n",
       "   'commonly',\n",
       "   'lead',\n",
       "   'divide_conquer_recurrence',\n",
       "   'form'],\n",
       "  ['would']],\n",
       " [['akra_bazzi_formula',\n",
       "   'solution',\n",
       "   'virtually',\n",
       "   'divide_conquer',\n",
       "   'solution',\n",
       "   'give',\n",
       "   'amazing',\n",
       "   'akra_bazzi_formula'],\n",
       "  ['quite',\n",
       "   'simply',\n",
       "   'asymptotic',\n",
       "   'solution',\n",
       "   'general',\n",
       "   'divide_conquer_recurrence',\n",
       "   'short',\n",
       "   'guide',\n",
       "   'solve',\n",
       "   'linear_recurrence',\n",
       "   'linear_recurrence',\n",
       "   'equation',\n",
       "   'together',\n",
       "   'boundary_condition'],\n",
       "  ['find', 'root_characteristic_equation', 'write', 'homogeneous_solution'],\n",
       "  ['root', 'generate', 'term', 'homogeneous_solution', 'sum'],\n",
       "  ['nonrepeate',\n",
       "   'root',\n",
       "   'generate',\n",
       "   'term',\n",
       "   'cr',\n",
       "   'find',\n",
       "   'particular_solution'],\n",
       "  ['solution',\n",
       "   'full',\n",
       "   'recurrence',\n",
       "   'need',\n",
       "   'consistent',\n",
       "   'boundary_condition'],\n",
       "  ['use', 'guess_verify'],\n",
       "  ['constant',\n",
       "   'polynomial',\n",
       "   'try',\n",
       "   'polynomial',\n",
       "   'degree',\n",
       "   'high',\n",
       "   'degree',\n",
       "   'high'],\n",
       "  ['example'],\n",
       "  ['try'],\n",
       "  ['bn',\n",
       "   'cc',\n",
       "   'form',\n",
       "   'general_solution',\n",
       "   'sum',\n",
       "   'homogeneous_solution',\n",
       "   'particular_solution'],\n",
       "  ['typical', 'general_solution'],\n",
       "  ['homogeneous_solution',\n",
       "   'inhomogeneous',\n",
       "   'solution',\n",
       "   'substitute',\n",
       "   'boundary_condition',\n",
       "   'general_solution'],\n",
       "  ['boundary_condition', 'give', 'linear_equation', 'unknown', 'constant'],\n",
       "  ['example', 'substituting'],\n",
       "  ['general_solution',\n",
       "   'give',\n",
       "   'determine',\n",
       "   'value',\n",
       "   'constant',\n",
       "   'solve',\n",
       "   'result',\n",
       "   'system',\n",
       "   'linear_equation'],\n",
       "  ['chapter_recurrence',\n",
       "   'satisfie',\n",
       "   'would',\n",
       "   'rarely',\n",
       "   'requirement',\n",
       "   'function'],\n",
       "  ['must', 'grow', 'oscillate', 'quickly'],\n",
       "  ['specifically',\n",
       "   'jg',\n",
       "   'let',\n",
       "   'solve',\n",
       "   'merge_sort_recurrence',\n",
       "   'use',\n",
       "   'akra_bazzi_formula',\n",
       "   'stead',\n",
       "   'plug_chug'],\n",
       "  ['first', 'find', 'value', 'satisfie'],\n",
       "  ['look', 'job'],\n",
       "  ['compute', 'integral'],\n",
       "  ['du', 'log_log', 'first_step', 'integration', 'second', 'simplification'],\n",
       "  ['drop', 'term', 'last', 'step', 'log', 'term', 'dominate'],\n",
       "  ['do', 'let_try', 'scary', 'looking', 'recurrence'],\n",
       "  ['equation',\n",
       "   'form',\n",
       "   'always',\n",
       "   'close_form',\n",
       "   'solution',\n",
       "   'may',\n",
       "   'need',\n",
       "   'approximate',\n",
       "   'numerically',\n",
       "   'sometimes'],\n",
       "  ['case', 'solution', 'simple'],\n",
       "  ['integrate']],\n",
       " [['technical',\n",
       "   'issue',\n",
       "   'sweep',\n",
       "   'couple',\n",
       "   'issue',\n",
       "   'relate',\n",
       "   'divide_conquer_recurrence'],\n",
       "  ['let', 'address', 'issue'],\n",
       "  ['first', 'akra_bazzi_formula', 'make', 'use', 'boundary_condition'],\n",
       "  ['let', 'go_back', 'merge_sort'],\n",
       "  ['plug_chug',\n",
       "   'analysis',\n",
       "   'find',\n",
       "   'express',\n",
       "   'nth',\n",
       "   'term',\n",
       "   'function',\n",
       "   'first',\n",
       "   'term',\n",
       "   'value',\n",
       "   'specify',\n",
       "   'boundary_condition'],\n",
       "  ['notice',\n",
       "   'typical',\n",
       "   'situation',\n",
       "   'asymptotic',\n",
       "   'solution',\n",
       "   'divide_conquer_recurrence',\n",
       "   'independent',\n",
       "   'boundary_condition'],\n",
       "  ['intuitively',\n",
       "   'bottom',\n",
       "   'level',\n",
       "   'operation',\n",
       "   'recursive',\n",
       "   'algorithm',\n",
       "   'take',\n",
       "   'say',\n",
       "   'twice',\n",
       "   'long',\n",
       "   'overall',\n",
       "   'run_time',\n",
       "   'double'],\n",
       "  ['matter', 'practice', 'factor', 'conceal', 'asymptotic_notation'],\n",
       "  ['corner', 'case', 'exception'],\n",
       "  ['example', 'solution'],\n",
       "  ['depend'],\n",
       "  ['case', 'little', 'practical', 'interest', 'consider'],\n",
       "  ['second',\n",
       "   'nagging',\n",
       "   'issue',\n",
       "   'divide_conquer_recurrence',\n",
       "   'arise',\n",
       "   'linear_recurrence'],\n",
       "  ['specifically',\n",
       "   'divide',\n",
       "   'problem',\n",
       "   'size',\n",
       "   'may',\n",
       "   'create',\n",
       "   'subproblem',\n",
       "   'non',\n",
       "   'integer',\n",
       "   'size'],\n",
       "  ['example', 'merge_sort_recurrence', 'contain', 'term'],\n",
       "  ['long',\n",
       "   'take',\n",
       "   'sort',\n",
       "   'half',\n",
       "   'item',\n",
       "   'previously',\n",
       "   'dodge',\n",
       "   'issue',\n",
       "   'analyze',\n",
       "   'merge_sort',\n",
       "   'size',\n",
       "   'input',\n",
       "   'power'],\n",
       "  ['know', 'happen', 'input', 'size', 'say'],\n",
       "  ['course',\n",
       "   'practical',\n",
       "   'implementation',\n",
       "   'merge_sort',\n",
       "   'would',\n",
       "   'split',\n",
       "   'input',\n",
       "   'proximately',\n",
       "   'sort',\n",
       "   'halve',\n",
       "   'recursively',\n",
       "   'merge',\n",
       "   'result'],\n",
       "  ['example', 'list', 'number', 'would', 'split', 'list'],\n",
       "  ['generally',\n",
       "   'list',\n",
       "   'number',\n",
       "   'would',\n",
       "   'split',\n",
       "   'approximate',\n",
       "   'half',\n",
       "   'size',\n",
       "   'dn',\n",
       "   'bn'],\n",
       "  ['maximum', 'number', 'comparison', 'actually', 'give', 'recurrence'],\n",
       "  ['dn'],\n",
       "  ['bn',\n",
       "   'may',\n",
       "   'rigorously',\n",
       "   'correct',\n",
       "   'ceiling',\n",
       "   'floor',\n",
       "   'operation',\n",
       "   'make',\n",
       "   'recur',\n",
       "   'rence',\n",
       "   'hard',\n",
       "   'solve',\n",
       "   'exactly'],\n",
       "  ['fortunately',\n",
       "   'asymptotic',\n",
       "   'solution',\n",
       "   'divide_conquer_recurrence',\n",
       "   'un',\n",
       "   'affect',\n",
       "   'floor',\n",
       "   'ceiling'],\n",
       "  ['precisely', 'solution', 'change', 'replace', 'term'],\n",
       "  ['chapter_recurrence',\n",
       "   'ceiling',\n",
       "   'divide_conquer_recurrence',\n",
       "   'make_sense',\n",
       "   'many',\n",
       "   'contexts',\n",
       "   'complication',\n",
       "   'make',\n",
       "   'difference']],\n",
       " [['akra_bazzi',\n",
       "   'theorem',\n",
       "   'akra_bazzi_formula',\n",
       "   'together',\n",
       "   'assertion',\n",
       "   'boundary_condition',\n",
       "   'integrality',\n",
       "   'follow',\n",
       "   'akra_bazzi',\n",
       "   'theorem',\n",
       "   'state'],\n",
       "  ['theorem'],\n",
       "  ['akra_bazzi'],\n",
       "  ['suppose', 'function', 'satisfie', 'recurrence'],\n",
       "  ['nonnegative',\n",
       "   'function',\n",
       "   'jg',\n",
       "   'jh',\n",
       "   'satisfie',\n",
       "   'would',\n",
       "   'akra_bazzi',\n",
       "   'theorem_prove',\n",
       "   'use',\n",
       "   'complicated',\n",
       "   'induction',\n",
       "   'argument',\n",
       "   'though'],\n",
       "  ['let', 'least', 'go', 'statement', 'theorem'],\n",
       "  ['recurrence', 'consider', 'define', 'integer', 'common', 'case'],\n",
       "  ['akra_bazzi',\n",
       "   'theorem',\n",
       "   'apply',\n",
       "   'generally',\n",
       "   'function',\n",
       "   'define',\n",
       "   'real_number'],\n",
       "  ['akra_bazzi_formula',\n",
       "   'lift',\n",
       "   'directed',\n",
       "   'theorem',\n",
       "   'statement',\n",
       "   'recurrence',\n",
       "   'theorem',\n",
       "   'include',\n",
       "   'extra',\n",
       "   'function',\n",
       "   'extend',\n",
       "   'theorem',\n",
       "   'address',\n",
       "   'floor',\n",
       "   'ceiling',\n",
       "   'small',\n",
       "   'adjustment',\n",
       "   'size',\n",
       "   'subproblem'],\n",
       "  ['trick',\n",
       "   'illustrate',\n",
       "   'combination',\n",
       "   'parameter',\n",
       "   'rigorously',\n",
       "   'correct',\n",
       "   'merge_sort_recurrence',\n",
       "   'valid',\n",
       "   'input',\n",
       "   'size',\n",
       "   'complete',\n",
       "   'floor',\n",
       "   'ceiling',\n",
       "   'operator'],\n",
       "  ['case', 'functions']],\n",
       " [['master_theorem',\n",
       "   'special_case',\n",
       "   'akra_bazzi_formula',\n",
       "   'know',\n",
       "   'master_theorem',\n",
       "   'handle',\n",
       "   'recurrence',\n",
       "   'commonly',\n",
       "   'arise',\n",
       "   'computer_science'],\n",
       "  ['call',\n",
       "   'master_theorem',\n",
       "   'prove',\n",
       "   'long',\n",
       "   'akra_bazzi',\n",
       "   'arrive',\n",
       "   'scene',\n",
       "   'many',\n",
       "   'year',\n",
       "   'final',\n",
       "   'word',\n",
       "   'solving',\n",
       "   'divide_conquer_recurrence'],\n",
       "  ['include',\n",
       "   'master_theorem',\n",
       "   'still',\n",
       "   'widely',\n",
       "   'referenced',\n",
       "   'algorithm',\n",
       "   'course',\n",
       "   'use',\n",
       "   'know',\n",
       "   'integration'],\n",
       "  ['theorem'],\n",
       "  ['master_theorem'],\n",
       "  ['let', 'recurrence', 'form'],\n",
       "  ['case'],\n",
       "  ['log', 'constant'],\n",
       "  ['log'],\n",
       "  ['master_theorem',\n",
       "   'prove',\n",
       "   'induction',\n",
       "   'easily',\n",
       "   'corol',\n",
       "   'lary',\n",
       "   'theorem']],\n",
       " [['pitfalls',\n",
       "   'asymptotic_notation',\n",
       "   'induction',\n",
       "   'see',\n",
       "   'asymptotic_notation',\n",
       "   'quite',\n",
       "   'useful',\n",
       "   'particularly',\n",
       "   'connection',\n",
       "   'recurrence'],\n",
       "  ['induction', 'favorite', 'proof', 'technique'],\n",
       "  ['mix',\n",
       "   'risky',\n",
       "   'business',\n",
       "   'great',\n",
       "   'potential',\n",
       "   'subtle',\n",
       "   'error',\n",
       "   'false',\n",
       "   'conclusion',\n",
       "   'false',\n",
       "   'claim'],\n",
       "  ['akra_bazzi', 'theorem', 'imply', 'correct', 'solution'],\n",
       "  ['log', 'claim', 'false'],\n",
       "  ['follow', 'proof', 'go', 'astray', 'bogus', 'proof'],\n",
       "  ['proof', 'strong_induction'],\n",
       "  ['let'],\n",
       "  ['proposition'],\n",
       "  ['base_case'],\n",
       "  ['true'],\n",
       "  ['inductive_step_assume'],\n",
       "  ['prove'],\n",
       "  ['first', 'equation', 'recurrence', 'second', 'use', 'assumption'],\n",
       "  ['third', 'simplification'],\n",
       "  ['bug',\n",
       "   'proof',\n",
       "   'already',\n",
       "   'far',\n",
       "   'mark',\n",
       "   'second',\n",
       "   'sentence',\n",
       "   'define',\n",
       "   'induction_hypothesis'],\n",
       "  ['statement'],\n",
       "  ['true_false', 'validity', 'depend', 'particular', 'value'],\n",
       "  ['thus', 'idea', 'try_prove', 'statement', 'hold'],\n",
       "  ['wrong', 'head'],\n",
       "  ['safe',\n",
       "   'way',\n",
       "   'reason',\n",
       "   'inductively',\n",
       "   'asymptotic',\n",
       "   'phenomenon',\n",
       "   'work',\n",
       "   'rectly',\n",
       "   'definition',\n",
       "   'asymptotic_notation'],\n",
       "  ['let_try', 'prove', 'claim', 'way'],\n",
       "  ['remember'],\n",
       "  ['means', 'exist', 'constant', 'proof', 'attempt'],\n",
       "  ['use_strong_induction'],\n",
       "  ['let'],\n",
       "  ['proposition'],\n",
       "  ['base_case'],\n",
       "  ['inductive_step'],\n",
       "  ['first', 'equation', 'recurrence'],\n",
       "  ['use_induction',\n",
       "   'simplify',\n",
       "   'argument',\n",
       "   'collapse',\n",
       "   'general',\n",
       "   'good_idea',\n",
       "   'stay',\n",
       "   'away',\n",
       "   'asymptotic_notation',\n",
       "   'altogether',\n",
       "   'induction'],\n",
       "  ['induction', 'do', 'safely', 'use', 'big', 'simplify', 'result']],\n",
       " [['feel',\n",
       "   'recurrence',\n",
       "   'guess_verify',\n",
       "   'plug',\n",
       "   'chugged',\n",
       "   'find',\n",
       "   'root',\n",
       "   'compute',\n",
       "   'integral',\n",
       "   'solve',\n",
       "   'linear',\n",
       "   'system',\n",
       "   'exponential',\n",
       "   'equation'],\n",
       "  ['let', 'step', 'look', 'rule_thumb'],\n",
       "  ['kinds',\n",
       "   'recurrence',\n",
       "   'sort',\n",
       "   'solution',\n",
       "   'chapter_recurrence',\n",
       "   'recurrence',\n",
       "   'solve',\n",
       "   'early',\n",
       "   'notice',\n",
       "   'recurrence_equation',\n",
       "   'tower_hanoi',\n",
       "   'merge_sort',\n",
       "   'similar',\n",
       "   'solution',\n",
       "   'radically',\n",
       "   'different'],\n",
       "  ['merge_sort',\n",
       "   'item',\n",
       "   'take',\n",
       "   'comparison',\n",
       "   'move',\n",
       "   'disk',\n",
       "   'take',\n",
       "   'recurrence',\n",
       "   'strength',\n",
       "   'weakness'],\n",
       "  ['towers',\n",
       "   'hanoi',\n",
       "   'break',\n",
       "   'problem',\n",
       "   'size',\n",
       "   'subproblem',\n",
       "   'size',\n",
       "   'large',\n",
       "   'need',\n",
       "   'additional',\n",
       "   'step',\n",
       "   'small'],\n",
       "  ['merge_sort',\n",
       "   'divided',\n",
       "   'problem',\n",
       "   'size',\n",
       "   'subproblem',\n",
       "   'size',\n",
       "   'small',\n",
       "   'need'],\n",
       "  ['additional', 'step', 'large'],\n",
       "  ['merge_sort',\n",
       "   'fast',\n",
       "   'mile',\n",
       "   'suggest',\n",
       "   'generate',\n",
       "   'small',\n",
       "   'subproblem',\n",
       "   'far',\n",
       "   'important',\n",
       "   'al',\n",
       "   'gorithmic',\n",
       "   'speed',\n",
       "   'reduce',\n",
       "   'additional',\n",
       "   'step',\n",
       "   'recursive',\n",
       "   'call'],\n",
       "  ['example',\n",
       "   'shift',\n",
       "   'variation',\n",
       "   'tower_hanoi',\n",
       "   'increase',\n",
       "   'last',\n",
       "   'term',\n",
       "   'cn',\n",
       "   'solution',\n",
       "   'double'],\n",
       "  ['subproblem',\n",
       "   'fibonacci_recurrence',\n",
       "   'slightly',\n",
       "   'small',\n",
       "   'tower_hanoi',\n",
       "   'size',\n",
       "   'instead'],\n",
       "  ['solution',\n",
       "   'exponentially',\n",
       "   'small',\n",
       "   'generally',\n",
       "   'linear_recurrence',\n",
       "   'big',\n",
       "   'subproblem',\n",
       "   'typically',\n",
       "   'exponential',\n",
       "   'solution',\n",
       "   'divide_conquer_recurrence',\n",
       "   'small',\n",
       "   'subproblem',\n",
       "   'usually',\n",
       "   'solution',\n",
       "   'bound',\n",
       "   'polynomial'],\n",
       "  ['example', 'list', 'break', 'problem', 'size', 'small', 'prob', 'lem'],\n",
       "  ['number',\n",
       "   'subproblem',\n",
       "   'affect',\n",
       "   'solution',\n",
       "   'example_suppose',\n",
       "   'increase',\n",
       "   'number',\n",
       "   'subproblem',\n",
       "   'tower_hanoi',\n",
       "   'give',\n",
       "   'recurrence',\n",
       "   'increase',\n",
       "   'root_characteristic_equation',\n",
       "   'raise',\n",
       "   'solution',\n",
       "   'exponentially'],\n",
       "  ['divide_conquer_recurrence', 'also', 'sensitive', 'number', 'subproblem'],\n",
       "  ['example',\n",
       "   'generalization',\n",
       "   'merge_sort_recurrence',\n",
       "   'solution',\n",
       "   'take',\n",
       "   'completely',\n",
       "   'different',\n",
       "   'form',\n",
       "   'go'],\n",
       "  ['boundary_condition',\n",
       "   'affect',\n",
       "   'solution_recurrence',\n",
       "   'see',\n",
       "   'almost',\n",
       "   'irrelevant',\n",
       "   'divide_conquer_recurrence'],\n",
       "  ['linear',\n",
       "   'currence',\n",
       "   'solution',\n",
       "   'usually',\n",
       "   'dominate',\n",
       "   'exponential',\n",
       "   'base',\n",
       "   'termined',\n",
       "   'number',\n",
       "   'size',\n",
       "   'subproblem'],\n",
       "  ['boundary_condition',\n",
       "   'matter',\n",
       "   'greatly',\n",
       "   'give',\n",
       "   'dominant',\n",
       "   'term',\n",
       "   'coefficient',\n",
       "   'change',\n",
       "   'asymptotic',\n",
       "   'solution'],\n",
       "  ['rule_thumb',\n",
       "   'performance',\n",
       "   'recursive',\n",
       "   'procedure',\n",
       "   'usually',\n",
       "   'dictate',\n",
       "   'size',\n",
       "   'number',\n",
       "   'subproblem',\n",
       "   'rather',\n",
       "   'amount',\n",
       "   'work',\n",
       "   'recursive',\n",
       "   'call',\n",
       "   'time',\n",
       "   'spend',\n",
       "   'base',\n",
       "   'recursion'],\n",
       "  ['particular',\n",
       "   'subproblem',\n",
       "   'small',\n",
       "   'original',\n",
       "   'additive',\n",
       "   'factor',\n",
       "   'solution',\n",
       "   'often',\n",
       "   'exponential'],\n",
       "  ['subproblems',\n",
       "   'fraction',\n",
       "   'size',\n",
       "   'original',\n",
       "   'solution',\n",
       "   'typically',\n",
       "   'bound',\n",
       "   'polynomial']],\n",
       " [['cardinality_rule']],\n",
       " [['count',\n",
       "   'thing',\n",
       "   'count',\n",
       "   'count',\n",
       "   'number',\n",
       "   'people',\n",
       "   'crowd',\n",
       "   'room',\n",
       "   'could',\n",
       "   'count',\n",
       "   'head',\n",
       "   'person',\n",
       "   'exactly',\n",
       "   'head'],\n",
       "  ['alternatively', 'could', 'count', 'ear', 'divide'],\n",
       "  ['course',\n",
       "   'may',\n",
       "   'adjust',\n",
       "   'calculation',\n",
       "   'lose',\n",
       "   'ear',\n",
       "   'pirate',\n",
       "   'raid',\n",
       "   'bear',\n",
       "   'ear'],\n",
       "  ['point',\n",
       "   'often',\n",
       "   'count',\n",
       "   'thing',\n",
       "   'count',\n",
       "   'fudge',\n",
       "   'factor',\n",
       "   'may',\n",
       "   'require'],\n",
       "  ['central', 'theme', 'count', 'easy', 'problem', 'hardest'],\n",
       "  ['formal', 'term', 'counting_problem', 'come', 'determine_size', 'set'],\n",
       "  ['size', 'cardinality', 'finite_set', 'number', 'element', 'denote', 'jsj'],\n",
       "  ['term',\n",
       "   'claim',\n",
       "   'often',\n",
       "   'find',\n",
       "   'size',\n",
       "   'set',\n",
       "   'find',\n",
       "   'size',\n",
       "   'relate',\n",
       "   'set'],\n",
       "  ['already',\n",
       "   'see',\n",
       "   'general',\n",
       "   'statement',\n",
       "   'idea',\n",
       "   'mapping_rule',\n",
       "   'theorem']],\n",
       " [['bijection_rule', 'rule'],\n",
       "  ['bijection_rule'],\n",
       "  ['bijection', 'jaj', 'jbj'],\n",
       "  ['bijection_rule',\n",
       "   'act',\n",
       "   'magnifier',\n",
       "   'count',\n",
       "   'ability',\n",
       "   'figure',\n",
       "   'size',\n",
       "   'set',\n",
       "   'immediately',\n",
       "   'determine_size',\n",
       "   'many',\n",
       "   'set',\n",
       "   'bijection'],\n",
       "  ['example_consider',\n",
       "   'set',\n",
       "   'mention',\n",
       "   'begin',\n",
       "   'part',\n",
       "   'way_select',\n",
       "   'dozen',\n",
       "   'doughnut',\n",
       "   'variety',\n",
       "   'available',\n",
       "   'bit_sequence',\n",
       "   'exactly',\n",
       "   'one',\n",
       "   'let',\n",
       "   'consider',\n",
       "   'particular',\n",
       "   'element_set',\n",
       "   'depict',\n",
       "   'doughnut',\n",
       "   'leave',\n",
       "   'gap',\n",
       "   'different',\n",
       "   'vari',\n",
       "   'etie'],\n",
       "  ['thus',\n",
       "   'selection',\n",
       "   'contain',\n",
       "   'chocolate',\n",
       "   'doughnut',\n",
       "   'lemon',\n",
       "   'fill',\n",
       "   'chapter_cardinality_rule',\n",
       "   'sugar',\n",
       "   'glaze',\n",
       "   'plain'],\n",
       "  ['let',\n",
       "   'put',\n",
       "   'gap',\n",
       "   'form',\n",
       "   'bit',\n",
       "   'number',\n",
       "   'exactly',\n",
       "   'one',\n",
       "   'element',\n",
       "   'example',\n",
       "   'suggest',\n",
       "   'bijection',\n",
       "   'set',\n",
       "   'set',\n",
       "   'map',\n",
       "   'dozen',\n",
       "   'doughnut',\n",
       "   'consist',\n",
       "   'chocolate',\n",
       "   'lemon',\n",
       "   'fill',\n",
       "   'sugar',\n",
       "   'glaze',\n",
       "   'plain',\n",
       "   'sequence',\n",
       "   'result',\n",
       "   'sequence',\n",
       "   'always',\n",
       "   'bit',\n",
       "   'exactly',\n",
       "   'one',\n",
       "   'thus',\n",
       "   'element'],\n",
       "  ['moreover',\n",
       "   'mapping',\n",
       "   'bijection',\n",
       "   'bit_sequence',\n",
       "   'map',\n",
       "   'exactly',\n",
       "   'order',\n",
       "   'dozen',\n",
       "   'doughnut'],\n",
       "  ['therefore',\n",
       "   'jaj',\n",
       "   'jbj',\n",
       "   'bijection_rule',\n",
       "   'example',\n",
       "   'demonstrate',\n",
       "   'magnify',\n",
       "   'power',\n",
       "   'bijection_rule'],\n",
       "  ['man',\n",
       "   'aged',\n",
       "   'prove',\n",
       "   'different',\n",
       "   'set',\n",
       "   'actually',\n",
       "   'size',\n",
       "   'even',\n",
       "   'know',\n",
       "   'exactly',\n",
       "   'big'],\n",
       "  ['soon', 'figure', 'size', 'set', 'immediately', 'know', 'size'],\n",
       "  ['particular', 'bijection', 'may_seem', 'frighteningly', 'ingenious', 'see'],\n",
       "  ['use', 'essentially', 'argument', 'soon', 'consider', 'routine']],\n",
       " [['count', 'sequences', 'bijection_rule', 'let', 'count', 'thing', 'count'],\n",
       "  ['suggest',\n",
       "   'general',\n",
       "   'strategy',\n",
       "   'get',\n",
       "   'really',\n",
       "   'good',\n",
       "   'count',\n",
       "   'thing',\n",
       "   'use',\n",
       "   'bijection',\n",
       "   'count',\n",
       "   'else'],\n",
       "  ['strategy', 'follow'],\n",
       "  ['particular', 'really', 'good', 'counting', 'sequence'],\n",
       "  ['want', 'determine_size', 'set', 'find', 'bijection', 'set', 'sequence'],\n",
       "  ['use',\n",
       "   'super',\n",
       "   'ninja',\n",
       "   'sequence',\n",
       "   'counting',\n",
       "   'skill',\n",
       "   'determine',\n",
       "   'jsj',\n",
       "   'immediately',\n",
       "   'give',\n",
       "   'jt'],\n",
       "  ['need', 'hone', 'idea', 'somewhat', 'go', 'pretty', 'much', 'plan']],\n",
       " [['product_rule', 'product_rule', 'give', 'size', 'product', 'set'],\n",
       "  ['recall', 'set', 'sequence', 'first', 'term', 'draw', 'rule'],\n",
       "  ['product_rule'],\n",
       "  ['jp',\n",
       "   'jp',\n",
       "   'jp',\n",
       "   'jp',\n",
       "   'example_suppose',\n",
       "   'daily',\n",
       "   'diet',\n",
       "   'consist',\n",
       "   'breakfast',\n",
       "   'select',\n",
       "   'set',\n",
       "   'lunch',\n",
       "   'set',\n",
       "   'dinner',\n",
       "   'set',\n",
       "   'fpancakes',\n",
       "   'bacon',\n",
       "   'eggs',\n",
       "   'bagel',\n",
       "   'doritosg',\n",
       "   'fburger',\n",
       "   'fry',\n",
       "   'garden',\n",
       "   'salad',\n",
       "   'doritosg',\n",
       "   'fmacaroni',\n",
       "   'pizza',\n",
       "   'frozen',\n",
       "   'burrito',\n",
       "   'pasta',\n",
       "   'doritosg',\n",
       "   'set',\n",
       "   'possible',\n",
       "   'daily',\n",
       "   'diet'],\n",
       "  ['sample',\n",
       "   'elements',\n",
       "   'product_rule',\n",
       "   'tell',\n",
       "   'many_different',\n",
       "   'daily',\n",
       "   'diet',\n",
       "   'possible',\n",
       "   'jb',\n",
       "   'dj',\n",
       "   'jbj',\n",
       "   'jlj',\n",
       "   'jdj']],\n",
       " [['subset',\n",
       "   'element_set',\n",
       "   'many_different',\n",
       "   'subset',\n",
       "   'element_set',\n",
       "   'example',\n",
       "   'set',\n",
       "   'fx',\n",
       "   'different_subset',\n",
       "   'fx_fx',\n",
       "   'fx_fx',\n",
       "   'fx_fx',\n",
       "   'fx',\n",
       "   'natural',\n",
       "   'bijection',\n",
       "   'subset',\n",
       "   'bit_sequence'],\n",
       "  ['let', 'element'],\n",
       "  ['particular', 'subset', 'map', 'sequence'],\n",
       "  ['chapter_cardinality_rule',\n",
       "   'map',\n",
       "   'bit_sequence',\n",
       "   'follow',\n",
       "   'use',\n",
       "   'bijection',\n",
       "   'transform',\n",
       "   'original',\n",
       "   'problem',\n",
       "   'question',\n",
       "   'sequence',\n",
       "   'exactly',\n",
       "   'accord',\n",
       "   'plan',\n",
       "   'answer',\n",
       "   'sequence',\n",
       "   'question',\n",
       "   'solve',\n",
       "   'original',\n",
       "   'problem',\n",
       "   'well'],\n",
       "  ['many_different',\n",
       "   'bit_sequence',\n",
       "   'example',\n",
       "   'different',\n",
       "   'bit_sequence',\n",
       "   'well',\n",
       "   'write',\n",
       "   'set',\n",
       "   'bit_sequence',\n",
       "   'product',\n",
       "   'set',\n",
       "   'product_rule',\n",
       "   'give',\n",
       "   'answer',\n",
       "   'jf',\n",
       "   'jf',\n",
       "   'gj',\n",
       "   'mean',\n",
       "   'number',\n",
       "   'subset',\n",
       "   'element_set',\n",
       "   'also']],\n",
       " [['sum_rule',\n",
       "   'linus',\n",
       "   'allocate',\n",
       "   'big',\n",
       "   'sister',\n",
       "   'lucy',\n",
       "   'quota',\n",
       "   'crabby',\n",
       "   'day',\n",
       "   'irritable',\n",
       "   'day',\n",
       "   'generally',\n",
       "   'surly',\n",
       "   'day'],\n",
       "  ['many',\n",
       "   'day',\n",
       "   'lucy',\n",
       "   'sort',\n",
       "   'way',\n",
       "   'let',\n",
       "   'set',\n",
       "   'crabby',\n",
       "   'day',\n",
       "   'irritable',\n",
       "   'day',\n",
       "   'generally',\n",
       "   'surly'],\n",
       "  ['term', 'answer_question', 'jc', 'sj'],\n",
       "  ['assume',\n",
       "   'permit',\n",
       "   'bad',\n",
       "   'quality',\n",
       "   'day',\n",
       "   'size_union',\n",
       "   'set',\n",
       "   'give',\n",
       "   'sum_rule',\n",
       "   'rule'],\n",
       "  ['sum_rule'],\n",
       "  ['ja',\n",
       "   'thus',\n",
       "   'accord',\n",
       "   'linus',\n",
       "   'budget',\n",
       "   'lucy',\n",
       "   'sort',\n",
       "   'jc',\n",
       "   'sj',\n",
       "   'jc',\n",
       "   'ji',\n",
       "   'jsj',\n",
       "   'day',\n",
       "   'notice',\n",
       "   'sum_rule',\n",
       "   'hold',\n",
       "   'union',\n",
       "   'disjoint',\n",
       "   'set'],\n",
       "  ['finding',\n",
       "   'size_union',\n",
       "   'intersect',\n",
       "   'set',\n",
       "   'complicated',\n",
       "   'problem',\n",
       "   'take',\n",
       "   'later']],\n",
       " [['count', 'password', 'count', 'problem', 'solve', 'single', 'rule'],\n",
       "  ['often', 'solution', 'flurry', 'sum_product', 'bijection', 'method'],\n",
       "  ['example',\n",
       "   'sum_product',\n",
       "   'rule',\n",
       "   'together',\n",
       "   'useful',\n",
       "   'solve_problem',\n",
       "   'involve',\n",
       "   'password',\n",
       "   'telephone',\n",
       "   'number',\n",
       "   'license',\n",
       "   'plate'],\n",
       "  ['example',\n",
       "   'certain',\n",
       "   'computer',\n",
       "   'system',\n",
       "   'valid',\n",
       "   'password',\n",
       "   'sequence',\n",
       "   'symbol'],\n",
       "  ['first',\n",
       "   'symbol',\n",
       "   'must',\n",
       "   'letter',\n",
       "   'lowercase',\n",
       "   'uppercase',\n",
       "   'remain',\n",
       "   'symbol',\n",
       "   'must',\n",
       "   'letter',\n",
       "   'digit'],\n",
       "  ['many_different',\n",
       "   'password',\n",
       "   'possible',\n",
       "   'let',\n",
       "   'define',\n",
       "   'set',\n",
       "   'correspond',\n",
       "   'valid',\n",
       "   'symbol',\n",
       "   'first',\n",
       "   'subsequent',\n",
       "   'position',\n",
       "   'password'],\n",
       "  ['fa',\n",
       "   'zg',\n",
       "   'term',\n",
       "   'set',\n",
       "   'possible',\n",
       "   'password',\n",
       "   'thus',\n",
       "   'length',\n",
       "   'password',\n",
       "   'set']],\n",
       " [['generalized',\n",
       "   'product_rule',\n",
       "   'realize',\n",
       "   'work',\n",
       "   'pretty',\n",
       "   'hard',\n",
       "   'term',\n",
       "   'consider',\n",
       "   'award',\n",
       "   'prize',\n",
       "   'truly',\n",
       "   'exceptional',\n",
       "   'coursework'],\n",
       "  ['possible', 'notation'],\n",
       "  ['chapter_cardinality_rule',\n",
       "   'category',\n",
       "   'best',\n",
       "   'administrative',\n",
       "   'critique',\n",
       "   'asserted',\n",
       "   'quiz',\n",
       "   'closed',\n",
       "   'book'],\n",
       "  ['cover', 'page', 'strong', 'candidate', 'award', 'write', 'book'],\n",
       "  ['awkward',\n",
       "   'question',\n",
       "   'award',\n",
       "   'leave',\n",
       "   'sock',\n",
       "   'right',\n",
       "   'sock',\n",
       "   'pant',\n",
       "   'antichain',\n",
       "   'even',\n",
       "   'assistance',\n",
       "   'could',\n",
       "   'put',\n",
       "   'good',\n",
       "   'collaboration',\n",
       "   'statement',\n",
       "   'inspire',\n",
       "   'student',\n",
       "   'write',\n",
       "   'work',\n",
       "   'alone',\n",
       "   'quiz'],\n",
       "  ['many_way',\n",
       "   'say',\n",
       "   'different',\n",
       "   'prize',\n",
       "   'award',\n",
       "   'people',\n",
       "   'easy',\n",
       "   'answer',\n",
       "   'use',\n",
       "   'strategy',\n",
       "   'translate',\n",
       "   'problem',\n",
       "   'award',\n",
       "   'problem',\n",
       "   'sequence'],\n",
       "  ['let', 'set', 'people', 'take', 'course'],\n",
       "  ['bijection', 'way', 'award', 'prize', 'set'],\n",
       "  ['particular', 'assignment', 'map', 'sequence'],\n",
       "  ['product_rule',\n",
       "   'jp',\n",
       "   'jp',\n",
       "   'prize',\n",
       "   'must',\n",
       "   'award',\n",
       "   'different',\n",
       "   'student',\n",
       "   'could',\n",
       "   'map',\n",
       "   'assignment',\n",
       "   'triple'],\n",
       "  ['reduce', 'original', 'problem', 'problem', 'count', 'sequence'],\n",
       "  ['unfortu',\n",
       "   'nately',\n",
       "   'product_rule',\n",
       "   'help',\n",
       "   'count',\n",
       "   'sequence',\n",
       "   'type',\n",
       "   'entry',\n",
       "   'depend',\n",
       "   'one',\n",
       "   'particular',\n",
       "   'must',\n",
       "   'different'],\n",
       "  ['ever', 'slightly', 'sharp', 'tool', 'trick'],\n",
       "  ['rule'],\n",
       "  ['generalized', 'product_rule'],\n",
       "  ['let', 'set', 'length', 'sequence'],\n",
       "  ['possible', 'third', 'entry', 'combination', 'first', 'second', 'entry'],\n",
       "  ['award', 'example', 'eligible'],\n",
       "  ['combination'],\n",
       "  ['ways', 'award', 'prize', 'different', 'people']],\n",
       " [['defective',\n",
       "   'dollar',\n",
       "   'bill',\n",
       "   'dollar',\n",
       "   'bill',\n",
       "   'defective',\n",
       "   'digit',\n",
       "   'appear',\n",
       "   'digit',\n",
       "   'serial',\n",
       "   'number'],\n",
       "  ['check', 'wallet', 'sad', 'discover', 'defective', 'bill', 'common'],\n",
       "  ['fact',\n",
       "   'common',\n",
       "   'nondefective',\n",
       "   'bill',\n",
       "   'assume',\n",
       "   'digit',\n",
       "   'portion',\n",
       "   'serial',\n",
       "   'number',\n",
       "   'occur',\n",
       "   'equally',\n",
       "   'often',\n",
       "   'could',\n",
       "   'answer_question',\n",
       "   'computing',\n",
       "   'let',\n",
       "   'first',\n",
       "   'consider',\n",
       "   'denominator'],\n",
       "  ['restriction',\n",
       "   'possible',\n",
       "   'first',\n",
       "   'digits',\n",
       "   'possible',\n",
       "   'second',\n",
       "   'digits',\n",
       "   'third',\n",
       "   'digit'],\n",
       "  ['thus',\n",
       "   'total_number',\n",
       "   'digit',\n",
       "   'serial',\n",
       "   'number',\n",
       "   'next',\n",
       "   'let',\n",
       "   'turn',\n",
       "   'numerator'],\n",
       "  ['permit', 'use', 'digit', 'twice'],\n",
       "  ['still',\n",
       "   'possible',\n",
       "   'first',\n",
       "   'digits',\n",
       "   'possible',\n",
       "   'second',\n",
       "   'digits',\n",
       "   'possible',\n",
       "   'third',\n",
       "   'digit',\n",
       "   'forth'],\n",
       "  ['thus',\n",
       "   'generalize',\n",
       "   'product_rule',\n",
       "   'serial',\n",
       "   'number',\n",
       "   'digit',\n",
       "   'different'],\n",
       "  ['plug',\n",
       "   'result',\n",
       "   'equation',\n",
       "   'fraction',\n",
       "   'nondefective',\n",
       "   'bill',\n",
       "   'chapter_cardinality_rule',\n",
       "   'zpz',\n",
       "   'znz',\n",
       "   'figure'],\n",
       "  ['way', 'place', 'pawn', 'knight', 'bishop', 'chessboard'],\n",
       "  ['configuration', 'show', 'invalid', 'bishop', 'knight', 'row']],\n",
       " [['chess',\n",
       "   'problem',\n",
       "   'many_different',\n",
       "   'way',\n",
       "   'place',\n",
       "   'pawn',\n",
       "   'knight',\n",
       "   'bishop',\n",
       "   'chessboard',\n",
       "   'piece',\n",
       "   'share',\n",
       "   'row',\n",
       "   'column',\n",
       "   'valid',\n",
       "   'con',\n",
       "   'figuration',\n",
       "   'show_figure',\n",
       "   'first',\n",
       "   'map',\n",
       "   'problem',\n",
       "   'chess',\n",
       "   'piece',\n",
       "   'question',\n",
       "   'sequence'],\n",
       "  ['bijection',\n",
       "   'configuration',\n",
       "   'sequence',\n",
       "   'thus',\n",
       "   'total_number',\n",
       "   'configuration']],\n",
       " [['permutation', 'permutation', 'set', 'many', 'permutation'],\n",
       "  ['permutation', 'permutation', 'element_set', 'number', 'find'],\n",
       "  ['permutation', 'come', 'course', 'approximately'],\n",
       "  ['bazillion', 'times'],\n",
       "  ['fact',\n",
       "   'permutation',\n",
       "   'reason',\n",
       "   'factorial',\n",
       "   'come',\n",
       "   'often',\n",
       "   'teach',\n",
       "   'stirle',\n",
       "   'approximation']],\n",
       " [['division_rule',\n",
       "   'count',\n",
       "   'ear',\n",
       "   'divide',\n",
       "   'silly',\n",
       "   'way',\n",
       "   'count',\n",
       "   'number',\n",
       "   'people',\n",
       "   'room',\n",
       "   'approach',\n",
       "   'representative',\n",
       "   'powerful',\n",
       "   'counting',\n",
       "   'principle'],\n",
       "  ['rule'],\n",
       "  ['division_rule'],\n",
       "  ['example_suppose'],\n",
       "  ['equivalently', 'people', 'half', 'number', 'ear'],\n",
       "  ['unlikely',\n",
       "   'may_seem',\n",
       "   'many',\n",
       "   'count',\n",
       "   'problem',\n",
       "   'make',\n",
       "   'much',\n",
       "   'easy',\n",
       "   'initially',\n",
       "   'count',\n",
       "   'item',\n",
       "   'multiple',\n",
       "   'time',\n",
       "   'correct',\n",
       "   'answer',\n",
       "   'use',\n",
       "   'division_rule'],\n",
       "  ['let_look', 'example'],\n",
       "  ['chapter_cardinality_rule', 'zrz', 'figure'],\n",
       "  ['way', 'place', 'rook', 'chessboard'],\n",
       "  ['configuration', 'invalid', 'rook', 'column']],\n",
       " [['chess',\n",
       "   'problem',\n",
       "   'many_different',\n",
       "   'way',\n",
       "   'place',\n",
       "   'identical',\n",
       "   'rooks',\n",
       "   'chessboard',\n",
       "   'share',\n",
       "   'row',\n",
       "   'column',\n",
       "   'valid',\n",
       "   'configuration',\n",
       "   'show_figure',\n",
       "   'let',\n",
       "   'set',\n",
       "   'sequence',\n",
       "   'snag'],\n",
       "  ['consider',\n",
       "   'sequence',\n",
       "   'first',\n",
       "   'sequence_map',\n",
       "   'configuration',\n",
       "   'rook',\n",
       "   'lower',\n",
       "   'leave',\n",
       "   'corner',\n",
       "   'rook',\n",
       "   'upper',\n",
       "   'right',\n",
       "   'corner'],\n",
       "  ['second',\n",
       "   'sequence_map',\n",
       "   'configuration',\n",
       "   'rook',\n",
       "   'upper',\n",
       "   'right',\n",
       "   'corner',\n",
       "   'rook',\n",
       "   'lower',\n",
       "   'leave',\n",
       "   'corner'],\n",
       "  ['problem',\n",
       "   'different_way',\n",
       "   'describe',\n",
       "   'configuration',\n",
       "   'fact',\n",
       "   'arrangement',\n",
       "   'show_figure',\n",
       "   'generally',\n",
       "   'function',\n",
       "   'map',\n",
       "   'exactly',\n",
       "   'sequence',\n",
       "   'board',\n",
       "   'con',\n",
       "   'figuration',\n",
       "   'function'],\n",
       "  ['thus', 'quotient', 'rule', 'jbj'],\n",
       "  ['rearrange',\n",
       "   'term',\n",
       "   'give',\n",
       "   'jbj',\n",
       "   'second_line',\n",
       "   'compute',\n",
       "   'size',\n",
       "   'use',\n",
       "   'general',\n",
       "   'product_rule',\n",
       "   'early',\n",
       "   'chess',\n",
       "   'problem']],\n",
       " [['knights',\n",
       "   'round',\n",
       "   'table',\n",
       "   'many_way',\n",
       "   'king',\n",
       "   'arthur',\n",
       "   'seat',\n",
       "   'different',\n",
       "   'knights',\n",
       "   'round',\n",
       "   'table',\n",
       "   'seating',\n",
       "   'consider',\n",
       "   'equivalent',\n",
       "   'obtained',\n",
       "   'rotation'],\n",
       "  ['example',\n",
       "   'follow',\n",
       "   'arrangement',\n",
       "   'equivalent',\n",
       "   'let',\n",
       "   'permutation',\n",
       "   'knight',\n",
       "   'let',\n",
       "   'set',\n",
       "   'possible',\n",
       "   'seating',\n",
       "   'arrangement',\n",
       "   'round',\n",
       "   'table'],\n",
       "  ['map',\n",
       "   'permutation',\n",
       "   'set',\n",
       "   'circular',\n",
       "   'seating',\n",
       "   'arrangement',\n",
       "   'set',\n",
       "   'seat',\n",
       "   'first',\n",
       "   'knight',\n",
       "   'permutation',\n",
       "   'anywhere',\n",
       "   'put',\n",
       "   'second',\n",
       "   'knight',\n",
       "   'leave',\n",
       "   'third',\n",
       "   'knight',\n",
       "   'leave',\n",
       "   'second',\n",
       "   'forth',\n",
       "   'way',\n",
       "   'table'],\n",
       "  ['example',\n",
       "   'mapping',\n",
       "   'actually',\n",
       "   'function',\n",
       "   'cyclic',\n",
       "   'shift',\n",
       "   'original',\n",
       "   'sequence_map',\n",
       "   'seating',\n",
       "   'arrangement'],\n",
       "  ['example',\n",
       "   'different',\n",
       "   'sequence_map',\n",
       "   'seating',\n",
       "   'arrangement',\n",
       "   'chapter_cardinality_rule',\n",
       "   'therefore',\n",
       "   'division_rule',\n",
       "   'number',\n",
       "   'circular',\n",
       "   'seating',\n",
       "   'arrangement',\n",
       "   'note']],\n",
       " [['count',\n",
       "   'subset',\n",
       "   'many',\n",
       "   'many_way',\n",
       "   'select',\n",
       "   'book',\n",
       "   'collection',\n",
       "   'bring',\n",
       "   'vacation',\n",
       "   'many_different',\n",
       "   'card',\n",
       "   'bridge',\n",
       "   'hand',\n",
       "   'deal',\n",
       "   'card_deck',\n",
       "   'many_way',\n",
       "   'select',\n",
       "   'topping',\n",
       "   'pizza',\n",
       "   'avail',\n",
       "   'able',\n",
       "   'topping',\n",
       "   'number',\n",
       "   'come',\n",
       "   'often',\n",
       "   'special',\n",
       "   'notation']],\n",
       " [['subset', 'rule', 'derive', 'simple', 'formula'],\n",
       "  ['notice',\n",
       "   'permutation',\n",
       "   'first',\n",
       "   'first',\n",
       "   'possible',\n",
       "   'permutation',\n",
       "   'first',\n",
       "   'element',\n",
       "   'permutation',\n",
       "   'remain',\n",
       "   'element',\n",
       "   'conclude',\n",
       "   'product_rule',\n",
       "   'exactly'],\n",
       "  ['know', 'prove', 'rule'],\n",
       "  ['subset', 'rule'],\n",
       "  ['number', 'notice', 'work', 'even', 'element', 'subset', 'equal']],\n",
       " [['bit_sequence',\n",
       "   'many',\n",
       "   'associate',\n",
       "   'bit_sequence',\n",
       "   'notice',\n",
       "   'sequence',\n",
       "   'exactly',\n",
       "   'one',\n",
       "   'correspond',\n",
       "   'element',\n",
       "   'element',\n",
       "   'subset'],\n",
       "  ['generally', 'one'],\n",
       "  ['bijection_rule', 'use', 'sum', 'term', 'equal']],\n",
       " [['sequence', 'repetition']],\n",
       " [['sequence', 'subset', 'choose', 'generalize', 'split', 'subset'],\n",
       "  ['namely', 'let', 'sequence', 'rule'],\n",
       "  ['subset', 'split', 'rule'],\n",
       "  ['number', 'proof', 'rule', 'essentially', 'subset', 'rule'],\n",
       "  ['namely', 'map', 'permutation', 'subset', 'split', 'final']],\n",
       " [['bookkeeper_rule', 'also', 'generalize', 'count', 'notice', 'bookkeeper'],\n",
       "  ['lead', 'straightforward', 'bijection', 'permutation', 'bookkeeper'],\n",
       "  ['namely',\n",
       "   'map',\n",
       "   'permutation',\n",
       "   'sequence',\n",
       "   'set',\n",
       "   'position',\n",
       "   'different',\n",
       "   'letter',\n",
       "   'occur'],\n",
       "  ['example',\n",
       "   'permutation',\n",
       "   'bookkeeper',\n",
       "   'st',\n",
       "   'posi',\n",
       "   'tion',\n",
       "   'occur',\n",
       "   'nd',\n",
       "   'rd',\n",
       "   'position',\n",
       "   'th',\n",
       "   'position'],\n",
       "  ['bookkeeper',\n",
       "   'maps',\n",
       "   'bijection',\n",
       "   'subset',\n",
       "   'split',\n",
       "   'rule',\n",
       "   'conclude',\n",
       "   'number',\n",
       "   'way',\n",
       "   'rearrange',\n",
       "   'letter',\n",
       "   'word',\n",
       "   'bookkeeper',\n",
       "   'total',\n",
       "   'letter',\n",
       "   'example',\n",
       "   'generalize',\n",
       "   'directly',\n",
       "   'exceptionally',\n",
       "   'useful',\n",
       "   'count',\n",
       "   'principle',\n",
       "   'call',\n",
       "   'rule'],\n",
       "  ['bookkeeper_rule'],\n",
       "  ['let',\n",
       "   'example_suppose',\n",
       "   'plan',\n",
       "   'mile',\n",
       "   'walk',\n",
       "   'include',\n",
       "   'northward',\n",
       "   'miles',\n",
       "   'eastward',\n",
       "   'miles',\n",
       "   'southward',\n",
       "   'miles',\n",
       "   'westward',\n",
       "   'mile'],\n",
       "  ['many_different', 'walk', 'possible', 'bijection', 'walk', 'sequence'],\n",
       "  ['bookkeeper_rule', 'number', 'sequence']],\n",
       " [['binomial',\n",
       "   'theorem',\n",
       "   'counting',\n",
       "   'give',\n",
       "   'insight',\n",
       "   'basic',\n",
       "   'theorem',\n",
       "   'algebra'],\n",
       "  ['binomial',\n",
       "   'sum',\n",
       "   'term',\n",
       "   'multiply',\n",
       "   'power',\n",
       "   'expression',\n",
       "   'completely',\n",
       "   'get',\n",
       "   'general',\n",
       "   'reasoning',\n",
       "   'give',\n",
       "   'binomial',\n",
       "   'theorem',\n",
       "   'theorem'],\n",
       "  ['binomial', 'theorem'],\n",
       "  ['pearance'],\n",
       "  ['reasoning', 'binomial', 'extend', 'nicely', 'multinomial', 'sum', 'term'],\n",
       "  ['example_suppose',\n",
       "   'want',\n",
       "   'coefficient',\n",
       "   'bo',\n",
       "   'pr',\n",
       "   'expansion',\n",
       "   'bo',\n",
       "   'pr',\n",
       "   'rearrangement',\n",
       "   'word',\n",
       "   'bookkeeper',\n",
       "   'expression',\n",
       "   'leave',\n",
       "   'call',\n",
       "   'multinomial',\n",
       "   'coefficient'],\n",
       "  ['reasoning', 'extend', 'general', 'theorem'],\n",
       "  ['definition'],\n",
       "  ['wwd',\n",
       "   'ck',\n",
       "   'dn',\n",
       "   'better',\n",
       "   'remember',\n",
       "   'reasoning',\n",
       "   'multinomial',\n",
       "   'theorem',\n",
       "   'rather',\n",
       "   'ugly',\n",
       "   'formal',\n",
       "   'statement']],\n",
       " [['word',\n",
       "   'word',\n",
       "   'someday',\n",
       "   'may',\n",
       "   'refer',\n",
       "   'subset',\n",
       "   'split',\n",
       "   'rule',\n",
       "   'bookkeeper_rule',\n",
       "   'front',\n",
       "   'roomful',\n",
       "   'colleague',\n",
       "   'discover',\n",
       "   'stare',\n",
       "   'blankly'],\n",
       "  ['dumb', 'rather', 'make', 'name', 'book', 'keeper', 'rule'],\n",
       "  ['however',\n",
       "   'rule',\n",
       "   'excellent',\n",
       "   'name',\n",
       "   'apt',\n",
       "   'suggest',\n",
       "   'play',\n",
       "   'know',\n",
       "   'bookkeeper_rule',\n",
       "   'guy',\n",
       "   'know',\n",
       "   'bookkeeper_rule',\n",
       "   'sometimes',\n",
       "   'call',\n",
       "   'formula',\n",
       "   'permutation',\n",
       "   'object'],\n",
       "  ['size', 'subset', 'element_set', 'sometimes', 'call', 'combination'],\n",
       "  ['similar',\n",
       "   'sound',\n",
       "   'description',\n",
       "   'combination',\n",
       "   'repetition',\n",
       "   'permutation',\n",
       "   'repetition',\n",
       "   'permutation',\n",
       "   'permutations',\n",
       "   'indis',\n",
       "   'tinguishable',\n",
       "   'object'],\n",
       "  ['however',\n",
       "   'count',\n",
       "   'rule',\n",
       "   'teach',\n",
       "   'sufficient',\n",
       "   'solve',\n",
       "   'sort',\n",
       "   'problem',\n",
       "   'know',\n",
       "   'jargon',\n",
       "   'burden']],\n",
       " [['count',\n",
       "   'practice',\n",
       "   'poker',\n",
       "   'hand',\n",
       "   'card',\n",
       "   'draw',\n",
       "   'card',\n",
       "   'game',\n",
       "   'player',\n",
       "   'initially',\n",
       "   'deal',\n",
       "   'hand',\n",
       "   'con',\n",
       "   'sisting',\n",
       "   'card_deck',\n",
       "   'card'],\n",
       "  ['cards', 'standard', 'deck'],\n",
       "  ['card', 'suit', 'rank'],\n",
       "  ['suit',\n",
       "   'rank',\n",
       "   'list',\n",
       "   'lowest',\n",
       "   'high',\n",
       "   'ace',\n",
       "   'jack',\n",
       "   'queen',\n",
       "   'king',\n",
       "   'thus',\n",
       "   'example',\n",
       "   'heart',\n",
       "   'spade'],\n",
       "  ['chapter_cardinality_rule',\n",
       "   'number',\n",
       "   'element',\n",
       "   'subset',\n",
       "   'element_set',\n",
       "   'let',\n",
       "   'counting',\n",
       "   'practice',\n",
       "   'work',\n",
       "   'number',\n",
       "   'hand',\n",
       "   'various',\n",
       "   'special',\n",
       "   'property']],\n",
       " [['hand', 'kind', 'kind', 'set', 'card_rank'],\n",
       "  ['many_different',\n",
       "   'hand',\n",
       "   'contain',\n",
       "   'kind',\n",
       "   'couple',\n",
       "   'example',\n",
       "   'usual',\n",
       "   'first_step',\n",
       "   'map',\n",
       "   'question',\n",
       "   'sequence',\n",
       "   'counting_problem'],\n",
       "  ['hand',\n",
       "   'kind',\n",
       "   'completely',\n",
       "   'describe_sequence',\n",
       "   'specify',\n",
       "   'rank',\n",
       "   'card'],\n",
       "  ['rank', 'extra_card'],\n",
       "  ['suit', 'extra_card'],\n",
       "  ['thus',\n",
       "   'bijection',\n",
       "   'hand',\n",
       "   'kind',\n",
       "   'sequence',\n",
       "   'siste',\n",
       "   'distinct',\n",
       "   'rank',\n",
       "   'follow',\n",
       "   'suit'],\n",
       "  ['example',\n",
       "   'hand',\n",
       "   'associate',\n",
       "   'follow',\n",
       "   'sequence',\n",
       "   'need',\n",
       "   'count',\n",
       "   'sequence'],\n",
       "  ['way',\n",
       "   'choose',\n",
       "   'first',\n",
       "   'rank',\n",
       "   'way',\n",
       "   'choose',\n",
       "   'second',\n",
       "   'rank',\n",
       "   'way',\n",
       "   'choose',\n",
       "   'suit'],\n",
       "  ['thus', 'generalize', 'product_rule', 'hand', 'kind'],\n",
       "  ['mean', 'hand', 'kind'],\n",
       "  ['surprisingly', 'kind', 'consider', 'good', 'poker', 'hand']],\n",
       " [['hand', 'full_house', 'full_house', 'hand', 'card_rank', 'card_rank'],\n",
       "  ['example', 'shift', 'problem', 'sequence'],\n",
       "  ['bijection',\n",
       "   'full_house',\n",
       "   'sequence',\n",
       "   'specify',\n",
       "   'rank',\n",
       "   'triple',\n",
       "   'choose_way'],\n",
       "  ['suit', 'triple', 'select', 'rank', 'pair', 'choose_way'],\n",
       "  ['suit',\n",
       "   'pair',\n",
       "   'select',\n",
       "   'generalize',\n",
       "   'product_rule',\n",
       "   'number',\n",
       "   'full_house',\n",
       "   'roll',\n",
       "   'hit',\n",
       "   'speed',\n",
       "   'bump']],\n",
       " [['hand_pair',\n",
       "   'many',\n",
       "   'hand_pair',\n",
       "   'card_rank',\n",
       "   'card_rank',\n",
       "   'card',\n",
       "   'third',\n",
       "   'rank',\n",
       "   'example',\n",
       "   'hand_pair',\n",
       "   'describe_sequence',\n",
       "   'consist',\n",
       "   'rank',\n",
       "   'first',\n",
       "   'pair',\n",
       "   'choose_way'],\n",
       "  ['suit',\n",
       "   'first',\n",
       "   'pair',\n",
       "   'select',\n",
       "   'chapter_cardinality_rule',\n",
       "   'rank',\n",
       "   'second',\n",
       "   'pair',\n",
       "   'choose_way'],\n",
       "  ['suit', 'second', 'pair', 'select', 'rank', 'extra_card', 'choose_way'],\n",
       "  ['suit',\n",
       "   'extra_card',\n",
       "   'select',\n",
       "   'wrong',\n",
       "   'answer',\n",
       "   'problem',\n",
       "   'bijection',\n",
       "   'sequence',\n",
       "   'hand_pair'],\n",
       "  ['actually', 'map'],\n",
       "  ['example',\n",
       "   'pair',\n",
       "   'sequence_map',\n",
       "   'hand',\n",
       "   'give',\n",
       "   'problem',\n",
       "   'distinguish',\n",
       "   'first',\n",
       "   'pair',\n",
       "   'second'],\n",
       "  ['pair', 'pair', 'pair', 'pair'],\n",
       "  ['avoid',\n",
       "   'difficulty',\n",
       "   'count',\n",
       "   'full_house',\n",
       "   'example',\n",
       "   'pair',\n",
       "   'triple',\n",
       "   'king',\n",
       "   'different',\n",
       "   'pair',\n",
       "   'king',\n",
       "   'triple'],\n",
       "  ['run',\n",
       "   'precisely',\n",
       "   'difficulty',\n",
       "   'last',\n",
       "   'time',\n",
       "   'go',\n",
       "   'count',\n",
       "   'ar',\n",
       "   'rangements',\n",
       "   'different',\n",
       "   'piece',\n",
       "   'chessboard',\n",
       "   'counting',\n",
       "   'arrangement',\n",
       "   'identical',\n",
       "   'rook'],\n",
       "  ['solution', 'apply', 'division_rule'],\n",
       "  ['case',\n",
       "   'division_rule',\n",
       "   'say',\n",
       "   'twice',\n",
       "   'many',\n",
       "   'sequence',\n",
       "   'hand',\n",
       "   'number',\n",
       "   'hand_pair',\n",
       "   'actually',\n",
       "   'approach',\n",
       "   'precede',\n",
       "   'example',\n",
       "   'disturb',\n",
       "   'could',\n",
       "   'easily',\n",
       "   'overlook',\n",
       "   'fact',\n",
       "   'mapping',\n",
       "   'exam',\n",
       "   'fail',\n",
       "   'course',\n",
       "   'turn',\n",
       "   'life',\n",
       "   'crime'],\n",
       "  ['make',\n",
       "   'world',\n",
       "   'safe',\n",
       "   'place',\n",
       "   'way',\n",
       "   'whenever',\n",
       "   'use',\n",
       "   'mapping',\n",
       "   'translate',\n",
       "   'counting_problem',\n",
       "   'check',\n",
       "   'number',\n",
       "   'element',\n",
       "   'map',\n",
       "   'element'],\n",
       "  ['element', 'map', 'element', 'apply', 'division_rule', 'use', 'constant'],\n",
       "  ['extra', 'check', 'try', 'solve_problem', 'different_way'],\n",
       "  ['multiple',\n",
       "   'approach',\n",
       "   'often',\n",
       "   'available',\n",
       "   'better',\n",
       "   'give',\n",
       "   'answer',\n",
       "   'sometimes',\n",
       "   'different',\n",
       "   'approach',\n",
       "   'give',\n",
       "   'answer',\n",
       "   'look',\n",
       "   'different',\n",
       "   'turn',\n",
       "   'algebra'],\n",
       "  ['already', 'use', 'first', 'method', 'let_try', 'second'],\n",
       "  ['bijection',\n",
       "   'tween',\n",
       "   'hand_pair',\n",
       "   'sequence',\n",
       "   'specify',\n",
       "   'rank',\n",
       "   'pair',\n",
       "   'choose',\n",
       "   'suit',\n",
       "   'low',\n",
       "   'rank',\n",
       "   'pair',\n",
       "   'select',\n",
       "   'suit',\n",
       "   'high',\n",
       "   'rank',\n",
       "   'pair',\n",
       "   'select',\n",
       "   'rank',\n",
       "   'extra_card',\n",
       "   'choose_way'],\n",
       "  ['suit', 'extra_card', 'select'],\n",
       "  ['thus',\n",
       "   'number',\n",
       "   'hand_pair',\n",
       "   'answer',\n",
       "   'get',\n",
       "   'slightly',\n",
       "   'different',\n",
       "   'form']],\n",
       " [['hand',\n",
       "   'suit',\n",
       "   'many',\n",
       "   'hand',\n",
       "   'contain',\n",
       "   'least',\n",
       "   'card',\n",
       "   'suit',\n",
       "   'example',\n",
       "   'hand',\n",
       "   'hand',\n",
       "   'describe_sequence',\n",
       "   'specify',\n",
       "   'rank',\n",
       "   'diamond',\n",
       "   'club',\n",
       "   'heart',\n",
       "   'spade',\n",
       "   'select',\n",
       "   'chapter_cardinality_rule',\n",
       "   'suit',\n",
       "   'extra_card',\n",
       "   'select',\n",
       "   'way'],\n",
       "  ['rank', 'extra_card', 'select', 'way'],\n",
       "  ['example',\n",
       "   'hand',\n",
       "   'describe_sequence',\n",
       "   'sequence',\n",
       "   'correspond',\n",
       "   'hand',\n",
       "   'could',\n",
       "   'equally',\n",
       "   'well',\n",
       "   'regard',\n",
       "   'extra_card',\n",
       "   'actually',\n",
       "   'map'],\n",
       "  ['sequence',\n",
       "   'correspond',\n",
       "   'example',\n",
       "   'hand',\n",
       "   'therefore',\n",
       "   'number',\n",
       "   'hand',\n",
       "   'suit']],\n",
       " [['inclusion_exclusion',\n",
       "   'big',\n",
       "   'union_set',\n",
       "   'example_suppose',\n",
       "   'math',\n",
       "   'major',\n",
       "   'eecs',\n",
       "   'majors',\n",
       "   'physics',\n",
       "   'major'],\n",
       "  ['many',\n",
       "   'student',\n",
       "   'department',\n",
       "   'let',\n",
       "   'set',\n",
       "   'math',\n",
       "   'major',\n",
       "   'set',\n",
       "   'eecs',\n",
       "   'major',\n",
       "   'set',\n",
       "   'physics',\n",
       "   'major'],\n",
       "  ['term', 'ask', 'jm'],\n",
       "  ['sum_rule',\n",
       "   'say',\n",
       "   'disjoint',\n",
       "   'sum',\n",
       "   'size',\n",
       "   'jm',\n",
       "   'jm',\n",
       "   'jej',\n",
       "   'jp',\n",
       "   'however',\n",
       "   'set',\n",
       "   'may',\n",
       "   'disjoint'],\n",
       "  ['example', 'may', 'student', 'major', 'math', 'physics'],\n",
       "  ['student',\n",
       "   'would',\n",
       "   'count',\n",
       "   'twice',\n",
       "   'right_side',\n",
       "   'equation',\n",
       "   'element',\n",
       "   'element'],\n",
       "  ['bad',\n",
       "   'may',\n",
       "   'triple',\n",
       "   'major',\n",
       "   'count',\n",
       "   'time',\n",
       "   'right_side',\n",
       "   'complicated',\n",
       "   'count',\n",
       "   'rule',\n",
       "   'determine_size',\n",
       "   'union_set',\n",
       "   'necessarily',\n",
       "   'disjoint'],\n",
       "  ['state',\n",
       "   'rule',\n",
       "   'let',\n",
       "   'build',\n",
       "   'intuition',\n",
       "   'consider',\n",
       "   'easy',\n",
       "   'special_case',\n",
       "   'union_set']],\n",
       " [['union_set', 'set', 'intuitively', 'element']],\n",
       " [['union_set',\n",
       "   'many',\n",
       "   'student',\n",
       "   'math',\n",
       "   'eecs',\n",
       "   'physics',\n",
       "   'department',\n",
       "   'word',\n",
       "   'jm',\n",
       "   'jm',\n",
       "   'jej',\n",
       "   'jp',\n",
       "   'size_union',\n",
       "   'set',\n",
       "   'give',\n",
       "   'complicate',\n",
       "   'inclusion_exclusion',\n",
       "   'formula',\n",
       "   'js_js',\n",
       "   'js_js',\n",
       "   'js_js',\n",
       "   'js_js',\n",
       "   'remarkably',\n",
       "   'expression',\n",
       "   'right',\n",
       "   'accounts',\n",
       "   'element',\n",
       "   'union',\n",
       "   'js_js',\n",
       "   'term',\n",
       "   'subtract',\n",
       "   'time',\n",
       "   'js_js',\n",
       "   'js',\n",
       "   'term',\n",
       "   'count',\n",
       "   'js',\n",
       "   'term'],\n",
       "  ['net', 'effect', 'count'],\n",
       "  ['set', 'say', 'term', 'subtract', 'js', 'term'],\n",
       "  ['case',\n",
       "   'factor',\n",
       "   'term',\n",
       "   'answer',\n",
       "   'original',\n",
       "   'question',\n",
       "   'know',\n",
       "   'size',\n",
       "   'various',\n",
       "   'intersection'],\n",
       "  ['let',\n",
       "   'suppose',\n",
       "   'math',\n",
       "   'eecs',\n",
       "   'double',\n",
       "   'major',\n",
       "   'math',\n",
       "   'physics',\n",
       "   'double',\n",
       "   'major',\n",
       "   'eecs',\n",
       "   'physics',\n",
       "   'double',\n",
       "   'major',\n",
       "   'triple',\n",
       "   'major',\n",
       "   'chapter_cardinality_rule',\n",
       "   'plug',\n",
       "   'formula',\n",
       "   'give']],\n",
       " [['sequence',\n",
       "   'many',\n",
       "   'permutation',\n",
       "   'set',\n",
       "   'appear',\n",
       "   'consecutively',\n",
       "   'example',\n",
       "   'none',\n",
       "   'pair',\n",
       "   'appear',\n",
       "   'end',\n",
       "   'count',\n",
       "   'need'],\n",
       "  ['hand',\n",
       "   'appear',\n",
       "   'consecutively',\n",
       "   'permutation',\n",
       "   'let',\n",
       "   'first',\n",
       "   'must',\n",
       "   'determine_size',\n",
       "   'individual',\n",
       "   'set',\n",
       "   'contain',\n",
       "   'consecutively',\n",
       "   'permutation',\n",
       "   'example',\n",
       "   'follow',\n",
       "   'sequence',\n",
       "   'correspond',\n",
       "   'next',\n",
       "   'must',\n",
       "   'determine_size',\n",
       "   'way_intersection',\n",
       "   'set',\n",
       "   'thus',\n",
       "   'bijection',\n",
       "   'set',\n",
       "   'plug',\n",
       "   'formula',\n",
       "   'give']],\n",
       " [['union_set', 'size_union', 'rule'],\n",
       "  ['inclusion_exclusion'],\n",
       "  ['sum',\n",
       "   'size',\n",
       "   'individual',\n",
       "   'set',\n",
       "   'minus',\n",
       "   'size_way',\n",
       "   'intersection',\n",
       "   'size_way',\n",
       "   'intersection',\n",
       "   'size_way',\n",
       "   'intersection',\n",
       "   'size_way',\n",
       "   'intersection'],\n",
       "  ['formulas', 'union_set', 'special_case', 'general', 'rule'],\n",
       "  ['way',\n",
       "   'express',\n",
       "   'inclusion_exclusion',\n",
       "   'easy',\n",
       "   'understand',\n",
       "   'nearly',\n",
       "   'precise',\n",
       "   'express',\n",
       "   'mathematical',\n",
       "   'symbol',\n",
       "   'need',\n",
       "   'symbolic',\n",
       "   'version',\n",
       "   'let',\n",
       "   'work',\n",
       "   'decipher'],\n",
       "  ['already',\n",
       "   'standard',\n",
       "   'notation',\n",
       "   'sum',\n",
       "   'size',\n",
       "   'individual',\n",
       "   'set',\n",
       "   'namely',\n",
       "   'way_intersection',\n",
       "   'set',\n",
       "   'form',\n",
       "   'similarly',\n",
       "   'sum',\n",
       "   'size_way',\n",
       "   'intersection',\n",
       "   'chapter_cardinality_rule',\n",
       "   'sum',\n",
       "   'alternate',\n",
       "   'sign',\n",
       "   'inclusion_exclusion',\n",
       "   'formula',\n",
       "   'sum',\n",
       "   'way_intersection',\n",
       "   'get',\n",
       "   'sign'],\n",
       "  ['rule', 'inclusion_exclusion'],\n",
       "  ['js', 'would', 'would', 'js_js']],\n",
       " [['compute',\n",
       "   'euler',\n",
       "   'function',\n",
       "   'example',\n",
       "   'let',\n",
       "   'use',\n",
       "   'inclusion_exclusion',\n",
       "   'calculate',\n",
       "   'eul',\n",
       "   'function'],\n",
       "  ['definition'],\n",
       "  ['number',\n",
       "   'nonnegative_integer',\n",
       "   'less',\n",
       "   'positive',\n",
       "   'inte',\n",
       "   'ger',\n",
       "   'relatively_prime'],\n",
       "  ['set', 'nonnegative_integer', 'less', 'relatively_prime', 'easy', 'count'],\n",
       "  ['suppose',\n",
       "   'prime',\n",
       "   'factorization',\n",
       "   'would',\n",
       "   'able',\n",
       "   'find',\n",
       "   'size_union',\n",
       "   'use',\n",
       "   'inclusion_exclusion',\n",
       "   'intersection',\n",
       "   'jc',\n",
       "   'reasoning',\n",
       "   'way_intersection',\n",
       "   'jsj',\n",
       "   'yike',\n",
       "   'pretty',\n",
       "   'hairy'],\n",
       "  ['get', 'tired', 'nasty', 'algebra', 'good_news', 'way'],\n",
       "  ['next',\n",
       "   'section',\n",
       "   'show',\n",
       "   'prove',\n",
       "   'heavy',\n",
       "   'duty',\n",
       "   'formula',\n",
       "   'use',\n",
       "   'algebra'],\n",
       "  ['word', 'do'],\n",
       "  ['kid']],\n",
       " [['combinatorial', 'proofs', 'suppose', 'different', 'shirt', 'want', 'keep'],\n",
       "  ['could',\n",
       "   'equally',\n",
       "   'well',\n",
       "   'select',\n",
       "   'shirt',\n",
       "   'want',\n",
       "   'keep',\n",
       "   'select',\n",
       "   'complementary',\n",
       "   'set',\n",
       "   'shirt',\n",
       "   'want',\n",
       "   'throw'],\n",
       "  ['thus',\n",
       "   'number',\n",
       "   'way_select',\n",
       "   'shirt',\n",
       "   'must',\n",
       "   'equal_number',\n",
       "   'way_select',\n",
       "   'shirt'],\n",
       "  ['jay',\n",
       "   'select',\n",
       "   'team',\n",
       "   'team',\n",
       "   'first',\n",
       "   'type',\n",
       "   'contain',\n",
       "   'jay',\n",
       "   'team',\n",
       "   'second',\n",
       "   'type',\n",
       "   'therefore',\n",
       "   'set',\n",
       "   'team',\n",
       "   'disjoint'],\n",
       "  ['thus',\n",
       "   'sum_rule',\n",
       "   'total_number',\n",
       "   'possible',\n",
       "   'olympic',\n",
       "   'boxing',\n",
       "   'team',\n",
       "   'jeremy',\n",
       "   'equally',\n",
       "   'fame',\n",
       "   'teaching',\n",
       "   'assistant',\n",
       "   'think',\n",
       "   'jay',\n",
       "   'tough',\n",
       "   'may',\n",
       "   'well',\n",
       "   'also',\n",
       "   'try'],\n",
       "  ['reasons',\n",
       "   'jeremy',\n",
       "   'jay',\n",
       "   'correctly',\n",
       "   'count',\n",
       "   'number',\n",
       "   'possible',\n",
       "   'box',\n",
       "   'team'],\n",
       "  ['thus', 'answer', 'must', 'equal'],\n",
       "  ['know', 'call', 'pascal', 'identity'],\n",
       "  ['prove', 'algebra', 'instead', 'rely', 'purely', 'count', 'technique']],\n",
       " [['find',\n",
       "   'combinatorial',\n",
       "   'proof',\n",
       "   'combinatorial',\n",
       "   'proof',\n",
       "   'argument',\n",
       "   'establish',\n",
       "   'algebraic',\n",
       "   'fact',\n",
       "   'rely',\n",
       "   'count',\n",
       "   'principle'],\n",
       "  ['many', 'proof', 'follow', 'basic', 'outline', 'define', 'set'],\n",
       "  ['show', 'jsj', 'count', 'way'],\n",
       "  ['show', 'jsj', 'count', 'way'],\n",
       "  ['conclude'],\n",
       "  ['precede', 'example', 'set', 'possible', 'olympic', 'boxing', 'team'],\n",
       "  ['jay',\n",
       "   'compute',\n",
       "   'count',\n",
       "   'way',\n",
       "   'jeremy',\n",
       "   'compute',\n",
       "   'jsj',\n",
       "   'count',\n",
       "   'way'],\n",
       "  ['equate', 'expression', 'give', 'pascal', 'identity'],\n",
       "  ['typically',\n",
       "   'set',\n",
       "   'define',\n",
       "   'term',\n",
       "   'simple',\n",
       "   'sequence',\n",
       "   'set',\n",
       "   'rather',\n",
       "   'elaborate',\n",
       "   'story'],\n",
       "  ['less', 'colorful', 'example', 'combinatorial', 'argu', 'ment'],\n",
       "  ['theorem'],\n",
       "  ['chapter_cardinality_rule', 'proof'],\n",
       "  ['give', 'combinatorial', 'proof'],\n",
       "  ['let',\n",
       "   'card',\n",
       "   'hand',\n",
       "   'deal',\n",
       "   'deck',\n",
       "   'contain',\n",
       "   'red',\n",
       "   'card',\n",
       "   'number',\n",
       "   'black',\n",
       "   'card',\n",
       "   'num',\n",
       "   'bere'],\n",
       "  ['first', 'note', 'element_set', 'jsj', 'element', 'subset'],\n",
       "  ['perspective', 'number', 'hand', 'exactly', 'red', 'card', 'black', 'card'],\n",
       "  ['number',\n",
       "   'red',\n",
       "   'card',\n",
       "   'anywhere',\n",
       "   'total_number',\n",
       "   'card',\n",
       "   'hand',\n",
       "   'combinatorial',\n",
       "   'proof',\n",
       "   'almost',\n",
       "   'magical'],\n",
       "  ['theorem', 'look', 'pretty', 'scary', 'prove', 'algebraic', 'manipulation'],\n",
       "  ['key',\n",
       "   'construct',\n",
       "   'combinatorial',\n",
       "   'proof',\n",
       "   'choose',\n",
       "   'set',\n",
       "   'properly',\n",
       "   'tricky'],\n",
       "  ['gener', 'ally', 'simple', 'side_equation', 'provide', 'guidance'],\n",
       "  ['example', 'right_side', 'theorem']],\n",
       " [['pigeonhole_principle',\n",
       "   'old',\n",
       "   'puzzle',\n",
       "   'drawer',\n",
       "   'dark',\n",
       "   'room',\n",
       "   'contain',\n",
       "   'red',\n",
       "   'socks',\n",
       "   'green',\n",
       "   'socks',\n",
       "   'blue',\n",
       "   'socks'],\n",
       "  ['many',\n",
       "   'sock',\n",
       "   'must',\n",
       "   'withdraw',\n",
       "   'sure',\n",
       "   'match',\n",
       "   'pair',\n",
       "   'example',\n",
       "   'pick',\n",
       "   'sock',\n",
       "   'enough',\n",
       "   'may',\n",
       "   'end',\n",
       "   'red',\n",
       "   'green',\n",
       "   'blue'],\n",
       "  ['solution',\n",
       "   'rely',\n",
       "   'pigeonhole_principle',\n",
       "   'friendly',\n",
       "   'name',\n",
       "   'contrapositive',\n",
       "   'injective',\n",
       "   'case',\n",
       "   'mapping_rule'],\n",
       "  ['pigeonhole_principle', 'st', 'nd', 'rd', 'th', 'figure'],\n",
       "  ['possible', 'mapping', 'sock', 'color'],\n",
       "  ['rule'],\n",
       "  ['pigeonhole_principle'],\n",
       "  ['jxj',\n",
       "   'jy',\n",
       "   'total',\n",
       "   'function',\n",
       "   'exist',\n",
       "   'different',\n",
       "   'element',\n",
       "   'map',\n",
       "   'element'],\n",
       "  ['abstract',\n",
       "   'mathematical',\n",
       "   'statement',\n",
       "   'select',\n",
       "   'footwear',\n",
       "   'un',\n",
       "   'der',\n",
       "   'poor',\n",
       "   'lighting',\n",
       "   'condition',\n",
       "   'maybe',\n",
       "   'obvious'],\n",
       "  ['however',\n",
       "   'let',\n",
       "   'set',\n",
       "   'sock',\n",
       "   'pick',\n",
       "   'let',\n",
       "   'set',\n",
       "   'color',\n",
       "   'available',\n",
       "   'let',\n",
       "   'map',\n",
       "   'sock',\n",
       "   'color'],\n",
       "  ['pigeonhole_principle',\n",
       "   'say',\n",
       "   'jaj',\n",
       "   'jb',\n",
       "   'least',\n",
       "   'element',\n",
       "   'least',\n",
       "   'sock',\n",
       "   'must',\n",
       "   'map',\n",
       "   'element',\n",
       "   'color'],\n",
       "  ['therefore', 'sock', 'enough', 'ensure', 'match', 'pair'],\n",
       "  ['example',\n",
       "   'possible',\n",
       "   'mapping',\n",
       "   'sock',\n",
       "   'color',\n",
       "   'show_figure',\n",
       "   'surprisingly',\n",
       "   'pigeonhole_principle',\n",
       "   'often',\n",
       "   'describe',\n",
       "   'term',\n",
       "   'pigeon',\n",
       "   'pigeon',\n",
       "   'hole',\n",
       "   'occupy',\n",
       "   'least',\n",
       "   'pigeon',\n",
       "   'must',\n",
       "   'hole'],\n",
       "  ['case',\n",
       "   'pigeon',\n",
       "   'form',\n",
       "   'set',\n",
       "   'pigeonhole',\n",
       "   'set',\n",
       "   'describe',\n",
       "   'hole',\n",
       "   'pigeon',\n",
       "   'fly'],\n",
       "  ['mathematician',\n",
       "   'come',\n",
       "   'many',\n",
       "   'ingenious',\n",
       "   'application',\n",
       "   'pigeon',\n",
       "   'hole',\n",
       "   'principle'],\n",
       "  ['cookbook', 'procedure', 'generating', 'argument', 'give'],\n",
       "  ['unfortunately'],\n",
       "  ['helpful',\n",
       "   'tip',\n",
       "   'try',\n",
       "   'solve_problem',\n",
       "   'pigeonhole_principle',\n",
       "   'key',\n",
       "   'clearly',\n",
       "   'iden',\n",
       "   'tify',\n",
       "   'thing',\n",
       "   'mapping_rule',\n",
       "   'apply',\n",
       "   'even',\n",
       "   'total',\n",
       "   'injective',\n",
       "   'relation'],\n",
       "  ['recall', 'function', 'total'],\n",
       "  ['chapter_cardinality_rule', 'set', 'pigeon'],\n",
       "  ['set', 'pigeonhole'],\n",
       "  ['function', 'rule', 'assign', 'pigeon', 'pigeonhole']],\n",
       " [['hairs', 'head', 'number', 'generalization', 'pigeonhole_principle'],\n",
       "  ['example', 'rule'],\n",
       "  ['generalize', 'pigeonhole_principle'],\n",
       "  ['jxj',\n",
       "   'jy',\n",
       "   'total',\n",
       "   'function',\n",
       "   'map',\n",
       "   'least',\n",
       "   'different',\n",
       "   'element',\n",
       "   'element'],\n",
       "  ['example',\n",
       "   'pick',\n",
       "   'people',\n",
       "   'random',\n",
       "   'surely',\n",
       "   'extremely',\n",
       "   'un',\n",
       "   'likely',\n",
       "   'exactly',\n",
       "   'number',\n",
       "   'hair',\n",
       "   'head'],\n",
       "  ['however',\n",
       "   'remarkable',\n",
       "   'city',\n",
       "   'boston',\n",
       "   'massachusetts',\n",
       "   'actually',\n",
       "   'people',\n",
       "   'exactly',\n",
       "   'number',\n",
       "   'hair',\n",
       "   'course',\n",
       "   'many',\n",
       "   'bald',\n",
       "   'people',\n",
       "   'boston',\n",
       "   'hairs'],\n",
       "  ['talk',\n",
       "   'non',\n",
       "   'bald',\n",
       "   'people',\n",
       "   'say',\n",
       "   'person',\n",
       "   'non',\n",
       "   'bald',\n",
       "   'least',\n",
       "   'hair',\n",
       "   'head'],\n",
       "  ['boston', 'non', 'bald', 'people', 'number', 'hair', 'person', 'head'],\n",
       "  ['let',\n",
       "   'set',\n",
       "   'non',\n",
       "   'bald',\n",
       "   'people',\n",
       "   'boston',\n",
       "   'let',\n",
       "   'let',\n",
       "   'map',\n",
       "   'person',\n",
       "   'number',\n",
       "   'hair',\n",
       "   'head'],\n",
       "  ['jbj',\n",
       "   'generalize',\n",
       "   'pigeonhole_principle',\n",
       "   'imply',\n",
       "   'least',\n",
       "   'people',\n",
       "   'exactly',\n",
       "   'number',\n",
       "   'hair'],\n",
       "  ['know', 'know', 'exist']],\n",
       " [['subsets',\n",
       "   'sum',\n",
       "   'reading',\n",
       "   'pleasure',\n",
       "   'display',\n",
       "   'digit',\n",
       "   'number',\n",
       "   'fig_ure',\n",
       "   'find',\n",
       "   'subset',\n",
       "   'sum',\n",
       "   'may_seem',\n",
       "   'silly',\n",
       "   'puzzle',\n",
       "   'solve',\n",
       "   'sort',\n",
       "   'problem',\n",
       "   'turn',\n",
       "   'useful',\n",
       "   'diverse',\n",
       "   'application',\n",
       "   'find',\n",
       "   'good',\n",
       "   'way',\n",
       "   'fit',\n",
       "   'package',\n",
       "   'ship',\n",
       "   'container',\n",
       "   'decode',\n",
       "   'secret',\n",
       "   'message'],\n",
       "  ['turn',\n",
       "   'hard',\n",
       "   'find',\n",
       "   'different_subset',\n",
       "   'sum',\n",
       "   'problem',\n",
       "   'arise',\n",
       "   'cryptography'],\n",
       "  ['easy', 'prove', 'subset', 'exist'],\n",
       "  ['pigeonhole_principle', 'come'],\n",
       "  ['let', 'collection', 'subset', 'number', 'list'],\n",
       "  ['sum', 'subset', 'number', 'let', 'map', 'subset', 'number', 'sum'],\n",
       "  ['figure'],\n",
       "  ['digit', 'number'],\n",
       "  ['find',\n",
       "   'different_subset',\n",
       "   'number',\n",
       "   'sum',\n",
       "   'chapter_cardinality_rule',\n",
       "   'prove',\n",
       "   'element_set',\n",
       "   'hand',\n",
       "   'jbj',\n",
       "   'quantity',\n",
       "   'enormous',\n",
       "   'bit',\n",
       "   'great',\n",
       "   'jbj'],\n",
       "  ['means', 'map', 'least', 'element', 'element'],\n",
       "  ['word',\n",
       "   'pigeonhole_principle',\n",
       "   'different_subset',\n",
       "   'must',\n",
       "   'sum',\n",
       "   'notice',\n",
       "   'proof',\n",
       "   'give',\n",
       "   'indication',\n",
       "   'set',\n",
       "   'number',\n",
       "   'sum'],\n",
       "  ['frustrating', 'variety', 'argument', 'call', 'nonconstructive', 'proof'],\n",
       "  ['see',\n",
       "   'possible',\n",
       "   'actually',\n",
       "   'find',\n",
       "   'different_subset',\n",
       "   'digit',\n",
       "   'number',\n",
       "   'sum',\n",
       "   'offer',\n",
       "   'prize',\n",
       "   'first',\n",
       "   'student'],\n",
       "  ['expect',\n",
       "   'pay',\n",
       "   'bet',\n",
       "   'underestimate',\n",
       "   'ingenuity',\n",
       "   'initiative',\n",
       "   'student'],\n",
       "  ['computer_science',\n",
       "   'major',\n",
       "   'write',\n",
       "   'program',\n",
       "   'cleverly',\n",
       "   'search',\n",
       "   'reasonably',\n",
       "   'small',\n",
       "   'set',\n",
       "   'plausible',\n",
       "   'set',\n",
       "   'sort',\n",
       "   'sum',\n",
       "   'actually',\n",
       "   'find',\n",
       "   'couple',\n",
       "   'sum'],\n",
       "  ['prize'],\n",
       "  ['day',\n",
       "   'later',\n",
       "   'math',\n",
       "   'major',\n",
       "   'figure',\n",
       "   'reformulate',\n",
       "   'sum',\n",
       "   'problem',\n",
       "   'lattice',\n",
       "   'basis',\n",
       "   'reduction',\n",
       "   'problem',\n",
       "   'find',\n",
       "   'software',\n",
       "   'package',\n",
       "   'implement',\n",
       "   'efficient',\n",
       "   'basis',\n",
       "   'reduction',\n",
       "   'procedure',\n",
       "   'use',\n",
       "   'quickly',\n",
       "   'find',\n",
       "   'lot',\n",
       "   'pair',\n",
       "   'subset',\n",
       "   'sum'],\n",
       "  ['win', 'prize', 'get', 'stand', 'ovation', 'class', 'staff', 'include']],\n",
       " [['magic', 'trick', 'magician_assistant'],\n",
       "  ['assistant', 'go', 'audience', 'deck_card', 'magician', 'look', 'away'],\n",
       "  ['audience', 'member', 'select', 'card_deck'],\n",
       "  ['assistant', 'gather', 'card', 'hold', 'magician', 'see'],\n",
       "  ['magician',\n",
       "   'concentrate',\n",
       "   'short',\n",
       "   'time',\n",
       "   'correctly',\n",
       "   'name',\n",
       "   'secret',\n",
       "   'fifth',\n",
       "   'card',\n",
       "   'really',\n",
       "   'believe',\n",
       "   'magician',\n",
       "   'read',\n",
       "   'mind',\n",
       "   'know',\n",
       "   'sistant',\n",
       "   'somehow',\n",
       "   'communicate',\n",
       "   'secret_card',\n",
       "   'magician'],\n",
       "  ['real',\n",
       "   'magician_assistant',\n",
       "   'trust',\n",
       "   'expect',\n",
       "   'assistant',\n",
       "   'would',\n",
       "   'illegitimately',\n",
       "   'signal',\n",
       "   'magician',\n",
       "   'code',\n",
       "   'phrases',\n",
       "   'body',\n",
       "   'language',\n",
       "   'cheat',\n",
       "   'way'],\n",
       "  ['fact',\n",
       "   'magician_assistant',\n",
       "   'could',\n",
       "   'sets',\n",
       "   'distinct',\n",
       "   'subset',\n",
       "   'sum',\n",
       "   'construct',\n",
       "   'set',\n",
       "   'distinct',\n",
       "   'sum',\n",
       "   'way',\n",
       "   'use',\n",
       "   'power',\n",
       "   'approach',\n",
       "   'natural',\n",
       "   'suspect',\n",
       "   'set',\n",
       "   'must',\n",
       "   'involve',\n",
       "   'large_number'],\n",
       "  ['example', 'could', 'safely', 'replace'],\n",
       "  ['remark',\n",
       "   'ably',\n",
       "   'example',\n",
       "   'involve',\n",
       "   'small',\n",
       "   'top',\n",
       "   'mathematicians',\n",
       "   'twentieth',\n",
       "   'century',\n",
       "   'paul',\n",
       "   'erdos',\n",
       "   'conjecture',\n",
       "   'set',\n",
       "   'involve',\n",
       "   'significantly',\n",
       "   'chapter_cardinality_rule',\n",
       "   'keep',\n",
       "   'sight',\n",
       "   'audience',\n",
       "   'member',\n",
       "   'hold',\n",
       "   'card',\n",
       "   'designate',\n",
       "   'assistant',\n",
       "   'magician',\n",
       "   'see'],\n",
       "  ['course',\n",
       "   'cheat',\n",
       "   'still',\n",
       "   'obvious',\n",
       "   'way',\n",
       "   'assistant',\n",
       "   'com',\n",
       "   'municate',\n",
       "   'magician',\n",
       "   'choose']],\n",
       " [['secret',\n",
       "   'method',\n",
       "   'assistant',\n",
       "   'use',\n",
       "   'communicate',\n",
       "   'fifth',\n",
       "   'card',\n",
       "   'exactly',\n",
       "   'nice',\n",
       "   'application',\n",
       "   'know',\n",
       "   'count',\n",
       "   'matching'],\n",
       "  ['assistant',\n",
       "   'second',\n",
       "   'legitimate',\n",
       "   'way',\n",
       "   'communicate',\n",
       "   'choose',\n",
       "   'card',\n",
       "   'keep',\n",
       "   'hide'],\n",
       "  ['course',\n",
       "   'clear',\n",
       "   'magician',\n",
       "   'could',\n",
       "   'determine',\n",
       "   'possibility',\n",
       "   'assistant',\n",
       "   'select',\n",
       "   'look',\n",
       "   'visible',\n",
       "   'card',\n",
       "   'way',\n",
       "   'explain'],\n",
       "  ['problem',\n",
       "   'face',\n",
       "   'magician_assistant',\n",
       "   'actually',\n",
       "   'bipartite',\n",
       "   'match',\n",
       "   'problem'],\n",
       "  ['put',\n",
       "   'set',\n",
       "   'card',\n",
       "   'collection',\n",
       "   'example',\n",
       "   'element',\n",
       "   'magician_assistant',\n",
       "   'nee',\n",
       "   'perform',\n",
       "   'trick',\n",
       "   'match',\n",
       "   'example_suppose',\n",
       "   'assistant',\n",
       "   'magician',\n",
       "   'agree',\n",
       "   'match',\n",
       "   'contain',\n",
       "   'bold',\n",
       "   'edge',\n",
       "   'figure',\n",
       "   'figure'],\n",
       "  ['bipartite_graph',\n",
       "   'node_leave',\n",
       "   'correspond',\n",
       "   'set',\n",
       "   'card',\n",
       "   'node',\n",
       "   'right',\n",
       "   'correspond',\n",
       "   'sequence',\n",
       "   'card'],\n",
       "  ['edge',\n",
       "   'set',\n",
       "   'sequence',\n",
       "   'whenever',\n",
       "   'card',\n",
       "   'sequence',\n",
       "   'contain',\n",
       "   'set'],\n",
       "  ['assistant',\n",
       "   'reveal',\n",
       "   'correspond',\n",
       "   'sequence',\n",
       "   'use',\n",
       "   'match',\n",
       "   'magician',\n",
       "   'see',\n",
       "   'hand',\n",
       "   'sure',\n",
       "   'need',\n",
       "   'matching',\n",
       "   'find',\n",
       "   'answer',\n",
       "   'vertex',\n",
       "   'left',\n",
       "   'degree',\n",
       "   'fact',\n",
       "   'reasoning',\n",
       "   'show',\n",
       "   'magician',\n",
       "   'could',\n",
       "   'still',\n",
       "   'pull',\n",
       "   'trick',\n",
       "   'card',\n",
       "   'leave',\n",
       "   'instead',\n",
       "   'trick',\n",
       "   'would',\n",
       "   'work',\n",
       "   'deck',\n",
       "   'large',\n",
       "   'different',\n",
       "   'card',\n",
       "   'magic',\n",
       "   'chapter_cardinality_rule',\n",
       "   'figure'],\n",
       "  ['card_rank', 'arrange', 'cyclic', 'order']],\n",
       " [['real',\n",
       "   'secret',\n",
       "   'wait',\n",
       "   'minute',\n",
       "   'principle',\n",
       "   'magician_assistant',\n",
       "   'agree',\n",
       "   'match',\n",
       "   'suppose',\n",
       "   'remember',\n",
       "   'match',\n",
       "   'describe',\n",
       "   'approach'],\n",
       "  ['run',\n",
       "   'example_suppose',\n",
       "   'audience',\n",
       "   'select',\n",
       "   'assistant',\n",
       "   'pick',\n",
       "   'card',\n",
       "   'suit'],\n",
       "  ['example', 'assistant', 'may', 'choose'],\n",
       "  ['always',\n",
       "   'possible',\n",
       "   'pigeonhole_principle',\n",
       "   'card',\n",
       "   'suit',\n",
       "   'card',\n",
       "   'must',\n",
       "   'suit'],\n",
       "  ['assistant',\n",
       "   'locate',\n",
       "   'rank',\n",
       "   'card',\n",
       "   'cycle',\n",
       "   'show',\n",
       "   'fig_ure',\n",
       "   'card_reveal',\n",
       "   'first',\n",
       "   'become',\n",
       "   'secret_card'],\n",
       "  ['thus', 'example', 'would', 'reveal', 'would', 'secret_card'],\n",
       "  ['therefore', 'remain', 'communicate', 'number'],\n",
       "  ['magician_assistant',\n",
       "   'agree',\n",
       "   'beforehand',\n",
       "   'order',\n",
       "   'card_deck',\n",
       "   'small',\n",
       "   'large',\n",
       "   'order',\n",
       "   'last',\n",
       "   'card_reveal',\n",
       "   'communicates',\n",
       "   'num_ber',\n",
       "   'accord',\n",
       "   'follow',\n",
       "   'scheme',\n",
       "   'example',\n",
       "   'assistant',\n",
       "   'want',\n",
       "   'send',\n",
       "   'reveal',\n",
       "   'remain',\n",
       "   'card',\n",
       "   'large',\n",
       "   'medium',\n",
       "   'small',\n",
       "   'order'],\n",
       "  ['complete',\n",
       "   'sequence',\n",
       "   'magician',\n",
       "   'see',\n",
       "   'magician',\n",
       "   'start',\n",
       "   'first',\n",
       "   'card',\n",
       "   'hop',\n",
       "   'rank',\n",
       "   'clockwise',\n",
       "   'reach',\n",
       "   'secret_card',\n",
       "   'trick',\n",
       "   'work',\n",
       "   'standard',\n",
       "   'deck_card'],\n",
       "  ['hand',\n",
       "   'hall',\n",
       "   'theorem',\n",
       "   'imply',\n",
       "   'magician_assistant',\n",
       "   'principle',\n",
       "   'form',\n",
       "   'trick',\n",
       "   'deck_card'],\n",
       "  ['turn',\n",
       "   'method',\n",
       "   'could',\n",
       "   'actually',\n",
       "   'learn',\n",
       "   'use',\n",
       "   'reasonable',\n",
       "   'amount',\n",
       "   'practice',\n",
       "   'card_deck',\n",
       "   'explain']],\n",
       " [['trick',\n",
       "   'card',\n",
       "   'suppose',\n",
       "   'audience',\n",
       "   'select',\n",
       "   'card',\n",
       "   'assistant',\n",
       "   'reveal',\n",
       "   'se',\n",
       "   'quence',\n",
       "   'magician'],\n",
       "  ['magician',\n",
       "   'determine',\n",
       "   'fourth',\n",
       "   'card',\n",
       "   'let',\n",
       "   'set',\n",
       "   'card',\n",
       "   'audience',\n",
       "   'may',\n",
       "   'select',\n",
       "   'let',\n",
       "   'sequence',\n",
       "   'card',\n",
       "   'assistant',\n",
       "   'may',\n",
       "   'reveal'],\n",
       "  ['hand', 'see', 'good', 'card', 'trick', 'michael', 'kleber', 'information'],\n",
       "  ['chapter_cardinality_rule', 'subset', 'rule'],\n",
       "  ['hand', 'jy', 'generalize', 'product_rule'],\n",
       "  ['thus',\n",
       "   'pigeonhole_principle',\n",
       "   'assistant',\n",
       "   'must',\n",
       "   'reveal',\n",
       "   'sequence',\n",
       "   'card',\n",
       "   'least',\n",
       "   'different',\n",
       "   'card',\n",
       "   'hand'],\n",
       "  ['bad_news',\n",
       "   'magician',\n",
       "   'see',\n",
       "   'se',\n",
       "   'quence',\n",
       "   'least',\n",
       "   'possibility',\n",
       "   'fourth',\n",
       "   'card',\n",
       "   'can',\n",
       "   'distinguish'],\n",
       "  ['legitimate',\n",
       "   'way',\n",
       "   'assistant',\n",
       "   'communi',\n",
       "   'cate',\n",
       "   'exactly',\n",
       "   'fourth',\n",
       "   'card']],\n",
       " [['never',\n",
       "   'say',\n",
       "   'never',\n",
       "   'sooner',\n",
       "   'finish',\n",
       "   'prove',\n",
       "   'magician',\n",
       "   'pull',\n",
       "   'trick',\n",
       "   'card',\n",
       "   'instead',\n",
       "   'student',\n",
       "   'show',\n",
       "   'way',\n",
       "   'may',\n",
       "   'doable'],\n",
       "  ['idea', 'place', 'card', 'table', 'time', 'instead', 'reveal'],\n",
       "  ['provide',\n",
       "   'magician',\n",
       "   'completely',\n",
       "   'independent',\n",
       "   'sequence',\n",
       "   'card',\n",
       "   'temporal',\n",
       "   'order',\n",
       "   'card',\n",
       "   'place',\n",
       "   'table',\n",
       "   'spatial',\n",
       "   'order',\n",
       "   'appear',\n",
       "   'place'],\n",
       "  ['example_suppose',\n",
       "   'audience',\n",
       "   'select',\n",
       "   'assistant',\n",
       "   'decide',\n",
       "   'reveal',\n",
       "   'assistant',\n",
       "   'may',\n",
       "   'decide',\n",
       "   'reveal',\n",
       "   'first',\n",
       "   'second',\n",
       "   'third',\n",
       "   'thereby',\n",
       "   'production',\n",
       "   'temporal',\n",
       "   'sequence',\n",
       "   'place',\n",
       "   'middle',\n",
       "   'position',\n",
       "   'table',\n",
       "   'place',\n",
       "   'rightmost',\n",
       "   'position',\n",
       "   'table',\n",
       "   'place',\n",
       "   'leftmost',\n",
       "   'position',\n",
       "   'table',\n",
       "   'spatial',\n",
       "   'sequence',\n",
       "   'would',\n",
       "   'version',\n",
       "   'card',\n",
       "   'trick',\n",
       "   'consist',\n",
       "   'set',\n",
       "   'card',\n",
       "   'consist',\n",
       "   'pair',\n",
       "   'sequence',\n",
       "   'card'],\n",
       "  ['create',\n",
       "   'bipartite_graph',\n",
       "   'edge_connect',\n",
       "   'set',\n",
       "   'degree_node',\n",
       "   'choice',\n",
       "   'card_reveal',\n",
       "   'degree_node',\n",
       "   'hence',\n",
       "   'magic',\n",
       "   'trick',\n",
       "   'doable',\n",
       "   'card',\n",
       "   'assistant',\n",
       "   'convey',\n",
       "   'information'],\n",
       "  ['figure',\n",
       "   'convenient',\n",
       "   'way',\n",
       "   'pull',\n",
       "   'trick',\n",
       "   'fly',\n",
       "   'card',\n",
       "   'version',\n",
       "   'surely',\n",
       "   'doable']],\n",
       " [['generate_function',\n",
       "   'generate_function',\n",
       "   'surprising',\n",
       "   'useful',\n",
       "   'invention',\n",
       "   'dis',\n",
       "   'crete',\n",
       "   'math'],\n",
       "  ['roughly',\n",
       "   'speak',\n",
       "   'generate_function',\n",
       "   'transform',\n",
       "   'problem',\n",
       "   'quence',\n",
       "   'problem',\n",
       "   'function'],\n",
       "  ['great',\n",
       "   'get',\n",
       "   'pile',\n",
       "   'mathematical',\n",
       "   'machinery',\n",
       "   'manipulating',\n",
       "   'function'],\n",
       "  ['thank',\n",
       "   'generate',\n",
       "   'func_tion',\n",
       "   'apply',\n",
       "   'machinery',\n",
       "   'problem',\n",
       "   'sequence'],\n",
       "  ['way', 'use', 'generate_function', 'solve', 'sort', 'count', 'problem'],\n",
       "  ['also', 'use', 'find_close_form', 'expression', 'sum', 'solve_recurrence'],\n",
       "  ['fact',\n",
       "   'many',\n",
       "   'problem',\n",
       "   'address',\n",
       "   'chapter',\n",
       "   'formulate',\n",
       "   'solve',\n",
       "   'use',\n",
       "   'generating_function']],\n",
       " [['definition', 'example', 'ordinary', 'generating_function', 'sequence'],\n",
       "  ['kind',\n",
       "   'generate_function',\n",
       "   'common',\n",
       "   'use',\n",
       "   'ordinary',\n",
       "   'generating_function',\n",
       "   'enough',\n",
       "   'illustrate',\n",
       "   'power',\n",
       "   'idea',\n",
       "   'stick',\n",
       "   'generating_function',\n",
       "   'mean',\n",
       "   'ordinary',\n",
       "   'kind'],\n",
       "  ['generate_function',\n",
       "   'formal',\n",
       "   'power',\n",
       "   'series',\n",
       "   'sense',\n",
       "   'usually',\n",
       "   'regard',\n",
       "   'placeholder',\n",
       "   'rather',\n",
       "   'number'],\n",
       "  ['rare',\n",
       "   'case',\n",
       "   'actually',\n",
       "   'evaluate',\n",
       "   'generate_function',\n",
       "   'let',\n",
       "   'take',\n",
       "   'real_number',\n",
       "   'value',\n",
       "   'generally',\n",
       "   'ignore',\n",
       "   'issue',\n",
       "   'convergence'],\n",
       "  ['chapter',\n",
       "   'indicate',\n",
       "   'correspondence',\n",
       "   'sequence',\n",
       "   'generating_function',\n",
       "   'double',\n",
       "   'side',\n",
       "   'arrow',\n",
       "   'follow',\n",
       "   'hg',\n",
       "   'example',\n",
       "   'sequence',\n",
       "   'generate_function',\n",
       "   'chapter',\n",
       "   'put',\n",
       "   'sequence',\n",
       "   'angle',\n",
       "   'bracket',\n",
       "   'clearly',\n",
       "   'distinguish',\n",
       "   'many',\n",
       "   'mathematical',\n",
       "   'expression',\n",
       "   'float',\n",
       "   'around'],\n",
       "  ['chapter_generating_function',\n",
       "   'pattern',\n",
       "   'simple',\n",
       "   'ith',\n",
       "   'term',\n",
       "   'sequence',\n",
       "   'indexing',\n",
       "   'coefficient',\n",
       "   'recall',\n",
       "   'sum',\n",
       "   'infinite',\n",
       "   'geometric_series',\n",
       "   'equation_hold',\n",
       "   'jzj',\n",
       "   'remark',\n",
       "   'worry',\n",
       "   'convergence',\n",
       "   'issue'],\n",
       "  ['formula',\n",
       "   'give',\n",
       "   'close_form',\n",
       "   'generating_function',\n",
       "   'whole',\n",
       "   'range',\n",
       "   'sequence'],\n",
       "  ['example']],\n",
       " [['operation',\n",
       "   'generate_function',\n",
       "   'magic',\n",
       "   'generating_function',\n",
       "   'carry',\n",
       "   'sort',\n",
       "   'manipulation',\n",
       "   'sequence',\n",
       "   'perform',\n",
       "   'mathematical',\n",
       "   'operation',\n",
       "   'associate',\n",
       "   'generate_function'],\n",
       "  ['let',\n",
       "   'experiment',\n",
       "   'various',\n",
       "   'operation',\n",
       "   'characterize',\n",
       "   'effect',\n",
       "   'term',\n",
       "   'sequence']],\n",
       " [['scale',\n",
       "   'multiply',\n",
       "   'generating_function',\n",
       "   'constant',\n",
       "   'scale',\n",
       "   'term',\n",
       "   'associate',\n",
       "   'sequence',\n",
       "   'constant'],\n",
       "  ['example', 'note', 'generate', 'sequence', 'hcf', 'cf'],\n",
       "  ['cf']],\n",
       " [['addition',\n",
       "   'add',\n",
       "   'generate_function',\n",
       "   'correspond',\n",
       "   'add',\n",
       "   'sequence',\n",
       "   'term',\n",
       "   'term'],\n",
       "  ['example',\n",
       "   'add',\n",
       "   'early',\n",
       "   'example',\n",
       "   'give',\n",
       "   'derive',\n",
       "   'different',\n",
       "   'expression',\n",
       "   'generate',\n",
       "   'sequence'],\n",
       "  ['course', 'equal', 'chapter_generating_function', 'idea', 'rule']],\n",
       " [['right',\n",
       "   'shifting',\n",
       "   'let',\n",
       "   'start',\n",
       "   'simple',\n",
       "   'sequence',\n",
       "   'generating_function',\n",
       "   'let',\n",
       "   'right_shift',\n",
       "   'sequence',\n",
       "   'add',\n",
       "   'lead',\n",
       "   'zero',\n",
       "   'zeroes',\n",
       "   'kc',\n",
       "   'kc',\n",
       "   'kc',\n",
       "   'evidently',\n",
       "   'add',\n",
       "   'lead',\n",
       "   'zero',\n",
       "   'sequence',\n",
       "   'correspond',\n",
       "   'multiply',\n",
       "   'generate_function',\n",
       "   'rule'],\n",
       "  ['right_shift', 'rule'],\n",
       "  ['hf', 'zeroes', 'idea', 'rule', 'zeroes', 'kc', 'kc']],\n",
       " [['differentiation',\n",
       "   'happen',\n",
       "   'take',\n",
       "   'derivative',\n",
       "   'generating_function',\n",
       "   'exam',\n",
       "   'let',\n",
       "   'differentiate',\n",
       "   'familiar',\n",
       "   'generating_function',\n",
       "   'infinite',\n",
       "   'sequence',\n",
       "   'find',\n",
       "   'generate_function',\n",
       "   'sequence',\n",
       "   'positive',\n",
       "   'inte',\n",
       "   'ger',\n",
       "   'general',\n",
       "   'differentiate',\n",
       "   'generating_function',\n",
       "   'effect',\n",
       "   'corre',\n",
       "   'sponde',\n",
       "   'sequence',\n",
       "   'term',\n",
       "   'multiply',\n",
       "   'index',\n",
       "   'entire',\n",
       "   'sequence',\n",
       "   'shift',\n",
       "   'leave',\n",
       "   'place'],\n",
       "  ['hf', 'dx', 'dx', 'derivative', 'rule', 'useful'],\n",
       "  ['fact',\n",
       "   'frequent',\n",
       "   'independent',\n",
       "   'need',\n",
       "   'differentiation',\n",
       "   'effect',\n",
       "   'multiply',\n",
       "   'term',\n",
       "   'index',\n",
       "   'leave',\n",
       "   'shift',\n",
       "   'place'],\n",
       "  ['typically', 'want', 'effect', 'must', 'somehow', 'cancel'],\n",
       "  ['example', 'let_try', 'find', 'generate_function', 'sequence', 'square'],\n",
       "  ['could',\n",
       "   'start',\n",
       "   'sequence',\n",
       "   'multiply',\n",
       "   'term',\n",
       "   'index',\n",
       "   'time',\n",
       "   'desire',\n",
       "   'result',\n",
       "   'chapter_generating_function',\n",
       "   'challenge',\n",
       "   'differentiation',\n",
       "   'multiply',\n",
       "   'term',\n",
       "   'index',\n",
       "   'also',\n",
       "   'shift',\n",
       "   'whole',\n",
       "   'sequence',\n",
       "   'leave',\n",
       "   'place'],\n",
       "  ['however',\n",
       "   'right_shift',\n",
       "   'rule',\n",
       "   'procedure',\n",
       "   'therefore',\n",
       "   'begin',\n",
       "   'generate_function',\n",
       "   'differentiate',\n",
       "   'multiply',\n",
       "   'differentiate',\n",
       "   'multiply'],\n",
       "  ['derivative',\n",
       "   'rule',\n",
       "   'right_shift',\n",
       "   'rule',\n",
       "   'derivative',\n",
       "   'rule',\n",
       "   'right_shift',\n",
       "   'rule']],\n",
       " [['product_rule'],\n",
       "  ['product_rule'],\n",
       "  ['evaluate', 'product'],\n",
       "  ['use',\n",
       "   'table',\n",
       "   'identify',\n",
       "   'cross',\n",
       "   'term',\n",
       "   'product',\n",
       "   'sum',\n",
       "   'notice',\n",
       "   'term',\n",
       "   'involve',\n",
       "   'power',\n",
       "   'lie',\n",
       "   'diagonal'],\n",
       "  ['collect', 'term', 'together', 'find', 'coefficient', 'expression']],\n",
       " [['evaluate', 'sum_product', 'rule', 'look', 'complicated'],\n",
       "  ['surprisingly', 'useful'],\n",
       "  ['example_suppose', 'set'],\n",
       "  ['nth', 'coefficient'],\n",
       "  ['would',\n",
       "   'word',\n",
       "   'give',\n",
       "   'sequence',\n",
       "   'would',\n",
       "   'chapter_generating_function',\n",
       "   'simply',\n",
       "   'multiply',\n",
       "   'sequence',\n",
       "   'generating_function'],\n",
       "  ['summation', 'rule'],\n",
       "  ['rule'],\n",
       "  ['summation', 'rule'],\n",
       "  ['would',\n",
       "   'summation',\n",
       "   'rule',\n",
       "   'sound',\n",
       "   'powerful',\n",
       "   'know',\n",
       "   'chapter',\n",
       "   'computing',\n",
       "   'sum',\n",
       "   'often',\n",
       "   'easy'],\n",
       "  ['multiplying'],\n",
       "  ['easy', 'get'],\n",
       "  ['example_suppose',\n",
       "   'want',\n",
       "   'compute',\n",
       "   'sum',\n",
       "   'first',\n",
       "   'square',\n",
       "   'would',\n",
       "   'forget',\n",
       "   'method',\n",
       "   'chapter'],\n",
       "  ['hence', 'generate_function', 'hs'],\n",
       "  ['mean',\n",
       "   'pretty',\n",
       "   'easy',\n",
       "   'problem',\n",
       "   'idea',\n",
       "   'deter',\n",
       "   'mine',\n",
       "   'coefficient']],\n",
       " [['extract', 'coefficient']],\n",
       " [['taylor', 'series', 'give', 'sequence', 'coefficient'],\n",
       "  ['compute',\n",
       "   'sequence',\n",
       "   'coefficient',\n",
       "   'generate_function',\n",
       "   'need',\n",
       "   'compute',\n",
       "   'taylor',\n",
       "   'series',\n",
       "   'generating_function'],\n",
       "  ['rule'],\n",
       "  ['taylor', 'series'],\n",
       "  ['let'],\n",
       "  ['derivative', 'evaluate'],\n",
       "  ['also', 'dx', 'chapter_generating_function', 'desire'],\n",
       "  ['take',\n",
       "   'second',\n",
       "   'derivative',\n",
       "   'find',\n",
       "   'dx',\n",
       "   'means',\n",
       "   'general',\n",
       "   'nc_nc',\n",
       "   'nck',\n",
       "   'claim'],\n",
       "  ['mean',\n",
       "   'sequence',\n",
       "   'leave_hand',\n",
       "   'side_equation',\n",
       "   'give',\n",
       "   'well',\n",
       "   'know',\n",
       "   'taylor',\n",
       "   'series',\n",
       "   'expansion',\n",
       "   'function']],\n",
       " [['example', 'let_try', 'familiar', 'example'],\n",
       "  ['word',\n",
       "   'reconfirm',\n",
       "   'already_know',\n",
       "   'namely',\n",
       "   'particular',\n",
       "   'nee',\n",
       "   'know',\n",
       "   'coefficient'],\n",
       "  ['theoretically', 'possible', 'compute', 'derivative'],\n",
       "  ['chapter_generating_function']],\n",
       " [['massage',\n",
       "   'help',\n",
       "   'time',\n",
       "   'stress',\n",
       "   'little',\n",
       "   'massage',\n",
       "   'often',\n",
       "   'help',\n",
       "   'relieve',\n",
       "   'tension'],\n",
       "  ['true', 'polynomial', 'painful', 'derivative'],\n",
       "  ['example',\n",
       "   'let',\n",
       "   'take',\n",
       "   'close',\n",
       "   'look',\n",
       "   'equation',\n",
       "   'goal',\n",
       "   'find',\n",
       "   'coefficient'],\n",
       "  ['long',\n",
       "   'enough',\n",
       "   'combine',\n",
       "   'right_shift',\n",
       "   'rule',\n",
       "   'addition',\n",
       "   'rule',\n",
       "   'notice',\n",
       "   'coefficient'],\n",
       "  ['maybe', 'hope'],\n",
       "  ['let_see', 'produce', 'coefficient'],\n",
       "  ['almost', 'do'],\n",
       "  ['equation',\n",
       "   'mean',\n",
       "   'coefficient',\n",
       "   'match',\n",
       "   'equation',\n",
       "   'chapter',\n",
       "   'may',\n",
       "   'argue',\n",
       "   'massage',\n",
       "   'step',\n",
       "   'little',\n",
       "   'tricky'],\n",
       "  ['suppose', 'know', 'converting'],\n",
       "  ['good_news',\n",
       "   'sort',\n",
       "   'massage',\n",
       "   'work',\n",
       "   'generate_function',\n",
       "   'ratio',\n",
       "   'polynomial'],\n",
       "  ['even',\n",
       "   'better',\n",
       "   'probably',\n",
       "   'already_know',\n",
       "   'calculus',\n",
       "   'method',\n",
       "   'partial_fraction']],\n",
       " [['partial_fraction',\n",
       "   'idea',\n",
       "   'partial_fraction',\n",
       "   'express',\n",
       "   'ratio',\n",
       "   'polynomial',\n",
       "   'sum',\n",
       "   'polynomial',\n",
       "   'term',\n",
       "   'form'],\n",
       "  ['lemma'],\n",
       "  ['th', 'derivative'],\n",
       "  ['precise', 'equation_hold', 'equation_hold'],\n",
       "  ['equation', 'equation', 'equation_hold'],\n",
       "  ['chapter_generating_function', 'proof'],\n",
       "  ['proof', 'induction'],\n",
       "  ['corollary'],\n",
       "  ['proof'],\n",
       "  ['taylor',\n",
       "   'series',\n",
       "   'rule',\n",
       "   'coefficient',\n",
       "   'derivative',\n",
       "   'expression',\n",
       "   'evaluate',\n",
       "   'lemma',\n",
       "   'chapter_generating_function',\n",
       "   'equation_hold',\n",
       "   'need',\n",
       "   'massage',\n",
       "   'do',\n",
       "   'compute',\n",
       "   'coefficient'],\n",
       "  ['sum_rule'],\n",
       "  ['result',\n",
       "   'glad',\n",
       "   'know',\n",
       "   'actually',\n",
       "   'method',\n",
       "   'turn',\n",
       "   'useful',\n",
       "   'solve',\n",
       "   'linear_recurrence',\n",
       "   'see',\n",
       "   'next',\n",
       "   'section']],\n",
       " [['solve',\n",
       "   'linear_recurrence',\n",
       "   'generate_function',\n",
       "   'use',\n",
       "   'find',\n",
       "   'solution',\n",
       "   'linear_recurrence'],\n",
       "  ['show',\n",
       "   'do',\n",
       "   'mean',\n",
       "   'familiar',\n",
       "   'example',\n",
       "   'fibonacci',\n",
       "   'recur',\n",
       "   'rence',\n",
       "   'easily',\n",
       "   'understand',\n",
       "   'similarity',\n",
       "   'difference',\n",
       "   'approach',\n",
       "   'method',\n",
       "   'show',\n",
       "   'chapter']],\n",
       " [['find',\n",
       "   'generating_function',\n",
       "   'let',\n",
       "   'begin',\n",
       "   'recall',\n",
       "   'definition',\n",
       "   'fibonacci_number',\n",
       "   'expand',\n",
       "   'final',\n",
       "   'clause',\n",
       "   'infinite',\n",
       "   'sequence',\n",
       "   'equation'],\n",
       "  ['thus', 'fibonacci_number', 'define', 'overall', 'plan', 'define_function'],\n",
       "  ['generate',\n",
       "   'sequence',\n",
       "   'leave_side',\n",
       "   'equality',\n",
       "   'symbol',\n",
       "   'fibonacci_number'],\n",
       "  ['derive', 'function', 'generate', 'sequence', 'right_side'],\n",
       "  ['finally', 'equate', 'solve'],\n",
       "  ['let_try'],\n",
       "  ['first', 'define'],\n",
       "  ['need',\n",
       "   'derive',\n",
       "   'generating_function',\n",
       "   'sequence',\n",
       "   'approach',\n",
       "   'break',\n",
       "   'sum',\n",
       "   'sequence',\n",
       "   'know',\n",
       "   'generating_function',\n",
       "   'apply',\n",
       "   'addition',\n",
       "   'rule',\n",
       "   'sequence',\n",
       "   'almost',\n",
       "   'identical',\n",
       "   'right_side',\n",
       "   'fibonacci',\n",
       "   'equation'],\n",
       "  ['blemish', 'second', 'term', 'chapter_generating_function', 'equate'],\n",
       "  ['new', 'function', 'xf'],\n",
       "  ['implicitly',\n",
       "   'write',\n",
       "   'equation',\n",
       "   'define',\n",
       "   'fibonacci_number',\n",
       "   'fall',\n",
       "   'swoop'],\n",
       "  ['xf'],\n",
       "  ['solve'],\n",
       "  ['give', 'generate_function', 'fibonacci', 'sequence', 'pretty', 'cool'],\n",
       "  ['would',\n",
       "   'think',\n",
       "   'fibonacci_number',\n",
       "   'precisely',\n",
       "   'coefficient',\n",
       "   'simple',\n",
       "   'function',\n",
       "   'even_well',\n",
       "   'function',\n",
       "   'ratio',\n",
       "   'polynomial',\n",
       "   'use',\n",
       "   'method',\n",
       "   'partial_fraction',\n",
       "   'section',\n",
       "   'find_close_form',\n",
       "   'expression',\n",
       "   'nth',\n",
       "   'fibonacci_number']],\n",
       " [['extract',\n",
       "   'coefficient',\n",
       "   'repeat',\n",
       "   'differentiation',\n",
       "   'equation',\n",
       "   'would',\n",
       "   'painful'],\n",
       "  ['easy', 'use', 'method', 'partial_fraction', 'compute', 'coefficient'],\n",
       "  ['degree',\n",
       "   'numerator',\n",
       "   'equation',\n",
       "   'less',\n",
       "   'degree',\n",
       "   'denominator',\n",
       "   'first_step',\n",
       "   'factor',\n",
       "   'denominator',\n",
       "   'root_characteristic_equation',\n",
       "   'fibonacci_recurrence',\n",
       "   'find',\n",
       "   'chapter',\n",
       "   'use',\n",
       "   'corollary',\n",
       "   'sum_rule',\n",
       "   'conclude',\n",
       "   'exactly',\n",
       "   'formula',\n",
       "   'derive',\n",
       "   'nth',\n",
       "   'fibonacci_number',\n",
       "   'chap',\n",
       "   'ter']],\n",
       " [['general',\n",
       "   'linear',\n",
       "   'recurrences',\n",
       "   'method',\n",
       "   'use',\n",
       "   'solve',\n",
       "   'fibonacci_recurrence',\n",
       "   'also',\n",
       "   'use',\n",
       "   'solve',\n",
       "   'general',\n",
       "   'linear_recurrence',\n",
       "   'form',\n",
       "   'nd'],\n",
       "  ['generate_function', 'hf'],\n",
       "  ['solve_recurrence',\n",
       "   'use',\n",
       "   'method',\n",
       "   'partial_fraction',\n",
       "   'describe',\n",
       "   'sec',\n",
       "   'tion',\n",
       "   'find_close_form',\n",
       "   'expression'],\n",
       "  ['easy', 'hard', 'depending'],\n",
       "  ['chapter_generating_function']],\n",
       " [['count',\n",
       "   'generating_function',\n",
       "   'generate_function',\n",
       "   'particularly',\n",
       "   'useful',\n",
       "   'solve',\n",
       "   'counting_problem'],\n",
       "  ['par',\n",
       "   'ticular',\n",
       "   'problem_involve',\n",
       "   'choose_item',\n",
       "   'set',\n",
       "   'often',\n",
       "   'lead',\n",
       "   'nice',\n",
       "   'generating_function',\n",
       "   'let',\n",
       "   'coefficient']],\n",
       " [['choose',\n",
       "   'distinct',\n",
       "   'item_set',\n",
       "   'generate_function',\n",
       "   'binomial',\n",
       "   'coefficient',\n",
       "   'follow',\n",
       "   'directly',\n",
       "   'bino',\n",
       "   'mial',\n",
       "   'theorem'],\n",
       "  ['thus', 'coefficient', 'set', 'size'],\n",
       "  ['example', 'coefficient', 'kc']],\n",
       " [['build',\n",
       "   'generating_function',\n",
       "   'count',\n",
       "   'often',\n",
       "   'translate',\n",
       "   'description',\n",
       "   'counting_problem',\n",
       "   'directly',\n",
       "   'gen',\n",
       "   'erate',\n",
       "   'function',\n",
       "   'solution'],\n",
       "  ['example', 'could', 'figure'],\n",
       "  ['first', 'consider', 'single', 'element_set'],\n",
       "  ['generate_function',\n",
       "   'number',\n",
       "   'way_select',\n",
       "   'element_set',\n",
       "   'simply',\n",
       "   'way_select',\n",
       "   'element',\n",
       "   'way_select',\n",
       "   'element',\n",
       "   'way_select',\n",
       "   'element'],\n",
       "  ['similarly',\n",
       "   'number',\n",
       "   'way_select',\n",
       "   'element_set',\n",
       "   'main',\n",
       "   'trick',\n",
       "   'generating_function',\n",
       "   'choose',\n",
       "   'element',\n",
       "   'union',\n",
       "   'disjoint',\n",
       "   'set',\n",
       "   'product',\n",
       "   'generating_function',\n",
       "   'choose',\n",
       "   'set'],\n",
       "  ['justify', 'moment', 'let', 'first', 'look', 'example'],\n",
       "  ['cord',\n",
       "   'principle',\n",
       "   'generating_function',\n",
       "   'number',\n",
       "   'way_select',\n",
       "   'watch',\n",
       "   'reversal',\n",
       "   'role',\n",
       "   'play',\n",
       "   'early',\n",
       "   'example',\n",
       "   'lead',\n",
       "   'reversal',\n",
       "   'use',\n",
       "   'refer',\n",
       "   'power',\n",
       "   'power',\n",
       "   'series'],\n",
       "  ['element',\n",
       "   'sure_enough',\n",
       "   'set',\n",
       "   'fa',\n",
       "   'way_select',\n",
       "   'element',\n",
       "   'way_select',\n",
       "   'element',\n",
       "   'way_select',\n",
       "   'element',\n",
       "   'way_select',\n",
       "   'element'],\n",
       "  ['repeat',\n",
       "   'application',\n",
       "   'rule',\n",
       "   'give',\n",
       "   'generate_function',\n",
       "   'select_item',\n",
       "   'element_set',\n",
       "   'fa',\n",
       "   'generating_function',\n",
       "   'obtain',\n",
       "   'use',\n",
       "   'binomial',\n",
       "   'theo',\n",
       "   'rem'],\n",
       "  ['time',\n",
       "   'around',\n",
       "   'translate',\n",
       "   'directly',\n",
       "   'count',\n",
       "   'problem',\n",
       "   'generating_function'],\n",
       "  ['extend', 'idea', 'general', 'principle', 'rule'],\n",
       "  ['convolution', 'rule'],\n",
       "  ['let'],\n",
       "  ['generate_function', 'select_item', 'set', 'let'],\n",
       "  ['generate_function', 'select_item', 'set'],\n",
       "  ['disjoint', 'generate_function', 'select_item', 'union', 'product'],\n",
       "  ['rule',\n",
       "   'rather',\n",
       "   'ambiguous',\n",
       "   'exactly',\n",
       "   'rule',\n",
       "   'govern',\n",
       "   'selection',\n",
       "   'item_set',\n",
       "   'remarkably',\n",
       "   'convolution',\n",
       "   'rule',\n",
       "   'remain',\n",
       "   'valid',\n",
       "   'many',\n",
       "   'interpretation',\n",
       "   'selection'],\n",
       "  ['example',\n",
       "   'could',\n",
       "   'insist',\n",
       "   'distinct',\n",
       "   'item',\n",
       "   'select',\n",
       "   'may',\n",
       "   'allow',\n",
       "   'item',\n",
       "   'pick',\n",
       "   'limited',\n",
       "   'number',\n",
       "   'time',\n",
       "   'number',\n",
       "   'time'],\n",
       "  ['informally',\n",
       "   'restriction',\n",
       "   'order',\n",
       "   'item',\n",
       "   'select',\n",
       "   'disregarded',\n",
       "   'restriction',\n",
       "   'selection',\n",
       "   'item_set',\n",
       "   'also',\n",
       "   'apply',\n",
       "   'selecting',\n",
       "   'item'],\n",
       "  ['formally',\n",
       "   'must',\n",
       "   'bijection',\n",
       "   'element',\n",
       "   'selection',\n",
       "   'order_pair',\n",
       "   'selection',\n",
       "   'contain',\n",
       "   'total',\n",
       "   'element'],\n",
       "  ['count',\n",
       "   'number',\n",
       "   'way_select',\n",
       "   'item',\n",
       "   'observe',\n",
       "   'select_item',\n",
       "   'choose_item',\n",
       "   'item',\n",
       "   'number'],\n",
       "  ['do', 'way_select', 'item'],\n",
       "  ['product_rule', 'precisely', 'coefficient', 'chapter_generating_function']],\n",
       " [['choose_item',\n",
       "   'repetition',\n",
       "   'first',\n",
       "   'count',\n",
       "   'problem',\n",
       "   'consider',\n",
       "   'number',\n",
       "   'way_select',\n",
       "   'dozen',\n",
       "   'doughnut',\n",
       "   'flavor',\n",
       "   'available'],\n",
       "  ['generalize',\n",
       "   'question',\n",
       "   'follow',\n",
       "   'many_way',\n",
       "   'select_item',\n",
       "   'element_set',\n",
       "   'allow',\n",
       "   'pick',\n",
       "   'item',\n",
       "   'multiple',\n",
       "   'time',\n",
       "   'term',\n",
       "   'doughnut',\n",
       "   'problem',\n",
       "   'ask',\n",
       "   'many_way',\n",
       "   'select',\n",
       "   'doughnut',\n",
       "   'set',\n",
       "   'flavor',\n",
       "   'fchocolate',\n",
       "   'lemon',\n",
       "   'fill',\n",
       "   'sugar',\n",
       "   'glaze',\n",
       "   'plae',\n",
       "   'course',\n",
       "   'allow',\n",
       "   'pick',\n",
       "   'several',\n",
       "   'doughnuts',\n",
       "   'flavor'],\n",
       "  ['let', 'approach', 'question', 'generating_function', 'perspective'],\n",
       "  ['suppose',\n",
       "   'make',\n",
       "   'choice',\n",
       "   'repetition',\n",
       "   'allow',\n",
       "   'item_set',\n",
       "   'con',\n",
       "   'taine',\n",
       "   'single',\n",
       "   'item'],\n",
       "  ['way', 'choose_item', 'way', 'choose_item', 'way', 'choose_item'],\n",
       "  ['thus',\n",
       "   'generate_function',\n",
       "   'choose',\n",
       "   'element',\n",
       "   'repetition',\n",
       "   'element_set',\n",
       "   'convolution',\n",
       "   'rule',\n",
       "   'say',\n",
       "   'generate_function',\n",
       "   'select_item',\n",
       "   'union',\n",
       "   'disjoint',\n",
       "   'set',\n",
       "   'product',\n",
       "   'generating_function',\n",
       "   'select_item',\n",
       "   'therefore',\n",
       "   'generate_function',\n",
       "   'choose_item',\n",
       "   'element_set',\n",
       "   'repetition',\n",
       "   'allow'],\n",
       "  ['bookkeeper_rule', 'chapter']],\n",
       " [['fruit',\n",
       "   'salad',\n",
       "   'chapter',\n",
       "   'cover',\n",
       "   'lot',\n",
       "   'method',\n",
       "   'rule',\n",
       "   'use',\n",
       "   'generate_function'],\n",
       "  ['example',\n",
       "   'demonstrate',\n",
       "   'rule',\n",
       "   'method',\n",
       "   'combine',\n",
       "   'solve',\n",
       "   'challenge',\n",
       "   'problem',\n",
       "   'make',\n",
       "   'fruit',\n",
       "   'salad'],\n",
       "  ['many_way',\n",
       "   'make',\n",
       "   'salad',\n",
       "   'fruit',\n",
       "   'subject',\n",
       "   'follow',\n",
       "   'constraint',\n",
       "   'number',\n",
       "   'apple',\n",
       "   'must',\n",
       "   'even'],\n",
       "  ['number', 'bananas', 'must', 'multiple'],\n",
       "  ['orange'],\n",
       "  ['pear'],\n",
       "  ['example',\n",
       "   'way_make',\n",
       "   'salad',\n",
       "   'fruit',\n",
       "   'constraint',\n",
       "   'complicated',\n",
       "   'problem',\n",
       "   'seem',\n",
       "   'hopeless',\n",
       "   'gener',\n",
       "   'ate',\n",
       "   'function',\n",
       "   'solve_problem',\n",
       "   'straightforward',\n",
       "   'way'],\n",
       "  ['let', 'first', 'construct', 'generate_function', 'choose', 'apple'],\n",
       "  ['choose',\n",
       "   'set',\n",
       "   'apple',\n",
       "   'way',\n",
       "   'set',\n",
       "   'apple',\n",
       "   'way',\n",
       "   'number',\n",
       "   'apple',\n",
       "   'must',\n",
       "   'even',\n",
       "   'set',\n",
       "   'apple',\n",
       "   'way',\n",
       "   'set',\n",
       "   'apple',\n",
       "   'way',\n",
       "   'forth'],\n",
       "  ['similarly',\n",
       "   'generate_function',\n",
       "   'choose',\n",
       "   'banana',\n",
       "   'choose',\n",
       "   'set',\n",
       "   'orange',\n",
       "   'way',\n",
       "   'set',\n",
       "   'orange',\n",
       "   'way'],\n",
       "  ['however',\n",
       "   'choose',\n",
       "   'orange',\n",
       "   'generate_function',\n",
       "   'use',\n",
       "   'geometric_sum',\n",
       "   'formula'],\n",
       "  ['finally', 'choose', 'pear']],\n",
       " [['infinite_set',\n",
       "   'may',\n",
       "   'wonder',\n",
       "   'much',\n",
       "   'say',\n",
       "   'infinite_set',\n",
       "   'well',\n",
       "   'infinite',\n",
       "   'number',\n",
       "   'element'],\n",
       "  ['course',\n",
       "   'infinite_set',\n",
       "   'infinite',\n",
       "   'number',\n",
       "   'element',\n",
       "   'turn',\n",
       "   'infinite_set',\n",
       "   'size',\n",
       "   'big',\n",
       "   'other',\n",
       "   'understand',\n",
       "   'infinity',\n",
       "   'easy',\n",
       "   'may_think'],\n",
       "  ['tough', 'question', 'mathematic', 'involve', 'infinite_set'],\n",
       "  ['care', 'indeed', 'computer_science', 'finite_set', 'exactly'],\n",
       "  ['example', 'deal', 'set', 'natural_number', 'time', 'infinite_set'],\n",
       "  ['fact', 'induction', 'reason', 'predicate'],\n",
       "  ['infinite_set',\n",
       "   'also',\n",
       "   'important',\n",
       "   'part',\n",
       "   'text',\n",
       "   'talk',\n",
       "   'random_variable',\n",
       "   'potentially',\n",
       "   'infinite',\n",
       "   'sample_space'],\n",
       "  ['sit', 'open', 'mind', 'moment', 'take', 'brief', 'look', 'infinity']],\n",
       " [['injection',\n",
       "   'surjection',\n",
       "   'bijection',\n",
       "   'know',\n",
       "   'theorem',\n",
       "   'injection',\n",
       "   'surjection',\n",
       "   'finite_set',\n",
       "   'say',\n",
       "   'relative',\n",
       "   'size',\n",
       "   'set'],\n",
       "  ['true', 'infinite_set'],\n",
       "  ['fact',\n",
       "   'relation',\n",
       "   'primary',\n",
       "   'tool',\n",
       "   'determine',\n",
       "   'relative',\n",
       "   'size',\n",
       "   'infinite_set'],\n",
       "  ['definition'],\n",
       "  ['give',\n",
       "   'set',\n",
       "   'say',\n",
       "   'surj',\n",
       "   'iff',\n",
       "   'surjection',\n",
       "   'inj',\n",
       "   'iff',\n",
       "   'injection',\n",
       "   'bij',\n",
       "   'iff',\n",
       "   'bijection',\n",
       "   'strict',\n",
       "   'iff',\n",
       "   'surjection',\n",
       "   'bijection'],\n",
       "  ['restate', 'theorem', 'new', 'terminology', 'theorem'],\n",
       "  ['pair',\n",
       "   'finite',\n",
       "   'sets',\n",
       "   'chapter',\n",
       "   'infinite_set',\n",
       "   'theorem',\n",
       "   'suggest',\n",
       "   'way',\n",
       "   'generalize',\n",
       "   'size',\n",
       "   'comparison',\n",
       "   'infinite_set',\n",
       "   'namely',\n",
       "   'think',\n",
       "   'relation',\n",
       "   'surj',\n",
       "   'least',\n",
       "   'big',\n",
       "   'relation',\n",
       "   'set',\n",
       "   'even'],\n",
       "  ['similarly',\n",
       "   'relation',\n",
       "   'bij',\n",
       "   'regard',\n",
       "   'size',\n",
       "   'relation',\n",
       "   'possibly',\n",
       "   'infinite_set',\n",
       "   'strict',\n",
       "   'think',\n",
       "   'strictly_big',\n",
       "   'relation',\n",
       "   'set'],\n",
       "  ['note', 'define', 'size', 'infinite_set'],\n",
       "  ['definition', 'infinite', 'size', 'cumbersome', 'technical', 'get', 'fine'],\n",
       "  ['need', 'big', 'size', 'relation', 'surj', 'bij', 'set'],\n",
       "  ['else', 'watch'],\n",
       "  ['refer', 'surj', 'big', 'relation', 'bij', 'size', 'relation', 'set'],\n",
       "  ['big',\n",
       "   'size',\n",
       "   'property',\n",
       "   'surj',\n",
       "   'bij',\n",
       "   'finite_set',\n",
       "   'carry',\n",
       "   'infinite_set',\n",
       "   'important',\n",
       "   'one',\n",
       "   'show'],\n",
       "  ['careful',\n",
       "   'assume',\n",
       "   'surj',\n",
       "   'particular',\n",
       "   'big',\n",
       "   'property',\n",
       "   'infinite_set',\n",
       "   'prove'],\n",
       "  ['let',\n",
       "   'begin',\n",
       "   'familiar',\n",
       "   'property',\n",
       "   'big',\n",
       "   'size',\n",
       "   'relation',\n",
       "   'finite_set',\n",
       "   'carry',\n",
       "   'exactly',\n",
       "   'infinite_set',\n",
       "   'theorem'],\n",
       "  ['sets',\n",
       "   'surj',\n",
       "   'surj',\n",
       "   'imply',\n",
       "   'bij',\n",
       "   'bij',\n",
       "   'imply',\n",
       "   'bij',\n",
       "   'imply',\n",
       "   'part',\n",
       "   'theorem',\n",
       "   'follow',\n",
       "   'immediately',\n",
       "   'fact',\n",
       "   'composi',\n",
       "   'tion',\n",
       "   'surjection',\n",
       "   'surjection',\n",
       "   'likewise',\n",
       "   'bijection'],\n",
       "  ['part', 'follow', 'fact', 'inverse', 'bijection', 'bijection'],\n",
       "  ['leave', 'proof', 'fact', 'problem'],\n",
       "  ['familiar',\n",
       "   'property',\n",
       "   'finite_set',\n",
       "   'carry',\n",
       "   'infinite_set',\n",
       "   'time',\n",
       "   'obvious',\n",
       "   'theorem'],\n",
       "  ['schroder', 'bernstein'],\n",
       "  ['pair', 'sets', 'surj', 'surj', 'bij'],\n",
       "  ['schroder',\n",
       "   'bernstein',\n",
       "   'theorem',\n",
       "   'say',\n",
       "   'least',\n",
       "   'big',\n",
       "   'con',\n",
       "   'versely',\n",
       "   'least',\n",
       "   'big',\n",
       "   'size'],\n",
       "  ['phrase',\n",
       "   'way',\n",
       "   'may',\n",
       "   'tempt',\n",
       "   'take',\n",
       "   'theorem',\n",
       "   'grant',\n",
       "   'would',\n",
       "   'mis',\n",
       "   'take'],\n",
       "  ['infinite_set',\n",
       "   'schroder',\n",
       "   'bernstein',\n",
       "   'theorem',\n",
       "   'actually',\n",
       "   'pretty',\n",
       "   'technical'],\n",
       "  ['surjective',\n",
       "   'function',\n",
       "   'need',\n",
       "   'bijection',\n",
       "   'surjective',\n",
       "   'function',\n",
       "   'also',\n",
       "   'need',\n",
       "   'bijection',\n",
       "   'clear',\n",
       "   'must',\n",
       "   'bijection'],\n",
       "  ['challenge', 'construct', 'part'],\n",
       "  ['leave', 'actual', 'construction', 'problem']],\n",
       " [['infinity',\n",
       "   'different',\n",
       "   'basic',\n",
       "   'property',\n",
       "   'finite_set',\n",
       "   'carry',\n",
       "   'infinite_set',\n",
       "   'add',\n",
       "   'new',\n",
       "   'make',\n",
       "   'set',\n",
       "   'big'],\n",
       "  ['finite_set', 'ja', 'fb', 'gj', 'jaj', 'fbg', 'size'],\n",
       "  ['infinite_set', 'size', 'theorem'],\n",
       "  ['let', 'set'],\n",
       "  ['infinite', 'iff', 'bij', 'fbg'],\n",
       "  ['proof'],\n",
       "  ['size', 'fbg', 'finite', 'show', 'fbg', 'size', 'infinite'],\n",
       "  ['find', 'bijection', 'fbg', 'infinite'],\n",
       "  ['infinite', 'certainly', 'least', 'element', 'call']],\n",
       " [['countable_set']],\n",
       " [['definition',\n",
       "   'set',\n",
       "   'countable',\n",
       "   'iff',\n",
       "   'element',\n",
       "   'list',\n",
       "   'order',\n",
       "   'distinct',\n",
       "   'element',\n",
       "   'precisely',\n",
       "   'mean',\n",
       "   'define_function',\n",
       "   'nonnegative_integer',\n",
       "   'rule'],\n",
       "  ['wwd', 'definition'],\n",
       "  ['set', 'countably_infinite', 'iff', 'bij'],\n",
       "  ['set', 'countable', 'iff', 'finite', 'countably_infinite'],\n",
       "  ['chapter',\n",
       "   'infinite_set',\n",
       "   'discrete',\n",
       "   'mathematic',\n",
       "   'often',\n",
       "   'define',\n",
       "   'mathematic',\n",
       "   'countable_set',\n",
       "   'probably',\n",
       "   'worth',\n",
       "   'spend',\n",
       "   'little',\n",
       "   'time',\n",
       "   'understanding',\n",
       "   'mean',\n",
       "   'countable',\n",
       "   'countable_set',\n",
       "   'special'],\n",
       "  ['example',\n",
       "   'small',\n",
       "   'modification',\n",
       "   'proof_theorem',\n",
       "   'show',\n",
       "   'countably_infinite',\n",
       "   'set',\n",
       "   'small',\n",
       "   'infinite_set',\n",
       "   'namely',\n",
       "   'infinite_set',\n",
       "   'surj']],\n",
       " [['union',\n",
       "   'add',\n",
       "   'new',\n",
       "   'element',\n",
       "   'infinite_set',\n",
       "   'change',\n",
       "   'size',\n",
       "   'obvi',\n",
       "   'ous',\n",
       "   'add',\n",
       "   'finite',\n",
       "   'number',\n",
       "   'element'],\n",
       "  ['common',\n",
       "   'mis',\n",
       "   'take',\n",
       "   'think',\n",
       "   'prove',\n",
       "   'throw',\n",
       "   'countably',\n",
       "   'infinitely_many',\n",
       "   'new',\n",
       "   'element',\n",
       "   'finite',\n",
       "   'number',\n",
       "   'time',\n",
       "   'make',\n",
       "   'ok',\n",
       "   'infinite',\n",
       "   'number',\n",
       "   'time'],\n",
       "  ['example_suppose',\n",
       "   'countably_infinite',\n",
       "   'set',\n",
       "   'valid',\n",
       "   'argument',\n",
       "   'equation',\n",
       "   'list'],\n",
       "  ['key',\n",
       "   'property',\n",
       "   'require',\n",
       "   'listing',\n",
       "   'element',\n",
       "   'countable_set',\n",
       "   'element_set',\n",
       "   'determine',\n",
       "   'finite',\n",
       "   'index',\n",
       "   'list'],\n",
       "  ['example', 'valid', 'list', 'purpose', 'show', 'countable', 'infinite'],\n",
       "  ['equation', 'useful', 'finite'],\n",
       "  ['turn',\n",
       "   'really',\n",
       "   'add',\n",
       "   'countably_infinite',\n",
       "   'number',\n",
       "   'new',\n",
       "   'element',\n",
       "   'countable_set',\n",
       "   'still',\n",
       "   'wind',\n",
       "   'countably_infinite',\n",
       "   'set',\n",
       "   'argument',\n",
       "   'need',\n",
       "   'prove'],\n",
       "  ['theorem'],\n",
       "  ['countable_set'],\n",
       "  ['proof'],\n",
       "  ['suppose',\n",
       "   'list',\n",
       "   'distinct',\n",
       "   'element',\n",
       "   'course',\n",
       "   'list',\n",
       "   'contain',\n",
       "   'duplicate',\n",
       "   'element',\n",
       "   'common',\n",
       "   'delete',\n",
       "   'first',\n",
       "   'occurrence',\n",
       "   'element',\n",
       "   'equation',\n",
       "   'leave',\n",
       "   'list',\n",
       "   'distinct',\n",
       "   'element'],\n",
       "  ['note',\n",
       "   'list',\n",
       "   'equation',\n",
       "   'defect',\n",
       "   'purport',\n",
       "   'list',\n",
       "   'equation',\n",
       "   'figure'],\n",
       "  ['list_element', 'fb']],\n",
       " [['cross',\n",
       "   'product',\n",
       "   'somewhat',\n",
       "   'surprisingly',\n",
       "   'cross',\n",
       "   'product',\n",
       "   'countable_set',\n",
       "   'also',\n",
       "   'countable'],\n",
       "  ['first',\n",
       "   'may',\n",
       "   'tempted',\n",
       "   'think',\n",
       "   'infinity',\n",
       "   'time',\n",
       "   'infinity',\n",
       "   'mean',\n",
       "   'somehow',\n",
       "   'result',\n",
       "   'large',\n",
       "   'infinity',\n",
       "   'case'],\n",
       "  ['theorem'],\n",
       "  ['cross', 'product', 'countable_set', 'countable'],\n",
       "  ['proof'],\n",
       "  ['let', 'pair', 'countable_set'],\n",
       "  ['show', 'also', 'countable', 'need', 'find', 'list_element'],\n",
       "  ['many', 'listing'],\n",
       "  ['show_figure', 'case', 'infinite_set'],\n",
       "  ['list'],\n",
       "  ['max'],\n",
       "  ['task', 'find', 'list', 'finite', 'leave', 'problem', 'end', 'chapter']],\n",
       " [['countable',\n",
       "   'theorem',\n",
       "   'also',\n",
       "   'surprise',\n",
       "   'corollary',\n",
       "   'namely',\n",
       "   'set',\n",
       "   'rational_number',\n",
       "   'countable'],\n",
       "  ['corollary'],\n",
       "  ['set', 'rational_number', 'countable'],\n",
       "  ['chapter', 'infinite_set', 'proof'],\n",
       "  ['countable', 'theorem'],\n",
       "  ['surjection'],\n",
       "  ['point', 'may_think', 'set', 'countable'],\n",
       "  ['case'],\n",
       "  ['fact',\n",
       "   'shortly',\n",
       "   'see',\n",
       "   'many',\n",
       "   'infinite_set',\n",
       "   'uncountable',\n",
       "   'include',\n",
       "   'set',\n",
       "   'real_number']],\n",
       " [['power',\n",
       "   'set',\n",
       "   'strictly_big',\n",
       "   'turn',\n",
       "   'idea',\n",
       "   'russell_paradox',\n",
       "   'cause',\n",
       "   'much',\n",
       "   'trouble',\n",
       "   'early',\n",
       "   'effort',\n",
       "   'formulate',\n",
       "   'set',\n",
       "   'theory',\n",
       "   'also',\n",
       "   'lead',\n",
       "   'correct',\n",
       "   'astonishing',\n",
       "   'fact',\n",
       "   'discover',\n",
       "   'georg',\n",
       "   'cantor',\n",
       "   'late',\n",
       "   'nineteenth',\n",
       "   'century',\n",
       "   'infinite_set',\n",
       "   'size'],\n",
       "  ['theorem'],\n",
       "  ['set', 'power', 'set'],\n",
       "  ['strictly_big'],\n",
       "  ['proof'],\n",
       "  ['first'],\n",
       "  ['big', 'example', 'partial', 'function'],\n",
       "  ['fag', 'wwd', 'surjection'],\n",
       "  ['show'],\n",
       "  ['strictly_big', 'show', 'function'],\n",
       "  ['surjection'],\n",
       "  ['mimicking', 'russell_paradox', 'define'],\n",
       "  ['iff', 'iff'],\n",
       "  ['let', 'iff', 'surjection', 'element', 'power', 'set', 'namely', 'set']],\n",
       " [['uncountable',\n",
       "   'prove',\n",
       "   'set',\n",
       "   'real_number',\n",
       "   'uncountable',\n",
       "   'show',\n",
       "   'surjection'],\n",
       "  ['apply', 'theorem'],\n",
       "  ['lemma'],\n",
       "  ['surj'],\n",
       "  ['proof'],\n",
       "  ['let', 'subset', 'natural_number'],\n",
       "  ['countable', 'mean', 'countable', 'thus', 'define', 'surjection'],\n",
       "  ['follow'],\n",
       "  ['otherwise', 'hence', 'surj'],\n",
       "  ['corollary'],\n",
       "  ['uncountable'],\n",
       "  ['proof'],\n",
       "  ['contradiction'],\n",
       "  ['assume', 'countable'],\n",
       "  ['surj'],\n",
       "  ['lemma', 'case'],\n",
       "  ['set',\n",
       "   'rational_number',\n",
       "   'set',\n",
       "   'natural_number',\n",
       "   'size',\n",
       "   'set',\n",
       "   'real_number',\n",
       "   'strictly',\n",
       "   'large'],\n",
       "  ['fact', 'bij'],\n",
       "  ['prove'],\n",
       "  ['big']],\n",
       " [['even', 'large', 'infinitie', 'lot', 'different', 'size', 'infinite_set'],\n",
       "  ['example',\n",
       "   'start',\n",
       "   'infinite_set',\n",
       "   'nonnegative_integer',\n",
       "   'build',\n",
       "   'infinite',\n",
       "   'sequence',\n",
       "   'set'],\n",
       "  ['theorem', 'chapter', 'infinite_set']],\n",
       " [['continuum_hypothesis',\n",
       "   'georg',\n",
       "   'cantor',\n",
       "   'mathematician',\n",
       "   'first',\n",
       "   'develop',\n",
       "   'theory',\n",
       "   'infinite',\n",
       "   'size',\n",
       "   'think',\n",
       "   'need',\n",
       "   'study',\n",
       "   'fourier',\n",
       "   'series'],\n",
       "  ['cantor',\n",
       "   'raise',\n",
       "   'question',\n",
       "   'set',\n",
       "   'size',\n",
       "   'strictly',\n",
       "   'small',\n",
       "   'infinite_set'],\n",
       "  ['guess', 'cantor', 'continuum_hypothesis'],\n",
       "  ['set'],\n",
       "  ['strictly_big', 'strictly_big'],\n",
       "  ['continuum_hypothesis', 'remain', 'open', 'problem', 'century', 'later'],\n",
       "  ['diffi',\n",
       "   'culty',\n",
       "   'arise',\n",
       "   'deep',\n",
       "   'result',\n",
       "   'modern',\n",
       "   'set',\n",
       "   'theory',\n",
       "   'discover',\n",
       "   'part',\n",
       "   'godel',\n",
       "   'paul',\n",
       "   'cohen',\n",
       "   'namely',\n",
       "   'zfc',\n",
       "   'axiom',\n",
       "   'sufficient',\n",
       "   'settle',\n",
       "   'continuum_hypothesis',\n",
       "   'collection',\n",
       "   'set',\n",
       "   'obey',\n",
       "   'law',\n",
       "   'zfc',\n",
       "   'collection',\n",
       "   'continuum',\n",
       "   'hy',\n",
       "   'pothesis',\n",
       "   'true_false'],\n",
       "  ['settle',\n",
       "   'continuum_hypothesis',\n",
       "   'require',\n",
       "   'new',\n",
       "   'understanding',\n",
       "   'set',\n",
       "   'arrive',\n",
       "   'persuasive',\n",
       "   'new',\n",
       "   'axiom',\n",
       "   'extend',\n",
       "   'zfc',\n",
       "   'strong',\n",
       "   'enough',\n",
       "   'determine',\n",
       "   'truth',\n",
       "   'con',\n",
       "   'tinuum',\n",
       "   'hypothesis',\n",
       "   'way']],\n",
       " [['infinity',\n",
       "   'computer_science',\n",
       "   'romance',\n",
       "   'different',\n",
       "   'size',\n",
       "   'infinitie',\n",
       "   'continuum_hypothesis',\n",
       "   'appeal',\n",
       "   'know',\n",
       "   'go',\n",
       "   'low',\n",
       "   'professional',\n",
       "   'ability',\n",
       "   'computer',\n",
       "   'scientist'],\n",
       "  ['abstract',\n",
       "   'issue',\n",
       "   'infinite_set',\n",
       "   'rarely',\n",
       "   'come',\n",
       "   'mainstream',\n",
       "   'mathematic',\n",
       "   'come',\n",
       "   'computer_science',\n",
       "   'focus',\n",
       "   'generally',\n",
       "   'countable',\n",
       "   'often',\n",
       "   'finite_set'],\n",
       "  ['practice',\n",
       "   'logicians',\n",
       "   'set',\n",
       "   'theorist',\n",
       "   'worry',\n",
       "   'collection',\n",
       "   'big',\n",
       "   'set'],\n",
       "  ['fact',\n",
       "   'end',\n",
       "   'century',\n",
       "   'even',\n",
       "   'general',\n",
       "   'mathematical',\n",
       "   'community',\n",
       "   'doubt',\n",
       "   'relevance',\n",
       "   'call',\n",
       "   'cantor',\n",
       "   'paradise',\n",
       "   'unfamiliar',\n",
       "   'set',\n",
       "   'arbitrary',\n",
       "   'infinite',\n",
       "   'size'],\n",
       "  ['say',\n",
       "   'worth',\n",
       "   'note',\n",
       "   'proof_theorem',\n",
       "   'give',\n",
       "   'simple',\n",
       "   'form',\n",
       "   'know',\n",
       "   'diagonal',\n",
       "   'argument'],\n",
       "  ['diagonal',\n",
       "   'argument',\n",
       "   'use',\n",
       "   'prove',\n",
       "   'many',\n",
       "   'fundamental',\n",
       "   'result',\n",
       "   'limitation',\n",
       "   'computation',\n",
       "   'undecidability',\n",
       "   'halt_problem',\n",
       "   'program',\n",
       "   'inherent',\n",
       "   'unavoid',\n",
       "   'able',\n",
       "   'inefficiency',\n",
       "   'exponential',\n",
       "   'time',\n",
       "   'bad',\n",
       "   'procedure',\n",
       "   'computational',\n",
       "   'problem'],\n",
       "  ['computer',\n",
       "   'scientist',\n",
       "   'need',\n",
       "   'study',\n",
       "   'diagonal',\n",
       "   'argument',\n",
       "   'order',\n",
       "   'understand',\n",
       "   'logical',\n",
       "   'limit',\n",
       "   'computation'],\n",
       "  ['ad',\n",
       "   'well',\n",
       "   'educate',\n",
       "   'computer',\n",
       "   'scien',\n",
       "   'tist',\n",
       "   'comfortable',\n",
       "   'deal',\n",
       "   'countable_set',\n",
       "   'finite',\n",
       "   'well',\n",
       "   'infinite'],\n",
       "  ['probability',\n",
       "   'introduction',\n",
       "   'probability',\n",
       "   'important',\n",
       "   'discipline',\n",
       "   'science'],\n",
       "  ['also', 'least', 'well', 'understand'],\n",
       "  ['probability',\n",
       "   'especially',\n",
       "   'important',\n",
       "   'computer_science',\n",
       "   'arise',\n",
       "   'virtually',\n",
       "   'branch',\n",
       "   'field'],\n",
       "  ['algorithm',\n",
       "   'design',\n",
       "   'game',\n",
       "   'theory',\n",
       "   'example',\n",
       "   'run',\n",
       "   'domize',\n",
       "   'algorithm',\n",
       "   'strategy',\n",
       "   'use',\n",
       "   'random',\n",
       "   'number',\n",
       "   'generator',\n",
       "   'key',\n",
       "   'input',\n",
       "   'decision',\n",
       "   'make',\n",
       "   'frequently',\n",
       "   'outperform',\n",
       "   'deterministic',\n",
       "   'algorithm',\n",
       "   'strategy'],\n",
       "  ['information',\n",
       "   'theory',\n",
       "   'signal',\n",
       "   'processing',\n",
       "   'understanding',\n",
       "   'run',\n",
       "   'domness',\n",
       "   'critical',\n",
       "   'filter',\n",
       "   'noise',\n",
       "   'compressing',\n",
       "   'datum'],\n",
       "  ['cryptography',\n",
       "   'digital',\n",
       "   'rights',\n",
       "   'management',\n",
       "   'probability',\n",
       "   'crucial',\n",
       "   'achieve',\n",
       "   'security'],\n",
       "  ['list', 'example', 'long'],\n",
       "  ['give',\n",
       "   'impact',\n",
       "   'probability',\n",
       "   'computer_science',\n",
       "   'seem',\n",
       "   'strange',\n",
       "   'probability',\n",
       "   'misunderstood',\n",
       "   'many'],\n",
       "  ['perhaps',\n",
       "   'trouble',\n",
       "   'basic',\n",
       "   'human',\n",
       "   'intuition',\n",
       "   'wrong',\n",
       "   'often',\n",
       "   'come',\n",
       "   'problem_involve',\n",
       "   'random',\n",
       "   'event'],\n",
       "  ['consequence', 'many', 'student', 'develop', 'fear', 'prob', 'ability'],\n",
       "  ['indeed',\n",
       "   'witness',\n",
       "   'many',\n",
       "   'graduate',\n",
       "   'oral',\n",
       "   'exam',\n",
       "   'student',\n",
       "   'solve',\n",
       "   'horrendous',\n",
       "   'calculation',\n",
       "   'trip',\n",
       "   'simple',\n",
       "   'probability',\n",
       "   'question'],\n",
       "  ['indeed',\n",
       "   'even',\n",
       "   'faculty',\n",
       "   'start',\n",
       "   'squirm',\n",
       "   'ask',\n",
       "   'question',\n",
       "   'start',\n",
       "   'probability'],\n",
       "  ['goal',\n",
       "   'remain',\n",
       "   'chapter',\n",
       "   'equip',\n",
       "   'tool',\n",
       "   'enable',\n",
       "   'easily',\n",
       "   'confidently',\n",
       "   'solve_problem',\n",
       "   'involve',\n",
       "   'probability'],\n",
       "  ['begin',\n",
       "   'chapter',\n",
       "   'basic',\n",
       "   'definition',\n",
       "   'elementary',\n",
       "   'step',\n",
       "   'cess',\n",
       "   'use',\n",
       "   'determine',\n",
       "   'probability',\n",
       "   'specify',\n",
       "   'event_occur'],\n",
       "  ['illustrate',\n",
       "   'method',\n",
       "   'famous',\n",
       "   'problem',\n",
       "   'intuition',\n",
       "   'probably',\n",
       "   'fail'],\n",
       "  ['chapter',\n",
       "   'part',\n",
       "   'probability',\n",
       "   'consider',\n",
       "   'probability',\n",
       "   'disease',\n",
       "   'give',\n",
       "   'test_positive',\n",
       "   'probability',\n",
       "   'suspect',\n",
       "   'guilty',\n",
       "   'give',\n",
       "   'blood',\n",
       "   'type',\n",
       "   'match',\n",
       "   'blood',\n",
       "   'find',\n",
       "   'scene',\n",
       "   'crime'],\n",
       "  ['study',\n",
       "   'random_variable',\n",
       "   'distributions',\n",
       "   'chapter',\n",
       "   'chapter',\n",
       "   'conclude',\n",
       "   'chapter',\n",
       "   'combining',\n",
       "   'tool',\n",
       "   'acquire',\n",
       "   'solve_problem',\n",
       "   'involve',\n",
       "   'complex',\n",
       "   'random',\n",
       "   'process'],\n",
       "  ['see',\n",
       "   'probably',\n",
       "   'never',\n",
       "   'far',\n",
       "   'ahead',\n",
       "   'casino',\n",
       "   'stanford',\n",
       "   'graduate',\n",
       "   'student',\n",
       "   'become',\n",
       "   'gazillionaire',\n",
       "   'combine',\n",
       "   'graph_theory',\n",
       "   'probability',\n",
       "   'theory',\n",
       "   'design',\n",
       "   'well',\n",
       "   'search',\n",
       "   'engine',\n",
       "   'web']],\n",
       " [['event_probability', 'space']],\n",
       " [['let',\n",
       "   'make',\n",
       "   'deal',\n",
       "   'september',\n",
       "   'issue',\n",
       "   'parade',\n",
       "   'magazine',\n",
       "   'columnist',\n",
       "   'marilyn',\n",
       "   'vos',\n",
       "   'savant',\n",
       "   'respond',\n",
       "   'letter',\n",
       "   'suppose',\n",
       "   'game',\n",
       "   'show',\n",
       "   'give',\n",
       "   'choice',\n",
       "   'door'],\n",
       "  ['door', 'car', 'other', 'goat'],\n",
       "  ['pick_door',\n",
       "   'say',\n",
       "   'number',\n",
       "   'host',\n",
       "   'know',\n",
       "   'door',\n",
       "   'open_door',\n",
       "   'say',\n",
       "   'number',\n",
       "   'goat'],\n",
       "  ['say',\n",
       "   'want',\n",
       "   'pick_door',\n",
       "   'number',\n",
       "   'advantage',\n",
       "   'switch',\n",
       "   'choice',\n",
       "   'door',\n",
       "   'craig'],\n",
       "  ['whitaker',\n",
       "   'columbia',\n",
       "   'md',\n",
       "   'letter',\n",
       "   'describe',\n",
       "   'situation',\n",
       "   'faced',\n",
       "   'contestant',\n",
       "   'game',\n",
       "   'show',\n",
       "   'let',\n",
       "   'make',\n",
       "   'deal',\n",
       "   'host',\n",
       "   'monty_hall',\n",
       "   'carol',\n",
       "   'merrill'],\n",
       "  ['marilyn', 'reply', 'contestant', 'indeed', 'switch'],\n",
       "  ['explain',\n",
       "   'car',\n",
       "   'unpicked',\n",
       "   'door',\n",
       "   'twice',\n",
       "   'likely',\n",
       "   'car',\n",
       "   'pick_door',\n",
       "   'contestant',\n",
       "   'win',\n",
       "   'switching'],\n",
       "  ['soon',\n",
       "   'receive',\n",
       "   'torrent',\n",
       "   'letter',\n",
       "   'many',\n",
       "   'mathematician',\n",
       "   'tell',\n",
       "   'wrong'],\n",
       "  ['problem',\n",
       "   'become',\n",
       "   'know',\n",
       "   'monty_hall_problem',\n",
       "   'generate',\n",
       "   'thousand',\n",
       "   'hour',\n",
       "   'heated',\n",
       "   'debate'],\n",
       "  ['incident',\n",
       "   'highlight',\n",
       "   'fact',\n",
       "   'probability',\n",
       "   'subject',\n",
       "   'uncover',\n",
       "   'lot',\n",
       "   'example',\n",
       "   'ordinary',\n",
       "   'intuition',\n",
       "   'lead',\n",
       "   'completely',\n",
       "   'wrong',\n",
       "   'conclusion'],\n",
       "  ['study',\n",
       "   'probability',\n",
       "   'enough',\n",
       "   'refined',\n",
       "   'intuition',\n",
       "   'way',\n",
       "   'avoid',\n",
       "   'error',\n",
       "   'fall',\n",
       "   'back',\n",
       "   'rigorous',\n",
       "   'systematic',\n",
       "   'approach',\n",
       "   'step_method',\n",
       "   'describe',\n",
       "   'shortly'],\n",
       "  ['first', 'let', 'make', 'sure', 'really', 'understand', 'setup', 'problem'],\n",
       "  ['always', 'good', 'thing', 'deal', 'probability']],\n",
       " [['clarify',\n",
       "   'problem',\n",
       "   'craig',\n",
       "   'original',\n",
       "   'letter',\n",
       "   'marilyn',\n",
       "   'vos',\n",
       "   'savant',\n",
       "   'bit',\n",
       "   'vague',\n",
       "   'must',\n",
       "   'make',\n",
       "   'assumption',\n",
       "   'order',\n",
       "   'hope',\n",
       "   'modeling',\n",
       "   'game',\n",
       "   'formally'],\n",
       "  ['exam_ple',\n",
       "   'assume',\n",
       "   'chapter_event',\n",
       "   'probability_space',\n",
       "   'car',\n",
       "   'equally_likely',\n",
       "   'hide',\n",
       "   'door'],\n",
       "  ['player', 'equally_likely', 'pick_door', 'regardless', 'car_location'],\n",
       "  ['player',\n",
       "   'pick_door',\n",
       "   'host',\n",
       "   'must',\n",
       "   'open',\n",
       "   'different',\n",
       "   'door',\n",
       "   'goat',\n",
       "   'offer',\n",
       "   'player',\n",
       "   'choice',\n",
       "   'stay',\n",
       "   'original',\n",
       "   'door',\n",
       "   'switching'],\n",
       "  ['host', 'choice', 'door', 'open', 'equally_likely', 'select'],\n",
       "  ['make', 'assumption', 'read', 'lot', 'craig', 'whitaker', 'letter'],\n",
       "  ['interpretation',\n",
       "   'least',\n",
       "   'defensible',\n",
       "   'actually',\n",
       "   'lead',\n",
       "   'different',\n",
       "   'swer'],\n",
       "  ['let',\n",
       "   'accept',\n",
       "   'assumption',\n",
       "   'address',\n",
       "   'question',\n",
       "   'probability',\n",
       "   'player',\n",
       "   'switch',\n",
       "   'win',\n",
       "   'car']],\n",
       " [['step_method',\n",
       "   'probability',\n",
       "   'problem_involve',\n",
       "   'sort',\n",
       "   'randomized',\n",
       "   'experiment',\n",
       "   'process',\n",
       "   'game'],\n",
       "  ['problem_involve',\n",
       "   'distinct',\n",
       "   'challenge',\n",
       "   'model',\n",
       "   'situation',\n",
       "   'mathematically',\n",
       "   'solve',\n",
       "   'result',\n",
       "   'mathematical',\n",
       "   'problem_section',\n",
       "   'introduce',\n",
       "   'step',\n",
       "   'approach',\n",
       "   'question',\n",
       "   'form',\n",
       "   'probability'],\n",
       "  ['approach',\n",
       "   'build',\n",
       "   'probabilistic',\n",
       "   'model',\n",
       "   'step_step',\n",
       "   'formalize',\n",
       "   'original',\n",
       "   'question',\n",
       "   'term',\n",
       "   'model'],\n",
       "  ['remarkably',\n",
       "   'structure',\n",
       "   'thinking',\n",
       "   'approach',\n",
       "   'impose',\n",
       "   'provide',\n",
       "   'simple',\n",
       "   'solution',\n",
       "   'many',\n",
       "   'famously',\n",
       "   'confusing',\n",
       "   'problem'],\n",
       "  ['example',\n",
       "   'see',\n",
       "   'step_method',\n",
       "   'cut',\n",
       "   'confusion',\n",
       "   'surround',\n",
       "   'monty_hall_problem',\n",
       "   'ginsu',\n",
       "   'knife']],\n",
       " [['step',\n",
       "   'find_sample_space',\n",
       "   'first',\n",
       "   'objective',\n",
       "   'identify',\n",
       "   'possible',\n",
       "   'outcome',\n",
       "   'experiment'],\n",
       "  ['typical',\n",
       "   'experiment',\n",
       "   'involve',\n",
       "   'several',\n",
       "   'randomly',\n",
       "   'determined',\n",
       "   'quantity'],\n",
       "  ['example',\n",
       "   'monty_hall',\n",
       "   'game',\n",
       "   'involve',\n",
       "   'quantity',\n",
       "   'door',\n",
       "   'conceal',\n",
       "   'car'],\n",
       "  ['door', 'initially', 'choose', 'player'],\n",
       "  ['car_location', 'figure'],\n",
       "  ['first', 'level', 'tree_diagram', 'monty_hall_problem'],\n",
       "  ['branch', 'correspond', 'door', 'car', 'locate'],\n",
       "  ['door', 'host', 'open', 'reveal', 'goat'],\n",
       "  ['possible',\n",
       "   'combination',\n",
       "   'randomly',\n",
       "   'determined',\n",
       "   'quantity',\n",
       "   'call',\n",
       "   'outcome'],\n",
       "  ['set', 'possible', 'outcome', 'call', 'sample_space', 'iment'],\n",
       "  ['tree_diagram',\n",
       "   'graphical',\n",
       "   'tool',\n",
       "   'help',\n",
       "   'work',\n",
       "   'step',\n",
       "   'approach',\n",
       "   'number',\n",
       "   'outcome',\n",
       "   'large',\n",
       "   'problem',\n",
       "   'nicely',\n",
       "   'structure'],\n",
       "  ['particular',\n",
       "   'use',\n",
       "   'tree_diagram',\n",
       "   'help',\n",
       "   'understand',\n",
       "   'sample_space',\n",
       "   'experiment'],\n",
       "  ['first',\n",
       "   'randomly',\n",
       "   'determine',\n",
       "   'quantity',\n",
       "   'experiment',\n",
       "   'door',\n",
       "   'concealing',\n",
       "   'prize'],\n",
       "  ['represent',\n",
       "   'tree',\n",
       "   'branch',\n",
       "   'show_figure',\n",
       "   'possible',\n",
       "   'location',\n",
       "   'prize',\n",
       "   'player',\n",
       "   'could',\n",
       "   'initially',\n",
       "   'choose',\n",
       "   'door'],\n",
       "  ['represent', 'second', 'layer', 'add', 'tree'],\n",
       "  ['third',\n",
       "   'layer',\n",
       "   'represent',\n",
       "   'possibility',\n",
       "   'final',\n",
       "   'step',\n",
       "   'host',\n",
       "   'open_door',\n",
       "   'reveal',\n",
       "   'goat',\n",
       "   'show_figure',\n",
       "   'notice',\n",
       "   'third',\n",
       "   'layer',\n",
       "   'reflect',\n",
       "   'fact',\n",
       "   'host',\n",
       "   'choice',\n",
       "   'depend',\n",
       "   'position',\n",
       "   'car',\n",
       "   'door',\n",
       "   'initially',\n",
       "   'select',\n",
       "   'player'],\n",
       "  ['example',\n",
       "   'prize',\n",
       "   'door',\n",
       "   'player',\n",
       "   'pick_door',\n",
       "   'chapter_event',\n",
       "   'probability_space',\n",
       "   'car_location',\n",
       "   'player',\n",
       "   'intial',\n",
       "   'guess',\n",
       "   'door_reveal',\n",
       "   'figure'],\n",
       "  ['full', 'tree_diagram', 'monty_hall_problem'],\n",
       "  ['second', 'level', 'indicate', 'door', 'initially', 'choose', 'player'],\n",
       "  ['third', 'level', 'indicate', 'door_reveal', 'monty_hall'],\n",
       "  ['host', 'must', 'open_door'],\n",
       "  ['however',\n",
       "   'prize',\n",
       "   'door',\n",
       "   'player',\n",
       "   'pick_door',\n",
       "   'host',\n",
       "   'could',\n",
       "   'open_door',\n",
       "   'door'],\n",
       "  ['let',\n",
       "   'relate',\n",
       "   'picture',\n",
       "   'term',\n",
       "   'introduce',\n",
       "   'early',\n",
       "   'leave',\n",
       "   'tree',\n",
       "   'represent',\n",
       "   'outcome',\n",
       "   'experiment',\n",
       "   'set',\n",
       "   'leave',\n",
       "   'represent',\n",
       "   'sample_space'],\n",
       "  ['thus', 'experiment', 'sample_space', 'consist', 'outcome'],\n",
       "  ['reference',\n",
       "   'label',\n",
       "   'outcome',\n",
       "   'figure',\n",
       "   'triple',\n",
       "   'door',\n",
       "   'indicate',\n",
       "   'tree_diagram',\n",
       "   'broad',\n",
       "   'interpretation',\n",
       "   'regard',\n",
       "   'whole',\n",
       "   'experiment',\n",
       "   'follow',\n",
       "   'path',\n",
       "   'root_leaf',\n",
       "   'branch',\n",
       "   'take',\n",
       "   'stage',\n",
       "   'randomly',\n",
       "   'determine'],\n",
       "  ['keep', 'interpretation', 'mind', 'use', 'later']],\n",
       " [['step_define',\n",
       "   'event_interest',\n",
       "   'objective',\n",
       "   'answer_question',\n",
       "   'form',\n",
       "   'probability'],\n",
       "  ['example',\n",
       "   'miss',\n",
       "   'phrase',\n",
       "   'may',\n",
       "   'player_win',\n",
       "   'switch',\n",
       "   'player',\n",
       "   'initially',\n",
       "   'pick_door',\n",
       "   'concealing',\n",
       "   'prize',\n",
       "   'prize',\n",
       "   'door'],\n",
       "  ['phrase', 'characterize', 'set', 'outcome'],\n",
       "  ['example', 'outcome', 'specify', 'prize', 'door'],\n",
       "  ['set', 'outcomes', 'call', 'event', 'subset', 'sample_space'],\n",
       "  ['event', 'player', 'initially', 'pick_door', 'concealing', 'prize', 'set'],\n",
       "  ['really', 'event', 'player_win', 'switching', 'set', 'outcome'],\n",
       "  ['outcome',\n",
       "   'denote',\n",
       "   'check',\n",
       "   'mark',\n",
       "   'figure',\n",
       "   'notice',\n",
       "   'exactly',\n",
       "   'half',\n",
       "   'outcome',\n",
       "   'check',\n",
       "   'meaning',\n",
       "   'player_win',\n",
       "   'switch',\n",
       "   'half',\n",
       "   'outcome'],\n",
       "  ['may', 'tempted', 'conclude', 'player', 'switch', 'win_probability'],\n",
       "  ['wrong'],\n",
       "  ['reason', 'outcome', 'equally_likely', 'see', 'shortly'],\n",
       "  ['chapter_event',\n",
       "   'probability_space',\n",
       "   'car_location',\n",
       "   'player',\n",
       "   'intial',\n",
       "   'guess',\n",
       "   'door_reveal',\n",
       "   'outcome',\n",
       "   'figure'],\n",
       "  ['tree_diagram',\n",
       "   'monty',\n",
       "   'hal',\n",
       "   'problem',\n",
       "   'outcomes',\n",
       "   'la',\n",
       "   'bele',\n",
       "   'path',\n",
       "   'root_leaf'],\n",
       "  ['example', 'outcome'],\n",
       "  ['corresponds',\n",
       "   'car',\n",
       "   'door',\n",
       "   'player',\n",
       "   'initially',\n",
       "   'choose',\n",
       "   'door',\n",
       "   'monty_hall',\n",
       "   'revealing',\n",
       "   'goat',\n",
       "   'door'],\n",
       "  ['car_location',\n",
       "   'player',\n",
       "   'intial',\n",
       "   'guess',\n",
       "   'door_reveal',\n",
       "   'outcome',\n",
       "   'switch',\n",
       "   'win',\n",
       "   'figure'],\n",
       "  ['tree_diagram',\n",
       "   'monty_hall_problem',\n",
       "   'outcomes',\n",
       "   'event',\n",
       "   'player_win',\n",
       "   'switch',\n",
       "   'denote',\n",
       "   'check',\n",
       "   'mark'],\n",
       "  ['chapter_event', 'probability_space']],\n",
       " [['step',\n",
       "   'determine',\n",
       "   'outcome_probability',\n",
       "   'far',\n",
       "   'enumerate',\n",
       "   'possible',\n",
       "   'outcome',\n",
       "   'experiment'],\n",
       "  ['must', 'start', 'assess', 'likelihood', 'outcome'],\n",
       "  ['particular',\n",
       "   'goal',\n",
       "   'step',\n",
       "   'assign',\n",
       "   'outcome_probability',\n",
       "   'indicate',\n",
       "   'fraction',\n",
       "   'time',\n",
       "   'outcome',\n",
       "   'expect',\n",
       "   'occur'],\n",
       "  ['sum',\n",
       "   'outcome_probability',\n",
       "   'must',\n",
       "   'reflect',\n",
       "   'fact',\n",
       "   'always',\n",
       "   'outcome'],\n",
       "  ['ultimately',\n",
       "   'outcome_probability',\n",
       "   'determine',\n",
       "   'phenomenon',\n",
       "   'mod',\n",
       "   'ele',\n",
       "   'thus',\n",
       "   'quantity',\n",
       "   'derive',\n",
       "   'mathematically'],\n",
       "  ['however',\n",
       "   'math',\n",
       "   'ematic',\n",
       "   'help',\n",
       "   'compute_probability',\n",
       "   'outcome',\n",
       "   'base',\n",
       "   'few',\n",
       "   'elementary',\n",
       "   'modeling',\n",
       "   'decision'],\n",
       "  ['particular',\n",
       "   'break',\n",
       "   'task',\n",
       "   'deter',\n",
       "   'mining',\n",
       "   'outcome',\n",
       "   'probabilitie',\n",
       "   'stage'],\n",
       "  ['step',\n",
       "   'assign',\n",
       "   'edge',\n",
       "   'probabilitie',\n",
       "   'first',\n",
       "   'record',\n",
       "   'probability',\n",
       "   'edge',\n",
       "   'tree_diagram'],\n",
       "  ['edge',\n",
       "   'probability',\n",
       "   'determined',\n",
       "   'assumption',\n",
       "   'make',\n",
       "   'outset',\n",
       "   'prize',\n",
       "   'equally_likely',\n",
       "   'door',\n",
       "   'player',\n",
       "   'equally_likely',\n",
       "   'pick_door',\n",
       "   'host',\n",
       "   'equally_likely',\n",
       "   'reveal',\n",
       "   'goat',\n",
       "   'choice'],\n",
       "  ['notice',\n",
       "   'host',\n",
       "   'choice',\n",
       "   'regard',\n",
       "   'door',\n",
       "   'open',\n",
       "   'single',\n",
       "   'branch',\n",
       "   'assign',\n",
       "   'probability'],\n",
       "  ['example',\n",
       "   'see_figure',\n",
       "   'step_compute',\n",
       "   'outcome_probability',\n",
       "   'next',\n",
       "   'job',\n",
       "   'convert',\n",
       "   'edge',\n",
       "   'probabilitie',\n",
       "   'outcome_probability'],\n",
       "  ['purely',\n",
       "   'mechanical',\n",
       "   'process',\n",
       "   'probability_outcome',\n",
       "   'equal',\n",
       "   'product',\n",
       "   'edge',\n",
       "   'probability',\n",
       "   'path',\n",
       "   'root',\n",
       "   'outcome'],\n",
       "  ['example',\n",
       "   'probability',\n",
       "   'topmost',\n",
       "   'outcome',\n",
       "   'figure',\n",
       "   'easy',\n",
       "   'intuitive',\n",
       "   'justification',\n",
       "   'rule'],\n",
       "  ['steps',\n",
       "   'experiment',\n",
       "   'progress',\n",
       "   'randomly',\n",
       "   'path',\n",
       "   'root',\n",
       "   'tree',\n",
       "   'leaf',\n",
       "   'probability',\n",
       "   'edge',\n",
       "   'indicate',\n",
       "   'likely',\n",
       "   'path',\n",
       "   'proceed',\n",
       "   'branch'],\n",
       "  ['example',\n",
       "   'path',\n",
       "   'start',\n",
       "   'root',\n",
       "   'example',\n",
       "   'equally_likely',\n",
       "   'go',\n",
       "   'top',\n",
       "   'level',\n",
       "   'branch'],\n",
       "  ['likely', 'path', 'arrive', 'topmost', 'outcome'],\n",
       "  ['chance',\n",
       "   'path',\n",
       "   'would',\n",
       "   'follow',\n",
       "   'branch',\n",
       "   'top',\n",
       "   'level',\n",
       "   'chance',\n",
       "   'would',\n",
       "   'continue',\n",
       "   'branch',\n",
       "   'second',\n",
       "   'level',\n",
       "   'chance',\n",
       "   'would',\n",
       "   'follow',\n",
       "   'branch',\n",
       "   'third',\n",
       "   'level'],\n",
       "  ['thus', 'seem', 'path', 'arrive'],\n",
       "  ['leaf', 'precisely', 'probability', 'assign'],\n",
       "  ['car_location',\n",
       "   'player',\n",
       "   'intial',\n",
       "   'guess',\n",
       "   'door_reveal',\n",
       "   'outcome',\n",
       "   'switch',\n",
       "   'win',\n",
       "   'figure'],\n",
       "  ['tree_diagram',\n",
       "   'monty_hall_problem',\n",
       "   'edge',\n",
       "   'weights',\n",
       "   'denote',\n",
       "   'probability',\n",
       "   'branch',\n",
       "   'take',\n",
       "   'give',\n",
       "   'parent',\n",
       "   'branch'],\n",
       "  ['example',\n",
       "   'car',\n",
       "   'door',\n",
       "   'chance',\n",
       "   'player',\n",
       "   'initial',\n",
       "   'selection',\n",
       "   'door'],\n",
       "  ['chapter_event',\n",
       "   'probability_space',\n",
       "   'illustrate',\n",
       "   'outcome_probability',\n",
       "   'figure',\n",
       "   'specify',\n",
       "   'probability_outcome',\n",
       "   'amount',\n",
       "   'define_function',\n",
       "   'map',\n",
       "   'outcome_probability'],\n",
       "  ['function', 'usually', 'call'],\n",
       "  ['term', 'determined', 'pr']],\n",
       " [['step_compute',\n",
       "   'event',\n",
       "   'probabilitie',\n",
       "   'probability_outcome',\n",
       "   'want',\n",
       "   'determine',\n",
       "   'proba',\n",
       "   'bility',\n",
       "   'event'],\n",
       "  ['probability_event',\n",
       "   'switching',\n",
       "   'win',\n",
       "   'pr',\n",
       "   'seem',\n",
       "   'marilyn',\n",
       "   'answer',\n",
       "   'correct',\n",
       "   'player',\n",
       "   'switch',\n",
       "   'door',\n",
       "   'win',\n",
       "   'car',\n",
       "   'probability',\n",
       "   'do',\n",
       "   'problem',\n",
       "   'need',\n",
       "   'appeal',\n",
       "   'intuition',\n",
       "   'nious',\n",
       "   'analogy'],\n",
       "  ['fact',\n",
       "   'mathematic',\n",
       "   'difficult',\n",
       "   'add',\n",
       "   'multiplying',\n",
       "   'fraction',\n",
       "   'require'],\n",
       "  ['hard',\n",
       "   'part',\n",
       "   'resist',\n",
       "   'temptation',\n",
       "   'leap',\n",
       "   'intuitively',\n",
       "   'obvious',\n",
       "   'answer']],\n",
       " [['alternative',\n",
       "   'interpretation',\n",
       "   'monty_hall_problem',\n",
       "   'marilyn',\n",
       "   'really',\n",
       "   'right',\n",
       "   'analysis',\n",
       "   'indicate'],\n",
       "  ['accurate',\n",
       "   'conclusion',\n",
       "   'answer',\n",
       "   'correct',\n",
       "   'provide',\n",
       "   'accept',\n",
       "   'interpretation',\n",
       "   'car_location',\n",
       "   'player',\n",
       "   'intial',\n",
       "   'guess',\n",
       "   'door_reveal',\n",
       "   'figure'],\n",
       "  ['rightmost', 'column', 'show', 'outcome_probability', 'monty_hall_problem'],\n",
       "  ['outcome_probability',\n",
       "   'simply',\n",
       "   'product',\n",
       "   'prob',\n",
       "   'ability',\n",
       "   'branch',\n",
       "   'path',\n",
       "   'root_leaf',\n",
       "   'outcome'],\n",
       "  ['chapter_event', 'probability_space', 'figure'],\n",
       "  ['strange_dice'],\n",
       "  ['number', 'pip', 'conceal', 'face', 'number', 'opposite', 'face'],\n",
       "  ['example', 'roll_die', 'probability_get'],\n",
       "  ['question'],\n",
       "  ['equally', 'plausible', 'interpretation', 'marilyn', 'answer', 'wrong'],\n",
       "  ['notice',\n",
       "   'craig',\n",
       "   'whitaker',\n",
       "   'original',\n",
       "   'letter',\n",
       "   'say',\n",
       "   'host',\n",
       "   'require',\n",
       "   'reveal',\n",
       "   'goat',\n",
       "   'offer',\n",
       "   'player',\n",
       "   'option',\n",
       "   'switch',\n",
       "   'merely',\n",
       "   'thing'],\n",
       "  ['fact',\n",
       "   'let',\n",
       "   'make',\n",
       "   'deal',\n",
       "   'show',\n",
       "   'monty_hall',\n",
       "   'sometimes',\n",
       "   'simply',\n",
       "   'open_door',\n",
       "   'contestant',\n",
       "   'pick',\n",
       "   'initially'],\n",
       "  ['therefore',\n",
       "   'want',\n",
       "   'monty',\n",
       "   'could',\n",
       "   'give',\n",
       "   'option',\n",
       "   'switching',\n",
       "   'contestant',\n",
       "   'pick',\n",
       "   'correct',\n",
       "   'door',\n",
       "   'initially'],\n",
       "  ['case', 'switch', 'never', 'work']],\n",
       " [['strange_dice', 'step_method', 'surprisingly', 'powerful'],\n",
       "  ['let', 'practice'],\n",
       "  ['imagine', 'follow', 'scenario'],\n",
       "  ['typical', 'saturday', 'night'],\n",
       "  ['favorite',\n",
       "   'pub',\n",
       "   'contemplate',\n",
       "   'true',\n",
       "   'meaning',\n",
       "   'infinite',\n",
       "   'cardinality',\n",
       "   'burly',\n",
       "   'look',\n",
       "   'biker',\n",
       "   'plop',\n",
       "   'stool',\n",
       "   'next'],\n",
       "  ['mind', 'around'],\n",
       "  ['biker_dude', 'slap', 'strange', 'looking', 'dice', 'bar', 'challenge'],\n",
       "  ['rule', 'simple'],\n",
       "  ['player', 'select', 'die', 'roll'],\n",
       "  ['player', 'low', 'value', 'pay', 'player'],\n",
       "  ['naturally', 'skeptical'],\n",
       "  ['quick', 'inspection', 'reveal', 'ordi', 'dice'],\n",
       "  ['side',\n",
       "   'number',\n",
       "   'dice',\n",
       "   'different',\n",
       "   'show_figure',\n",
       "   'biker_dude',\n",
       "   'notice',\n",
       "   'hesitation',\n",
       "   'offer',\n",
       "   'let',\n",
       "   'pick',\n",
       "   'die',\n",
       "   'first',\n",
       "   'choose',\n",
       "   'die',\n",
       "   'left'],\n",
       "  ['seal', 'deal', 'figure', 'advantage'],\n",
       "  ['dice', 'choose', 'die', 'appeal', 'sure', 'winner', 'come'],\n",
       "  ['die', 'fairly', 'large_number', 'die', 'really', 'small', 'value'],\n",
       "  ['end', 'choose', 'die', 'biker_dude', 'select', 'die'],\n",
       "  ['let_see', 'probability', 'win'],\n",
       "  ['surprisingly', 'use', 'step_method', 'compute_probability']],\n",
       " [['die', 'die', 'step', 'find_sample_space'],\n",
       "  ['sample_space',\n",
       "   'experiment',\n",
       "   'work',\n",
       "   'tree_diagram',\n",
       "   'show_figure',\n",
       "   'experiment',\n",
       "   'sample_space',\n",
       "   'set',\n",
       "   'outcome'],\n",
       "  ['step_define', 'event_interest'],\n",
       "  ['interested', 'event', 'number', 'die', 'great', 'number', 'die'],\n",
       "  ['event', 'set', 'outcome'],\n",
       "  ['outcomes',\n",
       "   'mark',\n",
       "   'tree_diagram',\n",
       "   'figure',\n",
       "   'step',\n",
       "   'determine',\n",
       "   'outcome_probability'],\n",
       "  ['find',\n",
       "   'outcome_probability',\n",
       "   'first',\n",
       "   'assign',\n",
       "   'probability',\n",
       "   'edge',\n",
       "   'tree',\n",
       "   'di',\n",
       "   'agram'],\n",
       "  ['number', 'die', 'come', 'probability', 'regardless', 'value', 'die'],\n",
       "  ['therefore', 'assign', 'edge', 'probability'],\n",
       "  ['probability_outcome',\n",
       "   'product',\n",
       "   'probability',\n",
       "   'correspond',\n",
       "   'ing',\n",
       "   'root_leaf',\n",
       "   'path',\n",
       "   'mean',\n",
       "   'outcome_probability'],\n",
       "  ['probability',\n",
       "   'record',\n",
       "   'right_side',\n",
       "   'tree_diagram',\n",
       "   'figure',\n",
       "   'step_compute',\n",
       "   'event_probability'],\n",
       "  ['probability_event', 'sum', 'probability_outcome', 'event'],\n",
       "  ['case', 'outcome_probability'],\n",
       "  ['general', 'probability_outcome', 'say', 'sample_space', 'uniform'],\n",
       "  ['compute_event',\n",
       "   'probability',\n",
       "   'uniform',\n",
       "   'sample_space',\n",
       "   'particularly',\n",
       "   'easy',\n",
       "   'course',\n",
       "   'probably',\n",
       "   'do',\n",
       "   'pick',\n",
       "   'die',\n",
       "   'first',\n",
       "   'place'],\n",
       "  ['actually', 'whole', 'probability_space', 'work', 'picture'],\n",
       "  ['pretend',\n",
       "   'component',\n",
       "   'sort',\n",
       "   'fade',\n",
       "   'nyyrrroom',\n",
       "   'read',\n",
       "   'correspond',\n",
       "   'step'],\n",
       "  ['chapter_event', 'probability_space', 'figure'],\n",
       "  ['tree_diagram', 'roll_die', 'die'],\n",
       "  ['die', 'win_probability'],\n",
       "  ['compute', 'number', 'outcome', 'event'],\n",
       "  ['particular', 'event', 'case', 'bad_news'],\n",
       "  ['die',\n",
       "   'biker_dude',\n",
       "   'console',\n",
       "   'bad',\n",
       "   'luck',\n",
       "   'give',\n",
       "   'sensitive',\n",
       "   'guy',\n",
       "   'leather',\n",
       "   'offer',\n",
       "   'go',\n",
       "   'double'],\n",
       "  ['give', 'wallet', 'sound', 'good', 'plan'],\n",
       "  ['figure', 'choose', 'die', 'choose']],\n",
       " [['die', 'die', 'construct', 'diagram', 'outcome_probability'],\n",
       "  ['result', 'show_figure', 'bad_news'],\n",
       "  ['die', 'owe', 'biker_dude', 'ask', 'money'],\n",
       "  ['reply', 'need', 'go', 'bathroom'],\n",
       "  ['sensitive',\n",
       "   'guy',\n",
       "   'biker_dude',\n",
       "   'nod',\n",
       "   'understandingly',\n",
       "   'offer',\n",
       "   'yet',\n",
       "   'wager'],\n",
       "  ['time', 'let', 'die', 'good', 'deal', 'pass'],\n",
       "  ['know', 'die', 'pick', 'double', 'slang', 'wager', 'lose', 'first'],\n",
       "  ['lose', 'owe', 'biker_dude', 'double', 'owe'],\n",
       "  ['win', 'even', 'owe'],\n",
       "  ['chapter_event', 'probability_space', 'figure'],\n",
       "  ['tree_diagram', 'roll_die', 'die'],\n",
       "  ['die', 'win_probability'],\n",
       "  ['figure'],\n",
       "  ['tree_diagram', 'roll_die', 'die'],\n",
       "  ['die', 'win_probability']],\n",
       " [['die',\n",
       "   'die',\n",
       "   'tree_diagram',\n",
       "   'outcome_probability',\n",
       "   'show',\n",
       "   'fig_ure',\n",
       "   'show',\n",
       "   'die',\n",
       "   'win_probability'],\n",
       "  ['possible',\n",
       "   'beat',\n",
       "   'probability',\n",
       "   'beat',\n",
       "   'probability',\n",
       "   'beat',\n",
       "   'probability',\n",
       "   'problem',\n",
       "   'math',\n",
       "   'intuition'],\n",
       "  ['seem', 'likely', 'beat', 'relation', 'transitive'],\n",
       "  ['die', 'pick', 'biker_dude', 'pick', 'other', 'likely', 'win'],\n",
       "  ['pick', 'first', 'big', 'disadvantage', 'owe', 'biker_dude'],\n",
       "  ['think', 'matter', 'get', 'bad', 'biker_dude', 'offer', 'final', 'wager'],\n",
       "  ['time', 'demand', 'choose', 'second'],\n",
       "  ['biker_dude', 'agree', 'figure'],\n",
       "  ['part', 'tree_diagram', 'die', 'die', 'die', 'roll', 'twice'],\n",
       "  ['first', 'level', 'show'],\n",
       "  ['last', 'level', 'consist', 'copy', 'tree'],\n",
       "  ['condition',\n",
       "   'instead',\n",
       "   'roll_die',\n",
       "   'roll_die',\n",
       "   'twice',\n",
       "   'score',\n",
       "   'sum',\n",
       "   'roll'],\n",
       "  ['believe', 'finally', 'win', 'wager', 'agree'],\n",
       "  ['biker_dude', 'choose', 'die', 'course', 'grab', 'die'],\n",
       "  ['know',\n",
       "   'die',\n",
       "   'beat',\n",
       "   'die',\n",
       "   'probability',\n",
       "   'roll',\n",
       "   'surely',\n",
       "   'roll_die',\n",
       "   'likely',\n",
       "   'beat',\n",
       "   'roll_die',\n",
       "   'right',\n",
       "   'wrong']],\n",
       " [['roll',\n",
       "   'twice',\n",
       "   'player',\n",
       "   'roll',\n",
       "   'twice',\n",
       "   'tree_diagram',\n",
       "   'level',\n",
       "   'probability_outcome'],\n",
       "  ['compute',\n",
       "   'number',\n",
       "   'outcome',\n",
       "   'beat',\n",
       "   'observe',\n",
       "   'sum',\n",
       "   'mention',\n",
       "   'play',\n",
       "   'strange',\n",
       "   'gambling_game',\n",
       "   'stranger',\n",
       "   'bar',\n",
       "   'bad',\n",
       "   'idea',\n",
       "   'roll_die',\n",
       "   'equally_likely',\n",
       "   'element',\n",
       "   'follow',\n",
       "   'multiset',\n",
       "   'sum',\n",
       "   'roll_die',\n",
       "   'equally_likely',\n",
       "   'element',\n",
       "   'follow',\n",
       "   'multiset',\n",
       "   'treat',\n",
       "   'outcome',\n",
       "   'pair'],\n",
       "  ['similar', 'count', 'show', 'pair', 'pair'],\n",
       "  ['result', 'tie'],\n",
       "  ['means', 'lose', 'probability', 'tie', 'probability'],\n",
       "  ['die', 'win_probability'],\n",
       "  ['likely',\n",
       "   'win',\n",
       "   'roll',\n",
       "   'likely',\n",
       "   'win',\n",
       "   'roll',\n",
       "   'reason',\n",
       "   'think',\n",
       "   'otherwise',\n",
       "   'faulty',\n",
       "   'intuition'],\n",
       "  ['fact', 'die', 'strength', 'reverse', 'matter', 'die', 'pick'],\n",
       "  ['roll',\n",
       "   'roll',\n",
       "   'use',\n",
       "   'symbol',\n",
       "   'denote',\n",
       "   'die',\n",
       "   'likely',\n",
       "   'result',\n",
       "   'large',\n",
       "   'value'],\n",
       "  ['surprise', 'even', 'least', 'owe', 'biker_dude']],\n",
       " [['even',\n",
       "   'strange_dice',\n",
       "   'know',\n",
       "   'strange',\n",
       "   'thing',\n",
       "   'happen',\n",
       "   'strange_dice',\n",
       "   'natural',\n",
       "   'least',\n",
       "   'mathematician',\n",
       "   'ask',\n",
       "   'strange',\n",
       "   'thing',\n",
       "   'get'],\n",
       "  ['turn', 'thing', 'get', 'strange'],\n",
       "  ['fact',\n",
       "   'mathematician',\n",
       "   'recently',\n",
       "   'make',\n",
       "   'follow',\n",
       "   'discovery',\n",
       "   'theorem'],\n",
       "  ['set', 'dice', 'number', 'roll', 'reference', 'ron', 'graham', 'paper'],\n",
       "  ['recall',\n",
       "   'tournament_graph',\n",
       "   'direct_graph',\n",
       "   'precisely',\n",
       "   'direct_edge',\n",
       "   'distinct',\n",
       "   'node'],\n",
       "  ['word', 'pair', 'distinct', 'node', 'beat', 'beat'],\n",
       "  ['figure'],\n",
       "  ['possible',\n",
       "   'relative',\n",
       "   'strength',\n",
       "   'dice',\n",
       "   'die',\n",
       "   'roll',\n",
       "   'time',\n",
       "   'sum',\n",
       "   'roll',\n",
       "   'probably',\n",
       "   'take',\n",
       "   'attempt',\n",
       "   'read',\n",
       "   'theorem',\n",
       "   'understand',\n",
       "   'say'],\n",
       "  ['idea',\n",
       "   'set',\n",
       "   'dice',\n",
       "   'roll',\n",
       "   'different',\n",
       "   'number',\n",
       "   'time',\n",
       "   'dice',\n",
       "   'vary',\n",
       "   'strength',\n",
       "   'relative'],\n",
       "  ['observe',\n",
       "   'dice',\n",
       "   'figure',\n",
       "   'say',\n",
       "   'set',\n",
       "   'strange_dice',\n",
       "   'possible',\n",
       "   'collection',\n",
       "   'relative',\n",
       "   'strength',\n",
       "   'observe',\n",
       "   'varying',\n",
       "   'number',\n",
       "   'roll'],\n",
       "  ['example',\n",
       "   'possible',\n",
       "   'relative',\n",
       "   'strength',\n",
       "   'dice',\n",
       "   'show_figure',\n",
       "   'analysis',\n",
       "   'dice',\n",
       "   'figure_show',\n",
       "   'roll',\n",
       "   'relative',\n",
       "   'strength',\n",
       "   'show_figure',\n",
       "   'use',\n",
       "   'roll',\n",
       "   'may',\n",
       "   'worth',\n",
       "   'prone',\n",
       "   'gambling',\n",
       "   'stranger',\n",
       "   'bar']],\n",
       " [['set',\n",
       "   'theory',\n",
       "   'probability',\n",
       "   'study',\n",
       "   'probability',\n",
       "   'closely',\n",
       "   'tie',\n",
       "   'set',\n",
       "   'theory'],\n",
       "  ['set', 'sample_space', 'subset', 'event'],\n",
       "  ['mean',\n",
       "   'rule',\n",
       "   'identity',\n",
       "   'develop',\n",
       "   'set',\n",
       "   'extend',\n",
       "   'naturally',\n",
       "   'probability'],\n",
       "  ['cover',\n",
       "   'several',\n",
       "   'example',\n",
       "   'section',\n",
       "   'first',\n",
       "   'let',\n",
       "   'review',\n",
       "   'definition',\n",
       "   'already',\n",
       "   'familiar']],\n",
       " [['probability_space', 'definition'],\n",
       "  ['countable', 'sample_space', 'nonempty', 'countable_set'],\n",
       "  ['element', 'definition'],\n",
       "  ['probability',\n",
       "   'function',\n",
       "   'sample_space',\n",
       "   'total',\n",
       "   'function',\n",
       "   'sample_space',\n",
       "   'together',\n",
       "   'probability',\n",
       "   'function',\n",
       "   'call',\n",
       "   'probability_space'],\n",
       "  ['event']],\n",
       " [['probability',\n",
       "   'rule',\n",
       "   'set',\n",
       "   'theory',\n",
       "   'immediate',\n",
       "   'consequence',\n",
       "   'definition',\n",
       "   'event_probability',\n",
       "   'disjoint',\n",
       "   'event',\n",
       "   'generalize',\n",
       "   'countable',\n",
       "   'number',\n",
       "   'event',\n",
       "   'follow'],\n",
       "  ['rule'],\n",
       "  ['sum_rule'],\n",
       "  ['sample_space', 'infinite'],\n",
       "  ['see', 'example', 'shortly'],\n",
       "  ['read',\n",
       "   'chap',\n",
       "   'ter',\n",
       "   'chapter_event',\n",
       "   'probability_space',\n",
       "   'sum_rule',\n",
       "   'let',\n",
       "   'analyze',\n",
       "   'complicated',\n",
       "   'event',\n",
       "   'break',\n",
       "   'simple',\n",
       "   'case'],\n",
       "  ['example',\n",
       "   'probability',\n",
       "   'randomly',\n",
       "   'choose',\n",
       "   'mit_student',\n",
       "   'native',\n",
       "   'united',\n",
       "   'states',\n",
       "   'canada',\n",
       "   'mexico',\n",
       "   'probability',\n",
       "   'random',\n",
       "   'mit_student',\n",
       "   'native',\n",
       "   'north',\n",
       "   'america'],\n",
       "  ['consequence', 'sum_rule', 'pr', 'rule'],\n",
       "  ['complement', 'rule'],\n",
       "  ['sometimes',\n",
       "   'easy',\n",
       "   'way',\n",
       "   'compute_probability',\n",
       "   'event',\n",
       "   'compute_probability',\n",
       "   'complement',\n",
       "   'apply',\n",
       "   'formula'],\n",
       "  ['basic',\n",
       "   'fact',\n",
       "   'probability',\n",
       "   'parallel',\n",
       "   'fact',\n",
       "   'cardinality',\n",
       "   'finite_set'],\n",
       "  ['particular',\n",
       "   'difference',\n",
       "   'rule',\n",
       "   'follow',\n",
       "   'sum_rule',\n",
       "   'probability',\n",
       "   'nonnegative'],\n",
       "  ['monotonicity',\n",
       "   'follow',\n",
       "   'definition',\n",
       "   'event_probability',\n",
       "   'fact',\n",
       "   'outcome_probability',\n",
       "   'nonnegative'],\n",
       "  ['event',\n",
       "   'inclusion_exclusion',\n",
       "   'equation',\n",
       "   'generalize',\n",
       "   'pr_pr',\n",
       "   'pr',\n",
       "   'simple',\n",
       "   'union',\n",
       "   'bind',\n",
       "   'useful',\n",
       "   'many',\n",
       "   'calculation'],\n",
       "  ['example_suppose',\n",
       "   'would',\n",
       "   'small',\n",
       "   'union',\n",
       "   'bind',\n",
       "   'give',\n",
       "   'adequate',\n",
       "   'upper_bind',\n",
       "   'vital',\n",
       "   'probability']],\n",
       " [['uniform', 'probability_space', 'definition'],\n",
       "  ['finite',\n",
       "   'probability_space',\n",
       "   'pr',\n",
       "   'say',\n",
       "   'uniform',\n",
       "   'pr',\n",
       "   'see',\n",
       "   'strange_dice',\n",
       "   'problem',\n",
       "   'uniform',\n",
       "   'sample_space',\n",
       "   'particularly',\n",
       "   'easy',\n",
       "   'work'],\n",
       "  ['event',\n",
       "   'mean',\n",
       "   'know',\n",
       "   'cardinality',\n",
       "   'example_suppose',\n",
       "   'select',\n",
       "   'card',\n",
       "   'random',\n",
       "   'standard',\n",
       "   'deck_card'],\n",
       "  ['probability',\n",
       "   'full_house',\n",
       "   'normally',\n",
       "   'question',\n",
       "   'would',\n",
       "   'take',\n",
       "   'effort',\n",
       "   'answer'],\n",
       "  ['analysis', 'section', 'find']],\n",
       " [['infinite',\n",
       "   'probability_space',\n",
       "   'general',\n",
       "   'probability',\n",
       "   'theory',\n",
       "   'deal',\n",
       "   'uncountable',\n",
       "   'set',\n",
       "   'computer',\n",
       "   'sci',\n",
       "   'ence',\n",
       "   'usually',\n",
       "   'sufficient',\n",
       "   'restrict',\n",
       "   'attention',\n",
       "   'countable',\n",
       "   'probability_space'],\n",
       "  ['chapter_event', 'probability_space', 'figure'],\n",
       "  ['tree_diagram', 'game', 'player', 'take', 'turn', 'flip_fair_coin'],\n",
       "  ['first', 'player', 'flip', 'head', 'win'],\n",
       "  ['also',\n",
       "   'lot',\n",
       "   'easy',\n",
       "   'infinite',\n",
       "   'sample_space',\n",
       "   'hard',\n",
       "   'enough',\n",
       "   'work',\n",
       "   'deal',\n",
       "   'uncountable',\n",
       "   'space'],\n",
       "  ['infinite', 'probability_space', 'fairly', 'common'],\n",
       "  ['example', 'player', 'take', 'turn', 'flip_fair_coin'],\n",
       "  ['flip', 'head', 'first', 'declare', 'winner'],\n",
       "  ['probability',\n",
       "   'first',\n",
       "   'player_win',\n",
       "   'tree_diagram',\n",
       "   'problem',\n",
       "   'show_figure',\n",
       "   'event',\n",
       "   'first',\n",
       "   'player_win',\n",
       "   'contain',\n",
       "   'infinite',\n",
       "   'number',\n",
       "   'outcome',\n",
       "   'still',\n",
       "   'sum',\n",
       "   'probability',\n",
       "   'similarly',\n",
       "   'compute_probability',\n",
       "   'second',\n",
       "   'player_win',\n",
       "   'case',\n",
       "   'sample_space',\n",
       "   'infinite_set',\n",
       "   'wwd',\n",
       "   'pr',\n",
       "   'wwd',\n",
       "   'verify',\n",
       "   'probability_space',\n",
       "   'check',\n",
       "   'probabili',\n",
       "   'tie',\n",
       "   'nonnegative',\n",
       "   'sum'],\n",
       "  ['nonnegativity',\n",
       "   'obvious',\n",
       "   'apply',\n",
       "   'formula',\n",
       "   'sum',\n",
       "   'geometric_series',\n",
       "   'find',\n",
       "   'notice',\n",
       "   'model',\n",
       "   'outcome',\n",
       "   'correspond',\n",
       "   'possibility',\n",
       "   'player',\n",
       "   'keep',\n",
       "   'flip',\n",
       "   'tail',\n",
       "   'forever'],\n",
       "  ['probability',\n",
       "   'flip',\n",
       "   'forever',\n",
       "   'would',\n",
       "   'outcomes',\n",
       "   'probability',\n",
       "   'impact',\n",
       "   'calculation'],\n",
       "  ['diagram',\n",
       "   'flip',\n",
       "   'forever',\n",
       "   'correspond',\n",
       "   'follow',\n",
       "   'infinite',\n",
       "   'path',\n",
       "   'tree',\n",
       "   'ever',\n",
       "   'reach',\n",
       "   'leaf',\n",
       "   'outcome'],\n",
       "  ['texts',\n",
       "   'deal',\n",
       "   'case',\n",
       "   'add',\n",
       "   'special',\n",
       "   'infinite',\n",
       "   'sample',\n",
       "   'point',\n",
       "   'forever']],\n",
       " [['conditional_probability']],\n",
       " [['definition', 'suppose', 'pick', 'random', 'person', 'world'],\n",
       "  ['equal', 'chance', 'select'],\n",
       "  ['let',\n",
       "   'event',\n",
       "   'person',\n",
       "   'mit_student',\n",
       "   'let',\n",
       "   'event',\n",
       "   'person',\n",
       "   'live',\n",
       "   'cambridge'],\n",
       "  ['probability_event',\n",
       "   'intuitively',\n",
       "   'pick',\n",
       "   'random',\n",
       "   'point',\n",
       "   'big',\n",
       "   'ellipse',\n",
       "   'show_figure',\n",
       "   'ask',\n",
       "   'likely',\n",
       "   'point',\n",
       "   'fall',\n",
       "   'region'],\n",
       "  ['world', 'set', 'mit_student', 'live', 'cambridge', 'figure'],\n",
       "  ['select', 'random', 'person'],\n",
       "  ['event', 'person', 'mit_student'],\n",
       "  ['even', 'person', 'live', 'cambridge'],\n",
       "  ['vast',\n",
       "   'majority',\n",
       "   'people',\n",
       "   'world',\n",
       "   'live',\n",
       "   'cambridge',\n",
       "   'mit_student',\n",
       "   'event',\n",
       "   'low',\n",
       "   'probability'],\n",
       "  ['prob',\n",
       "   'ability',\n",
       "   'person',\n",
       "   'mit_student',\n",
       "   'give',\n",
       "   'person',\n",
       "   'live',\n",
       "   'cambridge',\n",
       "   'much',\n",
       "   'great',\n",
       "   'exactly',\n",
       "   'ask',\n",
       "   'call',\n",
       "   'conditional_probability',\n",
       "   'probability_event',\n",
       "   'happen',\n",
       "   'give',\n",
       "   'event',\n",
       "   'definitely',\n",
       "   'happen'],\n",
       "  ['question',\n",
       "   'conditional_probability',\n",
       "   'come',\n",
       "   'time',\n",
       "   'probability',\n",
       "   'rain',\n",
       "   'afternoon',\n",
       "   'give',\n",
       "   'cloudy',\n",
       "   'morning',\n",
       "   'chapter_conditional_probability',\n",
       "   'probability',\n",
       "   'roll',\n",
       "   'dice',\n",
       "   'sum',\n",
       "   'give',\n",
       "   'odd',\n",
       "   'probability',\n",
       "   'kind',\n",
       "   'texas',\n",
       "   'limit',\n",
       "   'hold',\n",
       "   'poker',\n",
       "   'give',\n",
       "   'initially',\n",
       "   'deal',\n",
       "   'queen',\n",
       "   'special',\n",
       "   'notation',\n",
       "   'conditional_probability'],\n",
       "  ['general',\n",
       "   'pr_pr',\n",
       "   'compute',\n",
       "   'pr',\n",
       "   'outcome',\n",
       "   'outside',\n",
       "   'event',\n",
       "   'bad',\n",
       "   'conditioning',\n",
       "   'subtly',\n",
       "   'alter',\n",
       "   'probability',\n",
       "   'produce',\n",
       "   'unexpected',\n",
       "   'result',\n",
       "   'randomize',\n",
       "   'algorithm',\n",
       "   'computer',\n",
       "   'system',\n",
       "   'well',\n",
       "   'betting',\n",
       "   'game'],\n",
       "  ['mathematical',\n",
       "   'definition',\n",
       "   'conditional_probability',\n",
       "   'give',\n",
       "   'simple',\n",
       "   'give',\n",
       "   'trouble',\n",
       "   'provide',\n",
       "   'rely',\n",
       "   'formal',\n",
       "   'reasoning',\n",
       "   'intuition'],\n",
       "  ['step_method', 'also', 'helpful', 'see', 'next', 'example']],\n",
       " [['use', 'step_method', 'determine', 'conditional_probability']],\n",
       " [['halt_problem',\n",
       "   'halt_problem',\n",
       "   'first',\n",
       "   'example',\n",
       "   'property',\n",
       "   'could',\n",
       "   'test',\n",
       "   'program'],\n",
       "  ['introduce', 'alan_ture', 'seminal', 'paper'],\n",
       "  ['problem', 'determine', 'ture', 'machine', 'halt', 'give'],\n",
       "  ['yadda', 'yadda', 'yadda'],\n",
       "  ['importantly',\n",
       "   'name',\n",
       "   'mit',\n",
       "   'eecs',\n",
       "   'department',\n",
       "   'famed',\n",
       "   'league',\n",
       "   'hockey',\n",
       "   'team'],\n",
       "  ['best', 'tournament', 'halt_problem_win', 'first_game', 'prob', 'ability'],\n",
       "  ['subsequent',\n",
       "   'games',\n",
       "   'probability',\n",
       "   'win',\n",
       "   'determine',\n",
       "   'outcome',\n",
       "   'previous',\n",
       "   'game'],\n",
       "  ['halt_problem',\n",
       "   'previous',\n",
       "   'game',\n",
       "   'invigorate',\n",
       "   'victory',\n",
       "   'win',\n",
       "   'current',\n",
       "   'game',\n",
       "   'probability'],\n",
       "  ['lose',\n",
       "   'previous',\n",
       "   'game',\n",
       "   'demoralize',\n",
       "   'defeat',\n",
       "   'win',\n",
       "   'current',\n",
       "   'game',\n",
       "   'probability'],\n",
       "  ['probability_halt_problem',\n",
       "   'win',\n",
       "   'tournament',\n",
       "   'give',\n",
       "   'win_first',\n",
       "   'game',\n",
       "   'question',\n",
       "   'conditional_probability'],\n",
       "  ['let',\n",
       "   'event',\n",
       "   'halt_problem_win',\n",
       "   'tournament',\n",
       "   'let',\n",
       "   'event',\n",
       "   'win_first',\n",
       "   'game'],\n",
       "  ['goal', 'determine', 'conditional_probability'],\n",
       "  ['tackle',\n",
       "   'conditional_probability',\n",
       "   'question',\n",
       "   'ordinary',\n",
       "   'probability',\n",
       "   'problem',\n",
       "   'use',\n",
       "   'tree_diagram',\n",
       "   'step_method'],\n",
       "  ['complete', 'tree_diagram', 'show_figure', 'game', 'game', 'figure'],\n",
       "  ['tree_diagram',\n",
       "   'compute_probability',\n",
       "   'halt_problem_win',\n",
       "   'game',\n",
       "   'give',\n",
       "   'first_game'],\n",
       "  ['step',\n",
       "   'find_sample_space',\n",
       "   'internal',\n",
       "   'vertex',\n",
       "   'tree_diagram',\n",
       "   'child',\n",
       "   'correspond',\n",
       "   'win',\n",
       "   'halt_problem',\n",
       "   'label',\n",
       "   'correspond',\n",
       "   'loss',\n",
       "   'chapter_conditional_probability',\n",
       "   'bele',\n",
       "   'lw',\n",
       "   'lw',\n",
       "   'lw',\n",
       "   'step_define',\n",
       "   'event_interest',\n",
       "   'event',\n",
       "   'halt_problem_win',\n",
       "   'whole',\n",
       "   'tournament',\n",
       "   'lw',\n",
       "   'event',\n",
       "   'halt_problem_win',\n",
       "   'first_game',\n",
       "   'lw',\n",
       "   'outcome',\n",
       "   'event',\n",
       "   'indicate',\n",
       "   'check',\n",
       "   'mark',\n",
       "   'tree_diagram',\n",
       "   'figure',\n",
       "   'step',\n",
       "   'determine',\n",
       "   'outcome_probability',\n",
       "   'next',\n",
       "   'must',\n",
       "   'assign',\n",
       "   'probability_outcome'],\n",
       "  ['begin', 'label', 'edge', 'specify', 'problem', 'statement'],\n",
       "  ['specifically',\n",
       "   'halt_problem',\n",
       "   'step_compute',\n",
       "   'event',\n",
       "   'probabilitie',\n",
       "   'compute_probability',\n",
       "   'halt_problem_win',\n",
       "   'tourna',\n",
       "   'ment',\n",
       "   'give',\n",
       "   'win_first',\n",
       "   'game',\n",
       "   'lw',\n",
       "   'do',\n",
       "   'halt_problem_win',\n",
       "   'first_game',\n",
       "   'win',\n",
       "   'whole',\n",
       "   'tournament',\n",
       "   'probability']],\n",
       " [['tree_diagram',\n",
       "   'work',\n",
       "   'settle',\n",
       "   'routine',\n",
       "   'solve',\n",
       "   'probability',\n",
       "   'problem',\n",
       "   'use',\n",
       "   'tree',\n",
       "   'dia',\n",
       "   'gram'],\n",
       "  ['leave',\n",
       "   'big',\n",
       "   'question',\n",
       "   'unaddressed',\n",
       "   'mathematical',\n",
       "   'justifi',\n",
       "   'cation',\n",
       "   'funny',\n",
       "   'little',\n",
       "   'picture',\n",
       "   'work',\n",
       "   'answer',\n",
       "   'involve',\n",
       "   'conditional_probability'],\n",
       "  ['fact',\n",
       "   'probability',\n",
       "   'record',\n",
       "   'edge',\n",
       "   'tree_diagram',\n",
       "   'conditional_probability'],\n",
       "  ['example_consider',\n",
       "   'uppermost',\n",
       "   'path',\n",
       "   'tree_diagram',\n",
       "   'halt',\n",
       "   'prob',\n",
       "   'lem',\n",
       "   'correspond',\n",
       "   'outcome',\n",
       "   'use',\n",
       "   'conditional_probability'],\n",
       "  ['multiply',\n",
       "   'edge',\n",
       "   'probability_get',\n",
       "   'outcome_probability',\n",
       "   'example',\n",
       "   'conclude',\n",
       "   'correct',\n",
       "   'answer',\n",
       "   'go_back',\n",
       "   'definition',\n",
       "   'conditional_probability',\n",
       "   'could',\n",
       "   'write',\n",
       "   'form',\n",
       "   'call',\n",
       "   'product_rule',\n",
       "   'probability',\n",
       "   'rule',\n",
       "   'product_rule',\n",
       "   'event'],\n",
       "  ['pr',\n",
       "   'multiply',\n",
       "   'edge',\n",
       "   'probability',\n",
       "   'tree_diagram',\n",
       "   'amount',\n",
       "   'evaluate',\n",
       "   'right_side',\n",
       "   'equation'],\n",
       "  ['example',\n",
       "   'pr',\n",
       "   'win_first',\n",
       "   'game_win',\n",
       "   'second',\n",
       "   'game_win',\n",
       "   'first_game',\n",
       "   'win',\n",
       "   'second',\n",
       "   'game_win',\n",
       "   'first_game',\n",
       "   'product_rule',\n",
       "   'formal',\n",
       "   'justification',\n",
       "   'multiplying',\n",
       "   'edge',\n",
       "   'probability_get',\n",
       "   'outcome_probability',\n",
       "   'course',\n",
       "   'justify',\n",
       "   'multiply',\n",
       "   'edge',\n",
       "   'probability',\n",
       "   'long',\n",
       "   'path',\n",
       "   'need',\n",
       "   'product_rule',\n",
       "   'rule',\n",
       "   'product_rule',\n",
       "   'chapter_conditional_probability',\n",
       "   'provide',\n",
       "   'pr',\n",
       "   'rule',\n",
       "   'follow',\n",
       "   'definition',\n",
       "   'conditional_probability',\n",
       "   'induction']],\n",
       " [['medical',\n",
       "   'testing',\n",
       "   'unpleasant',\n",
       "   'condition',\n",
       "   'call',\n",
       "   'bo',\n",
       "   'suffer',\n",
       "   'population'],\n",
       "  ['prior', 'symptom', 'victim', 'suddenly', 'start', 'stink'],\n",
       "  ['fortunately', 'test', 'latent', 'bo', 'thing', 'start', 'smell'],\n",
       "  ['test', 'perfect', 'however', 'condition', 'chance', 'test', 'say'],\n",
       "  ['call', 'false', 'negative'],\n",
       "  ['condition', 'chance', 'test', 'say'],\n",
       "  ['false', 'positive'],\n",
       "  ['suppose', 'random', 'person', 'test', 'latent', 'bo'],\n",
       "  ['test_positive',\n",
       "   'probability',\n",
       "   'person',\n",
       "   'condition',\n",
       "   'step',\n",
       "   'find_sample_space',\n",
       "   'sample_space',\n",
       "   'find',\n",
       "   'tree_diagram',\n",
       "   'figure',\n",
       "   'figure'],\n",
       "  ['tree_diagram', 'bo', 'problem'],\n",
       "  ['step_define',\n",
       "   'event_interest',\n",
       "   'let',\n",
       "   'find',\n",
       "   'pr',\n",
       "   'step',\n",
       "   'find',\n",
       "   'outcome_probability',\n",
       "   'first',\n",
       "   'assign',\n",
       "   'probability',\n",
       "   'edge'],\n",
       "  ['probability', 'draw', 'directly', 'problem', 'statement'],\n",
       "  ['product_rule',\n",
       "   'probability_outcome',\n",
       "   'product',\n",
       "   'probability',\n",
       "   'correspond',\n",
       "   'root_leaf',\n",
       "   'path'],\n",
       "  ['probability',\n",
       "   'show_figure',\n",
       "   'step_compute',\n",
       "   'event_probability',\n",
       "   'definition',\n",
       "   'test_positive',\n",
       "   'chance',\n",
       "   'condition',\n",
       "   'answer',\n",
       "   'initially',\n",
       "   'surprising',\n",
       "   'make_sense',\n",
       "   'reflection'],\n",
       "  ['way', 'could', 'test_positive'],\n",
       "  ['first', 'could', 'condition', 'test', 'correct'],\n",
       "  ['second', 'could', 'healthy', 'test', 'incorrect'],\n",
       "  ['problem',\n",
       "   'almost',\n",
       "   'healthy',\n",
       "   'therefore',\n",
       "   'positive',\n",
       "   'result',\n",
       "   'arise',\n",
       "   'incorrect',\n",
       "   'test',\n",
       "   'healthy',\n",
       "   'people',\n",
       "   'also',\n",
       "   'compute_probability',\n",
       "   'test',\n",
       "   'correct',\n",
       "   'random',\n",
       "   'person'],\n",
       "  ['event', 'consist', 'outcome'],\n",
       "  ['person',\n",
       "   'could',\n",
       "   'condition',\n",
       "   'test_positive',\n",
       "   'probability',\n",
       "   'wait',\n",
       "   'simple',\n",
       "   'way_make',\n",
       "   'test',\n",
       "   'correct',\n",
       "   'time',\n",
       "   'always',\n",
       "   'return',\n",
       "   'negative',\n",
       "   'result',\n",
       "   'test',\n",
       "   'give',\n",
       "   'right',\n",
       "   'answer',\n",
       "   'healthy',\n",
       "   'people',\n",
       "   'wrong',\n",
       "   'answer',\n",
       "   'actually',\n",
       "   'condition'],\n",
       "  ['well',\n",
       "   'strategy',\n",
       "   'measure',\n",
       "   'completely',\n",
       "   'ignore',\n",
       "   'test',\n",
       "   'result',\n",
       "   'similar',\n",
       "   'paradox',\n",
       "   'weather',\n",
       "   'forecasting'],\n",
       "  ['winter', 'almost', 'days', 'boston', 'wet', 'overcast'],\n",
       "  ['predict',\n",
       "   'miserable',\n",
       "   'weather',\n",
       "   'day',\n",
       "   'may',\n",
       "   'accurate',\n",
       "   'really',\n",
       "   'try',\n",
       "   'right',\n",
       "   'chapter_conditional_probability']],\n",
       " [['posteriori',\n",
       "   'probability',\n",
       "   'think',\n",
       "   'much',\n",
       "   'medical',\n",
       "   'testing',\n",
       "   'problem',\n",
       "   'consider',\n",
       "   'could',\n",
       "   'start',\n",
       "   'trouble'],\n",
       "  ['concern', 'would', 'time', 'take', 'test', 'bo', 'condition', 'know'],\n",
       "  ['may',\n",
       "   'wonder',\n",
       "   'statement',\n",
       "   'test_positive',\n",
       "   'condition',\n",
       "   'probability',\n",
       "   'make_sense'],\n",
       "  ['fact', 'statement', 'make_sense'],\n",
       "  ['mean', 'people', 'test_positive', 'actually', 'condition'],\n",
       "  ['true',\n",
       "   'particular',\n",
       "   'person',\n",
       "   'randomly',\n",
       "   'select',\n",
       "   'person',\n",
       "   'test_positive',\n",
       "   'condition',\n",
       "   'probability'],\n",
       "  ['medical',\n",
       "   'testing',\n",
       "   'example',\n",
       "   'bother',\n",
       "   'definitely',\n",
       "   'wor',\n",
       "   'rie',\n",
       "   'follow',\n",
       "   'example',\n",
       "   'go',\n",
       "   'even',\n",
       "   'path']],\n",
       " [['halt_problem',\n",
       "   'reverse',\n",
       "   'suppose',\n",
       "   'turn',\n",
       "   'hockey',\n",
       "   'question',\n",
       "   'probability_halt_problem',\n",
       "   'first_game',\n",
       "   'give',\n",
       "   'series',\n",
       "   'seem',\n",
       "   'absurd',\n",
       "   'question',\n",
       "   'halt_problem',\n",
       "   'series',\n",
       "   'winner',\n",
       "   'first_game',\n",
       "   'already',\n",
       "   'determine'],\n",
       "  ['therefore', 'first_game', 'question', 'fact', 'question', 'probability'],\n",
       "  ['however',\n",
       "   'mathematical',\n",
       "   'theory',\n",
       "   'probability',\n",
       "   'contain',\n",
       "   'notion',\n",
       "   'event',\n",
       "   'precede',\n",
       "   'notion',\n",
       "   'time'],\n",
       "  ['therefore',\n",
       "   'mathematical',\n",
       "   'perspec',\n",
       "   'tive',\n",
       "   'perfectly',\n",
       "   'valid',\n",
       "   'question'],\n",
       "  ['also', 'meaningful', 'question', 'practical', 'perspective'],\n",
       "  ['suppose',\n",
       "   'tell',\n",
       "   'halt_problem',\n",
       "   'series',\n",
       "   'tell',\n",
       "   'result',\n",
       "   'individual',\n",
       "   'game'],\n",
       "  ['perspective',\n",
       "   'make',\n",
       "   'perfect',\n",
       "   'sense',\n",
       "   'wonder',\n",
       "   'likely',\n",
       "   'halt_problem',\n",
       "   'first_game'],\n",
       "  ['conditional_probability',\n",
       "   'call',\n",
       "   'posteriori',\n",
       "   'event',\n",
       "   'precede',\n",
       "   'event',\n",
       "   'time'],\n",
       "  ['example',\n",
       "   'posteriori',\n",
       "   'probabilitie',\n",
       "   'probability',\n",
       "   'cloudy',\n",
       "   'morning',\n",
       "   'give',\n",
       "   'rain',\n",
       "   'noon'],\n",
       "  ['probability',\n",
       "   'initially',\n",
       "   'deal',\n",
       "   'queens',\n",
       "   'texas',\n",
       "   'limit',\n",
       "   'hold',\n",
       "   'poker',\n",
       "   'give',\n",
       "   'eventually',\n",
       "   'get',\n",
       "   'kind'],\n",
       "  ['mathematically',\n",
       "   'posteriori',\n",
       "   'probability',\n",
       "   'different',\n",
       "   'ordinary',\n",
       "   'probabil',\n",
       "   'itie',\n",
       "   'distinction',\n",
       "   'high',\n",
       "   'philosophical',\n",
       "   'level'],\n",
       "  ['reason', 'draw', 'attention', 'say', 'let', 'rattle'],\n",
       "  ['let', 'return', 'original', 'problem'],\n",
       "  ['probability_halt_problem',\n",
       "   'answer',\n",
       "   'suspicious',\n",
       "   'precede',\n",
       "   'section',\n",
       "   'show',\n",
       "   'pr',\n",
       "   'reflection',\n",
       "   'suggest',\n",
       "   'unlikely'],\n",
       "  ['example',\n",
       "   'probability',\n",
       "   'feel',\n",
       "   'uneasy',\n",
       "   'give',\n",
       "   'abducted',\n",
       "   'alien',\n",
       "   'pretty',\n",
       "   'large'],\n",
       "  ['probability',\n",
       "   'abduct',\n",
       "   'alien',\n",
       "   'give',\n",
       "   'feel',\n",
       "   'uneasy',\n",
       "   'rather',\n",
       "   'small'],\n",
       "  ['equation',\n",
       "   'turn',\n",
       "   'hold',\n",
       "   'denominator',\n",
       "   'equal',\n",
       "   'numerator',\n",
       "   'namely',\n",
       "   'pr',\n",
       "   'former',\n",
       "   'condition_hold',\n",
       "   'hockey',\n",
       "   'example',\n",
       "   'probability_halt_problem',\n",
       "   'win',\n",
       "   'series',\n",
       "   'event',\n",
       "   'general',\n",
       "   'pair',\n",
       "   'probabilitie',\n",
       "   'relate',\n",
       "   'baye',\n",
       "   'rule',\n",
       "   'theorem'],\n",
       "  ['bayes', 'rule'],\n",
       "  ['pr', 'chapter_conditional_probability']],\n",
       " [['coin',\n",
       "   'problem',\n",
       "   'suppose',\n",
       "   'hand',\n",
       "   'fair_coin',\n",
       "   'trick',\n",
       "   'coin',\n",
       "   'head',\n",
       "   'side'],\n",
       "  ['flip', 'coin', 'time', 'see', 'head', 'time'],\n",
       "  ['say',\n",
       "   'probability',\n",
       "   'flip_fair_coin',\n",
       "   'remarkably',\n",
       "   'order',\n",
       "   'make_sense',\n",
       "   'outrageous',\n",
       "   'claim',\n",
       "   'let',\n",
       "   'formalize',\n",
       "   'problem'],\n",
       "  ['sample_space', 'work', 'tree_diagram', 'show_figure', 'figure'],\n",
       "  ['tree_diagram', 'coin', 'flipping', 'problem'],\n",
       "  ['fair_coin',\n",
       "   'let',\n",
       "   'ing',\n",
       "   'pr',\n",
       "   'expression',\n",
       "   'small',\n",
       "   'moderate',\n",
       "   'value',\n",
       "   'know',\n",
       "   'probability',\n",
       "   'course',\n",
       "   'extremely',\n",
       "   'unlikely',\n",
       "   'would',\n",
       "   'flip',\n",
       "   'straight',\n",
       "   'head',\n",
       "   'case',\n",
       "   'give',\n",
       "   'assumption',\n",
       "   'conditional_probability'],\n",
       "  ['really',\n",
       "   'see',\n",
       "   'straight',\n",
       "   'head',\n",
       "   'would',\n",
       "   'tempt',\n",
       "   'also',\n",
       "   'assume',\n",
       "   'encounter',\n",
       "   'similar',\n",
       "   'issue',\n",
       "   'look',\n",
       "   'method',\n",
       "   'estimation',\n",
       "   'sampling',\n",
       "   'section']],\n",
       " [['conditional', 'identity']],\n",
       " [['law_total',\n",
       "   'probability',\n",
       "   'break',\n",
       "   'probability',\n",
       "   'calculation',\n",
       "   'case',\n",
       "   'simplify',\n",
       "   'many',\n",
       "   'problem'],\n",
       "  ['idea', 'calculate', 'probability_event', 'rule'],\n",
       "  ['law_total', 'probability', 'single', 'event'],\n",
       "  ['pr', 'coin'],\n",
       "  ['head', 'come', 'roll_die', 'take', 'result'],\n",
       "  ['tails', 'come', 'roll', 'dice', 'take', 'sum', 'result'],\n",
       "  ['probability',\n",
       "   'process',\n",
       "   'yield',\n",
       "   'let',\n",
       "   'also',\n",
       "   'form',\n",
       "   'rule',\n",
       "   'handle',\n",
       "   'case'],\n",
       "  ['chapter_conditional_probability', 'rule'],\n",
       "  ['law_total', 'probability'],\n",
       "  ['would']],\n",
       " [['condition',\n",
       "   'single',\n",
       "   'event_probability',\n",
       "   'rule',\n",
       "   'derive',\n",
       "   'chapter',\n",
       "   'extend',\n",
       "   'probability',\n",
       "   'condi',\n",
       "   'tione',\n",
       "   'event'],\n",
       "  ['example',\n",
       "   'inclusion_exclusion',\n",
       "   'formula',\n",
       "   'set',\n",
       "   'hold',\n",
       "   'probability',\n",
       "   'condition',\n",
       "   'event',\n",
       "   'important',\n",
       "   'mix',\n",
       "   'event',\n",
       "   'condition',\n",
       "   'bar'],\n",
       "  ['convinced',\n",
       "   'equation',\n",
       "   'false',\n",
       "   'general',\n",
       "   'right',\n",
       "   'let_see',\n",
       "   'really',\n",
       "   'believe']],\n",
       " [['discrimination',\n",
       "   'lawsuit',\n",
       "   'several',\n",
       "   'year_ago',\n",
       "   'sex',\n",
       "   'discrimination',\n",
       "   'lawsuit',\n",
       "   'famous',\n",
       "   'uni',\n",
       "   'versity'],\n",
       "  ['female',\n",
       "   'math',\n",
       "   'professor',\n",
       "   'deny',\n",
       "   'tenure',\n",
       "   'allegedly',\n",
       "   'sample_space',\n",
       "   'figure'],\n",
       "  ['counterexample', 'equation', 'woman'],\n",
       "  ['argue',\n",
       "   'university',\n",
       "   'department',\n",
       "   'percentage',\n",
       "   'male',\n",
       "   'applicant',\n",
       "   'accept',\n",
       "   'great',\n",
       "   'percentage',\n",
       "   'female',\n",
       "   'applicant',\n",
       "   'accept'],\n",
       "  ['sound',\n",
       "   'suspicious',\n",
       "   'however',\n",
       "   'university',\n",
       "   'lawyer',\n",
       "   'argue',\n",
       "   'university',\n",
       "   'whole',\n",
       "   'percentage',\n",
       "   'male',\n",
       "   'applicant',\n",
       "   'accept',\n",
       "   'actually',\n",
       "   'low',\n",
       "   'percentage',\n",
       "   'female',\n",
       "   'applicant',\n",
       "   'accept'],\n",
       "  ['suggest',\n",
       "   'sex',\n",
       "   'discrimi',\n",
       "   'nation',\n",
       "   'man',\n",
       "   'surely',\n",
       "   'least',\n",
       "   'party',\n",
       "   'dispute',\n",
       "   'must',\n",
       "   'lie'],\n",
       "  ['let',\n",
       "   'simplify',\n",
       "   'problem',\n",
       "   'express',\n",
       "   'argument',\n",
       "   'term',\n",
       "   'conditional_probability'],\n",
       "  ['simplify',\n",
       "   'matter',\n",
       "   'suppose',\n",
       "   'department',\n",
       "   'consider',\n",
       "   'experiment',\n",
       "   'pick',\n",
       "   'random',\n",
       "   'applicant'],\n",
       "  ['define', 'follow', 'event', 'let', 'event', 'applicant', 'accept'],\n",
       "  ['let',\n",
       "   'ee_cs',\n",
       "   'ee_cs',\n",
       "   'assume',\n",
       "   'applicant',\n",
       "   'male',\n",
       "   'female',\n",
       "   'applicant',\n",
       "   'apply',\n",
       "   'department'],\n",
       "  ['event', 'ee_cs', 'ee_cs', 'table'],\n",
       "  ['scenario',\n",
       "   'female',\n",
       "   'less',\n",
       "   'likely',\n",
       "   'admit',\n",
       "   'male',\n",
       "   'department',\n",
       "   'likely',\n",
       "   'admit',\n",
       "   'overall'],\n",
       "  ['term',\n",
       "   'plaintiff',\n",
       "   'make',\n",
       "   'follow',\n",
       "   'argument',\n",
       "   'ee_cs',\n",
       "   'cs',\n",
       "   'departments',\n",
       "   'probability',\n",
       "   'woman',\n",
       "   'accept',\n",
       "   'tenure',\n",
       "   'less',\n",
       "   'probability',\n",
       "   'man',\n",
       "   'accept'],\n",
       "  ['university',\n",
       "   'retort',\n",
       "   'overall',\n",
       "   'woman',\n",
       "   'applicant',\n",
       "   'likely',\n",
       "   'accepted',\n",
       "   'man',\n",
       "   'namely',\n",
       "   'ee_cs',\n",
       "   'ee_cs',\n",
       "   'easy',\n",
       "   'believe',\n",
       "   'position',\n",
       "   'contradictory'],\n",
       "  ['fact',\n",
       "   'may',\n",
       "   'even',\n",
       "   'try_prove',\n",
       "   'add',\n",
       "   'plaintiff',\n",
       "   'inequality',\n",
       "   'argue',\n",
       "   'follow',\n",
       "   'pr',\n",
       "   'ee',\n",
       "   'ee_cs',\n",
       "   'pr',\n",
       "   'ee_cs',\n",
       "   'ee_cs',\n",
       "   'second_line',\n",
       "   'exactly',\n",
       "   'contradict',\n",
       "   'university',\n",
       "   'position',\n",
       "   'big',\n",
       "   'problem',\n",
       "   'argument',\n",
       "   'second',\n",
       "   'inequality',\n",
       "   'follow',\n",
       "   'first',\n",
       "   'accept',\n",
       "   'false',\n",
       "   'identity',\n",
       "   'fact',\n",
       "   'table',\n",
       "   'show',\n",
       "   'set',\n",
       "   'application',\n",
       "   'statistic',\n",
       "   'assertion',\n",
       "   'plaintiff',\n",
       "   'university',\n",
       "   'hold'],\n",
       "  ['case',\n",
       "   'high',\n",
       "   'percentage',\n",
       "   'male',\n",
       "   'accept',\n",
       "   'department',\n",
       "   'overall',\n",
       "   'high',\n",
       "   'percentage',\n",
       "   'female',\n",
       "   'accept',\n",
       "   'bizarre']],\n",
       " [['independence']],\n",
       " [['definition',\n",
       "   'suppose_flip_fair',\n",
       "   'coin',\n",
       "   'simultaneously',\n",
       "   'opposite',\n",
       "   'side',\n",
       "   'room'],\n",
       "  ['intuitively', 'way', 'coin', 'land', 'affect', 'way', 'coin', 'land'],\n",
       "  ['mathematical',\n",
       "   'concept',\n",
       "   'capture',\n",
       "   'intuition',\n",
       "   'call',\n",
       "   'independence',\n",
       "   'definition'],\n",
       "  ['event', 'word']],\n",
       " [['potential',\n",
       "   'pitfall',\n",
       "   'student',\n",
       "   'sometimes',\n",
       "   'get',\n",
       "   'idea',\n",
       "   'disjoint',\n",
       "   'event_independent'],\n",
       "  ['opposite', 'true']],\n",
       " [['alternative',\n",
       "   'formulation',\n",
       "   'sometimes',\n",
       "   'useful',\n",
       "   'express',\n",
       "   'independence',\n",
       "   'alternate',\n",
       "   'form',\n",
       "   'theorem'],\n",
       "  ['proof'],\n",
       "  ['case', 'consider', 'depend', 'pr', 'case', 'pr', 'hold', 'side'],\n",
       "  ['hence', 'theorem', 'true', 'case'],\n",
       "  ['case',\n",
       "   'pr',\n",
       "   'chapter',\n",
       "   'independence',\n",
       "   'equation_hold',\n",
       "   'definition',\n",
       "   'theorem',\n",
       "   'true',\n",
       "   'case',\n",
       "   'well']],\n",
       " [['independence',\n",
       "   'assumption',\n",
       "   'generally',\n",
       "   'independence',\n",
       "   'assume',\n",
       "   'model',\n",
       "   'phenomenon'],\n",
       "  ['example_consider', 'experiment', 'flip_fair_coin'],\n",
       "  ['let_pr', 'example', 'assumption', 'independence', 'reasonable'],\n",
       "  ['result',\n",
       "   'coin',\n",
       "   'toss',\n",
       "   'negligible',\n",
       "   'impact',\n",
       "   'outcome',\n",
       "   'coin',\n",
       "   'toss'],\n",
       "  ['repeat',\n",
       "   'experiment',\n",
       "   'many',\n",
       "   'time',\n",
       "   'would',\n",
       "   'likely',\n",
       "   'course',\n",
       "   'many',\n",
       "   'example',\n",
       "   'event',\n",
       "   'assume',\n",
       "   'independence',\n",
       "   'justified',\n",
       "   'example',\n",
       "   'let_pr',\n",
       "   'unfortunately',\n",
       "   'event',\n",
       "   'definitely',\n",
       "   'independent',\n",
       "   'particular',\n",
       "   'rainy',\n",
       "   'day',\n",
       "   'cloudy'],\n",
       "  ['thus',\n",
       "   'probability',\n",
       "   'rainy',\n",
       "   'cloudy',\n",
       "   'day',\n",
       "   'actually',\n",
       "   'decide',\n",
       "   'assume',\n",
       "   'event_independent',\n",
       "   'tricky',\n",
       "   'business'],\n",
       "  ['practice',\n",
       "   'strong',\n",
       "   'motivation',\n",
       "   'assume',\n",
       "   'independence',\n",
       "   'many',\n",
       "   'useful',\n",
       "   'formula',\n",
       "   'equation']],\n",
       " [['mutual', 'independence']],\n",
       " [['definition', 'define', 'mean', 'event_independent'],\n",
       "  ['event', 'example', 'say', 'flip', 'event', 'definition'],\n",
       "  ['set',\n",
       "   'event',\n",
       "   'word',\n",
       "   'matter',\n",
       "   'event',\n",
       "   'know',\n",
       "   'occur',\n",
       "   'probability',\n",
       "   'example',\n",
       "   'toss',\n",
       "   'fair_coin',\n",
       "   'different',\n",
       "   'time',\n",
       "   'may',\n",
       "   'reasonably',\n",
       "   'assume',\n",
       "   'toss',\n",
       "   'mutually_independent',\n",
       "   'probability',\n",
       "   'coin',\n",
       "   'head']],\n",
       " [['alternative',\n",
       "   'formulation',\n",
       "   'theorem',\n",
       "   'provide',\n",
       "   'alternative',\n",
       "   'definition',\n",
       "   'independence',\n",
       "   'event',\n",
       "   'alternative',\n",
       "   'definition',\n",
       "   'mutual',\n",
       "   'independence'],\n",
       "  ['theorem'],\n",
       "  ['set',\n",
       "   'event',\n",
       "   'proof_theorem',\n",
       "   'use_induction',\n",
       "   'reason',\n",
       "   'similar',\n",
       "   'proof_theorem',\n",
       "   'theorem',\n",
       "   'say',\n",
       "   'chapter',\n",
       "   'independence',\n",
       "   'follow',\n",
       "   'equation_hold',\n",
       "   'distinct',\n",
       "   'pr',\n",
       "   'example',\n",
       "   'toss']],\n",
       " [['dna',\n",
       "   'testing',\n",
       "   'assumption',\n",
       "   'independence',\n",
       "   'routinely',\n",
       "   'make',\n",
       "   'practice'],\n",
       "  ['frequently', 'assumption', 'quite', 'reasonable'],\n",
       "  ['sometimes',\n",
       "   'however',\n",
       "   'reasonableness',\n",
       "   'independence',\n",
       "   'assumption',\n",
       "   'clear',\n",
       "   'consequence',\n",
       "   'faulty',\n",
       "   'assump',\n",
       "   'tion',\n",
       "   'severe'],\n",
       "  ['example_consider', 'follow', 'testimony'],\n",
       "  ['simpson', 'murder', 'trial', 'may', 'mr'],\n",
       "  ['clarke',\n",
       "   'make',\n",
       "   'estimation',\n",
       "   'frequency',\n",
       "   'believe',\n",
       "   'touch',\n",
       "   'little',\n",
       "   'bit',\n",
       "   'concept',\n",
       "   'call',\n",
       "   'independence',\n",
       "   'dr'],\n",
       "  ['cotton'],\n",
       "  ['mr'],\n",
       "  ['clarke', 'dr'],\n",
       "  ['cotton', 'mean', 'inherit', 'allele', 'affect', 'second', 'allele', 'may'],\n",
       "  ['inherit',\n",
       "   'band',\n",
       "   'base',\n",
       "   'pair',\n",
       "   'mean',\n",
       "   'automatically',\n",
       "   'probability',\n",
       "   'inherit'],\n",
       "  ['inherit', 'parent', 'inherit'],\n",
       "  ['mr'],\n",
       "  ['clarke', 'important', 'dr'],\n",
       "  ['cotton',\n",
       "   'mathematically',\n",
       "   'important',\n",
       "   'case',\n",
       "   'would',\n",
       "   'improper',\n",
       "   'multiply',\n",
       "   'frequency',\n",
       "   'different',\n",
       "   'genetic',\n",
       "   'location'],\n",
       "  ['mr'],\n",
       "  ['clarke',\n",
       "   'well',\n",
       "   'first',\n",
       "   'marker',\n",
       "   'independent',\n",
       "   'describe',\n",
       "   'testing',\n",
       "   'case',\n",
       "   'presumably',\n",
       "   'dialogue',\n",
       "   'confusing',\n",
       "   'jury'],\n",
       "  ['es',\n",
       "   'sentially',\n",
       "   'jury',\n",
       "   'tell',\n",
       "   'genetic',\n",
       "   'marker',\n",
       "   'blood',\n",
       "   'find',\n",
       "   'crime',\n",
       "   'scene',\n",
       "   'match',\n",
       "   'simpson'],\n",
       "  ['furthermore',\n",
       "   'tell',\n",
       "   'probability',\n",
       "   'mark',\n",
       "   'er',\n",
       "   'would',\n",
       "   'find',\n",
       "   'randomly',\n",
       "   'select',\n",
       "   'person'],\n",
       "  ['astronomical',\n",
       "   'figure',\n",
       "   'derive',\n",
       "   'statistic',\n",
       "   'person',\n",
       "   'marker',\n",
       "   'person',\n",
       "   'marker',\n",
       "   'number',\n",
       "   'multiply',\n",
       "   'give',\n",
       "   'probability',\n",
       "   'randomly',\n",
       "   'select',\n",
       "   'person',\n",
       "   'would',\n",
       "   'marker',\n",
       "   'pr',\n",
       "   'defense',\n",
       "   'point',\n",
       "   'assume',\n",
       "   'marker',\n",
       "   'appear',\n",
       "   'mutually',\n",
       "   'inde',\n",
       "   'pendently'],\n",
       "  ['furthermore', 'statistic', 'base', 'blood', 'sample'],\n",
       "  ['trial', 'jury', 'widely', 'mock', 'fail', 'understand', 'dna', 'evidence'],\n",
       "  ['juror', 'would', 'accept', 'calculation']],\n",
       " [['pairwise',\n",
       "   'independence',\n",
       "   'definition',\n",
       "   'mutual',\n",
       "   'independence',\n",
       "   'seem',\n",
       "   'awfully',\n",
       "   'complicate',\n",
       "   'many',\n",
       "   'subset',\n",
       "   'event',\n",
       "   'consider',\n",
       "   'example',\n",
       "   'illustrate',\n",
       "   'subtlety',\n",
       "   'independence',\n",
       "   'event',\n",
       "   'involve'],\n",
       "  ['suppose_flip_fair', 'mutually_independent', 'coin'],\n",
       "  ['define', 'follow', 'event', 'event', 'coin', 'match', 'coin'],\n",
       "  ['event', 'coin', 'match', 'coin'],\n",
       "  ['chapter', 'independence', 'event', 'coin', 'match', 'coin'],\n",
       "  ['sample_space',\n",
       "   'experiment',\n",
       "   'thh',\n",
       "   'outcome_probability',\n",
       "   'see',\n",
       "   'event',\n",
       "   'symmetry',\n",
       "   'pr',\n",
       "   'hhh',\n",
       "   'symmetry',\n",
       "   'pr',\n",
       "   'hhh',\n",
       "   'event',\n",
       "   'definition'],\n",
       "  ['set', 'set', 'example_suppose', 'prosecutor'],\n",
       "  ['simpson',\n",
       "   'trial',\n",
       "   'wrong',\n",
       "   'marker',\n",
       "   'pr',\n",
       "   'first',\n",
       "   'line',\n",
       "   'use',\n",
       "   'fact',\n",
       "   'hand',\n",
       "   'bind',\n",
       "   'get',\n",
       "   'assume',\n",
       "   'pairwise',\n",
       "   'independence',\n",
       "   'lot',\n",
       "   'better',\n",
       "   'bind',\n",
       "   'would',\n",
       "   'independence'],\n",
       "  ['example',\n",
       "   'marker',\n",
       "   'dependent',\n",
       "   'possible',\n",
       "   'marker',\n",
       "   'marker',\n",
       "   'marker',\n",
       "   'marker',\n",
       "   'scenario',\n",
       "   'probability',\n",
       "   'match',\n",
       "   'pr',\n",
       "   'chapter',\n",
       "   'independence',\n",
       "   'strong',\n",
       "   'independence',\n",
       "   'assumption',\n",
       "   'lead',\n",
       "   'smaller',\n",
       "   'bind',\n",
       "   'prob',\n",
       "   'ability',\n",
       "   'match'],\n",
       "  ['trick', 'figure', 'independence', 'assumption', 'reasonable'],\n",
       "  ['assume',\n",
       "   'markers',\n",
       "   'mutually_independent',\n",
       "   'may',\n",
       "   'well',\n",
       "   'reasonable',\n",
       "   'examine',\n",
       "   'hundred',\n",
       "   'million',\n",
       "   'blood',\n",
       "   'sample'],\n",
       "  ['oth',\n",
       "   'erwise',\n",
       "   'would',\n",
       "   'know',\n",
       "   'marker',\n",
       "   'show',\n",
       "   'frequently',\n",
       "   'whenever',\n",
       "   'marker',\n",
       "   'simultaneously',\n",
       "   'present',\n",
       "   'conclude',\n",
       "   'discussion',\n",
       "   'independence',\n",
       "   'useful',\n",
       "   'somewhat',\n",
       "   'famous',\n",
       "   'example',\n",
       "   'know',\n",
       "   'birthday',\n",
       "   'paradox']],\n",
       " [['birthday', 'paradox', 'suppose', 'student', 'class'],\n",
       "  ['probability',\n",
       "   'birthday',\n",
       "   'share',\n",
       "   'people',\n",
       "   'compare',\n",
       "   'student',\n",
       "   'possible',\n",
       "   'birthday',\n",
       "   'may',\n",
       "   'guess',\n",
       "   'probability',\n",
       "   'lie',\n",
       "   'somewhere',\n",
       "   'wrong',\n",
       "   'probability',\n",
       "   'people',\n",
       "   'class',\n",
       "   'matching',\n",
       "   'birthday',\n",
       "   'actually'],\n",
       "  ['word', 'probability', 'birthday', 'different', 'less'],\n",
       "  ['probability',\n",
       "   'small',\n",
       "   'answer',\n",
       "   'involve',\n",
       "   'phenomenon',\n",
       "   'know',\n",
       "   'birthday',\n",
       "   'paradox',\n",
       "   'birthday',\n",
       "   'principle',\n",
       "   'surprisingly',\n",
       "   'important',\n",
       "   'computer_science',\n",
       "   'see',\n",
       "   'later'],\n",
       "  ['delve',\n",
       "   'analysis',\n",
       "   'nee',\n",
       "   'make',\n",
       "   'model',\n",
       "   'assump',\n",
       "   'tion',\n",
       "   'student',\n",
       "   'possible',\n",
       "   'birthday',\n",
       "   'equally_likely'],\n",
       "  ['idea',\n",
       "   'lie',\n",
       "   'assumption',\n",
       "   'student',\n",
       "   'birthday',\n",
       "   'determine',\n",
       "   'run',\n",
       "   'dom',\n",
       "   'process',\n",
       "   'involve',\n",
       "   'parent',\n",
       "   'fate',\n",
       "   'issue',\n",
       "   'discuss',\n",
       "   'early',\n",
       "   'context',\n",
       "   'graph_theory'],\n",
       "  ['assumption',\n",
       "   'completely',\n",
       "   'curate',\n",
       "   'however',\n",
       "   'number',\n",
       "   'baby',\n",
       "   'bear',\n",
       "   'august',\n",
       "   'september',\n",
       "   'example'],\n",
       "  ['birthdays', 'mutually_independent'],\n",
       "  ['perfectly', 'accurate', 'either'],\n",
       "  ['example', 'twins', 'class', 'birthday', 'surely', 'independent'],\n",
       "  ['stick', 'assumption', 'limitation'],\n",
       "  ['part', 'reason', 'simplify', 'analysis'],\n",
       "  ['big',\n",
       "   'reason',\n",
       "   'conclusion',\n",
       "   'apply',\n",
       "   'many',\n",
       "   'situation',\n",
       "   'computer_science',\n",
       "   'twins',\n",
       "   'leap',\n",
       "   'day',\n",
       "   'romantic',\n",
       "   'holiday',\n",
       "   'consideration'],\n",
       "  ['item',\n",
       "   'collide',\n",
       "   'hash',\n",
       "   'table',\n",
       "   'really',\n",
       "   'human',\n",
       "   'reproductive',\n",
       "   'preference'],\n",
       "  ['also',\n",
       "   'pursuit',\n",
       "   'generality',\n",
       "   'let',\n",
       "   'switch',\n",
       "   'specific',\n",
       "   'number',\n",
       "   'variable'],\n",
       "  ['let', 'solve_problem', 'use', 'standard', 'step_method'],\n",
       "  ['however', 'tree_diagram', 'little', 'value', 'sample_space', 'enormous'],\n",
       "  ['time',\n",
       "   'proceed',\n",
       "   'visual',\n",
       "   'aid',\n",
       "   'step',\n",
       "   'find_sample_space',\n",
       "   'let',\n",
       "   'number',\n",
       "   'people',\n",
       "   'room',\n",
       "   'person'],\n",
       "  ['sample_space',\n",
       "   'set',\n",
       "   'sequence',\n",
       "   'step_define',\n",
       "   'event_interest',\n",
       "   'goal',\n",
       "   'determine',\n",
       "   'probability_event',\n",
       "   'compute',\n",
       "   'pr_pr',\n",
       "   'step',\n",
       "   'assign',\n",
       "   'outcome_probability',\n",
       "   'need',\n",
       "   'compute_probability',\n",
       "   'person',\n",
       "   'bear',\n",
       "   'day',\n",
       "   'step_compute',\n",
       "   'event_probability',\n",
       "   'interested',\n",
       "   'probability_event',\n",
       "   'distinct',\n",
       "   'do',\n",
       "   'correct',\n",
       "   'would',\n",
       "   'certainly',\n",
       "   'nicer',\n",
       "   'close_form',\n",
       "   'ex',\n",
       "   'pression',\n",
       "   'equation',\n",
       "   'fact',\n",
       "   'excellent',\n",
       "   'approximation',\n",
       "   'accurate'],\n",
       "  ['mean'],\n",
       "  ['term'],\n",
       "  ['ratio', 'factor'],\n",
       "  ['evaluate',\n",
       "   'equation',\n",
       "   'also',\n",
       "   'plug',\n",
       "   'value',\n",
       "   'reveal',\n",
       "   'probability',\n",
       "   'birthday',\n",
       "   'differ'],\n",
       "  ['room',\n",
       "   'people',\n",
       "   'probability',\n",
       "   'pair_people',\n",
       "   'share',\n",
       "   'birthday',\n",
       "   'little',\n",
       "   'better']],\n",
       " [['application',\n",
       "   'hash',\n",
       "   'hash',\n",
       "   'frequently',\n",
       "   'use',\n",
       "   'computer_science',\n",
       "   'map',\n",
       "   'large',\n",
       "   'string',\n",
       "   'datum',\n",
       "   'short',\n",
       "   'string',\n",
       "   'datum'],\n",
       "  ['typical',\n",
       "   'scenario',\n",
       "   'set',\n",
       "   'item',\n",
       "   'assign',\n",
       "   'number',\n",
       "   'collision',\n",
       "   'say',\n",
       "   'occur'],\n",
       "  ['collision', 'generally', 'bad'],\n",
       "  ['example',\n",
       "   'collision',\n",
       "   'correspond',\n",
       "   'vari',\n",
       "   'able',\n",
       "   'store',\n",
       "   'place',\n",
       "   'message',\n",
       "   'assign',\n",
       "   'dig',\n",
       "   'ital',\n",
       "   'signature'],\n",
       "  ['imagine',\n",
       "   'electronic',\n",
       "   'banking',\n",
       "   'digital',\n",
       "   'signature',\n",
       "   'check',\n",
       "   'signature',\n",
       "   'dollar',\n",
       "   'check'],\n",
       "  ['fact',\n",
       "   'finding',\n",
       "   'collision',\n",
       "   'common',\n",
       "   'technique',\n",
       "   'break',\n",
       "   'cryptographic',\n",
       "   'code'],\n",
       "  ['practice',\n",
       "   'assignment',\n",
       "   'number',\n",
       "   'item',\n",
       "   'do',\n",
       "   'use',\n",
       "   'hash',\n",
       "   'function'],\n",
       "  ['typically', 'value'],\n",
       "  ['efficiency', 'purpose', 'generally', 'desirable', 'make', 'possible'],\n",
       "  ['error', 'small', 'lose'],\n",
       "  ['technique',\n",
       "   'often',\n",
       "   'refer',\n",
       "   'birthday',\n",
       "   'attack',\n",
       "   'association',\n",
       "   'attack',\n",
       "   'birthday',\n",
       "   'paradox'],\n",
       "  ['chapter',\n",
       "   'independence',\n",
       "   'theorem',\n",
       "   'derivation',\n",
       "   'equation',\n",
       "   'nee',\n",
       "   'find',\n",
       "   'value',\n",
       "   'expression',\n",
       "   'least'],\n",
       "  ['tell',\n",
       "   'big',\n",
       "   'hash',\n",
       "   'table',\n",
       "   'need',\n",
       "   'order',\n",
       "   'chance',\n",
       "   'avoid',\n",
       "   'collision'],\n",
       "  ['mean', 'need', 'find', 'value', 'term'],\n",
       "  ['may', 'look', 'simplification', 'stick'],\n",
       "  ['grow', 'faster', 'tend', 'equa', 'tion', 'can', 'satisfy'],\n",
       "  ['grow',\n",
       "   'slowly',\n",
       "   'diverge',\n",
       "   'negative',\n",
       "   'infinity',\n",
       "   'equation',\n",
       "   'can',\n",
       "   'satisfy'],\n",
       "  ['suggest', 'focus', 'case'],\n",
       "  ['simplifie',\n",
       "   'word',\n",
       "   'needs',\n",
       "   'grow',\n",
       "   'quadratically',\n",
       "   'order',\n",
       "   'avoid',\n",
       "   'collision'],\n",
       "  ['unfortunate',\n",
       "   'fact',\n",
       "   'know',\n",
       "   'birthday',\n",
       "   'principle',\n",
       "   'limit',\n",
       "   'efficiency',\n",
       "   'hashing',\n",
       "   'practice',\n",
       "   'quadratic',\n",
       "   'number',\n",
       "   'item',\n",
       "   'hash',\n",
       "   'need',\n",
       "   'able',\n",
       "   'deal',\n",
       "   'collision']],\n",
       " [['random_variable_distribution',\n",
       "   'thus',\n",
       "   'far',\n",
       "   'focus',\n",
       "   'probability_event'],\n",
       "  ['example',\n",
       "   'compute_probability',\n",
       "   'win',\n",
       "   'monty_hall',\n",
       "   'game',\n",
       "   'rare',\n",
       "   'medical',\n",
       "   'condition',\n",
       "   'give',\n",
       "   'test_positive'],\n",
       "  ['many', 'case', 'would', 'like'],\n",
       "  ['example',\n",
       "   'many',\n",
       "   'contestant',\n",
       "   'must',\n",
       "   'play',\n",
       "   'monty_hall',\n",
       "   'game',\n",
       "   'finally',\n",
       "   'win',\n",
       "   'long',\n",
       "   'condition',\n",
       "   'last',\n",
       "   'much',\n",
       "   'lose',\n",
       "   'gamble',\n",
       "   'strange_dice',\n",
       "   'night',\n",
       "   'answer_question',\n",
       "   'need',\n",
       "   'work',\n",
       "   'random_variable']],\n",
       " [['definition', 'example', 'definition'],\n",
       "  ['random_variable',\n",
       "   'probability_space',\n",
       "   'total',\n",
       "   'function',\n",
       "   'domain',\n",
       "   'sample_space'],\n",
       "  ['codomain', 'usually', 'subset', 'real_number'],\n",
       "  ['notice',\n",
       "   'name',\n",
       "   'random_variable',\n",
       "   'misnomer',\n",
       "   'random_variable',\n",
       "   'actually',\n",
       "   'function',\n",
       "   'example_suppose',\n",
       "   'toss',\n",
       "   'independent'],\n",
       "  ['flip', 'tails', 'tails', 'tail'],\n",
       "  ['effect', 'count', 'number_head', 'indicate', 'coin', 'match'],\n",
       "  ['outcome',\n",
       "   'uniquely',\n",
       "   'determine',\n",
       "   'regard',\n",
       "   'func_tion',\n",
       "   'mapping',\n",
       "   'outcome',\n",
       "   'number'],\n",
       "  ['experiment',\n",
       "   'sample_space',\n",
       "   'thh',\n",
       "   'th',\n",
       "   'th',\n",
       "   'function',\n",
       "   'map',\n",
       "   'outcome',\n",
       "   'sample_space',\n",
       "   'number',\n",
       "   'go',\n",
       "   'forward',\n",
       "   'talk',\n",
       "   'flip',\n",
       "   'independent',\n",
       "   'coin',\n",
       "   'assume',\n",
       "   'mutually_independent'],\n",
       "  ['random_variable']],\n",
       " [['indicator_random',\n",
       "   'variables',\n",
       "   'indicator_random_variable',\n",
       "   'random_variable',\n",
       "   'map',\n",
       "   'outcome',\n",
       "   'either'],\n",
       "  ['indicator_random_variable', 'also', 'call', 'bernoulli', 'variable'],\n",
       "  ['random_variable', 'example'],\n",
       "  ['coin', 'match', 'otherwise'],\n",
       "  ['indicator_random_variable', 'closely', 'related', 'event'],\n",
       "  ['particular',\n",
       "   'dicator',\n",
       "   'random_variable',\n",
       "   'partition',\n",
       "   'sample_space',\n",
       "   'outcome',\n",
       "   'map',\n",
       "   'outcome',\n",
       "   'map'],\n",
       "  ['example',\n",
       "   'indicator',\n",
       "   'partition',\n",
       "   'sample_space',\n",
       "   'block',\n",
       "   'follow',\n",
       "   'way',\n",
       "   'event',\n",
       "   'partition',\n",
       "   'sample_space',\n",
       "   'outcome'],\n",
       "  ['naturally', 'associate', 'indicator_random_variable']],\n",
       " [['random_variable',\n",
       "   'event',\n",
       "   'strong',\n",
       "   'relationship',\n",
       "   'event',\n",
       "   'general',\n",
       "   'random_variable',\n",
       "   'well'],\n",
       "  ['random_variable',\n",
       "   'take',\n",
       "   'several',\n",
       "   'value',\n",
       "   'partition',\n",
       "   'sample_space',\n",
       "   'several',\n",
       "   'block'],\n",
       "  ['example',\n",
       "   'partition',\n",
       "   'sample_space',\n",
       "   'follow',\n",
       "   'cd',\n",
       "   'cd',\n",
       "   'cd',\n",
       "   'cd',\n",
       "   'block',\n",
       "   'subset',\n",
       "   'sample_space',\n",
       "   'therefore',\n",
       "   'event'],\n",
       "  ['thus',\n",
       "   'regard',\n",
       "   'equation',\n",
       "   'inequality',\n",
       "   'involve',\n",
       "   'random_variable',\n",
       "   'event'],\n",
       "  ['example',\n",
       "   'event',\n",
       "   'thh',\n",
       "   'th',\n",
       "   'naturally',\n",
       "   'enough',\n",
       "   'talk',\n",
       "   'probability_event',\n",
       "   'define',\n",
       "   'proper',\n",
       "   'tie',\n",
       "   'random_variable'],\n",
       "  ['example', 'pr', 'thh', 'th', 'hh', 'example']],\n",
       " [['function',\n",
       "   'random_variable',\n",
       "   'random_variable',\n",
       "   'combine',\n",
       "   'form',\n",
       "   'random_variable'],\n",
       "  ['exam_ple', 'suppose', 'roll', 'unbiased', 'independent', 'sided', 'dice'],\n",
       "  ['let',\n",
       "   'th',\n",
       "   'die',\n",
       "   'let_pr',\n",
       "   'pr',\n",
       "   'random_variable',\n",
       "   'combine',\n",
       "   'complicated',\n",
       "   'way',\n",
       "   'see',\n",
       "   'chap',\n",
       "   'ter',\n",
       "   'also',\n",
       "   'random_variable'],\n",
       "  ['case', 'pr_pr', 'thh', 'th', 'hh', 'thh', 'th', 'expression']],\n",
       " [['independence',\n",
       "   'notion',\n",
       "   'independence',\n",
       "   'carry',\n",
       "   'event',\n",
       "   'random_variable',\n",
       "   'well'],\n",
       "  ['random_variable',\n",
       "   'event',\n",
       "   'formulate',\n",
       "   'independence',\n",
       "   'random_variable',\n",
       "   'equiva',\n",
       "   'lend',\n",
       "   'perhaps',\n",
       "   'useful',\n",
       "   'way',\n",
       "   'random_variable',\n",
       "   'pr_pr',\n",
       "   'example',\n",
       "   'appropriate',\n",
       "   'choice',\n",
       "   'value',\n",
       "   'pr',\n",
       "   'first',\n",
       "   'probability',\n",
       "   'never',\n",
       "   'exactly',\n",
       "   'head',\n",
       "   'hand',\n",
       "   'let_pr',\n",
       "   'example',\n",
       "   'instance',\n",
       "   'simple',\n",
       "   'lemma_lemma'],\n",
       "  ['event_independent', 'iff', 'indicator', 'variable', 'inde', 'pendent'],\n",
       "  ['event', 'notion', 'independence', 'generalize', 'random_variable'],\n",
       "  ['definition'],\n",
       "  ['random_variable',\n",
       "   'consequence',\n",
       "   'definition',\n",
       "   'probability',\n",
       "   'subset',\n",
       "   'variable',\n",
       "   'take',\n",
       "   'particular',\n",
       "   'set',\n",
       "   'value',\n",
       "   'equal',\n",
       "   'product',\n",
       "   'probability',\n",
       "   'individual',\n",
       "   'variable',\n",
       "   'take',\n",
       "   'value'],\n",
       "  ['thus',\n",
       "   'example',\n",
       "   'pr',\n",
       "   'proof',\n",
       "   'base',\n",
       "   'sum',\n",
       "   'possible',\n",
       "   'value',\n",
       "   'random_variable'],\n",
       "  ['chapter_random_variable', 'distribution']],\n",
       " [['distribution', 'function', 'random_variable', 'map', 'outcome', 'value'],\n",
       "  ['often',\n",
       "   'random_variable',\n",
       "   'show',\n",
       "   'different',\n",
       "   'space',\n",
       "   'outcome',\n",
       "   'wind',\n",
       "   'behave',\n",
       "   'much',\n",
       "   'way',\n",
       "   'probability',\n",
       "   'give',\n",
       "   'value'],\n",
       "  ['hence',\n",
       "   'random_variable',\n",
       "   'different',\n",
       "   'probability_space',\n",
       "   'may',\n",
       "   'wind',\n",
       "   'probability',\n",
       "   'density_function'],\n",
       "  ['definition'],\n",
       "  ['let',\n",
       "   'example_suppose',\n",
       "   'roll',\n",
       "   'unbiased',\n",
       "   'independent',\n",
       "   'sided',\n",
       "   'dice'],\n",
       "  ['let'],\n",
       "  ['plot', 'probability', 'density_function'],\n",
       "  ['closely',\n",
       "   'related',\n",
       "   'concept',\n",
       "   'pdf',\n",
       "   'cumulative_distribution_function',\n",
       "   'cdf',\n",
       "   'random_variable',\n",
       "   'codomain',\n",
       "   'real_number'],\n",
       "  ['function',\n",
       "   'cdf',\n",
       "   'cdf',\n",
       "   'example',\n",
       "   'cumulative_distribution_function',\n",
       "   'random_variable',\n",
       "   'th',\n",
       "   'bar',\n",
       "   'cumulative_distribution_function',\n",
       "   'equal',\n",
       "   'sum',\n",
       "   'height',\n",
       "   'leftmost',\n",
       "   'pdf',\n",
       "   'figure'],\n",
       "  ['probability', 'density_function', 'sum', 'sided', 'dice'],\n",
       "  ['cdf', 'figure'],\n",
       "  ['cumulative_distribution_function', 'sum', 'sided', 'dice'],\n",
       "  ['chapter_random_variable', 'distribution', 'density_function'],\n",
       "  ['follow',\n",
       "   'definitions',\n",
       "   'pdf',\n",
       "   'cdf',\n",
       "   'cdf',\n",
       "   'pr',\n",
       "   'pdf',\n",
       "   'summary',\n",
       "   'pdf',\n",
       "   'one',\n",
       "   'really',\n",
       "   'interesting',\n",
       "   'thing',\n",
       "   'density_function',\n",
       "   'distribution',\n",
       "   'func_tion',\n",
       "   'many',\n",
       "   'random_variable',\n",
       "   'turn',\n",
       "   'pdf',\n",
       "   'cdf'],\n",
       "  ['word', 'even', 'pdf', 'fact', 'pdfs', 'common', 'give', 'special', 'name'],\n",
       "  ['exam_ple',\n",
       "   'important',\n",
       "   'distribution',\n",
       "   'computer_science',\n",
       "   'bernoulli',\n",
       "   'distribution',\n",
       "   'uniform',\n",
       "   'distribution',\n",
       "   'binomial_distribution'],\n",
       "  ['look', 'closely', 'common', 'distribution', 'several', 'section']],\n",
       " [['bernoulli',\n",
       "   'distributions',\n",
       "   'bernoulli',\n",
       "   'distribution',\n",
       "   'simplest',\n",
       "   'common',\n",
       "   'distribution',\n",
       "   'func_tion'],\n",
       "  ['distribution', 'function', 'indicator_random', 'vari', 'able'],\n",
       "  ['specifically',\n",
       "   'bernoulli',\n",
       "   'distribution',\n",
       "   'probability',\n",
       "   'density_function',\n",
       "   'form']],\n",
       " [['uniform', 'distribution']],\n",
       " [['definition',\n",
       "   'random_variable',\n",
       "   'take',\n",
       "   'possible',\n",
       "   'value',\n",
       "   'probability',\n",
       "   'say',\n",
       "   'uniform'],\n",
       "  ['sample_space',\n",
       "   'uniform',\n",
       "   'distribu',\n",
       "   'tion',\n",
       "   'pdf',\n",
       "   'form',\n",
       "   'uniform',\n",
       "   'distribution',\n",
       "   'arise',\n",
       "   'frequently',\n",
       "   'practice'],\n",
       "  ['example', 'number', 'roll', 'fair', 'die', 'uniform', 'set']],\n",
       " [['number',\n",
       "   'game',\n",
       "   'enough',\n",
       "   'definition',\n",
       "   'let',\n",
       "   'play',\n",
       "   'game',\n",
       "   'envelope'],\n",
       "  ['contain',\n",
       "   'teger',\n",
       "   'range',\n",
       "   'example',\n",
       "   'could',\n",
       "   'pick',\n",
       "   'envelope',\n",
       "   'random',\n",
       "   'guess',\n",
       "   'contain',\n",
       "   'large_number'],\n",
       "  ['strategy', 'win', 'time'],\n",
       "  ['challenge', 'better'],\n",
       "  ['may', 'try', 'clever'],\n",
       "  ['suppose', 'peek', 'envelope', 'see', 'number'],\n",
       "  ['small', 'number', 'may', 'guess', 'number', 'envelope', 'large'],\n",
       "  ['perhaps', 'tricky', 'put', 'small', 'number', 'envelope'],\n",
       "  ['guess',\n",
       "   'may',\n",
       "   'good',\n",
       "   'important',\n",
       "   'point',\n",
       "   'number',\n",
       "   'envelope',\n",
       "   'may',\n",
       "   'random'],\n",
       "  ['pick', 'number', 'choose_way', 'think', 'defeat', 'guess', 'strategy'],\n",
       "  ['use',\n",
       "   'randomization',\n",
       "   'choose',\n",
       "   'number',\n",
       "   'serve',\n",
       "   'purpose',\n",
       "   'make',\n",
       "   'lose',\n",
       "   'chapter_random_variable',\n",
       "   'distribution',\n",
       "   'intuition',\n",
       "   'win',\n",
       "   'strategy',\n",
       "   'amazingly',\n",
       "   'strategy',\n",
       "   'win',\n",
       "   'time',\n",
       "   'regardless',\n",
       "   'number',\n",
       "   'put',\n",
       "   'envelope',\n",
       "   'suppose',\n",
       "   'somehow',\n",
       "   'know',\n",
       "   'number',\n",
       "   'number',\n",
       "   'envelope'],\n",
       "  ['peek', 'envelope', 'see', 'number'],\n",
       "  ['big', 'know', 'peek', 'high', 'number'],\n",
       "  ['small', 'peek', 'low', 'number'],\n",
       "  ['word', 'know', 'number', 'number', 'envelop', 'certain', 'win', 'game'],\n",
       "  ['flaw', 'brilliant', 'strategy', 'know'],\n",
       "  ['try', 'guess', 'probability', 'guess', 'cor', 'rectly'],\n",
       "  ['case', 'win', 'time'],\n",
       "  ['hand', 'guess', 'incorrectly', 'bad', 'chance', 'win', 'still'],\n",
       "  ['combine',\n",
       "   'case',\n",
       "   'overall',\n",
       "   'chance',\n",
       "   'win',\n",
       "   'better',\n",
       "   'informal',\n",
       "   'argument',\n",
       "   'probability',\n",
       "   'often',\n",
       "   'sound',\n",
       "   'plausible',\n",
       "   'hold',\n",
       "   'close',\n",
       "   'scrutiny'],\n",
       "  ['contrast',\n",
       "   'argument',\n",
       "   'sound',\n",
       "   'completely',\n",
       "   'implausible',\n",
       "   'actually',\n",
       "   'correct',\n",
       "   'analysis',\n",
       "   'win',\n",
       "   'strategy',\n",
       "   'generality',\n",
       "   'suppose',\n",
       "   'choose',\n",
       "   'number',\n",
       "   'set',\n",
       "   'ng'],\n",
       "  ['call', 'low', 'number', 'high', 'number'],\n",
       "  ['goal', 'guess', 'number'],\n",
       "  ['avoid',\n",
       "   'confusing',\n",
       "   'equality',\n",
       "   'case',\n",
       "   'select',\n",
       "   'random',\n",
       "   'half',\n",
       "   'integer',\n",
       "   'probability',\n",
       "   'distribution',\n",
       "   'use',\n",
       "   'uniform',\n",
       "   'distribution',\n",
       "   'turn',\n",
       "   'best',\n",
       "   'bet'],\n",
       "  ['informal',\n",
       "   'justification',\n",
       "   'figure',\n",
       "   'unlikely',\n",
       "   'pick',\n",
       "   'number',\n",
       "   'say',\n",
       "   'select',\n",
       "   'number',\n",
       "   'peek',\n",
       "   'envelope',\n",
       "   'see',\n",
       "   'number'],\n",
       "  ['guess', 'look', 'large_number'],\n",
       "  ['guess', 'number', 'large'],\n",
       "  ['remain', 'determine', 'probability', 'strategy', 'succeed'],\n",
       "  ['usual', 'step_method', 'tree_diagram'],\n",
       "  ['step', 'find_sample_space'],\n",
       "  ['choose', 'low', 'high', 'right'],\n",
       "  ['peek', 'low', 'number', 'high', 'number'],\n",
       "  ['give', 'total', 'possible', 'outcome', 'show_figure', 'figure'],\n",
       "  ['tree_diagram', 'number', 'game'],\n",
       "  ['step_define', 'event_interest'],\n",
       "  ['outcome', 'event', 'win', 'marked', 'tree_diagram'],\n",
       "  ['step', 'assign', 'outcome_probability'],\n",
       "  ['first', 'assign', 'edge', 'probability'],\n",
       "  ['guess', 'low', 'probability', 'high', 'probability'],\n",
       "  ['right', 'probability'],\n",
       "  ['next', 'peek', 'low', 'high', 'number', 'equal', 'probability'],\n",
       "  ['multi', 'ply', 'root_leaf', 'path', 'give', 'outcome_probability'],\n",
       "  ['chapter_random_variable',\n",
       "   'distribution',\n",
       "   'step_compute',\n",
       "   'event_probability'],\n",
       "  ['probability_event',\n",
       "   'win',\n",
       "   'sum',\n",
       "   'probability_outcome',\n",
       "   'event',\n",
       "   'final',\n",
       "   'inequality',\n",
       "   'rely',\n",
       "   'fact',\n",
       "   'high',\n",
       "   'number',\n",
       "   'sure_enough',\n",
       "   'win',\n",
       "   'strategy',\n",
       "   'half',\n",
       "   'time',\n",
       "   'regardless',\n",
       "   'number',\n",
       "   'envelop',\n",
       "   'example',\n",
       "   'choose',\n",
       "   'number',\n",
       "   'range',\n",
       "   'better',\n",
       "   'allow',\n",
       "   'number',\n",
       "   'range']],\n",
       " [['randomized',\n",
       "   'algorithm',\n",
       "   'good',\n",
       "   'strategy',\n",
       "   'win',\n",
       "   'number',\n",
       "   'game',\n",
       "   'example',\n",
       "   'randomize',\n",
       "   'algo',\n",
       "   'rithm',\n",
       "   'use',\n",
       "   'random',\n",
       "   'number',\n",
       "   'influence',\n",
       "   'decision'],\n",
       "  ['protocol',\n",
       "   'algorithm',\n",
       "   'make',\n",
       "   'use',\n",
       "   'random',\n",
       "   'number',\n",
       "   'important',\n",
       "   'computer_science'],\n",
       "  ['many',\n",
       "   'problem',\n",
       "   'best',\n",
       "   'know',\n",
       "   'solution',\n",
       "   'base',\n",
       "   'random',\n",
       "   'num_ber',\n",
       "   'generator'],\n",
       "  ['example',\n",
       "   'commonly_use',\n",
       "   'protocol',\n",
       "   'decide',\n",
       "   'send',\n",
       "   'broadcast',\n",
       "   'share',\n",
       "   'bus',\n",
       "   'ethernet',\n",
       "   'randomize',\n",
       "   'algorithm',\n",
       "   'know',\n",
       "   'expo',\n",
       "   'nential',\n",
       "   'backoff'],\n",
       "  ['commonly_use',\n",
       "   'sort',\n",
       "   'algorithm',\n",
       "   'use',\n",
       "   'prac',\n",
       "   'tice',\n",
       "   'call',\n",
       "   'quicksort',\n",
       "   'use',\n",
       "   'random',\n",
       "   'number'],\n",
       "  ['see', 'many', 'example', 'take', 'algorithm', 'course'],\n",
       "  ['case',\n",
       "   'randomness',\n",
       "   'use',\n",
       "   'improve',\n",
       "   'probability',\n",
       "   'algorithm',\n",
       "   'run',\n",
       "   'quickly',\n",
       "   'otherwise',\n",
       "   'perform',\n",
       "   'well']],\n",
       " [['binomial_distribution']],\n",
       " [['definition',\n",
       "   'third',\n",
       "   'commonly_use',\n",
       "   'distribution',\n",
       "   'computer_science',\n",
       "   'binomial',\n",
       "   'distri',\n",
       "   'bution'],\n",
       "  ['standard',\n",
       "   'example',\n",
       "   'random_variable',\n",
       "   'binomial_distribution',\n",
       "   'number_head',\n",
       "   'come',\n",
       "   'figure'],\n",
       "  ['pdf',\n",
       "   'unbiased',\n",
       "   'binomial_distribution',\n",
       "   'fair',\n",
       "   'number_head',\n",
       "   'unbiase',\n",
       "   'binomial_distribution',\n",
       "   'specify',\n",
       "   'pdf',\n",
       "   'plot',\n",
       "   'cumulative_distribution_function',\n",
       "   'unbiase',\n",
       "   'binomial_distribution',\n",
       "   'chapter_random_variable',\n",
       "   'distribution',\n",
       "   'figure'],\n",
       "  ['pdf',\n",
       "   'general',\n",
       "   'binomial_distribution',\n",
       "   'general',\n",
       "   'binomial_distribution',\n",
       "   'coin',\n",
       "   'bias',\n",
       "   'coin',\n",
       "   'head',\n",
       "   'probability',\n",
       "   'correspond',\n",
       "   'flip',\n",
       "   'independent',\n",
       "   'coin',\n",
       "   'head',\n",
       "   'probability',\n",
       "   'cumulative_distribution_function',\n",
       "   'general',\n",
       "   'binomial_distribution']],\n",
       " [['approximate',\n",
       "   'probability',\n",
       "   'density_function',\n",
       "   'compute',\n",
       "   'general',\n",
       "   'binomial',\n",
       "   'density_function',\n",
       "   'daunt',\n",
       "   'lemma'],\n",
       "  ['differ',\n",
       "   'graph',\n",
       "   'lemma',\n",
       "   'fac',\n",
       "   'torial',\n",
       "   'binomial',\n",
       "   'coefficient',\n",
       "   'simplifying'],\n",
       "  ['let', 'plug', 'equation', 'general', 'binomial', 'density_function'],\n",
       "  ['probability', 'flipping', 'log'],\n",
       "  ['means', 'log', 'chapter_random_variable', 'distribution'],\n",
       "  ['figure'],\n",
       "  ['entropy', 'function', 'probability'],\n",
       "  ['margin',\n",
       "   'error',\n",
       "   'approximation',\n",
       "   'lemma',\n",
       "   'formula',\n",
       "   'equation',\n",
       "   'ugly',\n",
       "   'bowl',\n",
       "   'shoe',\n",
       "   'useful',\n",
       "   'easy',\n",
       "   'evaluate'],\n",
       "  ['example_suppose', 'flip_fair_coin', 'time'],\n",
       "  ['probability_get', 'exactly', 'pn', 'head', 'plug'],\n",
       "  ['binomial_distribution', 'thus', 'example', 'flip_fair_coin']],\n",
       " [['approximate',\n",
       "   'cumulative_distribution_function',\n",
       "   'many',\n",
       "   'field',\n",
       "   'include',\n",
       "   'computer_science',\n",
       "   'probability',\n",
       "   'analysis',\n",
       "   'come',\n",
       "   'ting',\n",
       "   'small',\n",
       "   'bound',\n",
       "   'tail',\n",
       "   'binomial_distribution'],\n",
       "  ['typical',\n",
       "   'application',\n",
       "   'want',\n",
       "   'bind',\n",
       "   'tail',\n",
       "   'order',\n",
       "   'show',\n",
       "   'small',\n",
       "   'probability',\n",
       "   'many',\n",
       "   'bad',\n",
       "   'thing',\n",
       "   'happen'],\n",
       "  ['example',\n",
       "   'may',\n",
       "   'know',\n",
       "   'unlikely',\n",
       "   'many',\n",
       "   'bit',\n",
       "   'corrupt',\n",
       "   'message',\n",
       "   'many',\n",
       "   'server',\n",
       "   'communication',\n",
       "   'link',\n",
       "   'become',\n",
       "   'overloaded',\n",
       "   'randomized',\n",
       "   'algorithm',\n",
       "   'run',\n",
       "   'long'],\n",
       "  ['usually', 'good_news', 'binomial_distribution', 'small', 'tail'],\n",
       "  ['feel',\n",
       "   'size',\n",
       "   'consider',\n",
       "   'probability',\n",
       "   'flip',\n",
       "   'head',\n",
       "   'independent',\n",
       "   'toss',\n",
       "   'fair_coin'],\n",
       "  ['probability_get', 'bind', 'sum', 'bound', 'ratio', 'successive', 'term'],\n",
       "  ['particular',\n",
       "   'chapter_random_variable',\n",
       "   'distribution',\n",
       "   'probability',\n",
       "   'exactly',\n",
       "   'head'],\n",
       "  ['scenario',\n",
       "   'plug',\n",
       "   'equation',\n",
       "   'say',\n",
       "   'flip',\n",
       "   'few',\n",
       "   'head',\n",
       "   'extremely',\n",
       "   'unlikely',\n",
       "   'consis',\n",
       "   'tent',\n",
       "   'early',\n",
       "   'claim',\n",
       "   'tail',\n",
       "   'binomial_distribution',\n",
       "   'small'],\n",
       "  ['fact',\n",
       "   'notice',\n",
       "   'probability',\n",
       "   'flip',\n",
       "   'few',\n",
       "   'head',\n",
       "   'probability',\n",
       "   'flip',\n",
       "   'exactly',\n",
       "   'head'],\n",
       "  ['thus',\n",
       "   'flip',\n",
       "   'exactly',\n",
       "   'head',\n",
       "   'twice',\n",
       "   'likely',\n",
       "   'flipping',\n",
       "   'number',\n",
       "   'caveat'],\n",
       "  ['upper', 'bound', 'hold'],\n",
       "  ['case',\n",
       "   'problem',\n",
       "   'try',\n",
       "   'think',\n",
       "   'complementary',\n",
       "   'term',\n",
       "   'look',\n",
       "   'number',\n",
       "   'tail',\n",
       "   'flip',\n",
       "   'instead',\n",
       "   'number_head'],\n",
       "  ['fact', 'precisely', 'next', 'example']],\n",
       " [['noisy',\n",
       "   'channel',\n",
       "   'suppose',\n",
       "   'send',\n",
       "   'packet',\n",
       "   'datum',\n",
       "   'communication',\n",
       "   'channel',\n",
       "   'packet',\n",
       "   'lose',\n",
       "   'probability'],\n",
       "  ['also', 'suppose', 'packet', 'loss', 'independent'],\n",
       "  ['need',\n",
       "   'figure',\n",
       "   'much',\n",
       "   'redundancy',\n",
       "   'error',\n",
       "   'correction',\n",
       "   'build',\n",
       "   'communication',\n",
       "   'protocol'],\n",
       "  ['redundancy',\n",
       "   'expensive',\n",
       "   'overheard',\n",
       "   'would',\n",
       "   'like',\n",
       "   'use',\n",
       "   'little',\n",
       "   'possible'],\n",
       "  ['hand', 'never', 'want', 'catch', 'short'],\n",
       "  ['would', 'safe', 'assume', 'batch', 'packet', 'lose', 'let', 'find'],\n",
       "  ['noisy',\n",
       "   'channel',\n",
       "   'analogous',\n",
       "   'flip',\n",
       "   'independent',\n",
       "   'coin',\n",
       "   'probability',\n",
       "   'come',\n",
       "   'head',\n",
       "   'ask',\n",
       "   'probability',\n",
       "   'least',\n",
       "   'head'],\n",
       "  ['can',\n",
       "   'use',\n",
       "   'equa',\n",
       "   'tion',\n",
       "   'use',\n",
       "   'equation',\n",
       "   'find',\n",
       "   'probability_lose',\n",
       "   'good_news'],\n",
       "  ['say',\n",
       "   'plan',\n",
       "   'packet',\n",
       "   'loss',\n",
       "   'batch',\n",
       "   'packet',\n",
       "   'safe',\n",
       "   'least',\n",
       "   'next',\n",
       "   'millennia']],\n",
       " [['estimation',\n",
       "   'sampling',\n",
       "   'sample',\n",
       "   'common',\n",
       "   'technique',\n",
       "   'estimate',\n",
       "   'fraction',\n",
       "   'element_set',\n",
       "   'certain',\n",
       "   'property'],\n",
       "  ['example_suppose',\n",
       "   'would',\n",
       "   'know',\n",
       "   'many',\n",
       "   'americans',\n",
       "   'plan',\n",
       "   'vote_republican',\n",
       "   'candidate',\n",
       "   'next',\n",
       "   'presidential',\n",
       "   'election'],\n",
       "  ['infeasible',\n",
       "   'ask',\n",
       "   'american',\n",
       "   'intend_vote',\n",
       "   'pollster',\n",
       "   'typically',\n",
       "   'contact',\n",
       "   'americans',\n",
       "   'select',\n",
       "   'random',\n",
       "   'compute',\n",
       "   'fraction',\n",
       "   'americans',\n",
       "   'vote_republican'],\n",
       "  ['value', 'use', 'estimate', 'number', 'americans', 'vote_republican'],\n",
       "  ['example',\n",
       "   'contact',\n",
       "   'voter',\n",
       "   'report',\n",
       "   'vote_republican',\n",
       "   'pollster',\n",
       "   'report',\n",
       "   'americans',\n",
       "   'vote_republican'],\n",
       "  ['addition',\n",
       "   'pollster',\n",
       "   'usually',\n",
       "   'also',\n",
       "   'provide',\n",
       "   'sort',\n",
       "   'qualify',\n",
       "   'statement',\n",
       "   'qualifying',\n",
       "   'statement',\n",
       "   'often',\n",
       "   'source',\n",
       "   'confusion'],\n",
       "  ['example',\n",
       "   'many',\n",
       "   'people',\n",
       "   'interpret',\n",
       "   'qualifying',\n",
       "   'statement',\n",
       "   'mean',\n",
       "   'chance',\n",
       "   'americans',\n",
       "   'intend_vote_republican'],\n",
       "  ['wrong',\n",
       "   'fraction',\n",
       "   'americans',\n",
       "   'intend_vote_republican',\n",
       "   'fix',\n",
       "   'unknown',\n",
       "   'value',\n",
       "   'random_variable'],\n",
       "  ['random_variable', 'can', 'say', 'probability'],\n",
       "  ['chapter_random_variable',\n",
       "   'distribution',\n",
       "   'obtain',\n",
       "   'correct',\n",
       "   'interpretation',\n",
       "   'qualify',\n",
       "   'statement',\n",
       "   'result',\n",
       "   'poll',\n",
       "   'helpful',\n",
       "   'introduce',\n",
       "   'notation'],\n",
       "  ['define', 'contacted', 'american', 'sample'],\n",
       "  ['particular',\n",
       "   'set',\n",
       "   'contacted',\n",
       "   'american',\n",
       "   'intend_vote_republican',\n",
       "   'th',\n",
       "   'contacted',\n",
       "   'american',\n",
       "   'select',\n",
       "   'uniformly',\n",
       "   'random',\n",
       "   'replacement',\n",
       "   'set',\n",
       "   'americans'],\n",
       "  ['also',\n",
       "   'assume',\n",
       "   'contacted',\n",
       "   'person',\n",
       "   'respond',\n",
       "   'honestly',\n",
       "   'intend_vote_republican',\n",
       "   'options',\n",
       "   'american',\n",
       "   'intend_vote_republican'],\n",
       "  ['thus',\n",
       "   'next',\n",
       "   'define',\n",
       "   'number',\n",
       "   'contact',\n",
       "   'americans',\n",
       "   'intend_vote_republican'],\n",
       "  ['random_variable',\n",
       "   'estimate',\n",
       "   'fraction',\n",
       "   'americans',\n",
       "   'intend_vote_republican'],\n",
       "  ['ready',\n",
       "   'provide',\n",
       "   'correct',\n",
       "   'interpretation',\n",
       "   'qualify',\n",
       "   'state',\n",
       "   'ment'],\n",
       "  ['poll',\n",
       "   'result',\n",
       "   'mean',\n",
       "   'word',\n",
       "   'chance',\n",
       "   'sample',\n",
       "   'group',\n",
       "   'produce',\n",
       "   'esti',\n",
       "   'mate',\n",
       "   'many',\n",
       "   'people',\n",
       "   'need',\n",
       "   'contact',\n",
       "   'remain',\n",
       "   'important',\n",
       "   'question',\n",
       "   'many',\n",
       "   'people',\n",
       "   'true',\n",
       "   'general',\n",
       "   'would',\n",
       "   'like',\n",
       "   'surprisingly',\n",
       "   'answer',\n",
       "   'depend',\n",
       "   'desire',\n",
       "   'accuracy',\n",
       "   'confidence',\n",
       "   'poll',\n",
       "   'number',\n",
       "   'item_set',\n",
       "   'sample'],\n",
       "  ['case', 'desire', 'accuracy'],\n",
       "  ['desire', 'confidence'],\n",
       "  ['set', 'sampled', 'set', 'american'],\n",
       "  ['good', 'thing', 'mean', 'could', 'contact', 'multiple', 'time'],\n",
       "  ['task',\n",
       "   'finding',\n",
       "   'make',\n",
       "   'tractable',\n",
       "   'observ',\n",
       "   'ing',\n",
       "   'use',\n",
       "   'bound',\n",
       "   'tail',\n",
       "   'binomial_distribution',\n",
       "   'first',\n",
       "   'standard',\n",
       "   'conversion',\n",
       "   'pr',\n",
       "   'proceed',\n",
       "   'upper_bind',\n",
       "   'know',\n",
       "   'true',\n",
       "   'value',\n",
       "   'maximize'],\n",
       "  ['second_line',\n",
       "   'come',\n",
       "   'equation',\n",
       "   'use',\n",
       "   'equation',\n",
       "   'provide',\n",
       "   'bound',\n",
       "   'confidence',\n",
       "   'poll',\n",
       "   'different',\n",
       "   'value',\n",
       "   'evaluate',\n",
       "   'percentage',\n",
       "   'point',\n",
       "   'least',\n",
       "   'probability'],\n",
       "  ['bind', 'equation', 'exponential']],\n",
       " [['expectation']],\n",
       " [['definition',\n",
       "   'example',\n",
       "   'expectation',\n",
       "   'expect_value',\n",
       "   'random_variable',\n",
       "   'single',\n",
       "   'number',\n",
       "   'tell',\n",
       "   'lot',\n",
       "   'behavior',\n",
       "   'variable'],\n",
       "  ['roughly',\n",
       "   'expectation',\n",
       "   'average',\n",
       "   'value',\n",
       "   'random_variable',\n",
       "   'value',\n",
       "   'weight',\n",
       "   'accord',\n",
       "   'probability'],\n",
       "  ['formally',\n",
       "   'expect_value',\n",
       "   'also',\n",
       "   'know',\n",
       "   'average',\n",
       "   'mean',\n",
       "   'random_variable',\n",
       "   'define',\n",
       "   'follow'],\n",
       "  ['definition'],\n",
       "  ['example_suppose',\n",
       "   'set',\n",
       "   'student',\n",
       "   'class',\n",
       "   'select',\n",
       "   'student',\n",
       "   'uniformly',\n",
       "   'random'],\n",
       "  ['let', 'let', 'work', 'example']],\n",
       " [['expect_value',\n",
       "   'uniform',\n",
       "   'random_variable',\n",
       "   'let',\n",
       "   'ex',\n",
       "   'calculation',\n",
       "   'show',\n",
       "   'name',\n",
       "   'expect_value',\n",
       "   'little',\n",
       "   'misleading',\n",
       "   'random_variable',\n",
       "   'may',\n",
       "   'never',\n",
       "   'actually',\n",
       "   'take',\n",
       "   'value'],\n",
       "  ['ever',\n",
       "   'expect',\n",
       "   'roll',\n",
       "   'also',\n",
       "   'note',\n",
       "   'mean',\n",
       "   'random_variable',\n",
       "   'median'],\n",
       "  ['median', 'midpoint', 'distribution'],\n",
       "  ['definition'],\n",
       "  ['median',\n",
       "   'random_variable',\n",
       "   'text',\n",
       "   'define',\n",
       "   'median',\n",
       "   'value',\n",
       "   'chapter_expectation',\n",
       "   'text',\n",
       "   'devote',\n",
       "   'much',\n",
       "   'attention',\n",
       "   'median'],\n",
       "  ['rather', 'focus', 'expect_value', 'much', 'interesting', 'useful'],\n",
       "  ['roll', 'sided', 'die', 'provide', 'example', 'uniform', 'random_variable'],\n",
       "  ['general']],\n",
       " [['expect_value',\n",
       "   'indicator_random_variable',\n",
       "   'expect_value',\n",
       "   'indicator_random_variable',\n",
       "   'event',\n",
       "   'proba',\n",
       "   'bility',\n",
       "   'event'],\n",
       "  ['lemma'],\n",
       "  ['ex', 'proof'],\n",
       "  ['ex_pr', 'pr', 'example']],\n",
       " [['alternate',\n",
       "   'definition',\n",
       "   'several',\n",
       "   'equivalent',\n",
       "   'way',\n",
       "   'define',\n",
       "   'expectation'],\n",
       "  ['theorem'],\n",
       "  ['proof_theorem', 'first', 'equality', 'follow', 'event', 'sum'],\n",
       "  ['general',\n",
       "   'equation',\n",
       "   'useful',\n",
       "   'equation',\n",
       "   'calculate',\n",
       "   'ex',\n",
       "   'pecte',\n",
       "   'value',\n",
       "   'advantage',\n",
       "   'depend',\n",
       "   'sample_space',\n",
       "   'density_function',\n",
       "   'random_variable'],\n",
       "  ['especially',\n",
       "   'useful',\n",
       "   'range',\n",
       "   'random_variable',\n",
       "   'see',\n",
       "   'follow',\n",
       "   'corollary'],\n",
       "  ['corollary'],\n",
       "  ['range', 'random_variable', 'proof'],\n",
       "  ['first',\n",
       "   'equality',\n",
       "   'follow',\n",
       "   'directly',\n",
       "   'theorem',\n",
       "   'fact',\n",
       "   'range',\n",
       "   'pr',\n",
       "   'chapter_expectation']],\n",
       " [['mean_time_failure',\n",
       "   'mean_time_failure',\n",
       "   'critical',\n",
       "   'parameter',\n",
       "   'design',\n",
       "   'system'],\n",
       "  ['example_suppose',\n",
       "   'computer',\n",
       "   'program',\n",
       "   'crash',\n",
       "   'end',\n",
       "   'hour',\n",
       "   'use',\n",
       "   'probability',\n",
       "   'let',\n",
       "   'determine',\n",
       "   'pr',\n",
       "   'hour',\n",
       "   'iff',\n",
       "   'system',\n",
       "   'crash',\n",
       "   'first',\n",
       "   'give',\n",
       "   'example',\n",
       "   'chance',\n",
       "   'program',\n",
       "   'crash',\n",
       "   'end',\n",
       "   'hour',\n",
       "   'expect',\n",
       "   'time',\n",
       "   'program',\n",
       "   'crash',\n",
       "   'general',\n",
       "   'principle',\n",
       "   'well',\n",
       "   'worth',\n",
       "   'remember',\n",
       "   'system',\n",
       "   'fail',\n",
       "   'time',\n",
       "   'step',\n",
       "   'probability',\n",
       "   'make',\n",
       "   'baby',\n",
       "   'relate',\n",
       "   'example_suppose',\n",
       "   'couple',\n",
       "   'really',\n",
       "   'want',\n",
       "   'baby',\n",
       "   'girl'],\n",
       "  ['sim',\n",
       "   'plicity',\n",
       "   'assume',\n",
       "   'chance',\n",
       "   'child',\n",
       "   'girl',\n",
       "   'gender',\n",
       "   'child',\n",
       "   'mutually_independent'],\n",
       "  ['couple',\n",
       "   'insist',\n",
       "   'child',\n",
       "   'get',\n",
       "   'girl',\n",
       "   'many',\n",
       "   'baby',\n",
       "   'boy',\n",
       "   'expect',\n",
       "   'first',\n",
       "   'question',\n",
       "   'many',\n",
       "   'hour',\n",
       "   'program',\n",
       "   'crash',\n",
       "   'mathematically',\n",
       "   'question',\n",
       "   'many',\n",
       "   'child',\n",
       "   'must',\n",
       "   'couple',\n",
       "   'girl',\n",
       "   'case',\n",
       "   'crash',\n",
       "   'correspond',\n",
       "   'girl',\n",
       "   'set'],\n",
       "  ['precede', 'analysis', 'couple', 'expect', 'baby', 'girl', 'child'],\n",
       "  ['last', 'girl', 'expect', 'boy']],\n",
       " [['deal', 'infinity', 'analysis', 'mean_time_failure', 'easy', 'enough'],\n",
       "  ['think',\n",
       "   'may',\n",
       "   'start',\n",
       "   'wonder',\n",
       "   'case',\n",
       "   'computer',\n",
       "   'program',\n",
       "   'never',\n",
       "   'fail'],\n",
       "  ['example',\n",
       "   'program',\n",
       "   'run',\n",
       "   'forever',\n",
       "   'handle',\n",
       "   'outcome',\n",
       "   'infinite',\n",
       "   'value',\n",
       "   'good',\n",
       "   'question',\n",
       "   'wonder'],\n",
       "  ['indeed',\n",
       "   'mathemati',\n",
       "   'cian',\n",
       "   'go',\n",
       "   'lot',\n",
       "   'work',\n",
       "   'reason',\n",
       "   'sample_space',\n",
       "   'infinite',\n",
       "   'number',\n",
       "   'outcome',\n",
       "   'outcome',\n",
       "   'infinite',\n",
       "   'value'],\n",
       "  ['keep',\n",
       "   'matter',\n",
       "   'simple',\n",
       "   'text',\n",
       "   'follow',\n",
       "   'common',\n",
       "   'convention',\n",
       "   'ignore',\n",
       "   'contribution',\n",
       "   'outcome_probability',\n",
       "   'computing',\n",
       "   'expect_value'],\n",
       "  ['mean', 'safely', 'ignore', 'never', 'fail', 'outcome_probability', 'lim'],\n",
       "  ['general',\n",
       "   'computing',\n",
       "   'expectation',\n",
       "   'infinite',\n",
       "   'sample_space',\n",
       "   'generally',\n",
       "   'focus',\n",
       "   'attention',\n",
       "   'subset',\n",
       "   'outcome',\n",
       "   'occur',\n",
       "   'collec',\n",
       "   'tive',\n",
       "   'probability'],\n",
       "  ['part',\n",
       "   'allow',\n",
       "   'ignore',\n",
       "   'infinite',\n",
       "   'outcome',\n",
       "   'typically',\n",
       "   'happen',\n",
       "   'probability'],\n",
       "  ['assumption',\n",
       "   'mean',\n",
       "   'expect_value',\n",
       "   'random_variable',\n",
       "   'always',\n",
       "   'finite',\n",
       "   'however'],\n",
       "  ['indeed', 'many', 'example', 'expect_value', 'infinite'],\n",
       "  ['infinity', 'raise', 'ugly', 'head', 'trouble', 'sure', 'follow'],\n",
       "  ['let_see', 'example']],\n",
       " [['pitfall',\n",
       "   'computing',\n",
       "   'expectation',\n",
       "   'sample',\n",
       "   'suppose',\n",
       "   'try',\n",
       "   'estimate',\n",
       "   'parameter',\n",
       "   'average',\n",
       "   'delay',\n",
       "   'communication',\n",
       "   'channel'],\n",
       "  ['set',\n",
       "   'experiment',\n",
       "   'measure',\n",
       "   'long',\n",
       "   'take',\n",
       "   'send',\n",
       "   'test',\n",
       "   'packet',\n",
       "   'end',\n",
       "   'run',\n",
       "   'experiment',\n",
       "   'time'],\n",
       "  ['record',\n",
       "   'latency',\n",
       "   'round',\n",
       "   'near',\n",
       "   'millisecond',\n",
       "   'hun',\n",
       "   'dre',\n",
       "   'experiment',\n",
       "   'compute',\n",
       "   'average',\n",
       "   'measurement'],\n",
       "  ['suppose', 'average'],\n",
       "  ['ms'],\n",
       "  ['careful', 'repeat', 'entire', 'process', 'twice', 'get', 'aver', 'age'],\n",
       "  ['ms'],\n",
       "  ['ms'],\n",
       "  ['conclude',\n",
       "   'average',\n",
       "   'latency',\n",
       "   'channel',\n",
       "   'still',\n",
       "   'bother',\n",
       "   'may',\n",
       "   'consider',\n",
       "   'take',\n",
       "   'course',\n",
       "   'measure',\n",
       "   'theory'],\n",
       "  ['chapter_expectation',\n",
       "   'probability',\n",
       "   'sort',\n",
       "   'reason',\n",
       "   'calculation',\n",
       "   'expect_value',\n",
       "   'average',\n",
       "   'ex',\n",
       "   'perimental',\n",
       "   'value',\n",
       "   'common',\n",
       "   'practice'],\n",
       "  ['easily', 'lead', 'incorrect', 'con', 'clusion', 'however'],\n",
       "  ['example',\n",
       "   'use',\n",
       "   'corollary',\n",
       "   'ex_pr',\n",
       "   'expect',\n",
       "   'time',\n",
       "   'cross',\n",
       "   'communication',\n",
       "   'channel',\n",
       "   'infinite',\n",
       "   'result',\n",
       "   'far',\n",
       "   'cry',\n",
       "   'ms',\n",
       "   'calculate'],\n",
       "  ['go_wrong',\n",
       "   'true',\n",
       "   'time',\n",
       "   'value',\n",
       "   'large',\n",
       "   'happen',\n",
       "   'sufficient',\n",
       "   'probability',\n",
       "   'expect_value',\n",
       "   'general',\n",
       "   'good',\n",
       "   'way',\n",
       "   'compute',\n",
       "   'expect_value',\n",
       "   'practice',\n",
       "   'first',\n",
       "   'use',\n",
       "   'experimental',\n",
       "   'data',\n",
       "   'figure',\n",
       "   'distribution',\n",
       "   'good',\n",
       "   'use',\n",
       "   'theorem',\n",
       "   'corollary',\n",
       "   'compute',\n",
       "   'expectation'],\n",
       "  ['method',\n",
       "   'help',\n",
       "   'identify',\n",
       "   'case',\n",
       "   'expectation',\n",
       "   'infinite',\n",
       "   'generally',\n",
       "   'accurate',\n",
       "   'simple',\n",
       "   'averaging',\n",
       "   'datum']],\n",
       " [['conditional',\n",
       "   'expectation',\n",
       "   'event_probability',\n",
       "   'expectation',\n",
       "   'condition',\n",
       "   'event'],\n",
       "  ['give', 'random_variable', 'definition'],\n",
       "  ['conditional', 'expectation', 'ex_ex', 'pr', 'range'],\n",
       "  ['example',\n",
       "   'compute',\n",
       "   'expect_value',\n",
       "   'roll',\n",
       "   'fair',\n",
       "   'die',\n",
       "   'give',\n",
       "   'example',\n",
       "   'number',\n",
       "   'roll',\n",
       "   'least'],\n",
       "  ['let',\n",
       "   'ex_pr',\n",
       "   'example_consider',\n",
       "   'channel',\n",
       "   'latency',\n",
       "   'problem_section',\n",
       "   'chapter_expectation',\n",
       "   'expect',\n",
       "   'latency',\n",
       "   'condition',\n",
       "   'latency',\n",
       "   'exceed',\n",
       "   'ex_pr']],\n",
       " [['law_total',\n",
       "   'expectation',\n",
       "   'useful',\n",
       "   'feature',\n",
       "   'conditional',\n",
       "   'expectation',\n",
       "   'let',\n",
       "   'divide',\n",
       "   'compli',\n",
       "   'cat',\n",
       "   'expectation',\n",
       "   'calculation',\n",
       "   'simple',\n",
       "   'case'],\n",
       "  ['find',\n",
       "   'desire',\n",
       "   'expectation',\n",
       "   'calculate',\n",
       "   'conditional',\n",
       "   'expectation',\n",
       "   'simple',\n",
       "   'case',\n",
       "   'av',\n",
       "   'erage',\n",
       "   'weigh',\n",
       "   'case',\n",
       "   'probability'],\n",
       "  ['example_suppose'],\n",
       "  ['people', 'world', 'male', 'rest', 'female', 'less', 'true'],\n",
       "  ['also',\n",
       "   'suppose',\n",
       "   'expect',\n",
       "   'height',\n",
       "   'randomly',\n",
       "   'choose',\n",
       "   'male',\n",
       "   'ex',\n",
       "   'little',\n",
       "   'less'],\n",
       "  ['method', 'justify', 'law_total', 'expectation'],\n",
       "  ['theorem'],\n",
       "  ['law_total', 'expectation'],\n",
       "  ['let', 'ex_ex', 'range'],\n",
       "  ['pr_pr', 'cond'],\n",
       "  ['expectation',\n",
       "   'interesting',\n",
       "   'application',\n",
       "   'law_total',\n",
       "   'expectation',\n",
       "   'let',\n",
       "   'take',\n",
       "   'look',\n",
       "   'mean_time_failure',\n",
       "   'system',\n",
       "   'fail',\n",
       "   'probability',\n",
       "   'complementary',\n",
       "   'event',\n",
       "   'namely',\n",
       "   'system',\n",
       "   'fail',\n",
       "   'first_step'],\n",
       "  ['mean_time_failure', 'ex', 'plug', 'equation', 'equation', 'ex'],\n",
       "  ['ex_ex', 'rearranging', 'term', 'find', 'ex_ex', 'thus', 'ex', 'expect'],\n",
       "  ['use',\n",
       "   'sort',\n",
       "   'analysis',\n",
       "   'extensively',\n",
       "   'chapter',\n",
       "   'examine',\n",
       "   'expect',\n",
       "   'behavior',\n",
       "   'random_walk']],\n",
       " [['expectation',\n",
       "   'function',\n",
       "   'expectation',\n",
       "   'also',\n",
       "   'define_function',\n",
       "   'random_variable'],\n",
       "  ['definition'],\n",
       "  ['let', 'example_suppose']],\n",
       " [['expect_return',\n",
       "   'gamble',\n",
       "   'game',\n",
       "   'interesting',\n",
       "   'example',\n",
       "   'expectation',\n",
       "   'explain',\n",
       "   'term',\n",
       "   'gambling_game'],\n",
       "  ['straightforward', 'games', 'win', 'pa'],\n",
       "  ['example',\n",
       "   'flip_fair_coin',\n",
       "   'win',\n",
       "   'head',\n",
       "   'lose',\n",
       "   'tail',\n",
       "   'expect',\n",
       "   'winnings',\n",
       "   'chapter_expectation',\n",
       "   'case',\n",
       "   'game',\n",
       "   'say',\n",
       "   'fair',\n",
       "   'expect_return'],\n",
       "  ['gambling_game', 'complicate', 'thus', 'interesting'],\n",
       "  ['example_consider', 'follow', 'game', 'winner', 'split', 'pot'],\n",
       "  ['sort',\n",
       "   'game',\n",
       "   'representative',\n",
       "   'many',\n",
       "   'poker',\n",
       "   'game',\n",
       "   'bet',\n",
       "   'pool',\n",
       "   'lottery']],\n",
       " [['splitting',\n",
       "   'pot',\n",
       "   'last',\n",
       "   'encounter',\n",
       "   'biker_dude',\n",
       "   'thing',\n",
       "   'lead',\n",
       "   'drop',\n",
       "   'school',\n",
       "   'become',\n",
       "   'hell',\n",
       "   'angel'],\n",
       "  ['late',\n",
       "   'friday',\n",
       "   'night',\n",
       "   'feel',\n",
       "   'nostalgic',\n",
       "   'old',\n",
       "   'day',\n",
       "   'drop',\n",
       "   'old',\n",
       "   'hangout',\n",
       "   'counter',\n",
       "   'former',\n",
       "   'tas',\n",
       "   'eric',\n",
       "   'nick'],\n",
       "  ['eric', 'nick', 'propose', 'join', 'simple', 'wager'],\n",
       "  ['player', 'put', 'bar', 'secretly', 'write', 'head', 'tail', 'napkin'],\n",
       "  ['player', 'flip_fair_coin'],\n",
       "  ['bar',\n",
       "   'divide',\n",
       "   'equally',\n",
       "   'player',\n",
       "   'correctly',\n",
       "   'predict',\n",
       "   'outcome',\n",
       "   'coin',\n",
       "   'toss'],\n",
       "  ['life', 'altering', 'encounter', 'strange_dice', 'little', 'skeptical'],\n",
       "  ['eric', 'nick', 'agree', 'let', 'flip', 'coin'],\n",
       "  ['certainly', 'seem', 'fair'],\n",
       "  ['lose',\n",
       "   'learn',\n",
       "   'lesson',\n",
       "   'agree',\n",
       "   'go',\n",
       "   'step_method',\n",
       "   'write',\n",
       "   'tree_diagram',\n",
       "   'compute',\n",
       "   'expect_return'],\n",
       "  ['tree_diagram',\n",
       "   'show_figure',\n",
       "   'payoff',\n",
       "   'value',\n",
       "   'figure',\n",
       "   'compute',\n",
       "   'divide',\n",
       "   'pot',\n",
       "   'player',\n",
       "   'guess',\n",
       "   'correctly',\n",
       "   'subtract',\n",
       "   'put',\n",
       "   'pot',\n",
       "   'beginning'],\n",
       "  ['example',\n",
       "   'player',\n",
       "   'guess',\n",
       "   'correctly',\n",
       "   'payoff',\n",
       "   'get',\n",
       "   'back',\n",
       "   'wager'],\n",
       "  ['nick',\n",
       "   'guess',\n",
       "   'correctly',\n",
       "   'eric',\n",
       "   'guess',\n",
       "   'wrong',\n",
       "   'payoff',\n",
       "   'case',\n",
       "   'wrong',\n",
       "   'agree',\n",
       "   'split',\n",
       "   'pot',\n",
       "   'payoff'],\n",
       "  ['compute',\n",
       "   'expect_return',\n",
       "   'use',\n",
       "   'equation',\n",
       "   'definition',\n",
       "   'expect_value'],\n",
       "  ['yield', 'money', 'invest', 'wager', 'commonly', 'refer', 'pot'],\n",
       "  ['figure'],\n",
       "  ['tree_diagram',\n",
       "   'game',\n",
       "   'player',\n",
       "   'wager',\n",
       "   'guess',\n",
       "   'outcome',\n",
       "   'fair_coin',\n",
       "   'toss'],\n",
       "  ['winner', 'split', 'pot'],\n",
       "  ['chapter_expectation', 'confirm', 'game', 'fair'],\n",
       "  ['old',\n",
       "   'time',\n",
       "   'sake',\n",
       "   'break',\n",
       "   'solemn',\n",
       "   'vow',\n",
       "   'never',\n",
       "   'ever',\n",
       "   'engage',\n",
       "   'strange',\n",
       "   'gambling_game']],\n",
       " [['impact', 'collusion', 'needless', 'say', 'thing', 'turn', 'well'],\n",
       "  ['time', 'play', 'game', 'money', 'seem', 'lose'],\n",
       "  ['wager', 'lose'],\n",
       "  ['nick_eric',\n",
       "   'consoling',\n",
       "   'bad',\n",
       "   'luck',\n",
       "   'back',\n",
       "   'calculation',\n",
       "   'use',\n",
       "   'bound',\n",
       "   'tail',\n",
       "   'binomial_distribution',\n",
       "   'section',\n",
       "   'suggest',\n",
       "   'probability_lose',\n",
       "   'wager',\n",
       "   'less',\n",
       "   'probability',\n",
       "   'vietnamese',\n",
       "   'monk',\n",
       "   'waltz',\n",
       "   'hand',\n",
       "   'golden',\n",
       "   'disk'],\n",
       "  ['possible', 'truly', 'unlucky'],\n",
       "  ['likely',\n",
       "   'wrong',\n",
       "   'tree_diagram',\n",
       "   'figure',\n",
       "   'may',\n",
       "   'possibility',\n",
       "   'nick_eric',\n",
       "   'colluding'],\n",
       "  ['nick_eric',\n",
       "   'guess',\n",
       "   'outcome',\n",
       "   'coin',\n",
       "   'toss',\n",
       "   'probability',\n",
       "   'payoff',\n",
       "   'outcome',\n",
       "   'figure',\n",
       "   'use',\n",
       "   'equation',\n",
       "   'compute',\n",
       "   'expect_return',\n",
       "   'collusion',\n",
       "   'scenario',\n",
       "   'find',\n",
       "   'ex',\n",
       "   'payoff',\n",
       "   'bad',\n",
       "   'indeed'],\n",
       "  ['colluding', 'nick_eric', 'make', 'expect', 'lose'],\n",
       "  ['time', 'play'],\n",
       "  ['wonder', 'lose', 'course', 'wager'],\n",
       "  ['maybe',\n",
       "   'would',\n",
       "   'good_idea',\n",
       "   'go_back',\n",
       "   'school',\n",
       "   'hell',\n",
       "   'angel',\n",
       "   'bud',\n",
       "   'may',\n",
       "   'happy',\n",
       "   'lose'],\n",
       "  ['figure'],\n",
       "  ['revise',\n",
       "   'tree_diagram',\n",
       "   'reflect',\n",
       "   'scenario',\n",
       "   'nick',\n",
       "   'always',\n",
       "   'guess',\n",
       "   'eric'],\n",
       "  ['chapter_expectation']],\n",
       " [['win',\n",
       "   'lottery',\n",
       "   'similar',\n",
       "   'opportunity',\n",
       "   'collude',\n",
       "   'arise',\n",
       "   'many',\n",
       "   'betting',\n",
       "   'game'],\n",
       "  ['example',\n",
       "   'con',\n",
       "   'sider',\n",
       "   'typical',\n",
       "   'weekly',\n",
       "   'football',\n",
       "   'bet',\n",
       "   'pool',\n",
       "   'participant',\n",
       "   'wager',\n",
       "   'participant',\n",
       "   'pick',\n",
       "   'game',\n",
       "   'correctly',\n",
       "   'split',\n",
       "   'large',\n",
       "   'pot'],\n",
       "  ['pool',\n",
       "   'seem',\n",
       "   'fair',\n",
       "   'think',\n",
       "   'figure',\n",
       "   'case',\n",
       "   'collusion',\n",
       "   'inadvertent',\n",
       "   'profit'],\n",
       "  ['ex',\n",
       "   'ample',\n",
       "   'many',\n",
       "   'year_ago',\n",
       "   'former',\n",
       "   'mit',\n",
       "   'professor',\n",
       "   'mathematics',\n",
       "   'name',\n",
       "   'herman',\n",
       "   'chernoff',\n",
       "   'figure',\n",
       "   'way_make',\n",
       "   'money',\n",
       "   'play',\n",
       "   'state',\n",
       "   'lottery'],\n",
       "  ['surprising', 'state', 'lottery', 'typically', 'poor', 'expect_return'],\n",
       "  ['state',\n",
       "   'usually',\n",
       "   'take',\n",
       "   'large',\n",
       "   'share',\n",
       "   'wager',\n",
       "   'distribute',\n",
       "   'rest',\n",
       "   'pot',\n",
       "   'winner'],\n",
       "  ['hence', 'buy', 'lottery', 'ticket', 'expect', 'lose', 'money'],\n",
       "  ['chernoff',\n",
       "   'find',\n",
       "   'way_make',\n",
       "   'money',\n",
       "   'turn',\n",
       "   'easy',\n",
       "   'typical',\n",
       "   'state',\n",
       "   'lottery',\n",
       "   'player',\n",
       "   'pay',\n",
       "   'play',\n",
       "   'select',\n",
       "   'number',\n",
       "   'state',\n",
       "   'draw',\n",
       "   'number',\n",
       "   'uniformly',\n",
       "   'random',\n",
       "   'state',\n",
       "   'divide',\n",
       "   'money',\n",
       "   'collect',\n",
       "   'people',\n",
       "   'guess',\n",
       "   'correctly',\n",
       "   'spend',\n",
       "   'half',\n",
       "   'redecorate',\n",
       "   'governor',\n",
       "   'residence'],\n",
       "  ['lot', 'game', 'play', 'nick_eric', 'player', 'choice'],\n",
       "  ['chernoff',\n",
       "   'discover',\n",
       "   'small',\n",
       "   'set',\n",
       "   'number',\n",
       "   'select',\n",
       "   'large',\n",
       "   'fraction',\n",
       "   'population'],\n",
       "  ['apparently',\n",
       "   'many',\n",
       "   'people',\n",
       "   'think',\n",
       "   'way',\n",
       "   'pick',\n",
       "   'number',\n",
       "   'purpose',\n",
       "   'previous',\n",
       "   'game',\n",
       "   'nick_eric',\n",
       "   'base',\n",
       "   'manny',\n",
       "   'batting',\n",
       "   'average',\n",
       "   'today',\n",
       "   'date'],\n",
       "  ['player',\n",
       "   'collude',\n",
       "   'lose',\n",
       "   'guess',\n",
       "   'correctly',\n",
       "   'split',\n",
       "   'pot',\n",
       "   'many',\n",
       "   'player'],\n",
       "  ['select',\n",
       "   'number',\n",
       "   'uniformly',\n",
       "   'random',\n",
       "   'chernoff',\n",
       "   'unlikely',\n",
       "   'favored',\n",
       "   'sequence'],\n",
       "  ['likely',\n",
       "   'whole',\n",
       "   'pot',\n",
       "   'analyze',\n",
       "   'actual',\n",
       "   'state',\n",
       "   'lottery',\n",
       "   'datum',\n",
       "   'determine',\n",
       "   'could',\n",
       "   'win',\n",
       "   'average',\n",
       "   'cent',\n",
       "   'dollar'],\n",
       "  ['word', 'expect_return', 'may_think'],\n",
       "  ['inadvertent',\n",
       "   'collusion',\n",
       "   'often',\n",
       "   'arise',\n",
       "   'bet',\n",
       "   'pool',\n",
       "   'phenomenon',\n",
       "   'take',\n",
       "   'advantage'],\n",
       "  ['example_suppose',\n",
       "   'enter',\n",
       "   'super',\n",
       "   'bowl',\n",
       "   'bet',\n",
       "   'pool',\n",
       "   'goal',\n",
       "   'get',\n",
       "   'close',\n",
       "   'total_number',\n",
       "   'point',\n",
       "   'score',\n",
       "   'game'],\n",
       "  ['also',\n",
       "   'suppose',\n",
       "   'average',\n",
       "   'super',\n",
       "   'bowl',\n",
       "   'total',\n",
       "   'point',\n",
       "   'score',\n",
       "   'lottery',\n",
       "   'offer',\n",
       "   'randomized',\n",
       "   'ticket',\n",
       "   'help',\n",
       "   'smooth',\n",
       "   'distribution',\n",
       "   'select',\n",
       "   'se',\n",
       "   'quence'],\n",
       "  ['know'],\n",
       "  ['people', 'guess', 'point'],\n",
       "  ['guess',\n",
       "   'guess',\n",
       "   'outside',\n",
       "   'range',\n",
       "   'get',\n",
       "   'cover',\n",
       "   'lot',\n",
       "   'ground',\n",
       "   'share',\n",
       "   'pot',\n",
       "   'win'],\n",
       "  ['course',\n",
       "   'pool',\n",
       "   'math',\n",
       "   'student',\n",
       "   'know',\n",
       "   'strategy',\n",
       "   'maybe',\n",
       "   'guess',\n",
       "   'point']],\n",
       " [['expectation', 'sum']],\n",
       " [['linearity_expectation',\n",
       "   'expect_value',\n",
       "   'obey',\n",
       "   'simple',\n",
       "   'helpful',\n",
       "   'rule',\n",
       "   'call',\n",
       "   'linearity_expectation'],\n",
       "  ['simple',\n",
       "   'form',\n",
       "   'say',\n",
       "   'expect_value',\n",
       "   'sum',\n",
       "   'random_variable',\n",
       "   'sum',\n",
       "   'expect_value',\n",
       "   'variable'],\n",
       "  ['theorem'],\n",
       "  ['random_variable', 'ex', 'proof'],\n",
       "  ['let', 'theorem'],\n",
       "  ['random_variable', 'ex', 'word', 'expectation', 'linear', 'function'],\n",
       "  ['routine', 'induction', 'extend', 'result', 'variable', 'corollary'],\n",
       "  ['linearity_expectation'],\n",
       "  ['random_variable',\n",
       "   'constant',\n",
       "   'chapter_expectation',\n",
       "   'great',\n",
       "   'thing',\n",
       "   'linearity_expectation',\n",
       "   'independence',\n",
       "   'require'],\n",
       "  ['really',\n",
       "   'useful',\n",
       "   'deal',\n",
       "   'independence',\n",
       "   'pain',\n",
       "   'often',\n",
       "   'need',\n",
       "   'work',\n",
       "   'random_variable',\n",
       "   'know',\n",
       "   'independent'],\n",
       "  ['example', 'let', 'compute', 'expect_value', 'sum', 'fair', 'dice'],\n",
       "  ['let', 'random_variable', 'ex', 'notice', 'assume', 'dice', 'independent'],\n",
       "  ['expect',\n",
       "   'sum',\n",
       "   'dice',\n",
       "   'even',\n",
       "   'glue',\n",
       "   'together',\n",
       "   'provide',\n",
       "   'indi',\n",
       "   'vidual',\n",
       "   'die',\n",
       "   'remain',\n",
       "   'fair',\n",
       "   'gluing'],\n",
       "  ['prove', 'expect', 'sum', 'tree_diagram', 'would', 'bother', 'case'],\n",
       "  ['assume', 'dice', 'independent', 'job', 'would', 'really', 'tough']],\n",
       " [['sum',\n",
       "   'indicator_random_variable',\n",
       "   'linearity_expectation',\n",
       "   'especially',\n",
       "   'useful',\n",
       "   'sum',\n",
       "   'indicator',\n",
       "   'run',\n",
       "   'dom',\n",
       "   'variable'],\n",
       "  ['example_suppose',\n",
       "   'dinner',\n",
       "   'party',\n",
       "   'letting',\n",
       "   'trick',\n",
       "   'express',\n",
       "   'man_get',\n",
       "   'hat'],\n",
       "  ['man_get', 'hat', 'otherwise'],\n",
       "  ['number',\n",
       "   'man_get',\n",
       "   'hat',\n",
       "   'sum',\n",
       "   'indicator_random_variable',\n",
       "   'indicator',\n",
       "   'variable',\n",
       "   'mutually_independent'],\n",
       "  ['example', 'go', 'use', 'trick', 'lot', 'important', 'understand'],\n",
       "  ['ex_ex',\n",
       "   'even',\n",
       "   'know',\n",
       "   'much',\n",
       "   'hat',\n",
       "   'scramble',\n",
       "   'figure',\n",
       "   'average',\n",
       "   'man_get',\n",
       "   'hat',\n",
       "   'back',\n",
       "   'generally',\n",
       "   'linearity_expectation',\n",
       "   'provide',\n",
       "   'good',\n",
       "   'method',\n",
       "   'com',\n",
       "   'puting',\n",
       "   'expect_number',\n",
       "   'event',\n",
       "   'happen'],\n",
       "  ['theorem'],\n",
       "  ['give', 'collection', 'pr', 'example', 'man_get', 'right', 'hat', 'back'],\n",
       "  ['general',\n",
       "   'could',\n",
       "   'subset',\n",
       "   'sample_space',\n",
       "   'ask',\n",
       "   'expect_number',\n",
       "   'event',\n",
       "   'contain',\n",
       "   'random',\n",
       "   'sample',\n",
       "   'point'],\n",
       "  ['proof'],\n",
       "  ['define',\n",
       "   'would',\n",
       "   'chapter_expectation',\n",
       "   'whenever',\n",
       "   'ask',\n",
       "   'expect_number',\n",
       "   'event_occur',\n",
       "   'sum',\n",
       "   'probability_event',\n",
       "   'occur'],\n",
       "  ['independence', 'need']],\n",
       " [['expectation',\n",
       "   'binomial_distribution',\n",
       "   'suppose',\n",
       "   'independently',\n",
       "   'flip',\n",
       "   'let_pr',\n",
       "   'apply',\n",
       "   'equation',\n",
       "   'ex_pr',\n",
       "   'kd',\n",
       "   'ouch',\n",
       "   'nasty',\n",
       "   'look',\n",
       "   'sum'],\n",
       "  ['let_try', 'approach'],\n",
       "  ['learn',\n",
       "   'linearity_expectation',\n",
       "   'sum',\n",
       "   'indicator_random_variable',\n",
       "   'maybe',\n",
       "   'theorem',\n",
       "   'helpful'],\n",
       "  ['express', 'coin'],\n",
       "  ['particular',\n",
       "   'define',\n",
       "   'number_head',\n",
       "   'simply',\n",
       "   'theorem',\n",
       "   'ex_pr',\n",
       "   'would',\n",
       "   'np',\n",
       "   'really',\n",
       "   'easy'],\n",
       "  ['flip', 'mutually_independent', 'coin', 'expect', 'get', 'pn', 'head'],\n",
       "  ['hence',\n",
       "   'expect_value',\n",
       "   'binomial_distribution',\n",
       "   'parameter',\n",
       "   'simply',\n",
       "   'pn'],\n",
       "  ['coin',\n",
       "   'mutually_independent',\n",
       "   'matter',\n",
       "   'swer',\n",
       "   'still',\n",
       "   'pn',\n",
       "   'linearity_expectation',\n",
       "   'theorem',\n",
       "   'sume',\n",
       "   'independence'],\n",
       "  ['convince',\n",
       "   'linearity_expectation',\n",
       "   'theorem',\n",
       "   'still',\n",
       "   'convince',\n",
       "   'take',\n",
       "   'look',\n",
       "   'next',\n",
       "   'problem']],\n",
       " [['coupon',\n",
       "   'collector',\n",
       "   'problem',\n",
       "   'time',\n",
       "   'purchase',\n",
       "   'kid',\n",
       "   'meal',\n",
       "   'taco',\n",
       "   'bell',\n",
       "   'graciously',\n",
       "   'present',\n",
       "   'miniature',\n",
       "   'racin',\n",
       "   'rocket',\n",
       "   'car',\n",
       "   'together',\n",
       "   'launch',\n",
       "   'device',\n",
       "   'enable',\n",
       "   'project',\n",
       "   'new',\n",
       "   'vehicle',\n",
       "   'tabletop',\n",
       "   'smooth',\n",
       "   'floor',\n",
       "   'high',\n",
       "   'velocity'],\n",
       "  ['truly', 'delight', 'know', 'bound'],\n",
       "  ['different',\n",
       "   'type',\n",
       "   'racin',\n",
       "   'rocket',\n",
       "   'car',\n",
       "   'blue',\n",
       "   'green',\n",
       "   'red',\n",
       "   'gray'],\n",
       "  ['type',\n",
       "   'car',\n",
       "   'award',\n",
       "   'day',\n",
       "   'kind',\n",
       "   'woman',\n",
       "   'taco',\n",
       "   'bell',\n",
       "   'reg',\n",
       "   'ister',\n",
       "   'appear',\n",
       "   'select',\n",
       "   'uniformly',\n",
       "   'independently',\n",
       "   'random'],\n",
       "  ['expect_number',\n",
       "   'kid',\n",
       "   'meal',\n",
       "   'must',\n",
       "   'purchase',\n",
       "   'order',\n",
       "   'acquire',\n",
       "   'least',\n",
       "   'type',\n",
       "   'racin',\n",
       "   'rocket',\n",
       "   'car',\n",
       "   'mathematical',\n",
       "   'question',\n",
       "   'show',\n",
       "   'many',\n",
       "   'guise',\n",
       "   'example',\n",
       "   'expect_number',\n",
       "   'people',\n",
       "   'must',\n",
       "   'poll',\n",
       "   'order',\n",
       "   'find',\n",
       "   'least',\n",
       "   'person',\n",
       "   'possible',\n",
       "   'birthday',\n",
       "   'instead',\n",
       "   'collect',\n",
       "   'racin',\n",
       "   'rocket',\n",
       "   'car',\n",
       "   'collect',\n",
       "   'birthday'],\n",
       "  ['general',\n",
       "   'question',\n",
       "   'commonly',\n",
       "   'call',\n",
       "   'coupon',\n",
       "   'collector',\n",
       "   'problem',\n",
       "   'yet',\n",
       "   'interpretation'],\n",
       "  ['clever',\n",
       "   'application',\n",
       "   'linearity_expectation',\n",
       "   'lead',\n",
       "   'simple',\n",
       "   'solution',\n",
       "   'coupon',\n",
       "   'collector',\n",
       "   'problem'],\n",
       "  ['suppose',\n",
       "   'different',\n",
       "   'type',\n",
       "   'racin',\n",
       "   'rocket',\n",
       "   'car',\n",
       "   'receive',\n",
       "   'sequence',\n",
       "   'blue',\n",
       "   'green',\n",
       "   'green',\n",
       "   'red',\n",
       "   'blue',\n",
       "   'orange',\n",
       "   'blue',\n",
       "   'orange',\n",
       "   'gray'],\n",
       "  ['let',\n",
       "   'partition',\n",
       "   'sequence',\n",
       "   'segment',\n",
       "   'follow',\n",
       "   'combine',\n",
       "   'equation',\n",
       "   'chapter_expectation',\n",
       "   'rule',\n",
       "   'segment',\n",
       "   'end',\n",
       "   'whenever',\n",
       "   'get',\n",
       "   'new',\n",
       "   'kind',\n",
       "   'car'],\n",
       "  ['example',\n",
       "   'middle',\n",
       "   'segment',\n",
       "   'end',\n",
       "   'get',\n",
       "   'red',\n",
       "   'car',\n",
       "   'first',\n",
       "   'time'],\n",
       "  ['way', 'break', 'problem', 'collect', 'type', 'car', 'stage'],\n",
       "  ['analyze',\n",
       "   'stage',\n",
       "   'individually',\n",
       "   'assemble',\n",
       "   'result',\n",
       "   'use',\n",
       "   'linearity_expectation'],\n",
       "  ['let', 'return', 'general', 'case', 'collect', 'length', 'th', 'segment'],\n",
       "  ['total_number',\n",
       "   'kid',\n",
       "   'meal',\n",
       "   'must',\n",
       "   'purchase',\n",
       "   'let',\n",
       "   'focus',\n",
       "   'attention',\n",
       "   'segment'],\n",
       "  ['begin', 'segment', 'meal', 'get', 'new', 'kind', 'car'],\n",
       "  ['mean_time_failure',\n",
       "   'formula',\n",
       "   'equation',\n",
       "   'ex',\n",
       "   'linearity_expectation',\n",
       "   'together',\n",
       "   'observation',\n",
       "   'solve',\n",
       "   'coupon',\n",
       "   'col',\n",
       "   'lector',\n",
       "   'problem',\n",
       "   'ex_ex',\n",
       "   'harmonic_number',\n",
       "   'use',\n",
       "   'equation',\n",
       "   'answer',\n",
       "   'concrete',\n",
       "   'question'],\n",
       "  ['example',\n",
       "   'expect_number',\n",
       "   'die',\n",
       "   'roll',\n",
       "   'require',\n",
       "   'see',\n",
       "   'number',\n",
       "   'expect_number',\n",
       "   'people',\n",
       "   'must',\n",
       "   'poll',\n",
       "   'find',\n",
       "   'least',\n",
       "   'person',\n",
       "   'possible',\n",
       "   'birthday']],\n",
       " [['infinite',\n",
       "   'sum',\n",
       "   'linearity_expectation',\n",
       "   'also',\n",
       "   'work',\n",
       "   'infinite',\n",
       "   'number',\n",
       "   'random_variable',\n",
       "   'provide',\n",
       "   'variable',\n",
       "   'satisfy',\n",
       "   'stringent',\n",
       "   'absolute',\n",
       "   'convergence',\n",
       "   'criterion'],\n",
       "  ['theorem'],\n",
       "  ['linearity_expectation'],\n",
       "  ['let',\n",
       "   'ex',\n",
       "   'sum',\n",
       "   'follow',\n",
       "   'derivation',\n",
       "   'absolutely',\n",
       "   'convergent',\n",
       "   'justifie',\n",
       "   'rearrange',\n",
       "   'follow',\n",
       "   'would',\n",
       "   'chapter_expectation']],\n",
       " [['expectation',\n",
       "   'product',\n",
       "   'expectation',\n",
       "   'sum',\n",
       "   'sum',\n",
       "   'expectation',\n",
       "   'usually',\n",
       "   'true',\n",
       "   'product'],\n",
       "  ['example_suppose',\n",
       "   'roll',\n",
       "   'fair',\n",
       "   'sided',\n",
       "   'die',\n",
       "   'denote',\n",
       "   'outcome',\n",
       "   'random_variable',\n",
       "   'know',\n",
       "   'ex_pr',\n",
       "   'would',\n",
       "   'hence',\n",
       "   'ex',\n",
       "   'expectation',\n",
       "   'product',\n",
       "   'always',\n",
       "   'equal',\n",
       "   'product',\n",
       "   'expec',\n",
       "   'tation'],\n",
       "  ['special_case',\n",
       "   'relationship',\n",
       "   'hold',\n",
       "   'however',\n",
       "   'namely',\n",
       "   'random_variable',\n",
       "   'product',\n",
       "   'independent'],\n",
       "  ['theorem'],\n",
       "  ['independent', 'random_variable', 'ex_ex', 'proof'],\n",
       "  ['event',\n",
       "   'split',\n",
       "   'event',\n",
       "   'form',\n",
       "   'example',\n",
       "   'let',\n",
       "   'ex_ex',\n",
       "   'ex',\n",
       "   'theorem',\n",
       "   'extend',\n",
       "   'induction',\n",
       "   'collection',\n",
       "   'mutually_independent',\n",
       "   'random_variable'],\n",
       "  ['corollary'],\n",
       "  ['random_variable', 'chapter_expectation']],\n",
       " [['expectation',\n",
       "   'quotient',\n",
       "   'course',\n",
       "   'worry',\n",
       "   'situation',\n",
       "   'ex',\n",
       "   'usually',\n",
       "   'true',\n",
       "   'let_see',\n",
       "   'prove',\n",
       "   'anyway'],\n",
       "  ['false', 'claim'],\n",
       "  ['note', 'line', 'use', 'fact', 'independent'],\n",
       "  ['fact', 'need', 'proof', 'leave', 'reader', 'bug'],\n",
       "  ['bug', 'line', 'false', 'claim'],\n",
       "  ['table'],\n",
       "  ['sample',\n",
       "   'program_length',\n",
       "   'benchmark',\n",
       "   'problem',\n",
       "   'use',\n",
       "   'risc',\n",
       "   'cisc',\n",
       "   'compiler'],\n",
       "  ['means', 'claim', 'also', 'false', 'could', 'define', 'untrue', 'choice']],\n",
       " [['risc',\n",
       "   'paradox',\n",
       "   'data',\n",
       "   'table',\n",
       "   'representative',\n",
       "   'datum',\n",
       "   'paper',\n",
       "   'famous',\n",
       "   'pro',\n",
       "   'fessor'],\n",
       "  ['want',\n",
       "   'show',\n",
       "   'program',\n",
       "   'risc',\n",
       "   'processor',\n",
       "   'generally',\n",
       "   'short',\n",
       "   'program',\n",
       "   'cisc',\n",
       "   'processor'],\n",
       "  ['purpose',\n",
       "   'apply',\n",
       "   'risc',\n",
       "   'compiler',\n",
       "   'cisc',\n",
       "   'compiler',\n",
       "   'benchmark',\n",
       "   'source',\n",
       "   'program',\n",
       "   'make',\n",
       "   'table',\n",
       "   'compile',\n",
       "   'program_length'],\n",
       "  ['row', 'table', 'contain', 'datum', 'benchmark'],\n",
       "  ['number',\n",
       "   'second',\n",
       "   'third',\n",
       "   'column',\n",
       "   'program_length',\n",
       "   'type',\n",
       "   'compiler'],\n",
       "  ['fourth',\n",
       "   'column',\n",
       "   'contain',\n",
       "   'ratio',\n",
       "   'cisc',\n",
       "   'program_length',\n",
       "   'risc',\n",
       "   'program_length'],\n",
       "  ['average', 'ratio', 'benchmarks', 'give', 'value'],\n",
       "  ['lower', 'right'],\n",
       "  ['conclusion', 'cisc', 'program', 'longer', 'average'],\n",
       "  ['table'],\n",
       "  ['datum',\n",
       "   'table',\n",
       "   'however',\n",
       "   'critic',\n",
       "   'paper',\n",
       "   'take',\n",
       "   'datum',\n",
       "   'argue',\n",
       "   'way',\n",
       "   'redo',\n",
       "   'final',\n",
       "   'column',\n",
       "   'take',\n",
       "   'ratio',\n",
       "   'risc',\n",
       "   'cisc',\n",
       "   'instead',\n",
       "   'cisc',\n",
       "   'risc',\n",
       "   'show',\n",
       "   'table',\n",
       "   'table',\n",
       "   'probabilistic',\n",
       "   'interpretation',\n",
       "   'resolve',\n",
       "   'contradictory',\n",
       "   'conclusion',\n",
       "   'model',\n",
       "   'risc'],\n",
       "  ['cisc', 'de', 'bate', 'machinery', 'probability', 'theory'],\n",
       "  ['let', 'sample_space', 'set', 'benchmark', 'program'],\n",
       "  ['let',\n",
       "   'random_variable',\n",
       "   'length',\n",
       "   'compile',\n",
       "   'risc',\n",
       "   'program',\n",
       "   'let',\n",
       "   'random_variable',\n",
       "   'length',\n",
       "   'compile',\n",
       "   'cisc',\n",
       "   'program'],\n",
       "  ['would',\n",
       "   'like',\n",
       "   'compare',\n",
       "   'average',\n",
       "   'length',\n",
       "   'compare',\n",
       "   'average',\n",
       "   'program_length',\n",
       "   'must',\n",
       "   'assign',\n",
       "   'probability',\n",
       "   'sam',\n",
       "   'ple',\n",
       "   'point',\n",
       "   'effect',\n",
       "   'assign',\n",
       "   'weight',\n",
       "   'benchmark'],\n",
       "  ['may',\n",
       "   'like',\n",
       "   'weigh',\n",
       "   'benchmark',\n",
       "   'base',\n",
       "   'frequently',\n",
       "   'similar',\n",
       "   'program',\n",
       "   'arise_practice'],\n",
       "  ['lack',\n",
       "   'datum',\n",
       "   'however',\n",
       "   'assign',\n",
       "   'benchmark',\n",
       "   'equal',\n",
       "   'weight',\n",
       "   'sample_space',\n",
       "   'uniform'],\n",
       "  ['term',\n",
       "   'probability',\n",
       "   'model',\n",
       "   'paper',\n",
       "   'compute',\n",
       "   'assume',\n",
       "   'ex',\n",
       "   'proper',\n",
       "   'quotient',\n",
       "   'compute',\n",
       "   'ex_ex',\n",
       "   'pr',\n",
       "   'range',\n",
       "   'ex_pr',\n",
       "   'range',\n",
       "   'ex',\n",
       "   'simple',\n",
       "   'example',\n",
       "   'source',\n",
       "   'problem',\n",
       "   'clear',\n",
       "   'follow',\n",
       "   'simple',\n",
       "   'example'],\n",
       "  ['suppose', 'data', 'follow'],\n",
       "  ['data',\n",
       "   'processor',\n",
       "   'moral',\n",
       "   'must',\n",
       "   'careful',\n",
       "   'summarize',\n",
       "   'datum',\n",
       "   'must',\n",
       "   'take',\n",
       "   'average',\n",
       "   'ratio',\n",
       "   'blindly']],\n",
       " [['deviation', 'case', 'random_variable', 'likely', 'close', 'expect_value'],\n",
       "  ['example',\n",
       "   'flip_fair',\n",
       "   'mutually_independent',\n",
       "   'coin',\n",
       "   'likely',\n",
       "   'get',\n",
       "   'head'],\n",
       "  ['fact',\n",
       "   'prove',\n",
       "   'section',\n",
       "   'probability_get',\n",
       "   'few',\n",
       "   'head',\n",
       "   'less',\n",
       "   'case',\n",
       "   'random_variable',\n",
       "   'likely',\n",
       "   'far',\n",
       "   'expect_value'],\n",
       "  ['example_suppose',\n",
       "   'flip_fair_coin',\n",
       "   'glue',\n",
       "   'together',\n",
       "   'come',\n",
       "   'head',\n",
       "   'call',\n",
       "   'come',\n",
       "   'tail'],\n",
       "  ['case',\n",
       "   'expect_value',\n",
       "   'number_head',\n",
       "   'still',\n",
       "   'actual',\n",
       "   'number_head',\n",
       "   'guarantee',\n",
       "   'far',\n",
       "   'value',\n",
       "   'probability'],\n",
       "  ['mathematicians',\n",
       "   'develop',\n",
       "   'variety',\n",
       "   'measure',\n",
       "   'method',\n",
       "   'help',\n",
       "   'understand',\n",
       "   'random_variable',\n",
       "   'perform',\n",
       "   'comparison',\n",
       "   'mean'],\n",
       "  ['sim',\n",
       "   'plest',\n",
       "   'widely',\n",
       "   'use',\n",
       "   'measure',\n",
       "   'call',\n",
       "   'variance',\n",
       "   'random_variable'],\n",
       "  ['variance',\n",
       "   'single',\n",
       "   'value',\n",
       "   'associate',\n",
       "   'random_variable',\n",
       "   'large',\n",
       "   'random_variable',\n",
       "   'likely',\n",
       "   'deviate',\n",
       "   'significantly',\n",
       "   'mean',\n",
       "   'small',\n",
       "   'otherwise']],\n",
       " [['variance']],\n",
       " [['definition',\n",
       "   'example_consider',\n",
       "   'follow',\n",
       "   'gambling_game',\n",
       "   'game_win',\n",
       "   'probability_lose',\n",
       "   'probability'],\n",
       "  ['game_win', 'probability_lose', 'probabil', 'ity'],\n",
       "  ['game',\n",
       "   'would',\n",
       "   'rather',\n",
       "   'play',\n",
       "   'game',\n",
       "   'better',\n",
       "   'financially',\n",
       "   'probability',\n",
       "   'win',\n",
       "   'game',\n",
       "   'tell',\n",
       "   'whole',\n",
       "   'story'],\n",
       "  ['expect_return', 'game', 'let', 'random_variable', 'payoff', 'game'],\n",
       "  ['example', 'probability', 'chapter_deviation', 'probability'],\n",
       "  ['compute',\n",
       "   'expect',\n",
       "   'payoff',\n",
       "   'game',\n",
       "   'follow',\n",
       "   'expect',\n",
       "   'payoff',\n",
       "   'game',\n",
       "   'obviously',\n",
       "   'different',\n",
       "   'stake',\n",
       "   'lot',\n",
       "   'high',\n",
       "   'game',\n",
       "   'likely',\n",
       "   'deviate',\n",
       "   'much',\n",
       "   'farther',\n",
       "   'mean',\n",
       "   'game'],\n",
       "  ['fact', 'capture', 'notion', 'variance'],\n",
       "  ['definition'],\n",
       "  ['variance',\n",
       "   'var',\n",
       "   'var',\n",
       "   'word',\n",
       "   'variance',\n",
       "   'random_variable',\n",
       "   'yike',\n",
       "   'mouthful'],\n",
       "  ['try', 'say', 'time', 'row', 'let_look', 'definition', 'carefully'],\n",
       "  ['start',\n",
       "   'start',\n",
       "   'game',\n",
       "   'variance',\n",
       "   'game',\n",
       "   'variance',\n",
       "   'game',\n",
       "   'intuitively',\n",
       "   'mean',\n",
       "   'payoff',\n",
       "   'game',\n",
       "   'usually',\n",
       "   'close',\n",
       "   'expect_value',\n",
       "   'payoff',\n",
       "   'game',\n",
       "   'deviate',\n",
       "   'far',\n",
       "   'expect_value'],\n",
       "  ['high', 'variance', 'often', 'associate', 'high', 'risk'],\n",
       "  ['example',\n",
       "   'ten',\n",
       "   'round',\n",
       "   'game',\n",
       "   'expect',\n",
       "   'make',\n",
       "   'could',\n",
       "   'conceivably',\n",
       "   'lose',\n",
       "   'instead'],\n",
       "  ['hand',\n",
       "   'ten',\n",
       "   'round',\n",
       "   'game',\n",
       "   'also',\n",
       "   'expect',\n",
       "   'make',\n",
       "   'could',\n",
       "   'actually',\n",
       "   'lose',\n",
       "   'bother',\n",
       "   'square',\n",
       "   'variance',\n",
       "   'average',\n",
       "   'square',\n",
       "   'deviation_mean'],\n",
       "  ['reason', 'variance', 'sometimes', 'call', 'mean', 'squared', 'deviation'],\n",
       "  ['bother',\n",
       "   'square',\n",
       "   'simply',\n",
       "   'compute',\n",
       "   'average',\n",
       "   'deviation_mean',\n",
       "   'define',\n",
       "   'variance',\n",
       "   'ex',\n",
       "   'problem',\n",
       "   'definition',\n",
       "   'positive',\n",
       "   'negative',\n",
       "   'deviation_mean',\n",
       "   'exactly',\n",
       "   'cancel'],\n",
       "  ['linearity_expectation',\n",
       "   'ex_ex',\n",
       "   'ex',\n",
       "   'definition',\n",
       "   'random_variable',\n",
       "   'would',\n",
       "   'variance',\n",
       "   'would',\n",
       "   'useful',\n",
       "   'square',\n",
       "   'conventional',\n",
       "   'definition',\n",
       "   'pos',\n",
       "   'itive',\n",
       "   'negative',\n",
       "   'deviation_mean',\n",
       "   'increase',\n",
       "   'variance',\n",
       "   'cancel'],\n",
       "  ['course',\n",
       "   'could',\n",
       "   'also',\n",
       "   'prevent',\n",
       "   'positive',\n",
       "   'negative',\n",
       "   'deviation',\n",
       "   'cancel',\n",
       "   'take',\n",
       "   'absolute',\n",
       "   'value'],\n",
       "  ['word', 'could', 'compute', 'ex', 'chapter_deviation']],\n",
       " [['standard_deviation',\n",
       "   'definition',\n",
       "   'term',\n",
       "   'square',\n",
       "   'random_variable',\n",
       "   'variance',\n",
       "   'random_variable',\n",
       "   'may',\n",
       "   'far',\n",
       "   'typical',\n",
       "   'deviation_mean'],\n",
       "  ['example', 'game', 'deviation_mean', 'outcome'],\n",
       "  ['variance', 'whopping'],\n",
       "  ['dimensional',\n",
       "   'analysis',\n",
       "   'viewpoint',\n",
       "   'unit',\n",
       "   'variance',\n",
       "   'wrong',\n",
       "   'random_variable',\n",
       "   'dollar',\n",
       "   'expectation',\n",
       "   'also',\n",
       "   'dollar',\n",
       "   'variance',\n",
       "   'square',\n",
       "   'dollar'],\n",
       "  ['reason',\n",
       "   'people',\n",
       "   'often',\n",
       "   'describe',\n",
       "   'deviation',\n",
       "   'random_variable',\n",
       "   'use',\n",
       "   'standard_deviation',\n",
       "   'instead',\n",
       "   'variance'],\n",
       "  ['definition'],\n",
       "  ['standard_deviation',\n",
       "   'var',\n",
       "   'standard_deviation',\n",
       "   'square',\n",
       "   'root',\n",
       "   'mean',\n",
       "   'square',\n",
       "   'deviation',\n",
       "   'root',\n",
       "   'mean',\n",
       "   'square',\n",
       "   'short'],\n",
       "  ['unit', 'dollar', 'example', 'original', 'random_variable', 'mean'],\n",
       "  ['intuitively',\n",
       "   'measure',\n",
       "   'average',\n",
       "   'deviation_mean',\n",
       "   'think',\n",
       "   'square',\n",
       "   'root',\n",
       "   'roughly',\n",
       "   'cancel',\n",
       "   'square',\n",
       "   'inside'],\n",
       "  ['example', 'standard_deviation', 'random_variable']],\n",
       " [['alternative',\n",
       "   'formulation',\n",
       "   'apply',\n",
       "   'linearity_expectation',\n",
       "   'formula',\n",
       "   'variance',\n",
       "   'yield',\n",
       "   'convenient',\n",
       "   'alternative',\n",
       "   'formula'],\n",
       "  ['lemma'],\n",
       "  ['random_variable',\n",
       "   'var',\n",
       "   'use',\n",
       "   'notation',\n",
       "   'ex_ex',\n",
       "   'example',\n",
       "   'let',\n",
       "   'take',\n",
       "   'look',\n",
       "   'game',\n",
       "   'section',\n",
       "   'win_probability',\n",
       "   'lose',\n",
       "   'probability'],\n",
       "  ['ex',\n",
       "   'lemma',\n",
       "   'var',\n",
       "   'ex',\n",
       "   'confirming',\n",
       "   'result',\n",
       "   'equation',\n",
       "   'alternate',\n",
       "   'formulation',\n",
       "   'variance',\n",
       "   'give',\n",
       "   'lemma',\n",
       "   'cute',\n",
       "   'implica',\n",
       "   'tion',\n",
       "   'corollary'],\n",
       "  ['random_variable', 'ex_ex', 'proof'],\n",
       "  ['define',\n",
       "   'var',\n",
       "   'average',\n",
       "   'squared',\n",
       "   'expression',\n",
       "   'var',\n",
       "   'non',\n",
       "   'word',\n",
       "   'expectation',\n",
       "   'square',\n",
       "   'least',\n",
       "   'square',\n",
       "   'expectation'],\n",
       "  ['equal',\n",
       "   'exactly',\n",
       "   'variance',\n",
       "   'ex',\n",
       "   'var',\n",
       "   'happen',\n",
       "   'precisely',\n",
       "   'ex',\n",
       "   'namely',\n",
       "   'constant'],\n",
       "  ['technically',\n",
       "   'could',\n",
       "   'deviate',\n",
       "   'mean',\n",
       "   'sample',\n",
       "   'point',\n",
       "   'probability',\n",
       "   'ignore',\n",
       "   'event_probability',\n",
       "   'computing',\n",
       "   'expectation',\n",
       "   'variance'],\n",
       "  ['chapter_deviation']],\n",
       " [['indicator_random_variable',\n",
       "   'compute',\n",
       "   'variance',\n",
       "   'indicator_random_variable',\n",
       "   'straightforward',\n",
       "   'give',\n",
       "   'lemma_lemma'],\n",
       "  ['let']],\n",
       " [['mean_time_failure',\n",
       "   'example_consider',\n",
       "   'mean_time_failure',\n",
       "   'problem',\n",
       "   'describe',\n",
       "   'sec',\n",
       "   'tion',\n",
       "   'ex',\n",
       "   'variance',\n",
       "   'ex',\n",
       "   'use',\n",
       "   'lemma']],\n",
       " [['uniform',\n",
       "   'random_variable',\n",
       "   'compute',\n",
       "   'variance',\n",
       "   'uniform',\n",
       "   'random_variable',\n",
       "   'also',\n",
       "   'straightforward',\n",
       "   'give',\n",
       "   'lemma',\n",
       "   'ex_ex',\n",
       "   'general',\n",
       "   'uniform',\n",
       "   'random_variable',\n",
       "   'variance',\n",
       "   'chapter_deviation',\n",
       "   'compute',\n",
       "   'follow',\n",
       "   'ex'],\n",
       "  ['ex']],\n",
       " [['deal', 'constant', 'help', 'know', 'calculate', 'variance', 'theorem'],\n",
       "  ['let', 'proof'],\n",
       "  ['begin',\n",
       "   'lemma',\n",
       "   'repeatedly',\n",
       "   'apply',\n",
       "   'linearity',\n",
       "   'expec',\n",
       "   'tation',\n",
       "   'corollary'],\n",
       "  ['arcb']],\n",
       " [['variance',\n",
       "   'sum',\n",
       "   'general',\n",
       "   'variance',\n",
       "   'sum',\n",
       "   'equal',\n",
       "   'sum',\n",
       "   'variance',\n",
       "   'variance',\n",
       "   'add',\n",
       "   'independent',\n",
       "   'random_variable'],\n",
       "  ['fact', 'mutual', 'independence', 'necessary', 'pairwise', 'independence'],\n",
       "  ['theorem'],\n",
       "  ['proof'],\n",
       "  ['proof_theorem', 'linearity_expectation'],\n",
       "  ['var',\n",
       "   'ex_ex',\n",
       "   'note',\n",
       "   'theorem',\n",
       "   'necessarily',\n",
       "   'hold',\n",
       "   'last',\n",
       "   'step',\n",
       "   'proof'],\n",
       "  ['example_suppose',\n",
       "   'hold',\n",
       "   'proof_theorem',\n",
       "   'carry',\n",
       "   'sum',\n",
       "   'finite',\n",
       "   'number',\n",
       "   'variable'],\n",
       "  ['theorem'],\n",
       "  ['pairwise', 'independent', 'additivity', 'variance'],\n",
       "  ['var',\n",
       "   'unfortunately',\n",
       "   'product_rule',\n",
       "   'compute',\n",
       "   'variance',\n",
       "   'even',\n",
       "   'run',\n",
       "   'dom',\n",
       "   'variable',\n",
       "   'mutually_independent'],\n",
       "  ['however',\n",
       "   'use',\n",
       "   'theorem',\n",
       "   'quickly',\n",
       "   'compute',\n",
       "   'variance',\n",
       "   'random_variable',\n",
       "   'general',\n",
       "   'binomial',\n",
       "   'distri',\n",
       "   'bution'],\n",
       "  ['chapter_deviation']],\n",
       " [['binomial_distribution', 'lemma'],\n",
       "  ['variance', 'binomial_distribution'],\n",
       "  ['proof'],\n",
       "  ['definition', 'binomial_distribution', 'think', 'know', 'var'],\n",
       "  ['theorem', 'example_suppose', 'flip_fair_coin'],\n",
       "  ['let',\n",
       "   'tell',\n",
       "   'surprising',\n",
       "   'already_know',\n",
       "   'section',\n",
       "   'actually',\n",
       "   'need',\n",
       "   'assume',\n",
       "   'pairwise',\n",
       "   'independence',\n",
       "   'true',\n",
       "   'use',\n",
       "   'theorem']],\n",
       " [['markov_theorem',\n",
       "   'variance',\n",
       "   'random_variable',\n",
       "   'give',\n",
       "   'rough',\n",
       "   'idea',\n",
       "   'amount',\n",
       "   'random_variable',\n",
       "   'likely',\n",
       "   'deviate',\n",
       "   'mean'],\n",
       "  ['directly',\n",
       "   'give',\n",
       "   'specific',\n",
       "   'bound',\n",
       "   'probability',\n",
       "   'deviation',\n",
       "   'exceed',\n",
       "   'specify',\n",
       "   'threshold'],\n",
       "  ['obtain', 'specific', 'bound', 'need', 'work', 'little', 'harder'],\n",
       "  ['section',\n",
       "   'derive',\n",
       "   'famous',\n",
       "   'result',\n",
       "   'know',\n",
       "   'markov_theorem',\n",
       "   'give',\n",
       "   'upper_bind',\n",
       "   'probability',\n",
       "   'random_variable',\n",
       "   'exceed',\n",
       "   'specify',\n",
       "   'thresh',\n",
       "   'old'],\n",
       "  ['next',\n",
       "   'section',\n",
       "   'give',\n",
       "   'similar',\n",
       "   'strong',\n",
       "   'result',\n",
       "   'know',\n",
       "   'chebyshev_theorem'],\n",
       "  ['difference',\n",
       "   'result',\n",
       "   'markov_theorem',\n",
       "   'depend',\n",
       "   'mean',\n",
       "   'random_variable',\n",
       "   'chebyshev_theorem',\n",
       "   'make',\n",
       "   'use',\n",
       "   'mean',\n",
       "   'variance'],\n",
       "  ['basically',\n",
       "   'know',\n",
       "   'random_variable',\n",
       "   'well',\n",
       "   'bound',\n",
       "   'derive',\n",
       "   'probability',\n",
       "   'deviate',\n",
       "   'mean']],\n",
       " [['motivate',\n",
       "   'example',\n",
       "   'idea',\n",
       "   'markov_theorem',\n",
       "   'explain',\n",
       "   'simple',\n",
       "   'example',\n",
       "   'involv',\n",
       "   'e',\n",
       "   'intelligence',\n",
       "   'quotient',\n",
       "   'iqs'],\n",
       "  ['quantity', 'devise', 'average', 'iq', 'measurement', 'would'],\n",
       "  ['fact',\n",
       "   'alone',\n",
       "   'conclude',\n",
       "   'population',\n",
       "   'iq',\n",
       "   'third',\n",
       "   'iq',\n",
       "   'least',\n",
       "   'average',\n",
       "   'iq',\n",
       "   'would'],\n",
       "  ['contradict', 'fact', 'average'],\n",
       "  ['probability', 'randomly', 'choose', 'person', 'iq'],\n",
       "  ['course', 'strong', 'conclusion', 'iq', 'ever', 'record'],\n",
       "  ['logic', 'also', 'conclude', 'population', 'iq'],\n",
       "  ['iq',\n",
       "   'certainly',\n",
       "   'record',\n",
       "   'much',\n",
       "   'small',\n",
       "   'fraction',\n",
       "   'population',\n",
       "   'actually',\n",
       "   'iq',\n",
       "   'high'],\n",
       "  ['conclusion',\n",
       "   'iq',\n",
       "   'weak',\n",
       "   'actually',\n",
       "   'strong',\n",
       "   'general',\n",
       "   'conclusion',\n",
       "   'reach',\n",
       "   'random_variable',\n",
       "   'use',\n",
       "   'fact',\n",
       "   'nonnegative',\n",
       "   'mean'],\n",
       "  ['example',\n",
       "   'choose',\n",
       "   'random_variable',\n",
       "   'equal',\n",
       "   'probability',\n",
       "   'probability',\n",
       "   'mean',\n",
       "   'probability',\n",
       "   'value',\n",
       "   'really'],\n",
       "  ['hope',\n",
       "   'get',\n",
       "   'well',\n",
       "   'upper_bind',\n",
       "   'base',\n",
       "   'solely',\n",
       "   'limited',\n",
       "   'amount',\n",
       "   'information'],\n",
       "  ['markov_theorem',\n",
       "   'characterize',\n",
       "   'bound',\n",
       "   'achieve',\n",
       "   'kind',\n",
       "   'analysis',\n",
       "   'chapter_deviation']],\n",
       " [['theorem', 'theorem'],\n",
       "  ['markov_theorem'],\n",
       "  ['range'],\n",
       "  ['pr', 'range'],\n",
       "  ['example_suppose',\n",
       "   'flip_fair_coin',\n",
       "   'use',\n",
       "   'markov_theorem',\n",
       "   'compute_probability',\n",
       "   'get',\n",
       "   'head',\n",
       "   'head',\n",
       "   'ex',\n",
       "   'head',\n",
       "   'coin',\n",
       "   'mutually_independent',\n",
       "   'actual',\n",
       "   'probability_get',\n",
       "   'head',\n",
       "   'minuscule',\n",
       "   'chinese',\n",
       "   'appetizer',\n",
       "   'problem',\n",
       "   'suppose',\n",
       "   'person',\n",
       "   'get',\n",
       "   'original',\n",
       "   'appetizer',\n",
       "   'probability',\n",
       "   'ex',\n",
       "   'probability',\n",
       "   'ex',\n",
       "   'fact',\n",
       "   'bind',\n",
       "   'tight',\n",
       "   'sine',\n",
       "   'get',\n",
       "   'original',\n",
       "   'appetizer',\n",
       "   'back',\n",
       "   'rotate',\n",
       "   'tray',\n",
       "   'return',\n",
       "   'original',\n",
       "   'configuration',\n",
       "   'happen',\n",
       "   'probability',\n",
       "   'chinese',\n",
       "   'appetizer',\n",
       "   'problem',\n",
       "   'similar',\n",
       "   'hat',\n",
       "   'check',\n",
       "   'problem',\n",
       "   'study',\n",
       "   'section',\n",
       "   'probability',\n",
       "   'least',\n",
       "   'people',\n",
       "   'get',\n",
       "   'right',\n",
       "   'hat',\n",
       "   'back',\n",
       "   'markov_theorem',\n",
       "   'tell',\n",
       "   'ex',\n",
       "   'case',\n",
       "   'markov_theorem',\n",
       "   'far',\n",
       "   'right',\n",
       "   'answer',\n",
       "   'hat',\n",
       "   'distribute',\n",
       "   'accord',\n",
       "   'random',\n",
       "   'permutation',\n",
       "   'close',\n",
       "   'correct',\n",
       "   'answer',\n",
       "   'must',\n",
       "   'nonnegative',\n",
       "   'remember',\n",
       "   'markov_theorem',\n",
       "   'apply',\n",
       "   'nonnegative',\n",
       "   'random_variable',\n",
       "   'indeed',\n",
       "   'theorem',\n",
       "   'false',\n",
       "   'restriction',\n",
       "   'remove'],\n",
       "  ['example', 'let', 'proving', 'require', 'effort'],\n",
       "  ['wrong',\n",
       "   'answer',\n",
       "   'obviously',\n",
       "   'hand',\n",
       "   'still',\n",
       "   'apply',\n",
       "   'markov_theorem',\n",
       "   'indirectly',\n",
       "   'derive',\n",
       "   'bind',\n",
       "   'probability',\n",
       "   'arbitrary',\n",
       "   'variable',\n",
       "   'iff']],\n",
       " [['markov_theorem',\n",
       "   'bound',\n",
       "   'variable',\n",
       "   'suppose',\n",
       "   'learn',\n",
       "   'average',\n",
       "   'iq',\n",
       "   'mit_student',\n",
       "   'true',\n",
       "   'way'],\n",
       "  ['say',\n",
       "   'probability',\n",
       "   'mit_student',\n",
       "   'iq',\n",
       "   'markov_theorem',\n",
       "   'immediately',\n",
       "   'tell',\n",
       "   'us',\n",
       "   'student',\n",
       "   'high',\n",
       "   'iq'],\n",
       "  ['iq',\n",
       "   'random',\n",
       "   'mit_student',\n",
       "   'ex',\n",
       "   'let',\n",
       "   'also',\n",
       "   'suppose',\n",
       "   'mit_student',\n",
       "   'iq',\n",
       "   'less',\n",
       "   'may',\n",
       "   'half',\n",
       "   'student',\n",
       "   'amazing',\n",
       "   'think'],\n",
       "  ['bit',\n",
       "   'relief',\n",
       "   'generally',\n",
       "   'get',\n",
       "   'well',\n",
       "   'bound',\n",
       "   'apply',\n",
       "   'markov_theorem',\n",
       "   'theorem'],\n",
       "  ['let']],\n",
       " [['deviation_mean',\n",
       "   'markov_theorem',\n",
       "   'say',\n",
       "   'random_variable',\n",
       "   'unlikely',\n",
       "   'greatly',\n",
       "   'exceed',\n",
       "   'mean'],\n",
       "  ['correspondingly',\n",
       "   'variation',\n",
       "   'markov_theorem',\n",
       "   'say',\n",
       "   'run',\n",
       "   'dom',\n",
       "   'variable',\n",
       "   'unlikely',\n",
       "   'much',\n",
       "   'small',\n",
       "   'mean'],\n",
       "  ['theorem'],\n",
       "  ['let',\n",
       "   'chapter_deviation',\n",
       "   'example_suppose',\n",
       "   'class',\n",
       "   'average',\n",
       "   'midterm'],\n",
       "  ['fraction',\n",
       "   'class',\n",
       "   'score',\n",
       "   'enough',\n",
       "   'information',\n",
       "   'answer_question',\n",
       "   'exactly',\n",
       "   'theo',\n",
       "   'rem',\n",
       "   'give',\n",
       "   'upper_bind'],\n",
       "  ['let', 'half', 'class', 'score', 'worse'],\n",
       "  ['make_sense',\n",
       "   'half',\n",
       "   'class',\n",
       "   'score',\n",
       "   'bad',\n",
       "   'class',\n",
       "   'average',\n",
       "   'could',\n",
       "   'even',\n",
       "   'else',\n",
       "   'score'],\n",
       "  ['markov_theorem', 'theorem']],\n",
       " [['use',\n",
       "   'markov_theorem',\n",
       "   'analyze',\n",
       "   'non',\n",
       "   'random',\n",
       "   'event',\n",
       "   'previous',\n",
       "   'example',\n",
       "   'use',\n",
       "   'theorem',\n",
       "   'random_variable',\n",
       "   'conclude',\n",
       "   'fact',\n",
       "   'non',\n",
       "   'random',\n",
       "   'datum'],\n",
       "  ['example',\n",
       "   'conclude',\n",
       "   'average',\n",
       "   'score',\n",
       "   'test',\n",
       "   'reach',\n",
       "   'conclusion',\n",
       "   'explanation',\n",
       "   'difficult'],\n",
       "  ['set',\n",
       "   'score',\n",
       "   'introduce',\n",
       "   'random_variable',\n",
       "   'use',\n",
       "   'theorem',\n",
       "   'conclude']],\n",
       " [['chebyshev_theorem',\n",
       "   'see',\n",
       "   'markov_theorem',\n",
       "   'extend',\n",
       "   'apply',\n",
       "   'func',\n",
       "   'restatement',\n",
       "   'equation',\n",
       "   'theorem'],\n",
       "  ['chebyshev'],\n",
       "  ['let', 'proof'],\n",
       "  ['define', 'wwd', 'ex_pr', 'pr', 'corollary'],\n",
       "  ['let_pr', 'chapter_deviation', 'proof'],\n",
       "  ['substitute',\n",
       "   'example_suppose',\n",
       "   'addition',\n",
       "   'national',\n",
       "   'average',\n",
       "   'iq',\n",
       "   'also',\n",
       "   'know',\n",
       "   'standard_deviation',\n",
       "   'iq'],\n",
       "  ['rare',\n",
       "   'iq',\n",
       "   'let',\n",
       "   'random_variable',\n",
       "   'already',\n",
       "   'see',\n",
       "   'markov_theorem',\n",
       "   'give',\n",
       "   'coarse',\n",
       "   'bind',\n",
       "   'namely',\n",
       "   'apply',\n",
       "   'corollary',\n",
       "   'problem',\n",
       "   'chebyshev_theorem',\n",
       "   'imply',\n",
       "   'person',\n",
       "   'iq'],\n",
       "  ['gotten',\n",
       "   'much',\n",
       "   'tighter',\n",
       "   'bind',\n",
       "   'use',\n",
       "   'additional',\n",
       "   'information',\n",
       "   'namely',\n",
       "   'standard_deviation',\n",
       "   'generally',\n",
       "   'corollary',\n",
       "   'tell',\n",
       "   'random_variable',\n",
       "   'never',\n",
       "   'likely',\n",
       "   'stray',\n",
       "   'standard_deviation',\n",
       "   'mean'],\n",
       "  ['example',\n",
       "   'plug',\n",
       "   'ging',\n",
       "   'fact',\n",
       "   'nice',\n",
       "   'pictorial',\n",
       "   'pdf',\n",
       "   'bell',\n",
       "   'curve',\n",
       "   'shape',\n",
       "   'namely',\n",
       "   'width',\n",
       "   'bell']],\n",
       " [['bound',\n",
       "   'sided',\n",
       "   'error',\n",
       "   'corollary',\n",
       "   'give',\n",
       "   'bounds',\n",
       "   'probability',\n",
       "   'deviating',\n",
       "   'mean',\n",
       "   'direction'],\n",
       "  ['care',\n",
       "   'deviation',\n",
       "   'direction',\n",
       "   'case',\n",
       "   'iq',\n",
       "   'example',\n",
       "   'slightly',\n",
       "   'well',\n",
       "   'bound',\n",
       "   'obtain'],\n",
       "  ['theorem'],\n",
       "  ['random_variable', 'ex_pr', 'ex', 'mean'],\n",
       "  ['figure'],\n",
       "  ['pdf', 'random_variable', 'bell', 'shape', 'width', 'bell'],\n",
       "  ['proof_theorem', 'tricky', 'proof', 'chebyshev_theorem', 'give', 'detail'],\n",
       "  ['prove',\n",
       "   'fact',\n",
       "   'bound',\n",
       "   'theorem',\n",
       "   'good',\n",
       "   'bound',\n",
       "   'obtain',\n",
       "   'know',\n",
       "   'mean',\n",
       "   'standard_deviation',\n",
       "   'random_variable',\n",
       "   'return',\n",
       "   'iq',\n",
       "   'example',\n",
       "   'theorem',\n",
       "   'tell',\n",
       "   'slight',\n",
       "   'improvement',\n",
       "   'equation',\n",
       "   'example_suppose',\n",
       "   'give',\n",
       "   'exam'],\n",
       "  ['fraction',\n",
       "   'class',\n",
       "   'score',\n",
       "   'standard_deviation',\n",
       "   'average',\n",
       "   'sided',\n",
       "   'error',\n",
       "   'fraction',\n",
       "   'could',\n",
       "   'standard_deviation',\n",
       "   'average',\n",
       "   'result',\n",
       "   'hold',\n",
       "   'matter',\n",
       "   'test',\n",
       "   'score',\n",
       "   'deterministic',\n",
       "   'fact',\n",
       "   'derive',\n",
       "   'use',\n",
       "   'probabilistic',\n",
       "   'tool'],\n",
       "  ['chapter_deviation']],\n",
       " [['bound',\n",
       "   'sum',\n",
       "   'random_variable',\n",
       "   'know',\n",
       "   'random_variable',\n",
       "   'mean',\n",
       "   'variance',\n",
       "   'cheby',\n",
       "   'shev',\n",
       "   'theorem',\n",
       "   'best',\n",
       "   'come',\n",
       "   'bound',\n",
       "   'probabil',\n",
       "   'ity',\n",
       "   'random_variable',\n",
       "   'deviate',\n",
       "   'mean'],\n",
       "  ['case',\n",
       "   'however',\n",
       "   'know',\n",
       "   'example',\n",
       "   'random_variable',\n",
       "   'binomial_distribution',\n",
       "   'possible',\n",
       "   'prove',\n",
       "   'much',\n",
       "   'strong',\n",
       "   'bound'],\n",
       "  ['instead', 'polynomially', 'small', 'bound']],\n",
       " [['motivate',\n",
       "   'example',\n",
       "   'fussbook',\n",
       "   'new',\n",
       "   'social',\n",
       "   'networking',\n",
       "   'site',\n",
       "   'orient',\n",
       "   'unpleasant',\n",
       "   'people'],\n",
       "  ['major', 'web', 'service', 'fussbook', 'load', 'balancing', 'problem'],\n",
       "  ['specif', 'ically', 'fussbook', 'receive', 'forum', 'post', 'minute'],\n",
       "  ['post',\n",
       "   'sign',\n",
       "   'computer',\n",
       "   'process',\n",
       "   'computer',\n",
       "   'work',\n",
       "   'sequen',\n",
       "   'tially',\n",
       "   'assign',\n",
       "   'task'],\n",
       "  ['process', 'average', 'post', 'take', 'computer', 'second'],\n",
       "  ['post', 'pointless', 'grammar', 'critique', 'snide', 'witticism', 'easy'],\n",
       "  ['protract', 'harangue', 'require', 'full', 'second'],\n",
       "  ['balance',\n",
       "   'work',\n",
       "   'load',\n",
       "   'computer',\n",
       "   'vital',\n",
       "   'computer',\n",
       "   'sign',\n",
       "   'minute',\n",
       "   'work',\n",
       "   'minute',\n",
       "   'interval',\n",
       "   'computer',\n",
       "   'overload',\n",
       "   'system',\n",
       "   'performance',\n",
       "   'suffer'],\n",
       "  ['would', 'bad', 'fussbook', 'user', 'tolerant', 'bunch'],\n",
       "  ['early',\n",
       "   'idea',\n",
       "   'assign',\n",
       "   'computer',\n",
       "   'alphabetic',\n",
       "   'range',\n",
       "   'forum',\n",
       "   'topic'],\n",
       "  ['oughta', 'work', 'programmer', 'say'],\n",
       "  ['computer',\n",
       "   'handle',\n",
       "   'privacy',\n",
       "   'prefer',\n",
       "   'text',\n",
       "   'editor',\n",
       "   'thread',\n",
       "   'melt',\n",
       "   'drawback',\n",
       "   'approach',\n",
       "   'clear',\n",
       "   'guarantee'],\n",
       "  ['length',\n",
       "   'task',\n",
       "   'know',\n",
       "   'advance',\n",
       "   'finding',\n",
       "   'balance',\n",
       "   'dis',\n",
       "   'tribution',\n",
       "   'would',\n",
       "   'kind',\n",
       "   'bin',\n",
       "   'pack',\n",
       "   'problem'],\n",
       "  ['problem',\n",
       "   'hard',\n",
       "   'solve',\n",
       "   'exactly',\n",
       "   'approximation',\n",
       "   'algorithm',\n",
       "   'come',\n",
       "   'close'],\n",
       "  ['case',\n",
       "   'task',\n",
       "   'length',\n",
       "   'know',\n",
       "   'advance',\n",
       "   'typical',\n",
       "   'workload',\n",
       "   'problem',\n",
       "   'real',\n",
       "   'world'],\n",
       "  ['load',\n",
       "   'balancing',\n",
       "   'problem',\n",
       "   'seem',\n",
       "   'sort',\n",
       "   'hopeless',\n",
       "   'datum',\n",
       "   'available',\n",
       "   'guide',\n",
       "   'decision'],\n",
       "  ['heck',\n",
       "   'may',\n",
       "   'well',\n",
       "   'assign',\n",
       "   'task',\n",
       "   'computer',\n",
       "   'random',\n",
       "   'turn',\n",
       "   'random',\n",
       "   'assignment',\n",
       "   'balance',\n",
       "   'load',\n",
       "   'reasonably',\n",
       "   'well',\n",
       "   'also',\n",
       "   'permit',\n",
       "   'provable',\n",
       "   'performance',\n",
       "   'guarantee',\n",
       "   'place',\n",
       "   'oughta',\n",
       "   'work',\n",
       "   'sertion'],\n",
       "  ['general',\n",
       "   'randomized',\n",
       "   'approach',\n",
       "   'problem',\n",
       "   'worth',\n",
       "   'consider',\n",
       "   'deterministic',\n",
       "   'solution',\n",
       "   'hard',\n",
       "   'compute',\n",
       "   'require',\n",
       "   'unavailable',\n",
       "   'information'],\n",
       "  ['arithmetic', 'show', 'fussbook', 'traffic', 'sufficient', 'keep']],\n",
       " [['chernoff_bind',\n",
       "   'chernoff_bind',\n",
       "   'hammer',\n",
       "   'use',\n",
       "   'nail',\n",
       "   'great',\n",
       "   'many',\n",
       "   'problem'],\n",
       "  ['roughly',\n",
       "   'chernoff',\n",
       "   'bound',\n",
       "   'say',\n",
       "   'certain',\n",
       "   'random_variable',\n",
       "   'unlikely',\n",
       "   'significantly',\n",
       "   'exceed',\n",
       "   'expectation'],\n",
       "  ['example',\n",
       "   'expect',\n",
       "   'load',\n",
       "   'computer',\n",
       "   'bit',\n",
       "   'capacity',\n",
       "   'computer',\n",
       "   'unlikely',\n",
       "   'overload',\n",
       "   'provide',\n",
       "   'condition',\n",
       "   'chernoff_bind',\n",
       "   'satisfied'],\n",
       "  ['precisely',\n",
       "   'chernoff',\n",
       "   'bound',\n",
       "   'say',\n",
       "   'sum',\n",
       "   'lot',\n",
       "   'little',\n",
       "   'indepen',\n",
       "   'dent',\n",
       "   'random_variable',\n",
       "   'unlikely',\n",
       "   'significantly',\n",
       "   'exceed',\n",
       "   'mean',\n",
       "   'sum'],\n",
       "  ['markov',\n",
       "   'chebyshev',\n",
       "   'bound',\n",
       "   'lead',\n",
       "   'kind',\n",
       "   'conclusion',\n",
       "   'typically',\n",
       "   'provide',\n",
       "   'much',\n",
       "   'weak',\n",
       "   'bound'],\n",
       "  ['particular',\n",
       "   'markov',\n",
       "   'chebyshev',\n",
       "   'bound',\n",
       "   'polynomial',\n",
       "   'chernoff_bind',\n",
       "   'exponential'],\n",
       "  ['theorem'],\n",
       "  ['proof', 'come', 'later', 'section', 'theorem'],\n",
       "  ['chernoff_bind'],\n",
       "  ['let',\n",
       "   'chernoff',\n",
       "   'bound',\n",
       "   'applies',\n",
       "   'distribution',\n",
       "   'sum',\n",
       "   'independent',\n",
       "   'random_variable',\n",
       "   'take',\n",
       "   'value',\n",
       "   'interval',\n",
       "   'chernoff',\n",
       "   'figure',\n",
       "   'beat',\n",
       "   'state',\n",
       "   'lottery'],\n",
       "  ['may', 'want', 'pay', 'attention', 'guy', 'know', 'thing'],\n",
       "  ['chapter_deviation',\n",
       "   'example',\n",
       "   'chernoff_bind',\n",
       "   'pretty',\n",
       "   'easy',\n",
       "   'apply',\n",
       "   'detail',\n",
       "   'daunt',\n",
       "   'first'],\n",
       "  ['let', 'walk', 'simple', 'example', 'get', 'hang'],\n",
       "  ['probability',\n",
       "   'number_head',\n",
       "   'come',\n",
       "   'indepen',\n",
       "   'dent',\n",
       "   'toss',\n",
       "   'fair_coin',\n",
       "   'exceed',\n",
       "   'expectation',\n",
       "   'let',\n",
       "   'chernoff',\n",
       "   'bound',\n",
       "   'require',\n",
       "   'random_variable',\n",
       "   'goal',\n",
       "   'bind',\n",
       "   'probability',\n",
       "   'number_head',\n",
       "   'exceed',\n",
       "   'expec',\n",
       "   'tation',\n",
       "   'bind',\n",
       "   'ln',\n",
       "   'plug',\n",
       "   'value',\n",
       "   'chernoff_bind',\n",
       "   'give',\n",
       "   'pr',\n",
       "   'ex_ex',\n",
       "   'probability_get',\n",
       "   'extra',\n",
       "   'head',\n",
       "   'coin',\n",
       "   'less'],\n",
       "  ['bind',\n",
       "   'become',\n",
       "   'much',\n",
       "   'strong',\n",
       "   'number',\n",
       "   'coin',\n",
       "   'increase',\n",
       "   'expect_number',\n",
       "   'head',\n",
       "   'appear',\n",
       "   'exponent',\n",
       "   'upper_bind'],\n",
       "  ['example',\n",
       "   'probability_get',\n",
       "   'least',\n",
       "   'extra',\n",
       "   'head',\n",
       "   'coin',\n",
       "   'pretty',\n",
       "   'darn',\n",
       "   'small'],\n",
       "  ['alternatively', 'bind', 'also', 'become', 'strong', 'large', 'deviation'],\n",
       "  ['exam_ple',\n",
       "   'suppose',\n",
       "   'interested',\n",
       "   'odd',\n",
       "   'get',\n",
       "   'extra',\n",
       "   'head',\n",
       "   'toss',\n",
       "   'rather'],\n",
       "  ['case',\n",
       "   'analyze',\n",
       "   'binomial_distribution',\n",
       "   'get',\n",
       "   'somewhat',\n",
       "   'well',\n",
       "   'bound',\n",
       "   'use',\n",
       "   'method',\n",
       "   'section',\n",
       "   'pick',\n",
       "   'pick',\n",
       "   'lottery',\n",
       "   'game',\n",
       "   'pick',\n",
       "   'digit',\n",
       "   'number'],\n",
       "  ['number', 'come', 'random', 'drawing', 'win'],\n",
       "  ['chance', 'win'],\n",
       "  ['people', 'play', 'expect_number', 'winner'],\n",
       "  ['lottery',\n",
       "   'operator',\n",
       "   'nightmare',\n",
       "   'number',\n",
       "   'winner',\n",
       "   'much',\n",
       "   'great',\n",
       "   'say'],\n",
       "  ['probability',\n",
       "   'happen',\n",
       "   'let',\n",
       "   'player',\n",
       "   'pick',\n",
       "   'win',\n",
       "   'number',\n",
       "   'random',\n",
       "   'independent',\n",
       "   'uniform',\n",
       "   'indicator',\n",
       "   'winner',\n",
       "   'would',\n",
       "   'twice',\n",
       "   'expect_number',\n",
       "   'choose',\n",
       "   'ex_ex',\n",
       "   'almost',\n",
       "   'chance',\n",
       "   'lottery',\n",
       "   'operator',\n",
       "   'pay',\n",
       "   'double'],\n",
       "  ['fact', 'number', 'winner', 'even', 'higher', 'expect', 'often'],\n",
       "  ['prove',\n",
       "   'let_pr',\n",
       "   'ex',\n",
       "   'pick',\n",
       "   'lottery',\n",
       "   'may',\n",
       "   'exciting',\n",
       "   'player',\n",
       "   'lottery',\n",
       "   'operator',\n",
       "   'little',\n",
       "   'doubt',\n",
       "   'outcome',\n",
       "   'randomized',\n",
       "   'load',\n",
       "   'balancing',\n",
       "   'let',\n",
       "   'return',\n",
       "   'fussbook',\n",
       "   'load',\n",
       "   'balancing',\n",
       "   'problem'],\n",
       "  ['specifically',\n",
       "   'need',\n",
       "   'determine',\n",
       "   'many',\n",
       "   'machine',\n",
       "   'suffice',\n",
       "   'ensure',\n",
       "   'server',\n",
       "   'overload',\n",
       "   'note',\n",
       "   'chapter',\n",
       "   'chapter_deviation',\n",
       "   'assign',\n",
       "   'minute',\n",
       "   'work',\n",
       "   'minute',\n",
       "   'interval'],\n",
       "  ['begin', 'let', 'find', 'probability', 'first', 'server', 'overload'],\n",
       "  ['let',\n",
       "   'would',\n",
       "   'chernoff_bind',\n",
       "   'applicable',\n",
       "   'task',\n",
       "   'expect',\n",
       "   'length',\n",
       "   'second'],\n",
       "  ['task',\n",
       "   'assign',\n",
       "   'computer',\n",
       "   'random',\n",
       "   'expect',\n",
       "   'load',\n",
       "   'first',\n",
       "   'server',\n",
       "   'example',\n",
       "   'use',\n",
       "   'chernoff_bind',\n",
       "   'upper_bind',\n",
       "   'probability',\n",
       "   'first',\n",
       "   'probability',\n",
       "   'server',\n",
       "   'overload',\n",
       "   'ln'],\n",
       "  ['value', 'suggest', 'system']],\n",
       " [['proof', 'chernoff_bind', 'proof', 'chernoff_bind', 'somewhat', 'involve'],\n",
       "  ['even',\n",
       "   'chernoff',\n",
       "   'come',\n",
       "   'friend',\n",
       "   'herman',\n",
       "   'rubin',\n",
       "   'show',\n",
       "   'argument'],\n",
       "  ['think', 'bind', 'significant', 'chernoff', 'credit', 'rubin', 'print'],\n",
       "  ['feel',\n",
       "   'pretty',\n",
       "   'bad',\n",
       "   'become',\n",
       "   'famous',\n",
       "   'theorem',\n",
       "   'reference',\n",
       "   'theorem'],\n",
       "  ['chernoff_bind'],\n",
       "  ['let', 'proof'],\n",
       "  ['clarity',\n",
       "   'go',\n",
       "   'proof',\n",
       "   'top',\n",
       "   'use',\n",
       "   'fact',\n",
       "   'prove',\n",
       "   'immediately',\n",
       "   'afterward'],\n",
       "  ['key',\n",
       "   'step',\n",
       "   'exponentiate',\n",
       "   'side',\n",
       "   'inequality',\n",
       "   'ex',\n",
       "   'prove',\n",
       "   'lemma',\n",
       "   'fact',\n",
       "   'ln',\n",
       "   'see',\n",
       "   'conversation',\n",
       "   'herman',\n",
       "   'chernoff',\n",
       "   'statistical',\n",
       "   'science',\n",
       "   'vol'],\n",
       "  ['chapter_deviation',\n",
       "   'algebra',\n",
       "   'aside',\n",
       "   'brilliant',\n",
       "   'idea',\n",
       "   'proof',\n",
       "   'context',\n",
       "   'exponenti',\n",
       "   'ate',\n",
       "   'somehow',\n",
       "   'supercharge',\n",
       "   'markov',\n",
       "   'bind'],\n",
       "  ['true',\n",
       "   'general',\n",
       "   'unfortunate',\n",
       "   'side',\n",
       "   'effect',\n",
       "   'bind',\n",
       "   'nasty',\n",
       "   'expectation',\n",
       "   'involve',\n",
       "   'exponential',\n",
       "   'order',\n",
       "   'complete',\n",
       "   'proof'],\n",
       "  ['do', 'lemmas', 'variable', 'take', 'value', 'theorem', 'lemma'],\n",
       "  ['ex_ex', 'proof'],\n",
       "  ['ex_ex',\n",
       "   'ex_ex',\n",
       "   'first_step',\n",
       "   'use',\n",
       "   'definition',\n",
       "   'prove',\n",
       "   'lemma',\n",
       "   'proof'],\n",
       "  ['summation',\n",
       "   'range',\n",
       "   'value',\n",
       "   'require',\n",
       "   'interval',\n",
       "   'ex_ex',\n",
       "   'first_step',\n",
       "   'use',\n",
       "   'definition',\n",
       "   'expectation'],\n",
       "  ['second',\n",
       "   'step',\n",
       "   'rely',\n",
       "   'inequality',\n",
       "   'variable',\n",
       "   'second',\n",
       "   'sum',\n",
       "   'leave',\n",
       "   'definition',\n",
       "   'ex',\n",
       "   'use',\n",
       "   'standard',\n",
       "   'inequality']],\n",
       " [['mutually_independent',\n",
       "   'event',\n",
       "   'suppose',\n",
       "   'collection',\n",
       "   'mutually_independent',\n",
       "   'event',\n",
       "   'let_pr',\n",
       "   'pr',\n",
       "   'number',\n",
       "   'event_occur'],\n",
       "  ['chapter_deviation',\n",
       "   'know',\n",
       "   'linearity_expectation',\n",
       "   'ex_ex',\n",
       "   'true',\n",
       "   'even',\n",
       "   'event_independent'],\n",
       "  ['theorem',\n",
       "   'var',\n",
       "   'var',\n",
       "   'thus',\n",
       "   'true',\n",
       "   'even',\n",
       "   'event',\n",
       "   'pairwise',\n",
       "   'independent'],\n",
       "  ['markov_theorem',\n",
       "   'tell',\n",
       "   'ex',\n",
       "   'chebyshev_theorem',\n",
       "   'give',\n",
       "   'strong',\n",
       "   'result',\n",
       "   'pr',\n",
       "   'chernoff_bind',\n",
       "   'give',\n",
       "   'even',\n",
       "   'strong',\n",
       "   'result',\n",
       "   'namely',\n",
       "   'ex',\n",
       "   'ln',\n",
       "   'ex',\n",
       "   'case',\n",
       "   'probability',\n",
       "   'exceed',\n",
       "   'mean',\n",
       "   'consider',\n",
       "   'random_variable']],\n",
       " [['murphy',\n",
       "   'law',\n",
       "   'suppose_want',\n",
       "   'know',\n",
       "   'probability',\n",
       "   'least',\n",
       "   'event_occur'],\n",
       "  ['ex_pr', 'ex', 'hand', 'ex', 'theorem'],\n",
       "  ['murphy', 'law'],\n",
       "  ['let', 'wwd', 'number', 'event_occur'],\n",
       "  ['pr', 'ex', 'proof'],\n",
       "  ['pr',\n",
       "   'example',\n",
       "   'give',\n",
       "   'set',\n",
       "   'mutually_independent',\n",
       "   'event',\n",
       "   'expect',\n",
       "   'happen',\n",
       "   'least',\n",
       "   'happen',\n",
       "   'probability',\n",
       "   'least',\n",
       "   'lot',\n",
       "   'independent',\n",
       "   'thing',\n",
       "   'go_wrong',\n",
       "   'probabil',\n",
       "   'itie',\n",
       "   'sum',\n",
       "   'number',\n",
       "   'much',\n",
       "   'great',\n",
       "   'theorem_prove',\n",
       "   'surely',\n",
       "   'go_wrong'],\n",
       "  ['reference', 'deference', 'famous', 'say', 'go_wrong', 'go_wrong'],\n",
       "  ['chapter_deviation',\n",
       "   'result',\n",
       "   'help',\n",
       "   'explain',\n",
       "   'coincidence',\n",
       "   'miracle',\n",
       "   'crazy',\n",
       "   'event',\n",
       "   'seem',\n",
       "   'unlikely',\n",
       "   'happen'],\n",
       "  ['event',\n",
       "   'happen',\n",
       "   'part',\n",
       "   'many',\n",
       "   'possible',\n",
       "   'unlikely',\n",
       "   'event',\n",
       "   'sum',\n",
       "   'probability',\n",
       "   'great'],\n",
       "  ['example', 'win', 'lottery'],\n",
       "  ['fact',\n",
       "   'random',\n",
       "   'ticket',\n",
       "   'pick',\n",
       "   'theorem',\n",
       "   'say',\n",
       "   'probability',\n",
       "   'winner',\n",
       "   'less']],\n",
       " [['magic', 'trick', 'theorem', 'surprisingly', 'powerful'],\n",
       "  ['fact', 'powerful', 'enable', 'read', 'mind'],\n",
       "  ['choose', 'secret', 'number'],\n",
       "  ['randomly', 'shuffle', 'ordinary', 'deck_card', 'display', 'card', 'time'],\n",
       "  ['watch',\n",
       "   'reveal',\n",
       "   'card_reveal',\n",
       "   'nth',\n",
       "   'card',\n",
       "   'card',\n",
       "   'become',\n",
       "   'secret_card'],\n",
       "  ['card', 'ace', 'face', 'card', 'assign', 'card', 'value'],\n",
       "  ['otherwise', 'assign', 'card', 'value', 'number'],\n",
       "  ['example',\n",
       "   'get',\n",
       "   'assign',\n",
       "   'value',\n",
       "   'keep',\n",
       "   'revealing',\n",
       "   'card',\n",
       "   'proceed',\n",
       "   'fashion',\n",
       "   'card_reveal',\n",
       "   'whereupon',\n",
       "   'read',\n",
       "   'mind',\n",
       "   'predict',\n",
       "   'last',\n",
       "   'secret_card',\n",
       "   'possible',\n",
       "   'purpose',\n",
       "   'illustration',\n",
       "   'suppose',\n",
       "   'secret',\n",
       "   'number',\n",
       "   'deck',\n",
       "   'consist',\n",
       "   'card',\n",
       "   'secret_card',\n",
       "   'would',\n",
       "   'since',\n",
       "   'make',\n",
       "   'trick',\n",
       "   'work',\n",
       "   'follow',\n",
       "   'rule',\n",
       "   'start'],\n",
       "  ['card_deck',\n",
       "   'show',\n",
       "   'secret_card',\n",
       "   'would',\n",
       "   'last',\n",
       "   'secret_card',\n",
       "   'coincidence'],\n",
       "  ['fact', 'predict', 'last', 'card', 'guess', 'last', 'card'],\n",
       "  ['right', 'probability', 'great'],\n",
       "  ['see',\n",
       "   'trick',\n",
       "   'likely',\n",
       "   'work',\n",
       "   'need',\n",
       "   'notice',\n",
       "   'ever',\n",
       "   'share',\n",
       "   'secret_card',\n",
       "   'surely',\n",
       "   'last',\n",
       "   'secret_card'],\n",
       "  ['perform', 'exactly', 'step', 'card_reveal'],\n",
       "  ['time', 'new', 'secret_card', 'always', 'chance', 'secret_card'],\n",
       "  ['give', 'step', 'chance', 'match', 'small', 'get', 'lot', 'chance'],\n",
       "  ['fact',\n",
       "   'number',\n",
       "   'chance',\n",
       "   'typically',\n",
       "   'outweigh',\n",
       "   'inverse',\n",
       "   'probability',\n",
       "   'match',\n",
       "   'give',\n",
       "   'step',\n",
       "   'least',\n",
       "   'informally',\n",
       "   'murphy',\n",
       "   'law',\n",
       "   'suggest',\n",
       "   'likely',\n",
       "   'eventually',\n",
       "   'match',\n",
       "   'whereupon',\n",
       "   'read',\n",
       "   'mind'],\n",
       "  ['detail', 'proof', 'complicate', 'present'],\n",
       "  ['main',\n",
       "   'complication',\n",
       "   'reveal',\n",
       "   'card_deck',\n",
       "   'replacement',\n",
       "   'probability_get',\n",
       "   'match',\n",
       "   'give',\n",
       "   'step',\n",
       "   'conditional',\n",
       "   'base',\n",
       "   'card',\n",
       "   'already',\n",
       "   'reveal']],\n",
       " [['subprime',\n",
       "   'mortgage',\n",
       "   'disaster',\n",
       "   'last',\n",
       "   'chapter',\n",
       "   'see',\n",
       "   'many',\n",
       "   'example',\n",
       "   'powerful',\n",
       "   'conclusion',\n",
       "   'draw',\n",
       "   'collection',\n",
       "   'event',\n",
       "   'event_independent'],\n",
       "  ['course', 'conclusion', 'totally', 'invalid', 'event', 'dependency'],\n",
       "  ['unforeseen', 'dependencies', 'result', 'disaster', 'practice'],\n",
       "  ['example',\n",
       "   'misguided',\n",
       "   'assumption',\n",
       "   'independence',\n",
       "   'loan',\n",
       "   'combine',\n",
       "   'large',\n",
       "   'amount',\n",
       "   'greed',\n",
       "   'trigger',\n",
       "   'global',\n",
       "   'financial',\n",
       "   'meltdown'],\n",
       "  ['follow', 'explain', 'go_wrong'],\n",
       "  ['may', 'notice', 'change', 'name', 'key', 'participant'],\n",
       "  ['protect', 'innocent', 'innocent', 'far', 'sordid', 'tale'],\n",
       "  ['rather', 'change', 'name', 'protect'],\n",
       "  ['fact',\n",
       "   'safe',\n",
       "   'side',\n",
       "   'forget',\n",
       "   'really',\n",
       "   'happen',\n",
       "   'earth',\n",
       "   'instead',\n",
       "   'tell',\n",
       "   'fairy',\n",
       "   'tale',\n",
       "   'take',\n",
       "   'place',\n",
       "   'land',\n",
       "   'far',\n",
       "   'far',\n",
       "   'away'],\n",
       "  ['central',\n",
       "   'player',\n",
       "   'story',\n",
       "   'major',\n",
       "   'wall',\n",
       "   'street',\n",
       "   'firm',\n",
       "   'golden',\n",
       "   'scoundrel',\n",
       "   'commonly',\n",
       "   'refer',\n",
       "   'golden',\n",
       "   'big',\n",
       "   'aggressive'],\n",
       "  ['firm',\n",
       "   'golden',\n",
       "   'ostensibly',\n",
       "   'exist',\n",
       "   'make',\n",
       "   'market',\n",
       "   'purport',\n",
       "   'create',\n",
       "   'open',\n",
       "   'orderly',\n",
       "   'market',\n",
       "   'buyer',\n",
       "   'seller',\n",
       "   'bring',\n",
       "   'together',\n",
       "   'capitalism',\n",
       "   'flourish'],\n",
       "  ['sound',\n",
       "   'good',\n",
       "   'fee',\n",
       "   'facilitate',\n",
       "   'transaction',\n",
       "   'truly',\n",
       "   'open',\n",
       "   'orderly',\n",
       "   'market',\n",
       "   'often',\n",
       "   'enough',\n",
       "   'satisfy',\n",
       "   'ever',\n",
       "   'increase',\n",
       "   'need',\n",
       "   'make'],\n",
       "  ['employee',\n",
       "   'much',\n",
       "   'detailed',\n",
       "   'accounting',\n",
       "   'event',\n",
       "   'name',\n",
       "   'name',\n",
       "   'may',\n",
       "   'enjoy',\n",
       "   'read',\n",
       "   'big',\n",
       "   'short',\n",
       "   'michael',\n",
       "   'lewis'],\n",
       "  ['chapter_deviation',\n",
       "   'firm',\n",
       "   'always',\n",
       "   'try',\n",
       "   'figure',\n",
       "   'way',\n",
       "   'create',\n",
       "   'new',\n",
       "   'opportunity',\n",
       "   'make',\n",
       "   'even',\n",
       "   'money'],\n",
       "  ['day', 'come', 'whopper'],\n",
       "  ['suppose',\n",
       "   'buy',\n",
       "   'collection',\n",
       "   'say',\n",
       "   'subprime',\n",
       "   'mortgage',\n",
       "   'loan',\n",
       "   'country',\n",
       "   'package',\n",
       "   'single',\n",
       "   'entity',\n",
       "   'call',\n",
       "   'bond'],\n",
       "  ['mortgage',\n",
       "   'loan',\n",
       "   'loan',\n",
       "   'homeowner',\n",
       "   'use',\n",
       "   'house',\n",
       "   'collateral',\n",
       "   'homeowner',\n",
       "   'stop',\n",
       "   'pay',\n",
       "   'loan',\n",
       "   'case',\n",
       "   'loan',\n",
       "   'say',\n",
       "   'default',\n",
       "   'owner',\n",
       "   'loan',\n",
       "   'take',\n",
       "   'ownership',\n",
       "   'house'],\n",
       "  ['mortgage',\n",
       "   'loan',\n",
       "   'classify',\n",
       "   'subprime',\n",
       "   'homeowner',\n",
       "   'good',\n",
       "   'credit',\n",
       "   'history'],\n",
       "  ['subprime_loan', 'consider', 'risky', 'prime', 'loan', 'likely', 'default'],\n",
       "  ['default',\n",
       "   'bad',\n",
       "   'homeowner',\n",
       "   'lose',\n",
       "   'home',\n",
       "   'loan',\n",
       "   'owner',\n",
       "   'get',\n",
       "   'stuck',\n",
       "   'try',\n",
       "   'sell',\n",
       "   'house',\n",
       "   'take',\n",
       "   'year',\n",
       "   'often',\n",
       "   'result',\n",
       "   'high',\n",
       "   'loss'],\n",
       "  ['course',\n",
       "   'bond',\n",
       "   'consist',\n",
       "   'subprime_loan',\n",
       "   'sound',\n",
       "   'appeal',\n",
       "   'ing',\n",
       "   'investor',\n",
       "   'dress',\n",
       "   'golden',\n",
       "   'sell',\n",
       "   'bond',\n",
       "   'tranche'],\n",
       "  ['idea', 'tranche', 'provide', 'way', 'assign', 'loss', 'default'],\n",
       "  ['typical', 'scenario', 'would', 'tranche', 'prioritize'],\n",
       "  ['default', 'assess', 'low_tranche', 'first'],\n",
       "  ['example_suppose',\n",
       "   'default',\n",
       "   'collection',\n",
       "   'loan',\n",
       "   'impossibly',\n",
       "   'high',\n",
       "   'number',\n",
       "   'default',\n",
       "   'accord',\n",
       "   'golden'],\n",
       "  ['low_tranche',\n",
       "   'would',\n",
       "   'absorb',\n",
       "   'first',\n",
       "   'default',\n",
       "   'effectively',\n",
       "   'wipe',\n",
       "   'loan',\n",
       "   'would',\n",
       "   'default',\n",
       "   'second',\n",
       "   'low_tranche',\n",
       "   'would',\n",
       "   'assign',\n",
       "   'next',\n",
       "   'default',\n",
       "   'wipe',\n",
       "   'half',\n",
       "   'investment'],\n",
       "  ['remain', 'tranche_would', 'great', 'none', 'loan', 'would', 'default'],\n",
       "  ['take', 'risk', 'low_tranche', 'would', 'interest', 'payment'],\n",
       "  ['top', 'tranche_would', 'low', 'rate', 'return', 'would', 'also', 'safest'],\n",
       "  ['low_tranche', 'would', 'interest', 'also', 'expose'],\n",
       "  ['much',\n",
       "   'pay',\n",
       "   'tranche',\n",
       "   'suppose',\n",
       "   'probability',\n",
       "   'give',\n",
       "   'loan',\n",
       "   'default',\n",
       "   'year'],\n",
       "  ['word', 'suppose', 'expect', 'loan', 'default', 'year'],\n",
       "  ['default',\n",
       "   'independent',\n",
       "   'use',\n",
       "   'chernoff_bind',\n",
       "   'conclude',\n",
       "   'chance',\n",
       "   'defaults',\n",
       "   'loan',\n",
       "   'collection',\n",
       "   'exceedingly',\n",
       "   'tiny'],\n",
       "  ['mean', 'tranche', 'lowest', 'essentially', 'risk', 'free'],\n",
       "  ['excellent',\n",
       "   'news',\n",
       "   'golden',\n",
       "   'buy',\n",
       "   'cheap',\n",
       "   'subprime_loan',\n",
       "   'sell',\n",
       "   'top',\n",
       "   'tranche',\n",
       "   'premium',\n",
       "   'rate',\n",
       "   'thereby',\n",
       "   'make',\n",
       "   'large',\n",
       "   'instant',\n",
       "   'profit',\n",
       "   'loan'],\n",
       "  ['turn', 'bunch', 'junk', 'bunch', 'gold', 'little', 'junk', 'leave'],\n",
       "  ['remain',\n",
       "   'problem',\n",
       "   'low_tranche',\n",
       "   'expect',\n",
       "   'default',\n",
       "   'pool',\n",
       "   'loan',\n",
       "   'default',\n",
       "   'rate'],\n",
       "  ['good', 'subprime_loan'],\n",
       "  ['first',\n",
       "   'thing',\n",
       "   'give',\n",
       "   'tranche',\n",
       "   'better',\n",
       "   'sound',\n",
       "   'name',\n",
       "   'low_tranche'],\n",
       "  ['mezzanine_tranche', 'sound', 'much', 'less', 'ominous', 'use'],\n",
       "  ['chernoff_bind',\n",
       "   'default',\n",
       "   'rate',\n",
       "   'mezzanine_tranche',\n",
       "   'un',\n",
       "   'likely',\n",
       "   'much',\n",
       "   'great',\n",
       "   'risk',\n",
       "   'own',\n",
       "   'tranche',\n",
       "   'address',\n",
       "   'part',\n",
       "   'increase',\n",
       "   'interest',\n",
       "   'payment',\n",
       "   'tranche'],\n",
       "  ['golden',\n",
       "   'even_well',\n",
       "   'idea',\n",
       "   'whopper',\n",
       "   'number',\n",
       "   'rather',\n",
       "   'pay',\n",
       "   'ex',\n",
       "   'tra',\n",
       "   'collect',\n",
       "   'together',\n",
       "   'bunch',\n",
       "   'mezzanine',\n",
       "   'tranches',\n",
       "   'bunch',\n",
       "   'bond',\n",
       "   'package',\n",
       "   'together',\n",
       "   'super',\n",
       "   'bond',\n",
       "   'create',\n",
       "   'tranche',\n",
       "   'super',\n",
       "   'bond',\n",
       "   'technical',\n",
       "   'name',\n",
       "   'super',\n",
       "   'bond',\n",
       "   'collateralize',\n",
       "   'debt',\n",
       "   'obligation',\n",
       "   'cdo'],\n",
       "  ['way',\n",
       "   'mezzanine_tranche',\n",
       "   'instantly',\n",
       "   'come',\n",
       "   'essentially',\n",
       "   'risk',\n",
       "   'free',\n",
       "   'golden',\n",
       "   'claim',\n",
       "   'marketing'],\n",
       "  ['problem',\n",
       "   'get',\n",
       "   'pension',\n",
       "   'fund',\n",
       "   'big',\n",
       "   'investor',\n",
       "   'buy',\n",
       "   'cdos',\n",
       "   'price',\n",
       "   'aaa',\n",
       "   'rate',\n",
       "   'risk',\n",
       "   'free',\n",
       "   'bond'],\n",
       "  ['little',\n",
       "   'tricky',\n",
       "   'virtually',\n",
       "   'impossible',\n",
       "   'buyer',\n",
       "   'figure',\n",
       "   'exactly',\n",
       "   'loan',\n",
       "   'effectively',\n",
       "   'buy',\n",
       "   'buy',\n",
       "   'tranche',\n",
       "   'collection',\n",
       "   'tranche',\n",
       "   'could',\n",
       "   'ever',\n",
       "   'figure',\n",
       "   'would',\n",
       "   'discover',\n",
       "   'junk',\n",
       "   'junk',\n",
       "   'come',\n",
       "   'loan'],\n",
       "  ['solution',\n",
       "   'enlist',\n",
       "   'help',\n",
       "   'big',\n",
       "   'bond',\n",
       "   'rating',\n",
       "   'agency',\n",
       "   'substandard',\n",
       "   'prevaricator',\n",
       "   'mopey'],\n",
       "  ['golden',\n",
       "   'could',\n",
       "   'aaa',\n",
       "   'rating',\n",
       "   'tranche',\n",
       "   'pension',\n",
       "   'fund',\n",
       "   'big',\n",
       "   'investor',\n",
       "   'would',\n",
       "   'buy',\n",
       "   'premium',\n",
       "   'rate'],\n",
       "  ['turn',\n",
       "   'easy',\n",
       "   'may_think',\n",
       "   'hope',\n",
       "   'convince',\n",
       "   'mopey',\n",
       "   'give',\n",
       "   'high',\n",
       "   'rating',\n",
       "   'cdo',\n",
       "   'tranche'],\n",
       "  ['rating', 'agency', 'try', 'make_money', 'make_money', 'rating', 'bond'],\n",
       "  ['golden', 'go', 'pay', 'bond', 'cdos', 'get', 'good', 'rating'],\n",
       "  ['default',\n",
       "   'assume',\n",
       "   'essentially',\n",
       "   'independent',\n",
       "   'good',\n",
       "   'argument',\n",
       "   'mezzanine_tranche',\n",
       "   'bond',\n",
       "   'cdo',\n",
       "   'would',\n",
       "   'essentially',\n",
       "   'risk',\n",
       "   'free'],\n",
       "  ['stage', 'set', 'golden', 'make', 'bundle', 'money'],\n",
       "  ['cheap',\n",
       "   'junk',\n",
       "   'loan',\n",
       "   'come',\n",
       "   'back',\n",
       "   'door',\n",
       "   'exit',\n",
       "   'expensive',\n",
       "   'aaa',\n",
       "   'rate',\n",
       "   'bond',\n",
       "   'cdos',\n",
       "   'front',\n",
       "   'door'],\n",
       "  ['remain', 'challenge', 'ramp', 'new', 'money', 'make', 'machine'],\n",
       "  ['aaa',\n",
       "   'rating',\n",
       "   'best',\n",
       "   'get',\n",
       "   'suppose',\n",
       "   'imply',\n",
       "   'virtually',\n",
       "   'chance',\n",
       "   'default'],\n",
       "  ['logic',\n",
       "   'get',\n",
       "   'little',\n",
       "   'fuzzy',\n",
       "   'keep',\n",
       "   'slice',\n",
       "   'dicing',\n",
       "   'tranche',\n",
       "   'iteration',\n",
       "   'able',\n",
       "   'conclude',\n",
       "   'mezzanine_tranche',\n",
       "   'sure',\n",
       "   'default',\n",
       "   'require',\n",
       "   'effort',\n",
       "   'see',\n",
       "   'go',\n",
       "   'cover',\n",
       "   'effort',\n",
       "   'cost',\n",
       "   'money',\n",
       "   'rating',\n",
       "   'agency',\n",
       "   'consider',\n",
       "   'risk',\n",
       "   'mezzanine_tranche',\n",
       "   'cdo',\n",
       "   'mezzanine_tranche',\n",
       "   'even',\n",
       "   'though',\n",
       "   'could',\n",
       "   'wildly',\n",
       "   'different',\n",
       "   'probability',\n",
       "   'sustain',\n",
       "   'large_number',\n",
       "   'default'],\n",
       "  ['chapter_deviation',\n",
       "   'mean',\n",
       "   'create',\n",
       "   'preferably',\n",
       "   'many',\n",
       "   'many',\n",
       "   'junk',\n",
       "   'loan',\n",
       "   'fuel',\n",
       "   'machine'],\n",
       "  ['joe', 'enters', 'scene'],\n",
       "  ['joe', 'migrant', 'laborer', 'earn', 'year'],\n",
       "  ['joe',\n",
       "   'credit',\n",
       "   'history',\n",
       "   'great',\n",
       "   'never',\n",
       "   'loan',\n",
       "   'credit',\n",
       "   'card',\n",
       "   'also',\n",
       "   'bad',\n",
       "   'never',\n",
       "   'miss',\n",
       "   'payment',\n",
       "   'credit',\n",
       "   'card',\n",
       "   'never',\n",
       "   'default',\n",
       "   'loan'],\n",
       "  ['short',\n",
       "   'joe',\n",
       "   'perfect',\n",
       "   'candidate',\n",
       "   'subprime',\n",
       "   'mortgage',\n",
       "   'loan',\n",
       "   'home'],\n",
       "  ['loan',\n",
       "   'us',\n",
       "   'approach',\n",
       "   'joe',\n",
       "   'home',\n",
       "   'loan',\n",
       "   'joe',\n",
       "   'dutifully',\n",
       "   'explain',\n",
       "   'would',\n",
       "   'love',\n",
       "   'home',\n",
       "   'enough',\n",
       "   'money',\n",
       "   'pay',\n",
       "   'food',\n",
       "   'let',\n",
       "   'alone',\n",
       "   'interest',\n",
       "   'payment',\n",
       "   'mortgage'],\n",
       "  ['problem', 'reply', 'loan'],\n",
       "  ['joe', 'lucky', 'day'],\n",
       "  ['interest',\n",
       "   'rate',\n",
       "   'super',\n",
       "   'low',\n",
       "   'first',\n",
       "   'year',\n",
       "   'joe',\n",
       "   'take',\n",
       "   'second',\n",
       "   'loan',\n",
       "   'cover',\n",
       "   'period'],\n",
       "  ['happen', 'year', 'joe', 'want', 'know'],\n",
       "  ['problem', 'reply', 'loan'],\n",
       "  ['joe', 'refinance', 'home', 'surely', 'worth', 'year'],\n",
       "  ['indeed', 'joe', 'even', 'make_money', 'enjoy', 'comfort', 'new', 'home'],\n",
       "  ['go', 'even', 'ease', 'laborer', 'work', 'maybe', 'even', 'second', 'home'],\n",
       "  ['joe', 'sell'],\n",
       "  ['fact',\n",
       "   'million',\n",
       "   'joe',\n",
       "   'sell',\n",
       "   'long',\n",
       "   'subprime_loan',\n",
       "   'business',\n",
       "   'booming'],\n",
       "  ['turn', 'folk', 'really', 'math', 'homework', 'college'],\n",
       "  ['run',\n",
       "   'hedge_fund',\n",
       "   'money',\n",
       "   'make',\n",
       "   'machine',\n",
       "   'crank',\n",
       "   'away',\n",
       "   'realize',\n",
       "   'disaster',\n",
       "   'looming'],\n",
       "  ['knew', 'loan', 'default', 'independent', 'fact', 'dependent'],\n",
       "  ['home',\n",
       "   'value',\n",
       "   'stop',\n",
       "   'rise',\n",
       "   'recession',\n",
       "   'hit',\n",
       "   'come',\n",
       "   'time',\n",
       "   'joe',\n",
       "   'refinance',\n",
       "   'default',\n",
       "   'occur',\n",
       "   'much',\n",
       "   'high',\n",
       "   'rate',\n",
       "   'project',\n",
       "   'cdo',\n",
       "   'many',\n",
       "   'tranche',\n",
       "   'underlie',\n",
       "   'bond',\n",
       "   'become',\n",
       "   'worthless'],\n",
       "  ['much', 'money', 'invest', 'bond', 'cdos', 'economy', 'could', 'ruin'],\n",
       "  ['unfortunately', 'folk', 'figure', 'go', 'happen', 'alert'],\n",
       "  ['go', 'newspaper'],\n",
       "  ['call', 'see', 'evil', 'com', 'mission'],\n",
       "  ['even', 'call'],\n",
       "  ['instead',\n",
       "   'work',\n",
       "   'golden',\n",
       "   'find',\n",
       "   'new',\n",
       "   'way_make',\n",
       "   'even',\n",
       "   'money',\n",
       "   'bet',\n",
       "   'cdo',\n",
       "   'market'],\n",
       "  ['think',\n",
       "   'stock',\n",
       "   'go',\n",
       "   'decline',\n",
       "   'profit',\n",
       "   'decline',\n",
       "   'bor',\n",
       "   'row',\n",
       "   'stock',\n",
       "   'selling'],\n",
       "  ['stock', 'decline', 'value', 'buy', 'return', 'person', 'lend'],\n",
       "  ['profit', 'decline', 'price'],\n",
       "  ['process', 'call', 'short', 'stock'],\n",
       "  ['hedge_fund', 'want', 'short', 'cdos'],\n",
       "  ['unfortunately', 'establish', 'way', 'borrow', 'tranche', 'cdo'],\n",
       "  ['always',\n",
       "   'look',\n",
       "   'new',\n",
       "   'way_make',\n",
       "   'money',\n",
       "   'investment',\n",
       "   'house',\n",
       "   'come',\n",
       "   'even',\n",
       "   'big',\n",
       "   'whopper',\n",
       "   'know',\n",
       "   'suppose',\n",
       "   'go',\n",
       "   'way',\n",
       "   'joe',\n",
       "   'suppose',\n",
       "   'approach',\n",
       "   'loan',\n",
       "   'company',\n",
       "   'extraordinary',\n",
       "   'time'],\n",
       "  ['cdo', 'invent', 'credit', 'default', 'swap'],\n",
       "  ['idea',\n",
       "   'credit',\n",
       "   'default',\n",
       "   'swap',\n",
       "   'provide',\n",
       "   'kind',\n",
       "   'insurance',\n",
       "   'event',\n",
       "   'bond',\n",
       "   'cdo',\n",
       "   'suffer',\n",
       "   'certain',\n",
       "   'number',\n",
       "   'default'],\n",
       "  ['hedge_fund',\n",
       "   'believe',\n",
       "   'cdo',\n",
       "   'go',\n",
       "   'lot',\n",
       "   'default',\n",
       "   'want',\n",
       "   'buy',\n",
       "   'insurance'],\n",
       "  ['trick', 'find', 'dumb', 'enough', 'sell', 'insurance'],\n",
       "  ['world',\n",
       "   'large',\n",
       "   'insurance',\n",
       "   'company',\n",
       "   'awful',\n",
       "   'insurance',\n",
       "   'group',\n",
       "   'aig',\n",
       "   'enter',\n",
       "   'fray'],\n",
       "  ['aig',\n",
       "   'sell',\n",
       "   'insurance',\n",
       "   'look',\n",
       "   'new',\n",
       "   'way_make',\n",
       "   'money',\n",
       "   'sell',\n",
       "   'insurance',\n",
       "   'cdo',\n",
       "   'default',\n",
       "   'golden',\n",
       "   'new',\n",
       "   'business',\n",
       "   'buy',\n",
       "   'cdo',\n",
       "   'insurance',\n",
       "   'aig',\n",
       "   'astonishingly',\n",
       "   'low',\n",
       "   'price',\n",
       "   'annually',\n",
       "   'cdo',\n",
       "   'value',\n",
       "   'sell',\n",
       "   'hedge_fund',\n",
       "   'much',\n",
       "   'high',\n",
       "   'price',\n",
       "   'annually',\n",
       "   'cdo',\n",
       "   'value'],\n",
       "  ['cdo',\n",
       "   'sustains',\n",
       "   'defaults',\n",
       "   'aig',\n",
       "   'need',\n",
       "   'pay',\n",
       "   'value',\n",
       "   'hypothetical',\n",
       "   'example',\n",
       "   'hedge_fund',\n",
       "   'insurance'],\n",
       "  ['time',\n",
       "   'hedge_fund',\n",
       "   'pay',\n",
       "   'annual',\n",
       "   'fee',\n",
       "   'insurance',\n",
       "   'pocket',\n",
       "   'golden'],\n",
       "  ['great', 'business', 'golden', 'pocket', 'money', 'aig', 'take', 'risk'],\n",
       "  ['risk', 'golden', 'aig', 'go', 'aig', 'big', 'fail'],\n",
       "  ['golden',\n",
       "   'new',\n",
       "   'credit',\n",
       "   'default',\n",
       "   'swap',\n",
       "   'business',\n",
       "   'even_well',\n",
       "   'cdo',\n",
       "   'business'],\n",
       "  ['trouble', 'many', 'joe', 'take', 'subprime_loan'],\n",
       "  ['mean', 'hard', 'limit', 'many', 'billion', 'make'],\n",
       "  ['challenge', 'lead', 'whopper', 'number'],\n",
       "  ['hedge_fund',\n",
       "   'want',\n",
       "   'buy',\n",
       "   'insurance',\n",
       "   'aig',\n",
       "   'want',\n",
       "   'sell',\n",
       "   'really',\n",
       "   'care',\n",
       "   'insurance',\n",
       "   'policy',\n",
       "   'loan',\n",
       "   'cdo',\n",
       "   'indeed',\n",
       "   'sell',\n",
       "   'lot',\n",
       "   'credit',\n",
       "   'default',\n",
       "   'swap',\n",
       "   'set',\n",
       "   'junk',\n",
       "   'cdos',\n",
       "   'way',\n",
       "   'profit',\n",
       "   'could',\n",
       "   'unlimited',\n",
       "   'go'],\n",
       "  ['synthetic',\n",
       "   'cdo',\n",
       "   'create',\n",
       "   'soon',\n",
       "   'insurance',\n",
       "   'quickly',\n",
       "   'turn',\n",
       "   'high',\n",
       "   'stake',\n",
       "   'stupid',\n",
       "   'least',\n",
       "   'aig',\n",
       "   'bet'],\n",
       "  ['odd',\n",
       "   'weight',\n",
       "   'heavily',\n",
       "   'favor',\n",
       "   'folk',\n",
       "   'math',\n",
       "   'homework',\n",
       "   'hedge_fund',\n",
       "   'hedge_fund',\n",
       "   'figure',\n",
       "   'failure',\n",
       "   'cdos',\n",
       "   'virtual',\n",
       "   'certainty',\n",
       "   'aig',\n",
       "   'believe',\n",
       "   'failure',\n",
       "   'virtually',\n",
       "   'impossible'],\n",
       "  ['course', 'know', 'story', 'end'],\n",
       "  ['holder',\n",
       "   'cdos',\n",
       "   'sub',\n",
       "   'prime',\n",
       "   'debt',\n",
       "   'seller',\n",
       "   'insurance',\n",
       "   'get',\n",
       "   'wipe',\n",
       "   'lose',\n",
       "   'hundred',\n",
       "   'billion',\n",
       "   'dollar'],\n",
       "  ['many',\n",
       "   'folk',\n",
       "   'deem',\n",
       "   'government',\n",
       "   'big',\n",
       "   'fail',\n",
       "   'bail',\n",
       "   'use',\n",
       "   'nearly',\n",
       "   'dollar',\n",
       "   'taxpayer',\n",
       "   'money'],\n",
       "  ['executive',\n",
       "   'preside',\n",
       "   'disaster',\n",
       "   'give',\n",
       "   'huge',\n",
       "   'bonus',\n",
       "   'well',\n",
       "   'work',\n",
       "   'executive',\n",
       "   'land',\n",
       "   'far',\n",
       "   'far',\n",
       "   'away'],\n",
       "  ['story',\n",
       "   'also',\n",
       "   'end',\n",
       "   'well',\n",
       "   'hedge_fund',\n",
       "   'buy',\n",
       "   'insurance',\n",
       "   'make',\n",
       "   'many',\n",
       "   'many',\n",
       "   'billion',\n",
       "   'dollar'],\n",
       "  ['involve', 'disaster', 'end', 'rich'],\n",
       "  ['joe', 'chapter_deviation', 'course'],\n",
       "  ['joe', 'get', 'kick', 'home', 'lose', 'job', 'recession'],\n",
       "  ['bad', 'joe', 'fairy', 'tale']],\n",
       " [['random_walk',\n",
       "   'random_walk',\n",
       "   'use',\n",
       "   'model',\n",
       "   'situation',\n",
       "   'object',\n",
       "   'move',\n",
       "   'sequence',\n",
       "   'step',\n",
       "   'randomly',\n",
       "   'choose',\n",
       "   'direction'],\n",
       "  ['many',\n",
       "   'phenomenon',\n",
       "   'model',\n",
       "   'random_walk',\n",
       "   'see',\n",
       "   'several',\n",
       "   'example',\n",
       "   'chapter'],\n",
       "  ['thing',\n",
       "   'see',\n",
       "   'rare',\n",
       "   'leave',\n",
       "   'casino',\n",
       "   'money',\n",
       "   'enter',\n",
       "   'see',\n",
       "   'google',\n",
       "   'search',\n",
       "   'engine',\n",
       "   'use',\n",
       "   'random_walk',\n",
       "   'graph',\n",
       "   'world',\n",
       "   'wide',\n",
       "   'web',\n",
       "   'link',\n",
       "   'determine',\n",
       "   'relative',\n",
       "   'importance',\n",
       "   'website']],\n",
       " [['unbiased', 'random_walk']],\n",
       " [['bug', 'life', 'small', 'flea', 'name', 'stencil'],\n",
       "  ['endless', 'flat', 'plateau'],\n",
       "  ['inch_leave',\n",
       "   'cliff_doom',\n",
       "   'drop',\n",
       "   'rage',\n",
       "   'sea',\n",
       "   'fill',\n",
       "   'flea',\n",
       "   'eat',\n",
       "   'monster'],\n",
       "  ['inch',\n",
       "   'cliff_doom',\n",
       "   'second',\n",
       "   'stencil',\n",
       "   'hop',\n",
       "   'inch',\n",
       "   'right',\n",
       "   'inch_leave',\n",
       "   'equal',\n",
       "   'probability',\n",
       "   'independent',\n",
       "   'direction',\n",
       "   'previous',\n",
       "   'hop'],\n",
       "  ['ever', 'land', 'edge', 'cliff', 'teeter', 'fall', 'sea'],\n",
       "  ['example', 'stencil', 'first_hop', 'leave', 'fishbait'],\n",
       "  ['hand',\n",
       "   'first_hop',\n",
       "   'right',\n",
       "   'may',\n",
       "   'bounce',\n",
       "   'happily',\n",
       "   'plateau',\n",
       "   'quite',\n",
       "   'chapter_random',\n",
       "   'walk',\n",
       "   'oop'],\n",
       "  ['time'],\n",
       "  ['job', 'analyze', 'life', 'stencil'],\n",
       "  ['chance',\n",
       "   'avoid',\n",
       "   'fatal',\n",
       "   'plunge',\n",
       "   'long',\n",
       "   'hop',\n",
       "   'take',\n",
       "   'plunge',\n",
       "   'stencil',\n",
       "   'movement',\n",
       "   'example',\n",
       "   'random_walk'],\n",
       "  ['typical',\n",
       "   'dimensional',\n",
       "   'random_walk',\n",
       "   'involve',\n",
       "   'value',\n",
       "   'randomly',\n",
       "   'waver',\n",
       "   'time'],\n",
       "  ['walk', 'say', 'unbiased', 'value', 'equally_likely', 'move'],\n",
       "  ['walk',\n",
       "   'end',\n",
       "   'certain',\n",
       "   'value',\n",
       "   'reach',\n",
       "   'value',\n",
       "   'call',\n",
       "   'boundary_condition',\n",
       "   'absorbing',\n",
       "   'barrier'],\n",
       "  ['example', 'cliff_doom', 'boundary_condition', 'example'],\n",
       "  ['many', 'natural', 'phenomenon', 'nicely', 'model', 'random_walk'],\n",
       "  ['however',\n",
       "   'reason',\n",
       "   'traditionally',\n",
       "   'discuss',\n",
       "   'context',\n",
       "   'social',\n",
       "   'vice'],\n",
       "  ['example',\n",
       "   'value',\n",
       "   'often',\n",
       "   'regard',\n",
       "   'position',\n",
       "   'randomly',\n",
       "   'stagger',\n",
       "   'leave',\n",
       "   'stagger',\n",
       "   'right',\n",
       "   'wobbles',\n",
       "   'place',\n",
       "   'time',\n",
       "   'step'],\n",
       "  ['value', 'wealth', 'gambler', 'continually', 'win', 'lose', 'bet'],\n",
       "  ['discuss',\n",
       "   'random_walk',\n",
       "   'term',\n",
       "   'flea',\n",
       "   'actually',\n",
       "   'sort',\n",
       "   'elevate',\n",
       "   'discourse']],\n",
       " [['simple', 'problem', 'let', 'begin', 'simple', 'problem'],\n",
       "  ['suppose',\n",
       "   'stencil',\n",
       "   'small',\n",
       "   'island',\n",
       "   'cliff_doom',\n",
       "   'inch_leave',\n",
       "   'also',\n",
       "   'boundary_condition',\n",
       "   'pit_disaster',\n",
       "   'inch',\n",
       "   'right',\n",
       "   'example',\n",
       "   'see_figure',\n",
       "   'figure',\n",
       "   'work',\n",
       "   'tree_diagram',\n",
       "   'stencil',\n",
       "   'possible',\n",
       "   'fate'],\n",
       "  ['figure'],\n",
       "  ['unbiased', 'dimensional', 'random_walk', 'absorb', 'barrier', 'position'],\n",
       "  ['walk', 'begin', 'position'],\n",
       "  ['tree_diagram', 'show', 'probability', 'hit', 'barrier'],\n",
       "  ['particular',\n",
       "   'fall',\n",
       "   'cliff_doom',\n",
       "   'leave_side',\n",
       "   'probability',\n",
       "   'similarly',\n",
       "   'fall',\n",
       "   'pit_disaster',\n",
       "   'right_side',\n",
       "   'probability',\n",
       "   'remain',\n",
       "   'possibility',\n",
       "   'stencil',\n",
       "   'could',\n",
       "   'hop',\n",
       "   'back',\n",
       "   'forth',\n",
       "   'middle',\n",
       "   'island',\n",
       "   'forever'],\n",
       "  ['however',\n",
       "   'already',\n",
       "   'identify',\n",
       "   'disjoint',\n",
       "   'event',\n",
       "   'probabilitie',\n",
       "   'happy',\n",
       "   'alternative',\n",
       "   'must',\n",
       "   'probability']],\n",
       " [['big', 'island', 'put', 'stencil', 'tiny', 'island', 'sort', 'cruel'],\n",
       "  ['probably',\n",
       "   'carry',\n",
       "   'bubonic',\n",
       "   'plague',\n",
       "   'reason',\n",
       "   'pick',\n",
       "   'little',\n",
       "   'fella'],\n",
       "  ['suppose',\n",
       "   'instead',\n",
       "   'place',\n",
       "   'inch_leave',\n",
       "   'side',\n",
       "   'island',\n",
       "   'inch',\n",
       "   'chapter_random',\n",
       "   'walks',\n",
       "   'words',\n",
       "   'stencil',\n",
       "   'start',\n",
       "   'position',\n",
       "   'random_walk',\n",
       "   'end',\n",
       "   'ever',\n",
       "   'reach',\n",
       "   'position'],\n",
       "  ['possible',\n",
       "   'fate',\n",
       "   'could',\n",
       "   'fall',\n",
       "   'cliff_doom',\n",
       "   'fall',\n",
       "   'pit_disaster',\n",
       "   'hop',\n",
       "   'island',\n",
       "   'forever'],\n",
       "  ['could',\n",
       "   'compute_probability',\n",
       "   'event',\n",
       "   'horrific',\n",
       "   'summation',\n",
       "   'fortunately',\n",
       "   'far',\n",
       "   'easy',\n",
       "   'method',\n",
       "   'use',\n",
       "   'linear_recurrence'],\n",
       "  ['let',\n",
       "   'suppose',\n",
       "   'frolic',\n",
       "   'friend',\n",
       "   'start',\n",
       "   'somewhere',\n",
       "   'middle',\n",
       "   'island'],\n",
       "  ['break',\n",
       "   'analysis',\n",
       "   'fate',\n",
       "   'case',\n",
       "   'base',\n",
       "   'direction',\n",
       "   'first_hop',\n",
       "   'first_hop',\n",
       "   'leave',\n",
       "   'land',\n",
       "   'position',\n",
       "   'eventually',\n",
       "   'fall',\n",
       "   'pit_disaster',\n",
       "   'probability',\n",
       "   'hand',\n",
       "   'first_hop',\n",
       "   'right',\n",
       "   'lands',\n",
       "   'position',\n",
       "   'nc',\n",
       "   'eventually',\n",
       "   'fall',\n",
       "   'pit_disaster',\n",
       "   'probability',\n",
       "   'nc',\n",
       "   'therefore',\n",
       "   'total',\n",
       "   'probability',\n",
       "   'theorem',\n",
       "   'solve_recurrence',\n",
       "   'let',\n",
       "   'assemble',\n",
       "   'observation',\n",
       "   'linear_recurrence',\n",
       "   'know',\n",
       "   'solve',\n",
       "   'right',\n",
       "   'remember',\n",
       "   'chapter',\n",
       "   'chapter',\n",
       "   'unusual',\n",
       "   'complication',\n",
       "   'normal',\n",
       "   'recurrence',\n",
       "   'nc_nc',\n",
       "   'back',\n",
       "   'familiar',\n",
       "   'territory'],\n",
       "  ['let', 'solve_recurrence'],\n",
       "  ['characteristic_equation', 'equation', 'double', 'root'],\n",
       "  ['inhomogeneous',\n",
       "   'part',\n",
       "   'general_solution',\n",
       "   'form',\n",
       "   'substitute',\n",
       "   'boundary_condition',\n",
       "   'solution',\n",
       "   'system'],\n",
       "  ['therefore', 'solution_recurrence']],\n",
       " [['death',\n",
       "   'certain',\n",
       "   'analysis',\n",
       "   'show',\n",
       "   'place',\n",
       "   'stencil',\n",
       "   'inch_leave',\n",
       "   'side',\n",
       "   'island',\n",
       "   'inch',\n",
       "   'fall',\n",
       "   'right_side',\n",
       "   'probability'],\n",
       "  ['example',\n",
       "   'stencil',\n",
       "   'inch_leave',\n",
       "   'side',\n",
       "   'island',\n",
       "   'inch',\n",
       "   'fall',\n",
       "   'right_side',\n",
       "   'probability'],\n",
       "  ['compute_probability',\n",
       "   'fall',\n",
       "   'leave_side',\n",
       "   'exploit',\n",
       "   'symmetry',\n",
       "   'problem',\n",
       "   'probability',\n",
       "   'fall',\n",
       "   'leave_side',\n",
       "   'start',\n",
       "   'position',\n",
       "   'probability',\n",
       "   'fall',\n",
       "   'right_side',\n",
       "   'start',\n",
       "   'position'],\n",
       "  ['bad_news'],\n",
       "  ['probability',\n",
       "   'stencil',\n",
       "   'eventually',\n",
       "   'fall',\n",
       "   'side',\n",
       "   'chapter_random',\n",
       "   'walks',\n",
       "   'hope',\n",
       "   'probability',\n",
       "   'stencil',\n",
       "   'hop',\n",
       "   'island',\n",
       "   'forever'],\n",
       "  ['even', 'bad_news'],\n",
       "  ['let',\n",
       "   'go_back',\n",
       "   'original',\n",
       "   'problem',\n",
       "   'sten',\n",
       "   'cil',\n",
       "   'inch_leave',\n",
       "   'edge',\n",
       "   'infinite',\n",
       "   'plateau'],\n",
       "  ['case',\n",
       "   'probability',\n",
       "   'eventually',\n",
       "   'fall',\n",
       "   'sea',\n",
       "   'even',\n",
       "   'pit_disaster',\n",
       "   'stencil',\n",
       "   'still',\n",
       "   'fall',\n",
       "   'cliff_doom',\n",
       "   'probability'],\n",
       "  ['finite', 'true', 'matter', 'stencil', 'start'],\n",
       "  ['little',\n",
       "   'friend',\n",
       "   'doom',\n",
       "   'know',\n",
       "   'movie',\n",
       "   'often',\n",
       "   'make',\n",
       "   'look',\n",
       "   'hero',\n",
       "   'die',\n",
       "   'come',\n",
       "   'back',\n",
       "   'end',\n",
       "   'turn',\n",
       "   'sayin',\n",
       "   'point']],\n",
       " [['life',\n",
       "   'expectancy',\n",
       "   'bright',\n",
       "   'side',\n",
       "   'stencil',\n",
       "   'may',\n",
       "   'hop',\n",
       "   'around',\n",
       "   'go',\n",
       "   'edge'],\n",
       "  ['let',\n",
       "   'use',\n",
       "   'setup',\n",
       "   'start',\n",
       "   'inch_leave',\n",
       "   'side',\n",
       "   'island',\n",
       "   'inch',\n",
       "   'expect_number',\n",
       "   'hop',\n",
       "   'take',\n",
       "   'fall',\n",
       "   'edge',\n",
       "   'let',\n",
       "   'start',\n",
       "   'somewhere',\n",
       "   'middle',\n",
       "   'island',\n",
       "   'break',\n",
       "   'analysis',\n",
       "   'case',\n",
       "   'base',\n",
       "   'first_hop'],\n",
       "  ['unbiased',\n",
       "   'random_walk',\n",
       "   'first_hop',\n",
       "   'leave',\n",
       "   'land',\n",
       "   'position',\n",
       "   'expect',\n",
       "   'live',\n",
       "   'step'],\n",
       "  ['first_hop',\n",
       "   'right',\n",
       "   'land',\n",
       "   'position',\n",
       "   'expect',\n",
       "   'live',\n",
       "   'nc',\n",
       "   'thus',\n",
       "   'law_total',\n",
       "   'expectation',\n",
       "   'linearity_expectation',\n",
       "   'stencil',\n",
       "   'ex',\n",
       "   'pecte',\n",
       "   'lifespan',\n",
       "   'leading',\n",
       "   'account',\n",
       "   'first_hop'],\n",
       "  ['solve_recurrence',\n",
       "   'nc',\n",
       "   'stencil',\n",
       "   'fate',\n",
       "   'hinges',\n",
       "   'recurrence_equation',\n",
       "   'rewrite',\n",
       "   'last',\n",
       "   'line',\n",
       "   'characteristic_equation',\n",
       "   'double',\n",
       "   'root',\n",
       "   'homogeneous_solution',\n",
       "   'form',\n",
       "   'time',\n",
       "   'inhomogeneous',\n",
       "   'term',\n",
       "   'also',\n",
       "   'need',\n",
       "   'find',\n",
       "   'particular_solution'],\n",
       "  ['term',\n",
       "   'constant',\n",
       "   'try',\n",
       "   'particular_solution',\n",
       "   'form',\n",
       "   'give',\n",
       "   'particular_solution'],\n",
       "  ['simplicity', 'let', 'take'],\n",
       "  ['thus',\n",
       "   'particular_solution',\n",
       "   'stencil',\n",
       "   'certain',\n",
       "   'eventually',\n",
       "   'fall',\n",
       "   'cliff_doom',\n",
       "   'expect',\n",
       "   'lifespan',\n",
       "   'infinite',\n",
       "   'sound',\n",
       "   'almost',\n",
       "   'contradiction',\n",
       "   'answer',\n",
       "   'correct',\n",
       "   'informal',\n",
       "   'explanation'],\n",
       "  ['turn',\n",
       "   'probability',\n",
       "   'integration',\n",
       "   'bind',\n",
       "   'hand',\n",
       "   'expect',\n",
       "   'time',\n",
       "   'stencil',\n",
       "   'fall',\n",
       "   'edge',\n",
       "   'constant',\n",
       "   'come',\n",
       "   'notation'],\n",
       "  ['answer', 'compati', 'ble']],\n",
       " [['application',\n",
       "   'fair',\n",
       "   'gambling_game',\n",
       "   'take',\n",
       "   'high',\n",
       "   'road',\n",
       "   'let',\n",
       "   'discuss',\n",
       "   'random_walk',\n",
       "   'conventional',\n",
       "   'setting',\n",
       "   'gambling'],\n",
       "  ['gambler', 'go', 'las', 'vegas', 'pocket'],\n",
       "  ['plan',\n",
       "   'make',\n",
       "   'bet',\n",
       "   'somehow',\n",
       "   'find',\n",
       "   'casino',\n",
       "   'offer',\n",
       "   'truly',\n",
       "   'even',\n",
       "   'odd',\n",
       "   'dollar'],\n",
       "  ['probability', 'go_home_winner', 'identical', 'flea', 'problem', 'analyze'],\n",
       "  ['go', 'broke', 'analo', 'gous', 'fall', 'cliff_doom'],\n",
       "  ['go_home_winner', 'analogous', 'fall', 'pit_disaster', 'lot', 'fun'],\n",
       "  ['analysis',\n",
       "   'stencil',\n",
       "   'life',\n",
       "   'tell',\n",
       "   'want',\n",
       "   'know',\n",
       "   'gam',\n",
       "   'bler',\n",
       "   'prospects',\n",
       "   'gambler',\n",
       "   'go_home',\n",
       "   'break',\n",
       "   'probability',\n",
       "   'gambler',\n",
       "   'go_home_winner',\n",
       "   'probability',\n",
       "   'gambler',\n",
       "   'go_home',\n",
       "   'probability',\n",
       "   'number',\n",
       "   'bet',\n",
       "   'gambler',\n",
       "   'go_home',\n",
       "   'expect'],\n",
       "  ['nm',\n",
       "   'gambler',\n",
       "   'get',\n",
       "   'greedy',\n",
       "   'keep',\n",
       "   'play',\n",
       "   'go',\n",
       "   'break',\n",
       "   'gambler',\n",
       "   'eventually',\n",
       "   'go',\n",
       "   'broke',\n",
       "   'probability',\n",
       "   'number',\n",
       "   'bet',\n",
       "   'gambler',\n",
       "   'go',\n",
       "   'break',\n",
       "   'expect',\n",
       "   'infinite'],\n",
       "  ['bottom',\n",
       "   'line',\n",
       "   'clear',\n",
       "   'gambling',\n",
       "   'quit',\n",
       "   'ahead',\n",
       "   'play',\n",
       "   'go',\n",
       "   'break',\n",
       "   'certainly',\n",
       "   'go',\n",
       "   'broke'],\n",
       "  ['good_news', 'matter', 'get', 'much', 'bad', 'typical', 'scenario', 'odd'],\n",
       "  ['let_see'],\n",
       "  ['worry',\n",
       "   'realistic',\n",
       "   'scenario',\n",
       "   'likely',\n",
       "   'lose',\n",
       "   'win',\n",
       "   'moment',\n",
       "   'let',\n",
       "   'fantasize',\n",
       "   'fair',\n",
       "   'scenario',\n",
       "   'bit'],\n",
       "  ['chapter_random', 'walk']],\n",
       " [['gambler',\n",
       "   'ruin',\n",
       "   'far',\n",
       "   'consider',\n",
       "   'unbiased',\n",
       "   'random_walk',\n",
       "   'probability',\n",
       "   'mov',\n",
       "   'ing',\n",
       "   'leave_right'],\n",
       "  ['unfortunately',\n",
       "   'thing',\n",
       "   'never',\n",
       "   'quite',\n",
       "   'simple',\n",
       "   'fair',\n",
       "   'real',\n",
       "   'casino'],\n",
       "  ['example_suppose',\n",
       "   'gambler',\n",
       "   'go',\n",
       "   'las',\n",
       "   'vegas',\n",
       "   'make',\n",
       "   'bet',\n",
       "   'red',\n",
       "   'black',\n",
       "   'roulette'],\n",
       "  ['case',\n",
       "   'win_probability',\n",
       "   'lose',\n",
       "   'probability',\n",
       "   'casino',\n",
       "   'add',\n",
       "   'bothersome',\n",
       "   'green',\n",
       "   'give',\n",
       "   'house',\n",
       "   'slight',\n",
       "   'advantage'],\n",
       "  ['first',\n",
       "   'glance',\n",
       "   'drink',\n",
       "   'seem',\n",
       "   'awfully',\n",
       "   'close',\n",
       "   'intuition',\n",
       "   'tell',\n",
       "   'game',\n",
       "   'almost',\n",
       "   'fair'],\n",
       "  ['may',\n",
       "   'expect',\n",
       "   'analysis',\n",
       "   'fair_game',\n",
       "   'almost',\n",
       "   'right',\n",
       "   'real',\n",
       "   'game'],\n",
       "  ['example',\n",
       "   'gambler_start',\n",
       "   'quit',\n",
       "   'get',\n",
       "   'ahead',\n",
       "   'fair_game',\n",
       "   'go_home_winner',\n",
       "   'probability',\n",
       "   'want',\n",
       "   'improve',\n",
       "   'chance',\n",
       "   'go_home_winner',\n",
       "   'could',\n",
       "   'bring',\n",
       "   'money'],\n",
       "  ['bring',\n",
       "   'quit',\n",
       "   'get',\n",
       "   'ahead',\n",
       "   'fair_game',\n",
       "   'go_home_winner',\n",
       "   'probability',\n",
       "   'give',\n",
       "   'real',\n",
       "   'game',\n",
       "   'almost',\n",
       "   'fair',\n",
       "   'may',\n",
       "   'expect',\n",
       "   'probability',\n",
       "   'go_home_winner',\n",
       "   'scenario',\n",
       "   'almost',\n",
       "   'respec',\n",
       "   'tively'],\n",
       "  ['unfortunately',\n",
       "   'gambler',\n",
       "   'almost',\n",
       "   'reason',\n",
       "   'almost',\n",
       "   'surely',\n",
       "   'lead',\n",
       "   'disaster'],\n",
       "  ['grim', 'fact', 'real', 'game', 'gambler', 'win_probability'],\n",
       "  ['low',\n",
       "   'end',\n",
       "   'amount',\n",
       "   'money',\n",
       "   'bring',\n",
       "   'make',\n",
       "   'almost',\n",
       "   'difference',\n",
       "   'almost',\n",
       "   'certain',\n",
       "   'go',\n",
       "   'broke',\n",
       "   'win'],\n",
       "  ['let_see']],\n",
       " [['find',\n",
       "   'recurrence',\n",
       "   'approach',\n",
       "   'gambling',\n",
       "   'problem',\n",
       "   'way',\n",
       "   'study',\n",
       "   'life',\n",
       "   'stencil'],\n",
       "  ['suppose', 'gambler_start', 'dollar'],\n",
       "  ['win', 'bet', 'probability', 'play', 'go', 'bankrupt', 'dollar', 'pocket'],\n",
       "  ['clear',\n",
       "   'total',\n",
       "   'amount',\n",
       "   'money',\n",
       "   'want',\n",
       "   'end',\n",
       "   'amount',\n",
       "   'want',\n",
       "   'increase',\n",
       "   'wealth'],\n",
       "  ['objective', 'compute', 'usual', 'begin', 'identify', 'boundary_condition'],\n",
       "  ['start',\n",
       "   'money',\n",
       "   'bankrupt',\n",
       "   'immediately',\n",
       "   'divide',\n",
       "   'analysis',\n",
       "   'general',\n",
       "   'situation',\n",
       "   'case',\n",
       "   'base',\n",
       "   'outcome',\n",
       "   'first',\n",
       "   'bet',\n",
       "   'win_first',\n",
       "   'bet',\n",
       "   'probability'],\n",
       "  ['dollars', 'probability', 'nc', 'lose', 'first', 'bet', 'probability'],\n",
       "  ['leave',\n",
       "   'dollar',\n",
       "   'probability',\n",
       "   'plugging',\n",
       "   'fact',\n",
       "   'total',\n",
       "   'probability',\n",
       "   'theorem',\n",
       "   'give',\n",
       "   'equation']],\n",
       " [['solve_recurrence',\n",
       "   'rearranging',\n",
       "   'term',\n",
       "   'equation',\n",
       "   'give',\n",
       "   'recurrence',\n",
       "   'pr',\n",
       "   'nc',\n",
       "   'characteristic_equation',\n",
       "   'px',\n",
       "   'fact',\n",
       "   'digit',\n",
       "   'change',\n",
       "   'first',\n",
       "   'case',\n",
       "   'second',\n",
       "   'peripheral',\n",
       "   'bit',\n",
       "   'bizarreness',\n",
       "   'leave_hand'],\n",
       "  ['chapter_random',\n",
       "   'walk',\n",
       "   'quadratic',\n",
       "   'formula',\n",
       "   'give',\n",
       "   'root',\n",
       "   'important',\n",
       "   'point',\n",
       "   'lurk'],\n",
       "  ['gambler',\n",
       "   'equally_likely',\n",
       "   'win',\n",
       "   'lose',\n",
       "   'bet',\n",
       "   'characteristic_equation',\n",
       "   'double',\n",
       "   'root'],\n",
       "  ['situation', 'consider', 'flea', 'problem'],\n",
       "  ['double',\n",
       "   'root',\n",
       "   'lead',\n",
       "   'general_solution',\n",
       "   'form',\n",
       "   'suppose',\n",
       "   'gambler',\n",
       "   'equally_likely',\n",
       "   'win',\n",
       "   'lose',\n",
       "   'bet',\n",
       "   'mathematical',\n",
       "   'term',\n",
       "   'fair_game',\n",
       "   'almost',\n",
       "   'fair_game',\n",
       "   'take',\n",
       "   'completely',\n",
       "   'different',\n",
       "   'direction',\n",
       "   'case',\n",
       "   'get',\n",
       "   'linear',\n",
       "   'solution',\n",
       "   'get',\n",
       "   'exponential',\n",
       "   'solution',\n",
       "   'go',\n",
       "   'bad_news',\n",
       "   'play',\n",
       "   'almost',\n",
       "   'fair_game'],\n",
       "  ['substitute',\n",
       "   'boundary_condition',\n",
       "   'general',\n",
       "   'form',\n",
       "   'solu',\n",
       "   'tion',\n",
       "   'give',\n",
       "   'system',\n",
       "   'linear_equation',\n",
       "   'solve',\n",
       "   'system',\n",
       "   'give',\n",
       "   'substituting',\n",
       "   'value',\n",
       "   'back',\n",
       "   'general_solution',\n",
       "   'give']],\n",
       " [['bad_news', 'answer', 'good_news'],\n",
       "  ['gambler_start',\n",
       "   'dollar',\n",
       "   'win',\n",
       "   'bet',\n",
       "   'probability',\n",
       "   'probability',\n",
       "   'reach',\n",
       "   'dollar',\n",
       "   'go',\n",
       "   'break',\n",
       "   'let_try',\n",
       "   'make_sense',\n",
       "   'expression'],\n",
       "  ['game',\n",
       "   'bias',\n",
       "   'roulette',\n",
       "   'probability_lose',\n",
       "   'great',\n",
       "   'probability',\n",
       "   'win'],\n",
       "  ['start',\n",
       "   'wealth',\n",
       "   'also',\n",
       "   'reasonably',\n",
       "   'large',\n",
       "   'exponenti',\n",
       "   'ate',\n",
       "   'fraction',\n",
       "   'big',\n",
       "   'number',\n",
       "   'make',\n",
       "   'much',\n",
       "   'difference'],\n",
       "  ['thus',\n",
       "   'probability',\n",
       "   'reach',\n",
       "   'dollar',\n",
       "   'close',\n",
       "   'nw',\n",
       "   'particular',\n",
       "   'hope',\n",
       "   'come',\n",
       "   'ahead',\n",
       "   'roulette',\n",
       "   'probability',\n",
       "   'success',\n",
       "   'explain',\n",
       "   'strange',\n",
       "   'number',\n",
       "   'arrive',\n",
       "   'early',\n",
       "   'fact',\n",
       "   'number',\n",
       "   'change',\n",
       "   'matter',\n",
       "   'large',\n",
       "   'get',\n",
       "   'even',\n",
       "   'gambler_start',\n",
       "   'dollar',\n",
       "   'sill',\n",
       "   'likely',\n",
       "   'ever',\n",
       "   'ahead',\n",
       "   'even']],\n",
       " [['gambler_start',\n",
       "   'wealth',\n",
       "   'little',\n",
       "   'impact',\n",
       "   'probability',\n",
       "   'come',\n",
       "   'ahead',\n",
       "   'intuitively',\n",
       "   'force',\n",
       "   'work'],\n",
       "  ['first',\n",
       "   'gambler',\n",
       "   'chapter_random',\n",
       "   'walk',\n",
       "   'wealth',\n",
       "   'random',\n",
       "   'upward',\n",
       "   'downward',\n",
       "   'swing',\n",
       "   'due',\n",
       "   'run',\n",
       "   'good',\n",
       "   'bad',\n",
       "   'luck'],\n",
       "  ['second',\n",
       "   'wealth',\n",
       "   'steady',\n",
       "   'downward',\n",
       "   'drift',\n",
       "   'small',\n",
       "   'expect',\n",
       "   'loss',\n",
       "   'bet'],\n",
       "  ['situation',\n",
       "   'illustrate_figure',\n",
       "   'upward',\n",
       "   'gambler',\n",
       "   'downward',\n",
       "   'wealth',\n",
       "   'drift',\n",
       "   'time',\n",
       "   'figure'],\n",
       "  ['biased',\n",
       "   'random_walk',\n",
       "   'downward',\n",
       "   'drift',\n",
       "   'usually',\n",
       "   'dominate',\n",
       "   'swing',\n",
       "   'good',\n",
       "   'luck'],\n",
       "  ['example',\n",
       "   'roulette',\n",
       "   'gambler',\n",
       "   'win',\n",
       "   'dollar',\n",
       "   'probability_lose',\n",
       "   'dollar',\n",
       "   'probability'],\n",
       "  ['therefore',\n",
       "   'expect_return',\n",
       "   'bet',\n",
       "   'thus',\n",
       "   'expect',\n",
       "   'wealth',\n",
       "   'drift',\n",
       "   'downward',\n",
       "   'little',\n",
       "   'cent',\n",
       "   'bet'],\n",
       "  ['may_think',\n",
       "   'gambler_start',\n",
       "   'dollar',\n",
       "   'play',\n",
       "   'long',\n",
       "   'time',\n",
       "   'point',\n",
       "   'lucky',\n",
       "   'upward',\n",
       "   'swing',\n",
       "   'put',\n",
       "   'ahead'],\n",
       "  ['problem', 'capital', 'steadily', 'drift', 'downward'],\n",
       "  ['capital', 'drift', 'dollar', 'need', 'huge', 'upward', 'swing', 'save'],\n",
       "  ['huge', 'swing', 'extremely', 'improbable'],\n",
       "  ['lucky', 'upward', 'swing', 'early', 'doom', 'forever'],\n",
       "  ['rule_thumb', 'drift', 'dominate', 'swing', 'long', 'term']],\n",
       " [['expect',\n",
       "   'play',\n",
       "   'time',\n",
       "   'even',\n",
       "   'casino',\n",
       "   'gambler',\n",
       "   'destine',\n",
       "   'lose',\n",
       "   'enjoy',\n",
       "   'process'],\n",
       "  ['let', 'figure', 'long', 'enjoyment', 'expect', 'last'],\n",
       "  ['let', 'reason', 'section', 'recurrence', 'inhomo', 'geneous', 'part'],\n",
       "  ['find',\n",
       "   'particular_solution',\n",
       "   'try',\n",
       "   'already',\n",
       "   'determine',\n",
       "   'root',\n",
       "   'equation',\n",
       "   'final',\n",
       "   'solution_recurrence',\n",
       "   'yike',\n",
       "   'gambler',\n",
       "   'fun',\n",
       "   'think',\n",
       "   'equa',\n",
       "   'tion'],\n",
       "  ['let_see', 'make', 'simple', 'case', 'large'],\n",
       "  ['large', 'much', 'simple'],\n",
       "  ['say', 'gambler_start', 'expect'],\n",
       "  ['bet', 'go_home', 'break'],\n",
       "  ['seem', 'make_sense', 'expect', 'lose'],\n",
       "  ['dollar', 'bet', 'start', 'dollar'],\n",
       "  ['careful',\n",
       "   'tempting',\n",
       "   'use',\n",
       "   'direct',\n",
       "   'simple',\n",
       "   'argument',\n",
       "   'instead',\n",
       "   'nasty',\n",
       "   'recurrence',\n",
       "   'argument',\n",
       "   'correct'],\n",
       "  ['example',\n",
       "   'expect',\n",
       "   'duration',\n",
       "   'process',\n",
       "   'close',\n",
       "   'start',\n",
       "   'point',\n",
       "   'divide',\n",
       "   'expect',\n",
       "   'decrease',\n",
       "   'step'],\n",
       "  ['figure'],\n",
       "  ['people', 'sit', 'circle'],\n",
       "  ['indicate', 'person', 'broccoli', 'case', 'person']],\n",
       " [['walk', 'circle', 'far', 'consider', 'random_walk', 'line'],\n",
       "  ['look', 'problem', 'random_walk', 'circle'],\n",
       "  ['go',\n",
       "   'line',\n",
       "   'circle',\n",
       "   'may_seem',\n",
       "   'big',\n",
       "   'change',\n",
       "   'see',\n",
       "   'often',\n",
       "   'probability',\n",
       "   'small',\n",
       "   'change',\n",
       "   'large',\n",
       "   'consequence',\n",
       "   'often',\n",
       "   'grasp',\n",
       "   'intuition']],\n",
       " [['pass', 'broccoli', 'suppose', 'people', 'number'],\n",
       "  ['sit',\n",
       "   'circle',\n",
       "   'show_figure',\n",
       "   'indicate',\n",
       "   'person',\n",
       "   'big',\n",
       "   'stalk',\n",
       "   'nutritious',\n",
       "   'broccoli',\n",
       "   'provide',\n",
       "   'recommend',\n",
       "   'daily',\n",
       "   'allowance',\n",
       "   'vitamin',\n",
       "   'also',\n",
       "   'good',\n",
       "   'source',\n",
       "   'vitamin',\n",
       "   'iron'],\n",
       "  ['typical',\n",
       "   'random_walk',\n",
       "   'problem',\n",
       "   'game',\n",
       "   'originally',\n",
       "   'involve',\n",
       "   'pitcher',\n",
       "   'beer',\n",
       "   'instead',\n",
       "   'broccoli'],\n",
       "  ['take', 'high', 'road'],\n",
       "  ['person',\n",
       "   'pass',\n",
       "   'broccoli',\n",
       "   'person',\n",
       "   'leave',\n",
       "   'person',\n",
       "   'right',\n",
       "   'equal',\n",
       "   'probability'],\n",
       "  ['person', 'also', 'pass', 'broccoli', 'leave_right', 'random'],\n",
       "  ['arc', 'circle', 'touch', 'broccoli', 'arc'],\n",
       "  ['eventually', 'arc', 'grow', 'person', 'touch', 'broccoli'],\n",
       "  ['final',\n",
       "   'person',\n",
       "   'declare',\n",
       "   'winner',\n",
       "   'avoid',\n",
       "   'brocolli',\n",
       "   'long',\n",
       "   'time'],\n",
       "  ['suppose', 'allow', 'position', 'anywhere', 'circle'],\n",
       "  ['stand',\n",
       "   'order',\n",
       "   'maximize',\n",
       "   'probability',\n",
       "   'win',\n",
       "   'person',\n",
       "   'win',\n",
       "   'position'],\n",
       "  ['answer',\n",
       "   'intuitively',\n",
       "   'obvious',\n",
       "   'sit',\n",
       "   'far',\n",
       "   'possible',\n",
       "   'person',\n",
       "   'would',\n",
       "   'position'],\n",
       "  ['depend', 'even', 'odd'],\n",
       "  ['chapter_random', 'walk']],\n",
       " [['escape', 'let_try', 'verify', 'intuition'],\n",
       "  ['suppose', 'sit', 'position'],\n",
       "  ['point', 'broccoli', 'go', 'end', 'hand', 'neighbor'],\n",
       "  ['happen', 'eventually', 'game', 'end', 'least', 'touch'],\n",
       "  ['let', 'say', 'person', 'get', 'broccoli', 'first'],\n",
       "  ['let', 'cut', 'circle', 'neighbor', 'person'],\n",
       "  ['possibility'],\n",
       "  ['broccoli', 'reach', 'reach', 'person', 'lose'],\n",
       "  ['broccoli',\n",
       "   'reach',\n",
       "   'person',\n",
       "   'reach',\n",
       "   'person',\n",
       "   'touch',\n",
       "   'broccoli',\n",
       "   'win'],\n",
       "  ['need',\n",
       "   'compute_probability',\n",
       "   'broccoli',\n",
       "   'hop',\n",
       "   'people',\n",
       "   'right',\n",
       "   'take',\n",
       "   'hop',\n",
       "   'left'],\n",
       "  ['probability', 'win'],\n",
       "  ['flea', 'problem'],\n",
       "  ['analysis', 'section', 'intuition', 'completely', 'wrong', 'matter', 'sit'],\n",
       "  ['close',\n",
       "   'broccoli',\n",
       "   'far',\n",
       "   'away',\n",
       "   'start',\n",
       "   'make',\n",
       "   'difference',\n",
       "   'escape',\n",
       "   'still',\n",
       "   'broccoli',\n",
       "   'last',\n",
       "   'probability'],\n",
       "  ['enough',\n",
       "   'bad_news',\n",
       "   'stencil',\n",
       "   'doom',\n",
       "   'go_home',\n",
       "   'broke',\n",
       "   'casino',\n",
       "   'escape',\n",
       "   'broccoli'],\n",
       "  ['let_see', 'use', 'probability', 'make_money'],\n",
       "  ['mit', 'opencourseware'],\n",
       "  ['mathematics', 'computer_science', 'fall']]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_docx(total_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
